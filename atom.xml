<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Nobody&#39;s Website</title>
  
  <subtitle>long journey with great sightings</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2023-08-05T03:14:26.389Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>sixwalter</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>linux笔记：静态库和动态库浅析</title>
    <link href="http://example.com/2023/08/05/unix-program/linux_foundations_notes/Linux%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/"/>
    <id>http://example.com/2023/08/05/unix-program/linux_foundations_notes/Linux%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/</id>
    <published>2023-08-05T03:14:26.389Z</published>
    <updated>2023-08-05T03:14:26.389Z</updated>
    
    <content type="html"><![CDATA[<h1 id="linux静态库和动态库"><a href="#linux静态库和动态库" class="headerlink" title="linux静态库和动态库"></a>linux静态库和动态库</h1><h2 id="静态库和动态库的工作原理"><a href="#静态库和动态库的工作原理" class="headerlink" title="静态库和动态库的工作原理"></a>静态库和动态库的工作原理</h2><ul><li>静态库：进行链接时，会把静态库中的代码打包到可执行文件中</li><li>动态库：进行链接时，不会把动态库中的代码打包到可执行文件中</li></ul><p>它们的区别在于链接阶段如何处理: 静态链接方式和动态链接方式</p><h2 id="静态库与动态库的优缺点"><a href="#静态库与动态库的优缺点" class="headerlink" title="静态库与动态库的优缺点"></a>静态库与动态库的优缺点</h2><table><thead><tr><th>链接方式</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>静态库</td><td>加载速度快,无需提供静态库,移植方便</td><td>占多份内存,消耗系统资源,浪费内存,更新发布部署麻烦</td></tr><tr><td>动态库</td><td>进程间资源共享,更新,部署,发布简单</td><td>加载慢,需要提供动态库</td></tr></tbody></table><h2 id="静态库的制作和使用"><a href="#静态库的制作和使用" class="headerlink" title="静态库的制作和使用"></a>静态库的制作和使用</h2><ul><li><p>当前的目录结构如下：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206061732768.png" alt="image-20220606173223714" style="zoom:50%;"></li><li><p>首先到源代码目录进行编译和汇编得到目标文件，但不进行连接：</p></li></ul><p><code>gcc -c *.c -I ../include/</code></p><ul><li>制作静态库libxxx.a:</li></ul><p><code>ar rcs libcalc.a *.o</code>并移到lib目录下</p><p>注意：需提供静态库.a文件以及头文件，才可以成功对main.c进行编译</p><ul><li> 编译测试文件main.c，需指定包含<strong>头文件的路径、静态库的目录和静态库的名称</strong></li></ul><p><code>gcc main.c -o app -I ./include/ -L ./lib/ -l calc</code></p><ul><li>运行测试文件./app ，结果如图：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206061823645.png" alt="image-20220606182353621" style="zoom:50%;"><h2 id="gcc编译选项总结"><a href="#gcc编译选项总结" class="headerlink" title="gcc编译选项总结"></a>gcc编译选项总结</h2><table><thead><tr><th>gcc编译选项</th><th>说明</th></tr></thead><tbody><tr><td>-E</td><td>预处理指定的源文件，不进行编译</td></tr><tr><td>-S</td><td>编译指定的源文件，但是不进行汇编</td></tr><tr><td>-c</td><td>编译、汇编指定的源文件，但是不进行链接</td></tr><tr><td>[file2] -o [file1]</td><td>将文件 file2 编译成可执行文件 file1</td></tr><tr><td>-I directory</td><td>指定 include 包含文件的搜索目录</td></tr><tr><td>-g</td><td>在编译的时候，生成调试信息，该程序可以被调试器调试</td></tr><tr><td>-D</td><td>在程序编译的时候，指定一个宏</td></tr><tr><td>-Wall</td><td>生成所有警告信息</td></tr><tr><td>-On</td><td>n的取值范围：0~3。编译器的优化选项的4个级别</td></tr><tr><td>-l</td><td>在程序编译的时候，指定使用的库</td></tr><tr><td>-L</td><td>指定编译的时候，搜索的库的路径</td></tr><tr><td>-fPIC/fpic</td><td>生成与位置无关的代码</td></tr><tr><td>-shared</td><td>生成共享目标文件，通常用在建立共享库时</td></tr></tbody></table><h2 id="动态库的制作和使用"><a href="#动态库的制作和使用" class="headerlink" title="动态库的制作和使用"></a>动态库的制作和使用</h2><ul><li><p>命名：</p><ul><li>Linux：libxxx.so</li><li>windows：libxxx.dll</li></ul></li><li><p>动态库制作：</p><ul><li>得到和<strong>位置无关</strong>的代码 -fpic</li><li>得到动态库：gcc -shared a.o b.o -o libcalc.so</li></ul></li><li><p> 编译测试文件main.c：</p></li></ul><p><code>gcc main.c -o app -I ./include/ -L ./lib/ -l calc</code></p><ul><li>运行测试文件./app ，结果如图：</li></ul><h2 id="动态库的搜索路径"><a href="#动态库的搜索路径" class="headerlink" title="动态库的搜索路径"></a>动态库的搜索路径</h2><p>定位共享库（动态库）文件时，需要知道其绝对路径，此时就需要系统的动态载入器来获取该路径，并将其载入内存，它是通过ld-linux.so来完成的。搜索顺序如下：</p><ul><li>环境变量LD_LIBRARY_PATH</li></ul><ol><li>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:动态库所在目录；(当前会话有效)</li><li>vim ~/.bashrc 把上面的代码拷贝到最后一行；（用户级别）</li><li>vim /etc/profile 同理（系统级别）</li></ol><ul><li>/etc/ld.so.cache</li></ul><p>需要修改/etc/ld.so.conf文件, 并运行ldconfig进行更新</p><ul><li><p>/lib</p></li><li><p>/usr/lib</p><p>第三种和第四种不建议，推荐前两种配置</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;linux静态库和动态库&quot;&gt;&lt;a href=&quot;#linux静态库和动态库&quot; class=&quot;headerlink&quot; title=&quot;linux静态库和动态库&quot;&gt;&lt;/a&gt;linux静态库和动态库&lt;/h1&gt;&lt;h2 id=&quot;静态库和动态库的工作原理&quot;&gt;&lt;a href=&quot;#静</summary>
      
    
    
    
    <category term="linux" scheme="http://example.com/categories/linux/"/>
    
    
    <category term="静态库和动态库" scheme="http://example.com/tags/%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/"/>
    
    <category term="linux" scheme="http://example.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>linux笔记： Makefile基础</title>
    <link href="http://example.com/2023/08/05/unix-program/linux_foundations_notes/Makefile%E5%9F%BA%E7%A1%80/"/>
    <id>http://example.com/2023/08/05/unix-program/linux_foundations_notes/Makefile%E5%9F%BA%E7%A1%80/</id>
    <published>2023-08-05T03:14:26.389Z</published>
    <updated>2023-08-05T03:14:26.389Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Makefile基础"><a href="#Makefile基础" class="headerlink" title="Makefile基础"></a>Makefile基础</h1><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><ul><li>成百上千个源文件，按照类型，功能，模块分别放到若干个目录中，Makefile文件定义了一系列的规则来指定哪些文件需要先编译，哪些文件需要后编译</li><li>自动化编译，一旦写好就可以整个工程完全自动编译</li></ul><h2 id="使用规则"><a href="#使用规则" class="headerlink" title="使用规则"></a>使用规则</h2><ul><li><p><strong>规则</strong>：</p><ul><li><p>目标 …：依赖 …</p><p>tab    命令</p><p>​        …</p></li><li><p>目标：最终要生成的文件</p></li><li><p>依赖：生成目标所需要的文件或是目标</p></li><li><p>命令：通过执行命令对依赖操作生成目标（需添加tab缩进）</p></li></ul></li><li><p>可以有多个规则，一般来说其他规则都是<strong>为了第一个规则服务的</strong></p></li><li><p>命令在执行之前，会先<strong>检查依赖</strong>：</p><ul><li>若依赖存在，直接执行命令；</li><li>若不存在，看之后的规则能否生成当前规则所需的依赖，若能即正常执行；若不能则报错</li></ul></li><li><p><strong>检测更新</strong>，在执行规则中的命令时，会比较目标和依赖文件的时间，<strong>不做不必要的工作</strong></p><ul><li>若依赖的时间比目标的时间晚，则会重新生成目录；</li><li>否则不需要更新，即对应规则中的命令不执行；</li></ul></li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207121604695.png" alt="image-20220712160431625" style="zoom:50%;"><ul><li>一般来说，写的越详细，效率越高（检测更新）：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207121607583.png" alt="image-20220712160746521" style="zoom:50%;"><ul><li><p>但是上面的写得特别繁琐，可以用变量改进</p></li><li><p>变量：</p><ul><li>自定义变量</li><li>预定义变量<ul><li>CC：C编译器的名称</li><li>$@：目标的完整名称</li><li>$&lt;：所有的依赖文件名称</li><li>$^：第一个依赖文件名称</li></ul></li><li>获取变量值：$(变量名)</li></ul></li><li><p>模式匹配：</p></li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207121620059.png" alt="image-20220712162046026" style="zoom:50%;"><ul><li><p>函数：</p><ul><li><p>$(wildcard PATTERN…)</p><p>功能：获取指定目录下指定类型的文件列表</p><p>实例：<code>$(wildcard *.c ./sub/*.c)</code></p></li><li><p>$(patsubst <pattern> , <replacement>,<text>)</text></replacement></pattern></p><p>功能：进行字符串替换</p><p>实例：<code>$(patsubstr %.c ,%.o, x.c bar.c)</code></p></li></ul></li><li><p>clean规则：</p><ul><li>make clean</li><li>伪目标：.PHONY:clean 不真实地生成clean目标文件因此一定会执行</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Makefile基础&quot;&gt;&lt;a href=&quot;#Makefile基础&quot; class=&quot;headerlink&quot; title=&quot;Makefile基础&quot;&gt;&lt;/a&gt;Makefile基础&lt;/h1&gt;&lt;h2 id=&quot;思想&quot;&gt;&lt;a href=&quot;#思想&quot; class=&quot;headerli</summary>
      
    
    
    
    <category term="linux" scheme="http://example.com/categories/linux/"/>
    
    
    <category term="makefile" scheme="http://example.com/tags/makefile/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/unix-program/apue_notes/chapt1_unix%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://example.com/2023/08/05/unix-program/apue_notes/chapt1_unix%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="chapter-1-unix基础知识"><a href="#chapter-1-unix基础知识" class="headerlink" title="chapter 1 unix基础知识"></a>chapter 1 unix基础知识</h1><h2 id="1-1-引言"><a href="#1-1-引言" class="headerlink" title="1.1 引言"></a>1.1 引言</h2><p>从程序员的角度，快速浏览UNIX。</p><h2 id="1-2-UNIX体系结构"><a href="#1-2-UNIX体系结构" class="headerlink" title="1.2 UNIX体系结构"></a>1.2 UNIX体系结构</h2><p>操作系统狭义上指的就是内核，内核的接口称为系统调用，公用函数库建立在系统调用之上。应用程序既可以使用公用函数库，也可以使用系统调用。shell是一个特殊的应用程序，为运行其他应用提供接口。</p><p>广义上讲，操作系统包含内核和一些其他软件。实际上Linux是GNU操作系统的内核，但大家普遍上称其为操作系统</p><h2 id="1-3-登录"><a href="#1-3-登录" class="headerlink" title="1.3 登录"></a>1.3 登录</h2><p>可在/etc/passwd文件中查看登录名，目前系统已经加密口令移到了另一个文件中</p><h2 id="1-4-文件和目录"><a href="#1-4-文件和目录" class="headerlink" title="1.4 文件和目录"></a>1.4 文件和目录</h2><ul><li>目录：<strong>一个包含目录项的文件</strong>。逻辑上认为每个目录项都包含一个文件名和文件属性信息。stat命令可以查看文件属性。目录项的逻辑视图与实际在磁盘上的存储是不同的。</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207151723488.png" alt="image-20220715172312460" style="zoom:50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207151720796.png" alt="image-20220715172038726" style="zoom:50%;"><ul><li>创建新目录时，会自动创建两个文件名：<code>.</code> 和 <code>..</code></li><li>列出一个目录所有文件的名字</li></ul><h2 id="1-5-输入和输出"><a href="#1-5-输入和输出" class="headerlink" title="1.5 输入和输出"></a>1.5 输入和输出</h2><ul><li>文件描述符：小的非负整数，内核用以标识特定进程正在访问的文件。当打开或是创建一个新文件时，内核都返回一个文件描述符，在读写的时候可以使用它</li><li>标准输入，标准输出和标准错误：每当运行一个新程序时，shell都会默认为其打开3个文件描述符，即标准输入，标准输出和标准错误，若不做特殊处理，这三个文件描述符都链接向终端。</li><li>不带缓冲的IO：<ul><li>read：返回读取的字节数。到达文件尾端时，返回0；出错时，返回-1</li><li>write：返回写入的字节数<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"apue.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span>    BUFFSIZE   4096</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span></span></span><br><span class="line"><span class="function"><span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">   <span class="keyword">int</span>       n;</span><br><span class="line">   <span class="keyword">char</span>   buf[BUFFSIZE];</span><br><span class="line"></span><br><span class="line">   <span class="keyword">while</span> ((n = read(STDIN_FILENO, buf, BUFFSIZE)) &gt; <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">if</span> (write(STDOUT_FILENO, buf, n) != n)</span><br><span class="line">         err_sys(<span class="string">"write error"</span>);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (n &lt; <span class="number">0</span>)</span><br><span class="line">      err_sys(<span class="string">"read error"</span>);</span><br><span class="line"></span><br><span class="line">   <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure></li></ul></li><li>标准IO的优势：<ul><li>无需担心选取最佳的缓冲区大小</li><li>简化了对输入的处理：如fgets函数可以读入一个完整的行，而read要指定字节数</li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"apue.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span></span></span><br><span class="line"><span class="function"><span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">   <span class="keyword">int</span>       c;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">while</span> ((c = getc(<span class="built_in">stdin</span>)) != EOF)</span><br><span class="line">      <span class="keyword">if</span> (putc(c, <span class="built_in">stdout</span>) == EOF)</span><br><span class="line">         err_sys(<span class="string">"output error"</span>);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">if</span> (ferror(<span class="built_in">stdin</span>))</span><br><span class="line">      err_sys(<span class="string">"input error"</span>);</span><br><span class="line"></span><br><span class="line">   <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>stdin和stdout也在头文件&lt;stdio.h&gt;中定义，分别代表标准输入和标准输出。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207151750815.png" alt="image-20220715175012785" style="zoom:50%;"><blockquote><p>文件结束符通常是ctrl-D</p></blockquote><h2 id="1-6-程序和进程"><a href="#1-6-程序和进程" class="headerlink" title="1.6 程序和进程"></a>1.6 程序和进程</h2><ul><li>打印进程ID</li></ul><p>getpid()函数可以得到进程ID，数据类型为pid_t，标准会保证它可以存储在长整型当中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"apue.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span></span></span><br><span class="line"><span class="function"><span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"hello world from process ID %ld\n"</span>, (<span class="keyword">long</span>)getpid());</span><br><span class="line">   <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure><ul><li>进程控制<ul><li>fgets<ul><li>fgets从标准输入一次读取一行，当键入文件结束符作为行的第一个字符时，fgets返回null指针，进程终止</li><li>fgets返回的每一行都以换行符结尾，后接一个null字节。需要将换行符替换为null，因为execlp要求的参数是以null结束的</li></ul></li><li>fork<ul><li>用fork可以创建一个新进程，fork对于父进程返回子进程的pid，而对于子进程则返回0；</li><li>因为fork创建一个新进程，所以它被调用一次（在父进程），但返回了两次（在父进程和子进程）</li></ul></li><li>execlp<ul><li>execlp用以执行从标准输入读入的命令，实际上是用新的程序文件代替了子进程原先执行的程序文件</li><li>fork和exec两者的组合就是产生(spawn)一个新进程</li><li>子进程调用execlp执行新程序文件，而父进程希望等待子进程终止，这就是通过调用waitpid实现的。</li></ul></li><li>waitpid<ul><li>需要指定要等待进程的pid，返回子进程的终止状态(status变量)</li></ul></li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"apue.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span></span></span><br><span class="line"><span class="function"><span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">   <span class="keyword">char</span>   buf[MAXLINE];  <span class="comment">/* from apue.h */</span></span><br><span class="line">   <span class="keyword">pid_t</span>  pid;</span><br><span class="line">   <span class="keyword">int</span>       status;</span><br><span class="line"></span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"%% "</span>); <span class="comment">/* print prompt (printf requires %% to print %) */</span></span><br><span class="line">   <span class="keyword">while</span> (fgets(buf, MAXLINE, <span class="built_in">stdin</span>) != <span class="literal">NULL</span>) {</span><br><span class="line">      <span class="keyword">if</span> (buf[<span class="built_in">strlen</span>(buf) - <span class="number">1</span>] == <span class="string">'\n'</span>)</span><br><span class="line">         buf[<span class="built_in">strlen</span>(buf) - <span class="number">1</span>] = <span class="number">0</span>; <span class="comment">/* replace newline with null */</span></span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> ((pid = fork()) &lt; <span class="number">0</span>) {</span><br><span class="line">         err_sys(<span class="string">"fork error"</span>);</span><br><span class="line">      } <span class="keyword">else</span> <span class="keyword">if</span> (pid == <span class="number">0</span>) {    <span class="comment">/* child */</span></span><br><span class="line">         execlp(buf, buf, (<span class="keyword">char</span> *)<span class="number">0</span>);</span><br><span class="line">         err_ret(<span class="string">"couldn't execute: %s"</span>, buf);</span><br><span class="line">         <span class="built_in">exit</span>(<span class="number">127</span>);</span><br><span class="line">      }</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* parent */</span></span><br><span class="line">      <span class="keyword">if</span> ((pid = waitpid(pid, &amp;status, <span class="number">0</span>)) &lt; <span class="number">0</span>)</span><br><span class="line">         err_sys(<span class="string">"waitpid error"</span>);</span><br><span class="line">      <span class="built_in">printf</span>(<span class="string">"%% "</span>);</span><br><span class="line">   }</span><br><span class="line">   <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>该命令的主要缺陷是不能向所执行的命令传递参数，如下图，需要进一步通过某种约定对行进行解析。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207181653086.png" alt="image-20220718165339040" style="zoom:50%;"><ul><li>线程与线程ID<ul><li>使用线程的好处<ul><li>有多个控制线程分别作用于问题的不同部分，解决起来就会容易得多</li><li>多个线程可以充分利用多处理器系统的并行能力</li></ul></li><li>一个进程内的所有线程共享<strong>同一地址空间、文件描述符、栈以及进程相关的属性</strong>，所以访问共享数据时需要采取同步措施以避免不一致性</li><li>线程也通过ID标识，但它只对它所属的进程有作用</li></ul></li></ul><h2 id="1-7-出错处理"><a href="#1-7-出错处理" class="headerlink" title="1.7 出错处理"></a>1.7 出错处理</h2><ul><li>系统函数出错时通常会返回一个负值</li><li>Linux出错常量在errno中定义</li><li>C标准定义了两个函数，用于打印出错消息<ul><li>strerror：将errno映射为一个出错消息字符串</li><li>perror：基于errno在标准错误上产生一条出错消息</li></ul></li><li>出错恢复：<ul><li>致命性错误</li><li>非致命性错误<ul><li>延迟一段时间，重试等方法</li></ul></li></ul></li></ul><h2 id="1-8-用户标识"><a href="#1-8-用户标识" class="headerlink" title="1.8 用户标识"></a>1.8 用户标识</h2><ul><li><p>用户ID：</p><ul><li>用户ID是系统用来标识不同用户的，每个用户有唯一的ID，内核通过使用用户ID来检验该用户是否有执行某些操作的权限</li><li>ID为0的用户为超级用户(root)</li></ul></li><li><p>组ID：</p><ul><li>被用于将若干用户集合到项目或部门中去，该机制允许同组的各个成员之间共享资源</li><li>组文件将组名映射为组ID，通常是/etc/group</li></ul></li><li><p>存储用户ID和组ID仅需4字节</p></li><li><p>打印用户id和组id</p><ul><li>getuid()：用户id</li><li>getgid()：组id</li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"apue.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span></span></span><br><span class="line"><span class="function"><span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">"uid = %d, gid = %d\n"</span>, getuid(), getgid());</span><br><span class="line">   <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">}</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207181733182.png" alt="image-20220718173304157" style="zoom: 67%;"><h2 id="1-9-信号"><a href="#1-9-信号" class="headerlink" title="1.9 信号"></a>1.9 信号</h2><blockquote><p>用户通知进程发生了某种状况，如若发生了除0错误，会将名为SIGFPE的信号发送给该进程。</p></blockquote><ul><li>进程有以下处理信号的方式<ul><li>忽略信号</li><li>按系统默认方式处理</li><li>提供一个函数，信号发生时调用该函数</li></ul></li><li>终端键盘上产生信号的两种方法：<ul><li>中断键：ctrl-c</li><li>退出键：ctrl-\</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;chapter-1-unix基础知识&quot;&gt;&lt;a href=&quot;#chapter-1-unix基础知识&quot; class=&quot;headerlink&quot; title=&quot;chapter 1 unix基础知识&quot;&gt;&lt;/a&gt;chapter 1 unix基础知识&lt;/h1&gt;&lt;h2 id=&quot;1</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>使用docker配置深度学习环境</title>
    <link href="http://example.com/2023/08/05/projects/kinetics%20project/docker%20for%20pytrorch/"/>
    <id>http://example.com/2023/08/05/projects/kinetics%20project/docker%20for%20pytrorch/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="docker使用基础"><a href="#docker使用基础" class="headerlink" title="docker使用基础"></a>docker使用基础</h1><blockquote><p>参考教程：</p><p><a href="https://www.runoob.com/docker/docker-container-usage.html">https://www.runoob.com/docker/docker-container-usage.html</a></p><p><a href="https://blog.csdn.net/dreamhome_s/article/details/106049253">https://blog.csdn.net/dreamhome_s/article/details/106049253</a></p><p>这里默认docker已安装好</p></blockquote><h2 id="1-dockers运行命令"><a href="#1-dockers运行命令" class="headerlink" title="1. dockers运行命令"></a>1. dockers运行命令</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus all -itd --name torchtest -v <span class="variable">$PWD</span> -w /tmp/workplace -p 10035:22 -p 8889:8888 pytorch/pytorch:latest bash</span><br></pre></td></tr></table></figure><p><strong>notes</strong>:</p><ul><li><p>10035映射到容器的22号端口：用于SSH远程连接服务器</p></li><li><p>8889映射到8888端口：用于远程访问服务器的jupyter notebook</p></li><li><p>若端口号被占用，换一个未被占用的即可</p></li><li><p>-v -w：将当前目录挂载到容器的workplace目录下</p></li><li><p>-i: 交互式操作。</p></li><li><p>-t: 终端。</p></li><li><p>-d: 在后台执行</p></li></ul><p>可以将该命令写入<strong>脚本</strong>里方便持续执行，如图：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204141420457.png" alt="image-20220414142028424" style="zoom: 67%;"><h2 id="2-docker进入命令"><a href="#2-docker进入命令" class="headerlink" title="2. docker进入命令"></a>2. docker进入命令</h2><ul><li><strong>docker exec</strong>：推荐大家使用 docker exec 命令，因为此命令会退出容器终端，但不会导致容器的停止。</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it torchtest /bin/bash</span><br></pre></td></tr></table></figure><p>使用该命令可以进入终端，退出root也不会导致容器停止。</p><h2 id="3-开启SSH服务"><a href="#3-开启SSH服务" class="headerlink" title="3. 开启SSH服务"></a>3. 开启SSH服务</h2><ul><li>安装SSH服务：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apt update</span><br><span class="line">apt install openssh-server</span><br><span class="line">service ssh start</span><br></pre></td></tr></table></figure><ul><li>设置容器密码：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输入passwd设置密码</span><br></pre></td></tr></table></figure><ul><li>修改容器配置：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">apt install vim</span><br><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line"><span class="comment"># 在 sshd_config 文件里</span></span><br><span class="line">PermitRootLogin prohibit-password <span class="comment"># 注释掉</span></span><br><span class="line">PermitRootLogin yes <span class="comment"># 添加该行</span></span><br></pre></td></tr></table></figure><ul><li>重新激活SSH服务：</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh restart</span><br></pre></td></tr></table></figure><ul><li>在本机测试是否可以连接成功：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204141504398.png" alt="image-20220414150403363" style="zoom:50%;"><h2 id="4-docker-保存镜像"><a href="#4-docker-保存镜像" class="headerlink" title="4. docker 保存镜像"></a>4. docker 保存镜像</h2><blockquote><p>当对环境做出了修改时，安装新的包等，我们需要对当前比较稳定的环境做一个备份。方便错误恢复或是迁移到其他机器。</p></blockquote><blockquote><p>有这个需求的原因是需要在宿主机和docker容器加一个端口映射，但是我不想丢失之前对容器所做的任何变动，才有了这一步骤</p></blockquote><h3 id="基础版-基于备份"><a href="#基础版-基于备份" class="headerlink" title="基础版-基于备份"></a>基础版-基于备份</h3><p><strong>导出容器</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker <span class="built_in">export</span> 1e560fca3906 &gt; ubuntu.tar</span><br></pre></td></tr></table></figure><p><strong>导入容器</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat docker/ubuntu.tar | sudo docker import - <span class="built_in">test</span>/ubuntu:v1</span><br></pre></td></tr></table></figure><h2 id="进阶版-基于版本控制"><a href="#进阶版-基于版本控制" class="headerlink" title="进阶版-基于版本控制"></a>进阶版-基于版本控制</h2><p><strong>更新镜像</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit -m=<span class="string">"has update"</span> -a=<span class="string">"runoob"</span> e218edb10161 runoob/ubuntu:v2</span><br></pre></td></tr></table></figure><p>各个参数说明：</p><ul><li><strong>-m:</strong> 提交的描述信息</li><li><strong>-a:</strong> 指定镜像作者</li><li><strong>e218edb10161：</strong>容器 ID</li><li><strong>runoob/ubuntu:v2:</strong> 指定要创建的目标镜像名</li></ul><p>可以使用 <strong>docker images</strong> 命令来查看我们的新镜像 <strong>runoob/ubuntu:v2</strong>：</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;docker使用基础&quot;&gt;&lt;a href=&quot;#docker使用基础&quot; class=&quot;headerlink&quot; title=&quot;docker使用基础&quot;&gt;&lt;/a&gt;docker使用基础&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考教程：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;htt</summary>
      
    
    
    
    <category term="kinetics项目" scheme="http://example.com/categories/kinetics%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="环境配置" scheme="http://example.com/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    <category term="docker" scheme="http://example.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>setuptools入门</title>
    <link href="http://example.com/2023/08/05/projects/kinetics%20project/setuptools/"/>
    <id>http://example.com/2023/08/05/projects/kinetics%20project/setuptools/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="setuptools-Quickstart"><a href="#setuptools-Quickstart" class="headerlink" title="setuptools Quickstart"></a><code>setuptools</code> Quickstart</h1><h2 id="basics"><a href="#basics" class="headerlink" title="basics"></a>basics</h2><ol><li>声明使用setuptools 来打包项目</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># pyproject.toml</span><br><span class="line">[build-system]</span><br><span class="line">requires = ["setuptools"]</span><br><span class="line">build-backend = "setuptools.build_meta"</span><br></pre></td></tr></table></figure><ol start="2"><li>通过配置文件setup.py来 specify 包信息</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">'mypackage'</span>,</span><br><span class="line">    version=<span class="string">'0.0.1'</span>,</span><br><span class="line">    packages=[<span class="string">'mypackage'</span>],</span><br><span class="line">    install_requires=[</span><br><span class="line">        <span class="string">'requests'</span>,</span><br><span class="line">        <span class="string">'importlib-metadata; python_version == "3.8"'</span>,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="3"><li>需要一个构建器builder</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># pip install build</span><br><span class="line">python -m build</span><br></pre></td></tr></table></figure><h2 id="extensions"><a href="#extensions" class="headerlink" title="extensions"></a>extensions</h2><ol><li>自动包发现</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from setuptools import find_packages  # or find_namespace_packages</span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    # ...</span><br><span class="line">    packages=find_packages(</span><br><span class="line">        where='.',</span><br><span class="line">        include=['mypackage*'],  # ["*"] by default</span><br><span class="line">        exclude=['mypackage.tests'],  # empty by default</span><br><span class="line">    ),</span><br><span class="line">    # ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="2"><li>依赖管理</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">setup(</span><br><span class="line">    # ...</span><br><span class="line">    install_requires=["docutils", "requests &lt;= 0.4"],</span><br><span class="line">    # ...</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ol start="3"><li>开发者模式</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --editable .</span><br></pre></td></tr></table></figure><h2 id="experiments"><a href="#experiments" class="headerlink" title="experiments"></a>experiments</h2><blockquote><p>遵循教程，实验打包流程：<a href="https://packaging.python.org/en/latest/tutorials/packaging-projects/">https://packaging.python.org/en/latest/tutorials/packaging-projects/</a></p></blockquote><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204141406193.png" alt="image-20220414140619160"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;setuptools-Quickstart&quot;&gt;&lt;a href=&quot;#setuptools-Quickstart&quot; class=&quot;headerlink&quot; title=&quot;setuptools Quickstart&quot;&gt;&lt;/a&gt;&lt;code&gt;setuptools&lt;/code&gt;</summary>
      
    
    
    
    <category term="kinetics项目" scheme="http://example.com/categories/kinetics%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="环境配置" scheme="http://example.com/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    <category term="setuptools" scheme="http://example.com/tags/setuptools/"/>
    
  </entry>
  
  <entry>
    <title>docker内配置facebook pyslowfast环境</title>
    <link href="http://example.com/2023/08/05/projects/kinetics%20project/installation%20of%20slowfast/"/>
    <id>http://example.com/2023/08/05/projects/kinetics%20project/installation%20of%20slowfast/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="facebook-PySlowFast-安装"><a href="#facebook-PySlowFast-安装" class="headerlink" title="facebook PySlowFast 安装"></a>facebook PySlowFast 安装</h1><h2 id="环境配置并处理依赖"><a href="#环境配置并处理依赖" class="headerlink" title="环境配置并处理依赖"></a>环境配置并处理依赖</h2><blockquote><p>docker环境配置方法参考docker for pytorch.md</p><p>下面是项目安装所需要的依赖，详见该<a href="https://github.com/facebookresearch/SlowFast">仓库</a></p></blockquote><h3 id="fvcore"><a href="#fvcore" class="headerlink" title="fvcore"></a>fvcore</h3><p>轻量级的核心库，提供视觉框架开发最通用和基础的功能</p><p><strong>Features:</strong></p><p>Besides some basic utilities, fvcore includes the following features:</p><ul><li>Common pytorch layers, functions and losses in <a href="https://github.com/facebookresearch/fvcore/blob/main/fvcore/nn">fvcore.nn</a>.</li><li>A hierarchical per-operator flop counting tool: see <a href="https://github.com/facebookresearch/fvcore/blob/main/docs/flop_count.md">this note for details</a>.</li><li>Recursive parameter counting: see <a href="https://detectron2.readthedocs.io/en/latest/modules/fvcore.html#fvcore.nn.parameter_count">API doc</a>.</li><li>Recompute BatchNorm population statistics: see its <a href="https://detectron2.readthedocs.io/en/latest/modules/fvcore.html#fvcore.nn.update_bn_stats">API doc</a>.</li><li>A stateless, scale-invariant hyperparameter scheduler: see its <a href="https://detectron2.readthedocs.io/en/latest/modules/fvcore.html#fvcore.common.param_scheduler.ParamScheduler">API doc</a>.</li></ul><h3 id="FFmpeg"><a href="#FFmpeg" class="headerlink" title="FFmpeg"></a>FFmpeg</h3><p>用来处理多媒体内容（音频，视频，字幕）的工具库集合。 官方网站：<a href="https://ffmpeg.org/">website</a></p><blockquote><p>sth interesting: <a href="https://ffmpeg.org/git-howto.html">Using Git to develop FFmpeg</a></p></blockquote><p><strong>Tools</strong></p><ul><li><a href="https://ffmpeg.org/ffmpeg.html">ffmpeg</a> is a command line toolbox to manipulate, convert and stream multimedia content.</li><li><a href="https://ffmpeg.org/ffplay.html">ffplay</a> is a minimalistic multimedia player.</li><li><a href="https://ffmpeg.org/ffprobe.html">ffprobe</a> is a simple analysis tool to inspect multimedia content.</li><li>Additional small tools such as <code>aviocat</code>, <code>ismindex</code> and <code>qt-faststart</code>.</li></ul><h3 id="PyAV"><a href="#PyAV" class="headerlink" title="PyAV"></a>PyAV</h3><p>是对FFmpeg python 风格的binding，提供对下层的库提供强大的控制。PyAV 用于通过容器、流、数据包、编解码器和帧直接和精确地访问媒体。<a href="https://pyav.org/docs/stable/">文档链接</a></p><h3 id="psutil"><a href="#psutil" class="headerlink" title="psutil"></a>psutil</h3><p>获取运行进程和系统利用率信息的库（CPU, memory, disks, network, sensors）。<a href="https://psutil.readthedocs.io/en/latest/">文档链接</a></p><h3 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h3><p><a href="https://pytorch.org/docs/stable/tensorboard.html?highlight=tensorboard">pytorch教程</a></p><p><a href="https://www.tensorflow.org/tensorboard/get_started">更详细的</a></p><p><a href="https://zhuanlan.zhihu.com/p/143809933">Pytorch下的tensorboard可视化</a></p><p><a href="https://www.jianshu.com/p/46eb3004beca">Pytorch使用tensorboardX可视化</a></p><h3 id="PyTorchVideo"><a href="#PyTorchVideo" class="headerlink" title="PyTorchVideo"></a>PyTorchVideo</h3><p>PyTorchVideo is a deeplearning library with a focus on video understanding work. PytorchVideo provides reusable, modular and efficient components needed to accelerate the video understanding research. PyTorchVideo is developed using <a href="https://pytorch.org/">PyTorch</a> and supports different deeplearning video components like video models, video datasets, and video-specific transforms.</p><p><a href="https://pytorchvideo.org/docs/tutorial_overview">getting started</a></p><p><a href="https://pytorchvideo.org/#quickstart">quick start</a></p><p><a href="https://github.com/facebookresearch/pytorchvideo/blob/main/docs/source/model_zoo.md">Using PyTorchVideo model zoo</a></p><h3 id="Detectron2"><a href="#Detectron2" class="headerlink" title="Detectron2"></a>Detectron2</h3><p><a href="https://github.com/facebookresearch/detectron2">https://github.com/facebookresearch/detectron2</a></p><h3 id="pytorch"><a href="#pytorch" class="headerlink" title="pytorch"></a>pytorch</h3><h4 id="install-from-binaries"><a href="#install-from-binaries" class="headerlink" title="install from binaries"></a>install from binaries</h4><ol><li>PyTorch is supported on Linux distributions that use <a href="https://www.gnu.org/software/libc/">glibc</a> &gt;= v2.17</li><li><a href="https://www.ubuntu.com/download/desktop">Ubuntu</a>, minimum version 13.04</li><li>Python 3.7 or greater</li></ol><h4 id="building-from-source"><a href="#building-from-source" class="headerlink" title="building from source"></a>building from source</h4><blockquote><p> install bleeding edge PyTorch code</p></blockquote><p><strong>pre-knowledge</strong></p><p>GPU 计算能力表：<a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a></p><img src="C:\Users\sixwa\AppData\Roaming\Typora\typora-user-images\image-20220414113639291.png" alt="image-20220414113639291" style="zoom:50%;"><p><strong>CUDA</strong>是一个工具包，是NVIDIA推出的用于自家GPU上的并行计算框架。For convenience, the NVIDIA driver is installed as part of the CUDA Toolkit installation</p><p><strong>cuDNN</strong>是一个SDK，是一个专门用于神经网络的加速包，注意，它跟我们的CUDA没有一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般有一个最新版本的cuDNN版本与CUDA对应更好，<a href="https://developer.nvidia.com/rdp/cudnn-archive">链接地址</a></p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204141233189.png" alt="image-20220414123339104" style="zoom: 50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204141235527.png" alt="image-20220414123544479" style="zoom:50%;"><h2 id="数据下载与处理"><a href="#数据下载与处理" class="headerlink" title="数据下载与处理"></a>数据下载与处理</h2><blockquote><p>kinetics数据集下载 github:<a href="https://github.com/cvdfoundation/kinetics-dataset">https://github.com/cvdfoundation/kinetics-dataset</a></p></blockquote><ul><li>我下载的数据集为kinetics-700-2020，可参考：<a href="https://github.com/cvdfoundation/kinetics-dataset#kinetics-700-2020">https://github.com/cvdfoundation/kinetics-dataset#kinetics-700-2020</a></li></ul><ol><li><strong>数据集下载</strong>：bash ./k700_2020_downloader.sh<ul><li>确定下载目录和数据集目录</li><li>将训练，验证，测试数据集，标注下载到对应目录</li><li>使用命令：wget -P 下载到指定目录 -c 断点续传 -i 下载多个文件</li></ul></li><li><strong>数据集处理</strong>：bash ./k700_2020_extractor.sh<ul><li>分别解压训练，验证，测试数据集和标注</li><li>使用命令 tar zxf 来解压 -C 解压到的目录</li></ul></li></ol><ul><li><p>下载数据集也可参考<a href="https://github.com/activitynet/ActivityNet/tree/master/Crawler/Kinetics%EF%BC%8C%E4%BD%86%E5%8F%AA%E6%9C%89k600%E4%B9%8B%E5%89%8D%E7%9A%84">https://github.com/activitynet/ActivityNet/tree/master/Crawler/Kinetics，但只有k600之前的</a></p></li><li><p>可参考该仓库进行数据集准备：<a href="https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md">https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md</a></p><ol><li><p>获得类别标签映射，因为原仓库是针对k400的，所以我重新生成了映射</p><blockquote><p>详见data_process文件夹下的preprocess.py的generatejsonmap函数</p></blockquote></li><li><p> 使用gen_py_list.py改变文件夹名称，并对训练集和验证集生成txt列表.</p></li></ol><blockquote><p>若gen_py_list.py中途报错，则生成的txt列表会不全，这里写了个简单的函数来进行重新生成（preprocess.py下的generatetxtlist()）。若输出与实际数据集视频数相等，则生成正确（ 即和“ls -lR /tmp/data/train | grep “^-“ | wc -l ”的结果进行比较）</p></blockquote><ol start="3"><li><p>使用downscale_video_joblib.py把视频的高度缩小为256 pixels</p><blockquote><p>检查文件数是否匹配即可</p></blockquote></li></ol></li><li><p>调整视频大小到256, 准备训练集，验证集，测试集的csv文件如 <code>train.csv</code>, <code>val.csv</code>, <code>test.csv</code>. 格式如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path_to_video_1 label_1</span><br><span class="line">path_to_video_2 label_2</span><br><span class="line">path_to_video_3 label_3</span><br><span class="line">...</span><br><span class="line">path_to_video_N label_N</span><br></pre></td></tr></table></figure></li><li><p>依据txt列表生成CSV文件：</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data_process/preprocess.py</span></span><br><span class="line"><span class="comment"># generate_csv_file() function</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">"data process/trainlist.txt"</span>,<span class="string">"r"</span>) <span class="keyword">as</span> file:</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">"f"</span>)</span><br><span class="line">     lines = file.readlines()</span><br><span class="line">     <span class="built_in">print</span>(<span class="string">"d"</span>)</span><br><span class="line">     list_paths = []</span><br><span class="line">     list_labels = []</span><br><span class="line">     <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">         elems = line.strip().split()</span><br><span class="line">         list_labels.append(<span class="built_in">int</span>(elems[<span class="number">1</span>]))</span><br><span class="line">         list_paths.append(videodir+elems[<span class="number">0</span>])</span><br><span class="line">     series_paths = pd.Series(np.array(list_paths))</span><br><span class="line">     series_labels = pd.Series(np.array(list_labels))</span><br><span class="line">     d = {</span><br><span class="line">         <span class="string">"video_path"</span>:series_paths,</span><br><span class="line">         <span class="string">"label"</span>:series_labels</span><br><span class="line">     }</span><br><span class="line">     <span class="built_in">print</span>(d)</span><br><span class="line">     df = pd.DataFrame(d)</span><br><span class="line">     df.to_csv(<span class="string">"data process/train.csv"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;facebook-PySlowFast-安装&quot;&gt;&lt;a href=&quot;#facebook-PySlowFast-安装&quot; class=&quot;headerlink&quot; title=&quot;facebook PySlowFast 安装&quot;&gt;&lt;/a&gt;facebook PySlowFast </summary>
      
    
    
    
    <category term="kinetics项目" scheme="http://example.com/categories/kinetics%E9%A1%B9%E7%9B%AE/"/>
    
    <category term="环境安装" scheme="http://example.com/categories/kinetics%E9%A1%B9%E7%9B%AE/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/"/>
    
    
    <category term="环境配置" scheme="http://example.com/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    <category term="docker" scheme="http://example.com/tags/docker/"/>
    
    <category term="pySlowFast" scheme="http://example.com/tags/pySlowFast/"/>
    
  </entry>
  
  <entry>
    <title>AI-EARTH学习记录</title>
    <link href="http://example.com/2023/08/05/projects/nlp%20project/ai-earth_with_pytorch/"/>
    <id>http://example.com/2023/08/05/projects/nlp%20project/ai-earth_with_pytorch/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据挖掘-AI-Earth项目"><a href="#数据挖掘-AI-Earth项目" class="headerlink" title="数据挖掘-AI-Earth项目"></a>数据挖掘-AI-Earth项目</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><blockquote><p><strong>2021 “AI Earth”人工智能创新挑战赛</strong>:<a href="https://tianchi.aliyun.com/competition/entrance/531871/introduction">链接</a></p></blockquote><p>发生在热带太平洋上的厄尔尼诺-南方涛动(ENSO)现象是地球上最强、最显著的年际气候信号。准确预测ENSO，是提高东亚和全球气候预测水平和防灾减灾的关键。</p><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><p>基于历史气候观测和模式模拟数据，利用T时刻过去12个月(包含T时刻)的时空序列（气象因子），构建预测ENSO的深度学习模型，预测未来1-24个月的Nino3.4指数</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="STTransformer"><a href="#STTransformer" class="headerlink" title="STTransformer"></a>STTransformer</h3><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p><strong>学习率衰减策略</strong></p><blockquote><p>训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，可学习该<a href="https://zhuanlan.zhihu.com/p/93624972?utm_source=qq&utm_medium=social&utm_oi=799204418460459008">post</a>了解更多</p></blockquote><p>STTransformer采用了Noamopt优化策略，详细可参考Annotated Transformer, Harvard NLP Group, <a href="http://nlp.seas.harvard.edu/annotated-transformer/">ArdalanM/annotated-transformer</a>，衰减公式如下所示：</p><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205081136303.png" alt="image-20220508113623206"></p><p><strong>训练器</strong></p><p><strong>包含变量</strong>：</p><ul><li>配置 config</li><li>设备  device</li><li>网络结构 network</li><li>优化器 opt</li></ul><blockquote><p>optim作用：基于梯度更新当前的参数，具体地，其<a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step"><code>step()</code></a>方法可以更新所有参数（要在梯度计算出来之后调用，例：loss.backward()）</p></blockquote><p><strong>注意</strong>，将model放入gpu在<strong>构建优化器之前</strong></p><ul><li>权重 weight</li></ul><p>我们可以由下图得知，不同的月份有不同的权重，self.weight实际上是公式1.2中的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="7.906ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3494.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(751.2,0)"><path data-c="2217" d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path></g><g data-mml-node="mi" transform="translate(1473.4,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(1771.4,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2371.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2760.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3105.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，a实际上是accskill权重，预报提取时间越长，accskill权重越高<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="64.48ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 28500.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1011.8,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(2067.6,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(2567.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3012.2,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(3819,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(4874.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(6152.8,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mn" transform="translate(6597.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></g><g data-mml-node="mo" transform="translate(7375.2,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(8431,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(9053.8,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(10109.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(11109.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(11554.2,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(12361,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(13416.8,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(13916.8,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mn" transform="translate(14361.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(15639.2,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(16695,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(17317.8,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mn" transform="translate(18373.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(19373.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(19818.2,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(20625,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(21680.8,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mo" transform="translate(22180.8,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mn" transform="translate(22625.4,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(23903.2,0)"><path data-c="2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></g><g data-mml-node="mi" transform="translate(24959,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(25304,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(25748.7,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mo" transform="translate(26555.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(27611.2,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(28111.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p><img src="C:/Users/sixwa/AppData/Roaming/Typora/typora-user-images/image-20220510151538633.png" alt="image-20220510151538633" style="zoom: 33%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.weight = torch.from_numpy(np.array([<span class="number">1.5</span>]*<span class="number">4</span> + [<span class="number">2</span>]*<span class="number">7</span> + [<span class="number">3</span>]*<span class="number">7</span> + [<span class="number">4</span>]*<span class="number">6</span>) * np.log(np.arange(<span class="number">24</span>)+<span class="number">1</span>)).to(configs.device)</span><br></pre></td></tr></table></figure><p><strong>包含函数</strong>：</p><ul><li><p>得分函数score</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205101504511.png" alt="image-20220510150436482" style="zoom:50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205101504154.png" alt="image-20220510150417127" style="zoom:50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205101502854.png" alt="image-20220510150206737" style="zoom: 50%;"></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中心化</span></span><br><span class="line">pred = y_pred - y_pred.mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># (N, 24)</span></span><br><span class="line">true = y_true - y_true.mean(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># (N, 24)</span></span><br><span class="line"><span class="comment"># 协方差矩阵判断相关性，值越大相关性越高</span></span><br><span class="line">cor = (pred * true).<span class="built_in">sum</span>(dim=<span class="number">0</span>) / (torch.sqrt(torch.<span class="built_in">sum</span>(pred**<span class="number">2</span>, dim=<span class="number">0</span>) * torch.<span class="built_in">sum</span>(true**<span class="number">2</span>, dim=<span class="number">0</span>)) + <span class="number">1e-6</span>)</span><br><span class="line">acc = (acc_weight * cor).<span class="built_in">sum</span>()</span><br><span class="line"><span class="comment"># rmse是所有预测月份的均方根误差</span></span><br><span class="line">rmse = torch.mean((y_pred - y_true)**<span class="number">2</span>, dim=<span class="number">0</span>).sqrt().<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span>/<span class="number">3.</span> * acc - rmse</span><br></pre></td></tr></table></figure><ul><li>sst损失函数</li></ul><p>在经纬度上计算均方根误差，再在样本维度上求均值，再返回所有月份的和</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (5400+5010,26,1,24,48)</span></span><br><span class="line">rmse = torch.mean((y_pred - y_true)**<span class="number">2</span>, dim=[<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">rmse = torch.<span class="built_in">sum</span>(rmse.sqrt().mean(dim=<span class="number">0</span>))</span><br><span class="line"><span class="keyword">return</span> rmse</span><br></pre></td></tr></table></figure><ul><li>nino损失函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (5400+5010,24)</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    rmse = torch.sqrt(torch.mean((y_pred - y_true)**<span class="number">2</span>, dim=<span class="number">0</span>)) * self.weight</span><br><span class="line"><span class="keyword">return</span> rmse.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure><ul><li>训练单步</li></ul><p>需要三个<strong>输入</strong>：input_sst, sst_true, nino_true, ssr_ratio，将input_sst和sst_true作为source和target送入STTransformer进行处理，输出为sst_pred, nino_pred。</p><blockquote><p>注：该模型虽然提供了两个Loss函数，但是只根据sst损失函数来更新梯度</p></blockquote><p>在计算得到梯度之后，更新参数之前，代码使用了<strong>梯度裁剪</strong>的方法来防止梯度爆炸</p><blockquote><p>注：梯度裁剪：如果梯度变得非常大，那么我们就调节它使其保持较小的状态</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205101550159.png" alt="img" style="zoom:33%;"></blockquote><p>训练单步的<strong>返回</strong>为sst损失, nino损失和nino_pred</p><ul><li>测试</li></ul><p>测试函数将测试数据数据送入网络得到了sst_pred, nino_pred，将他们存入了列表中，之后在样本维度将他们连接起来，这样的好处是损失计算是针对整个测试数据集的。</p><ul><li>推理</li></ul><p>在推理函数中使用了上面的test函数，可以直接计算损失：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">nino_true = torch.from_numpy(dataset.target_nino).<span class="built_in">float</span>().to(self.device)</span><br><span class="line">sst_true = torch.from_numpy(dataset.target_sst).<span class="built_in">float</span>().to(self.device)</span><br><span class="line">sc = self.score(nino_pred, nino_true)</span><br><span class="line">loss_sst = self.loss_sst(sst_pred, sst_true).item()</span><br><span class="line">loss_nino = self.loss_nino(nino_pred, nino_true).item()</span><br></pre></td></tr></table></figure><p>推理函数的<strong>返回</strong>值即为loss_sst,loss_nino,sc</p><ul><li>训练</li></ul><p>训练时首先将准备好的训练集和验证集用dataloader封装一下我们的cmip_dataset，并设定其为随机采样。将最好的score设定为负的无穷大浮点数。在每一个epoch里，更新ssr比率，调用train_once得到我们的损失和nino预测。根据nino预测和真实值我们可以得到score，它不只是在每个epoch结束后进行evaluate而是每300个batch评估一次，以免最优点被错过，因为该模型的训练时间较短。训练还设计了patience机制，若多个epoch之后score未变好就直接结束训练。</p><ul><li><p>保存config</p></li><li><p>保存模型ConvTTLSTM</p></li><li><p>训练入口main函数：</p></li></ul><p>main做的都大同小异，首先读入数据，并划分为训练，验证和测试集，之后使用cmipdataset对训练集和测试集进行wrap，初始化训练器进行训练即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(configs)</span><br><span class="line">trainer.save_configs(<span class="string">'config_train.pkl'</span>)</span><br><span class="line">trainer.train(dataset_train, dataset_eval, <span class="string">'checkpoint.chk'</span>)</span><br></pre></td></tr></table></figure><h4 id="模型-1"><a href="#模型-1" class="headerlink" title="模型"></a>模型</h4><h5 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h5><p>论文设计的自注意力模块（Space-Time Attention）如下图所示，</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205101637540.png" alt="image-20220510163737467" style="zoom:50%;"><p>首先我们要定义一个SpaceTimeTransformer类，在其初始化函数中，首先保存其设置，设备，输入维度</p><p><strong>线性嵌入</strong></p><p>首先论文将clip分解为patches，用x来表示每一个patch，公式1进行了线性嵌入得到嵌入向量z，其中E和e都是可以学习的参数，e代表对每个patch的时空位置进行编码的位置嵌入向量。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204291136330.png" alt="image-20220429113605223" style="zoom:50%;"><p><strong>查询键值计算</strong></p><p>模型包含了L个编码块，在每个块中，为每一个patch的表示（由上一个块编码得到）中计算查询/键/值向量。其中LN（）代表LayerNorm；a = 1,…,A，其中A为多头注意力的数量，其中每个注意力头的隐维度数量为Dh = D/A</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204291150047.png" alt="image-20220429115006018" style="zoom:50%;"><p><strong>自注意力计算</strong></p><p>自注意力权重可以按照如下的公式进行计算：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204291204875.png" alt="image-20220429120419846" style="zoom:50%;"><p>SM（）代表softmax激活函数，自注意力仅在p(空间维度)或t(时间维度)上进行计算所以计算量被显著地降低了。</p><p><strong>编码过程</strong></p><p>第l个块的patch编码z可以通过:</p><ul><li>先计算值向量的加权和，公式如下：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204291223852.png" alt="image-20220429122304822" style="zoom:50%;"><ul><li>将这些向量沿HEAD维度进行连接，再传入多层感知机即可得到最终编码向量（注，在每一个操作中还使用了残差连接）：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204291226426.png" alt="image-20220429122626393" style="zoom:50%;"><h5 id="模型实现"><a href="#模型实现" class="headerlink" title="模型实现"></a>模型实现</h5><p>上边主要从理论方面解释了如何计算attention权重，下面从代码的角度分析如何去实现模型：</p><p>我将encoding和decoding所做的处理进行了分析，如下图所示：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205141433841.png" alt="image-20220514143322612" style="zoom: 50%;"><p>首先代码定义了SpaceTimeTransformer类，在该类中定义了如下变量：</p><ul><li><p>src_emb</p><p>该变量是input_embedding类的实例，用于对输入进行嵌入，所作的简而言之就是进行一个线性变换，加上位置编码和时间编码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(x.size()) == <span class="number">4</span> </span><br><span class="line">embedded_space = self.emb_space(self.spatial_pos)  <span class="comment"># (1, S, 1, D)</span></span><br><span class="line">x = self.linear(x) + self.pe_time[:, :, :x.size(<span class="number">2</span>)] + embedded_space  <span class="comment"># (N, S, T, D)</span></span><br><span class="line"><span class="keyword">return</span> self.norm(x)</span><br></pre></td></tr></table></figure></li><li><p>tgt_emb</p><p>该变量是input_embedding类的实例，用于对输出进行嵌入。</p></li><li><p>encoder</p></li><li><p>decoder</p></li><li><p>linear_output</p></li></ul><p>由 定义的变量可以看出，该模型采样了encoder-decoder框架，src即输入序列期待通过该框架生成目标序列tgt，encoder将输入句子通过非线性变换转化为中间表示，decoder根据中间表示和历史信息yi-1生成yi。</p><p>该类的方法为前馈操作，编码方法，解码方法，生成掩膜：</p><ul><li><p>forward</p><p>在forward方法中首先调用了encode方法将src和src_mask作为参数进行编码，如果处在训练过程中：为target生成mask，并将必要参数传入解码器进行解码得到了sst_pred。如果ssr_ratio&gt;1e-6，那么使用Teacher forcing生成一个teacher_forcing_mask，否则该mask为0，Teacher forcing就是直接使用实际标签<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex" xmlns="http://www.w3.org/2000/svg" width="3.918ex" height="1.471ex" role="img" focusable="false" viewBox="0 -442 1731.9 650"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>作为下一个时间步的输入，由老师（ground truth）带领着防止模型越走越偏。但是老师不能总是手把手领着学生走，要逐渐放手让学生自主学习，于是我们使用Scheduled Sampling rate来控制使用实际标签的概率。在训练初期，ratio=1，模型完全由老师带领着，随着训练轮数的增加，ratio以一定的方式衰减（该方案中使用线性衰减，ratio每次减小一个衰减率decay_rate），每个时间步以ratio的概率从伯努利分布中提取二进制随机数0或1，为1时输入就是实际标签<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex" xmlns="http://www.w3.org/2000/svg" width="3.918ex" height="1.471ex" role="img" focusable="false" viewBox="0 -442 1731.9 650"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>，否则输入为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex" xmlns="http://www.w3.org/2000/svg" width="3.918ex" height="2.303ex" role="img" focusable="false" viewBox="0 -810 1731.9 1018"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(300.6,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(523,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>。再将新的tgt送入decoder进行预测得到了sst_pred。</p><p>如果处于验证阶段，每次预测一次sst_pred并加入，之后计算nino_pred并返回。</p></li><li><p>encode</p><p>在encode方法中，使用了unfold_StackOverChannel方法将原图像分解为patches</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">unfold_StackOverChannel</span>(<span class="params">img, kernel_size</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    divide the original image to patches, then stack the grids in each patch along the channels</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        img (N, *, C, H, W): the last two dimensions must be the spatial dimension</span></span><br><span class="line"><span class="string">        kernel_size: tuple of length 2</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        output (N, *, C*H_k*N_k, H_output, W_output)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_dim = <span class="built_in">len</span>(img.size())</span><br><span class="line">    <span class="keyword">assert</span> n_dim == <span class="number">4</span> <span class="keyword">or</span> n_dim == <span class="number">5</span></span><br><span class="line"></span><br><span class="line">    pt = img.unfold(-<span class="number">2</span>, size=kernel_size[<span class="number">0</span>], step=kernel_size[<span class="number">0</span>])</span><br><span class="line">    pt = pt.unfold(-<span class="number">2</span>, size=kernel_size[<span class="number">1</span>], step=kernel_size[<span class="number">1</span>]).flatten(-<span class="number">2</span>)  <span class="comment"># (N, *, C, n0, n1, k0*k1)</span></span><br><span class="line">    <span class="keyword">if</span> n_dim == <span class="number">4</span>:  <span class="comment"># (N, C, H, W)</span></span><br><span class="line">        pt = pt.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">3</span>).flatten(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">elif</span> n_dim == <span class="number">5</span>:  <span class="comment"># (N, T, C, H, W)</span></span><br><span class="line">        pt = pt.permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">4</span>).flatten(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">assert</span> pt.size(-<span class="number">3</span>) == img.size(-<span class="number">3</span>) * kernel_size[<span class="number">0</span>] * kernel_size[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">return</span> pt</span><br></pre></td></tr></table></figure><p>分解为patches后，将其reshape并做一个embeding，再将编码张量送入encoder中进行处理并返回（memory）</p></li><li><p>decode</p><p>与encode的过程类似，也需将tgt分解为patches并将其嵌入传给decoder进行解码（还有memory,mask等参数）并返回</p></li><li><p>generate_square_subsequent_mask</p><p>该方法为生成掩膜的方法</p></li></ul><h4 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h4><h5 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h5><p><strong>读入数据</strong></p><ul><li>首先使用xarray库读入数据集</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131549861.png" alt="image-20220513154957818" style="zoom: 50%;"><ul><li>查看cmip数据集的sst变量的shape</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131549347.png" alt="image-20220513154921242" style="zoom:50%;"><p><strong>数据扁平化</strong></p><ul><li><p>使用sel方法选择纬度在一定范围内的数据：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131553372.png" alt="image-20220513155342338" style="zoom:50%;"></li></ul><blockquote><p>这一步的主要作用在于降低空间分辨率，从而减少计算量</p></blockquote><ul><li>分解为cmip6和cmip5并对每一个数据集进行数据变换，以cmip6为例，他只使用sst特征，一共有15个模式，每个模式151年，并将同种模式下的数据拼接起来，之后采用滑窗构造数据集（每3年采样一次，去重）：</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131622431.png" alt="image-20220513162228369" style="zoom:50%;"><p><strong>构造CMIP数据集</strong></p><blockquote><p>12+26 = 38</p></blockquote><p>下面是我手动分析如何构造cmipdataset的过程，简要概括一下就是，cmipdataset将cmip5、cmip6连接在了一起，对于cmip5的操作，对于cmip6是同理的。下面的红色的shape主要是针对cmip6的，概括一下数据集构建的过程：</p><ul><li>将序列数据集模拟为视频数据集，设定输入帧时间间隔，输入帧长度，预测偏移和要预测的未来帧长度，具体如下图所示；</li><li>以gap=5为采样间隔提取clips，将clips分为input_sst(长度为12)和target_sst(长度为26)，每两个输入clip之间有7个月是重复的，输出clip之间有21个帧是重复的；</li><li>维度转换在每一步中已清晰列出，注意，为了模拟视频数据集，代码手动添加了channel维度；</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131632136.png" alt="image-20220513163209973" style="zoom:50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131632278.png" alt="image-20220513163226142" style="zoom: 67%;"><p>下图是数据集的生成结果，可以看出sst_input，sst_target，nino target均与手动推导的shape是一致的：</p><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131629150.png" alt="image-20220513162900082"></p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131630853.png" alt="image-20220513163040825" style="zoom:50%;"><p>验证集的处理类似，这里不再赘述：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131655406.png" alt="image-20220513165542374" style="zoom:50%;"><h5 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h5><p>导入训练以及模型配置：</p><ul><li>单卡gpu</li><li>batch-size=8</li><li>epochs=100</li><li>gradient_clipping = False</li><li>weight_decay=0</li><li>d_model=256</li><li>patience = 3</li><li>patch_size=(2,3)</li><li>emb_spatial_size = 12*16</li><li>number of heads = 4</li><li>num of encoding layers = 3</li><li>num of decoding layers = 3</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131705401.png" alt="image-20220513170526353" style="zoom:50%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205131722699.png" alt="image-20220513172233630" style="zoom:50%;"><h5 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h5><p>将训练好的模型进行验证，先将模型的weight进行读取，将得到的模型在测试集上进行推理，最终的score分数约为33，如下图所示：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205132125646.png" alt="image-20220513212548609" style="zoom: 67%;"><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205132125790.png" alt="image-20220513212503712" style="zoom:50%;"><h5 id="精度优化"><a href="#精度优化" class="headerlink" title="精度优化"></a>精度优化</h5><p><strong>自注意力权重修改</strong></p><p>计算注意力权重时，将顺序计算改为对空间和时间同时进行计算</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205132130277.png" alt="image-20220513213041188" style="zoom:50%;"><p>并将合并式注意力替代分离式注意力重新进行训练，发现效果没有提升</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>实验证明，将时间序列数据集当作视频使用transformer进行训练是可行的，最终的score可以达到32。相较于CNN，transformer的结构更加复杂，而且自注意力的设计对于网络的性能影响很大，稍微修改一点，网络就有可能无法收敛。实验证明使用transformer去捕获长范围的时间依赖是十分有效的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据挖掘-AI-Earth项目&quot;&gt;&lt;a href=&quot;#数据挖掘-AI-Earth项目&quot; class=&quot;headerlink&quot; title=&quot;数据挖掘-AI-Earth项目&quot;&gt;&lt;/a&gt;数据挖掘-AI-Earth项目&lt;/h1&gt;&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;</summary>
      
    
    
    
    <category term="nlp项目" scheme="http://example.com/categories/nlp%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="nlp" scheme="http://example.com/tags/nlp/"/>
    
    <category term="time-transformer" scheme="http://example.com/tags/time-transformer/"/>
    
    <category term="AI-EARTH" scheme="http://example.com/tags/AI-EARTH/"/>
    
  </entry>
  
  <entry>
    <title>跨域问题解决</title>
    <link href="http://example.com/2023/08/05/projects/nlp%20project/%E8%B7%A8%E5%9F%9F/"/>
    <id>http://example.com/2023/08/05/projects/nlp%20project/%E8%B7%A8%E5%9F%9F/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="跨域"><a href="#跨域" class="headerlink" title="跨域"></a>跨域</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul><li>为什么会出现跨域</li></ul><p>同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互：即两个页面具有相同的协议（protocol），主机（host）和端口号（port）</p><ul><li>跨域案例<br>当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域</li></ul><table><thead><tr><th>当前页面url</th><th>被请求页面url</th><th>是否跨域</th><th>原因</th></tr></thead><tbody><tr><td><a href="http://www.lluozh.com/">http://www.lluozh.com/</a></td><td><a href="http://www.lluozh.com/index.html">http://www.lluozh.com/index.html</a></td><td>否</td><td>同源(协议、域名、端口号相同)</td></tr></tbody></table><ul><li>客户端发起的这个<code>OPTIONS</code>可以说是一个<code>"预请求"</code>，用于探测后续真正需要发起的跨域<code>POST</code>请求对于服务器来说是否是安全可接受的，因为跨域提交数据对于服务器来说可能存在很大的安全问题</li><li>请求头<code>Access-Control-Request-Method</code>用于提醒服务器在接下来的请求中将会使用什么样的方法来发起请求</li><li><code>Access-Control-Allow-Method</code>和<code>Access-Control-Allow-Origin</code>分别告知客户端，服务器允许客户端用于跨域的方法和域名</li></ul><h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><ul><li>下载flask-cors包</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;跨域&quot;&gt;&lt;a href=&quot;#跨域&quot; class=&quot;headerlink&quot; title=&quot;跨域&quot;&gt;&lt;/a&gt;跨域&lt;/h1&gt;&lt;h2 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;ul&gt;
&lt;</summary>
      
    
    
    
    <category term="nlp项目" scheme="http://example.com/categories/nlp%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="跨域" scheme="http://example.com/tags/%E8%B7%A8%E5%9F%9F/"/>
    
    <category term="flask" scheme="http://example.com/tags/flask/"/>
    
  </entry>
  
  <entry>
    <title>基于知识图谱的开放域问答系统</title>
    <link href="http://example.com/2023/08/05/projects/nlp%20project/%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%A7%88/"/>
    <id>http://example.com/2023/08/05/projects/nlp%20project/%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%A7%88/</id>
    <published>2023-08-05T03:14:26.388Z</published>
    <updated>2023-08-05T03:14:26.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基于知识图谱的开放域问答系统"><a href="#基于知识图谱的开放域问答系统" class="headerlink" title="基于知识图谱的开放域问答系统"></a>基于知识图谱的开放域问答系统</h1><h2 id="一-项目总体介绍"><a href="#一-项目总体介绍" class="headerlink" title="一. 项目总体介绍"></a>一. 项目总体介绍</h2><h3 id="1-任务目标"><a href="#1-任务目标" class="headerlink" title="1. 任务目标"></a>1. 任务目标</h3><p><strong>开放域问答系统：</strong></p><p>使用大量不同主题的文档来回答问题，是自然语言处理（NLP）、信息检索（IR）和相关领域长期研究的主题。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205061136170.png" alt="image-20220506113613101" style="zoom:50%;"><p><strong>知识图谱：</strong></p><p>知识图谱（Knowledge Graph），是结构化的语义知识库，用于以符号形式描述物理世界中的概念及其相互关系。其基本组成单位是“实体-关系-实体”三元组，以及实体及其相关属性-值对，实体间通过关系相互联结，构成网状的知识结构。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205061138448.png" alt="image-20220506113858423" style="zoom:50%;"><h3 id="2-模型整体设计及流程"><a href="#2-模型整体设计及流程" class="headerlink" title="2. 模型整体设计及流程"></a>2. 模型整体设计及流程</h3><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031723438.png" alt="image-20220503172309406" style="zoom:50%;"><p>具体流程如下：</p><ul><li>使用NER模型从问题中抽取实体并将其送入知识库进行匹配，找出所有可能的候选关系。</li><li>使用相似度模型计算所有候选关系与问题实体的相似度，找到可能性最大的候选关系。</li><li>使用该候选关系在知识图谱中查找，找到最终答案。</li></ul><h2 id="二-模型介绍"><a href="#二-模型介绍" class="headerlink" title="二. 模型介绍"></a>二. 模型介绍</h2><h3 id="1-命名实体识别（NER）"><a href="#1-命名实体识别（NER）" class="headerlink" title="1. 命名实体识别（NER）"></a>1. 命名实体识别（NER）</h3><p>命名实体识别( NER )是<a href="https://en.wikipedia.org/wiki/Information_extraction">信息提取</a>、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工具，旨在将<a href="https://en.wikipedia.org/wiki/Unstructured_data">非结构化文本</a>中提到的<a href="https://en.wikipedia.org/wiki/Named_entity">命名实体</a>定位并分类为预定义的类别，例如人姓名、组织、地点、<a href="https://en.wikipedia.org/wiki/Medical_classification">医疗代码</a>、时间表达、数量、货币价值、百分比等。</p><p><strong>BIO标注法</strong></p><p>将每个元素标注为“B-X”、“I-X”或者“O”。其中，“B-X”表示此元素所在的片段属于X类型并且此元素在此片段的开头，“I-X”表示此元素所在的片段属于X类型并且此元素在此片段的中间位置，“O”表示不属于任何类型，如下图所示：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031725389.png" alt="image-20220503172543360" style="zoom: 80%;"><p><strong>NER模型结构</strong></p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031726967.png" alt="image-20220503172634938" style="zoom: 80%;"><p>上图展示的NER模型使用Bert+BiLSTM+CRF的结构，首先使用Bert对输入的句子进行embedding,然后将这些向量输入BILSTM提取句子信息，最后输入CRF测算不同标注序列的概率，最后选取概率最大的序列作为最终结果。具体流程如下图所示。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031727724.png" alt="image-20220503172702670" style="zoom:67%;"><h3 id="2-相似度计算（SIM）"><a href="#2-相似度计算（SIM）" class="headerlink" title="2. 相似度计算（SIM）"></a>2. 相似度计算（SIM）</h3><p><strong>模型设计</strong></p><ul><li><p>KGQA子任务(关系识别)</p><p>确定哪个关系必须被逻辑形式的特定部分使用是一项关键任务。类似于实体链接，我们需要学习映射自然语言表达到知识图谱，在该任务中是针对关系映射。</p></li><li><p>阶段目标</p><p>获得问题与知识三元组&lt;头实体，关系，尾实体&gt; 中相对应的关系。</p></li><li><p>上游任务</p><p>获得通过NER阶段识别到的头实体。</p></li><li><p>下游任务</p><p>通过头实体与SIM计算得到的关系检索尾实体（答案）。</p></li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031731183.png" alt="image-20220503173133145" style="zoom: 80%;"><p><strong>流程实现</strong></p><ol><li><p>根据识别到的实体，通过es接口找到可能的候选关系的列表</p></li><li><p>训练相似度模型进行关系预测：输入为问句和候选关系的拼接，输出为两者相似度</p></li><li><p>获得问句和候选关系的相似度，以最高相似度的关系作为结果用于下游任务</p></li></ol><h2 id="三-数据集介绍"><a href="#三-数据集介绍" class="headerlink" title="三. 数据集介绍"></a>三. 数据集介绍</h2><p><strong>知识库</strong></p><p>知识库来源于百科类数据，由百科类搜索页面的事实性三元组构成。格式为&lt;头实体，关系，尾实体&gt;</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031739828.png" alt="image-20220503173921792" style="zoom:67%;"><table><thead><tr><th><strong>实体数量</strong></th><th><strong>关系数量</strong></th><th>高频关系(&gt;100)</th><th><strong>三元组数量</strong></th></tr></thead><tbody><tr><td>3121457</td><td>245838</td><td>3833</td><td>20559652</td></tr></tbody></table><p><strong>问答数据集</strong></p><p>问答数据集为json格式，每行为一条问答对。问题是one-hop问题，即答案为知识库中的一条三元组。数据格式如下，其中id为问答对索引，quetion为问题，answer为答案，来自知识库，以’ ||| ‘分割。</p><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031741753.png" alt="image-20220503174113714"></p><table><thead><tr><th><strong>Corpus</strong></th><th><strong>Train</strong></th><th><strong>Dev</strong></th><th><strong>Test Public</strong></th><th><strong>Test Private</strong></th></tr></thead><tbody><tr><td>Num Samples</td><td>18k</td><td>2k</td><td>2k</td><td>3k</td></tr><tr><td>Num Relations</td><td>2164</td><td>1258</td><td>1260</td><td>423</td></tr></tbody></table><h2 id="四-项目设计与体验优化"><a href="#四-项目设计与体验优化" class="headerlink" title="四. 项目设计与体验优化"></a>四. 项目设计与体验优化</h2><h3 id="1-项目设计前端"><a href="#1-项目设计前端" class="headerlink" title="1. 项目设计前端"></a>1. 项目设计前端</h3><p>项目采用前端采用uni-app框架，开发者编写一套代码，可发布到iOS、Android、Web（响应式）、以及各种小程序、快应用等多个平台。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031743369.png" alt="image-20220503174331338" style="zoom: 80%;"><h3 id="2-项目设计后端"><a href="#2-项目设计后端" class="headerlink" title="2. 项目设计后端"></a>2. 项目设计后端</h3><p>项目后端采用flask框架，搭建简便快速，较其他同类型框架更为灵活、轻便、安全且容易上手；flask社区活跃，基于flask的应用插件及其丰富，足够满足后端需求，同时它也具有很好的扩展性。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031744361.png" alt="image-20220503174458340" style="zoom:67%;"><h3 id="3-体验优化"><a href="#3-体验优化" class="headerlink" title="3. 体验优化"></a>3. 体验优化</h3><p><strong>意图识别</strong></p><p>普通的问答系统难以满足日益增长的用户需求，如果是知识库中不存在的问题或是用户的意图不够明确的话，问答系统都难以给出我们期望的回复，因此实现一个可以能够理解我们在问什么的，并能根据我们的询问以不同的方式来回复的聊天机器人是很必要的。目前的话，该项目采用的svm分类器，对预先可能的结果进行分类。作为训练数据目前主要有三类，如打招呼，百科信息询问，普通聊天。若分类为信息询问，则接入我们的问答接口，如果是普通聊天，则接入我们的聊天机器人接口。因为是手动构想用户可能的输入作为训练数据，所有难免效果不好，未来我们打算采用RASA这一更加强大的框架作为我们的意图分类器。</p><p><strong>聊天室</strong></p><p>设计聊天室的功能，是有多方面因素推动的，而非冗余的扩展。</p><ol><li><p>首先的目的是分不同的群组，每个群组有特定支持的机器人，即该机器人是用该领域的语料训练的，并且表现较好。</p></li><li><p>二是收集特定领域的语料数据，有利于机器人把握句子的语义，持续有新的训练数据补充来对模型进行更新，有利于模型的迭代优化。</p></li></ol><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205031811717.png" alt="image-20220503181147667" style="zoom: 50%;"><h2 id="五-个人工作总结"><a href="#五-个人工作总结" class="headerlink" title="五. 个人工作总结"></a>五. 个人工作总结</h2><blockquote><p>后端模型代码基于<a href="https://github.com/CLUEbenchmark/KgCLUE">该仓库</a>进行修改</p></blockquote><ul><li><p>NER和SIM模型解耦（提取出推理部分，去掉了冗余wrapper）</p></li><li><p>Flask服务器搭建及与前端交互的代码（socketio）编写加调试</p></li><li><p>前端Uniapp聊天室编写及与后端交互的代码编写加调试</p></li><li><p>将该项目开源到<a href="https://gitee.com/sixwalter/KgCLUE">gitee仓库</a>并进行维护</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基于知识图谱的开放域问答系统&quot;&gt;&lt;a href=&quot;#基于知识图谱的开放域问答系统&quot; class=&quot;headerlink&quot; title=&quot;基于知识图谱的开放域问答系统&quot;&gt;&lt;/a&gt;基于知识图谱的开放域问答系统&lt;/h1&gt;&lt;h2 id=&quot;一-项目总体介绍&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="nlp项目" scheme="http://example.com/categories/nlp%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="知识图谱" scheme="http://example.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"/>
    
    <category term="问答系统" scheme="http://example.com/tags/%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/projects/huawei%20project/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BB%BF%E7%9C%9F%E6%B5%8B%E8%AF%95%E8%B0%83%E7%A0%94/"/>
    <id>http://example.com/2023/08/05/projects/huawei%20project/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BB%BF%E7%9C%9F%E6%B5%8B%E8%AF%95%E8%B0%83%E7%A0%94/</id>
    <published>2023-08-05T03:14:26.387Z</published>
    <updated>2023-08-05T03:14:26.387Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自动驾驶仿真测试系统调研"><a href="#自动驾驶仿真测试系统调研" class="headerlink" title="自动驾驶仿真测试系统调研"></a>自动驾驶仿真测试系统调研</h1><h2 id="调研方法"><a href="#调研方法" class="headerlink" title="调研方法"></a>调研方法</h2><p>我们采取了阅读自动驾驶相关论文、github开源项目搜索、官网搜索等方式，对目前市面上用于研究或商业目的的自动驾驶仿真系统进行了调研。以下是我们的调研结果：</p><h2 id="自动驾驶主要结构"><a href="#自动驾驶主要结构" class="headerlink" title="自动驾驶主要结构"></a>自动驾驶主要结构</h2><p>我们首先调研了自动驾驶仿真工具的整体功能模块结构，如下图所示：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207200936739.jpeg" alt="car.jpg" style="zoom:50%;"><p>如图，自动驾驶仿真系统的主要结构包括：GUI主控，感知，决策和控制四个部分。GUI主控是展示自动驾驶算法的用户界面和仿真场景，在上面我们可以直观地检验我们所设计的算法的效果。感知是视觉算法的主阵地，通过车道线检测、标识牌检测、障碍物检测、车辆目标检测算法，我们可以估计目标与自动驾驶车辆的距离并进行决策。雷达和GPS也是进行决策的辅助信息。在决策模块，我们将通过感知得到的相关距离等数据进行利用以对未来的路径规划进行决策。控制模块根据得到的决策对车辆进行控制，以改变车辆行为。</p><p>目前市面上用于工程商业目的的自动驾驶仿真系统包括：用于车辆动力学的 CarSim、用于复杂车辆模型和交通场景的 PanoSim、用于高级驾驶辅助系统（ADAS）的 PreScan。例如PanoSim支持自动驾驶感知/决策/规划/控制算法开发。它构建的交通场景具有一定的真实性与复杂性，适合我们在之上进行算法的开发。</p><p>我们对项目从两个角度进行了调研：github上的开源代码和仿真平台商业软件</p><h2 id="github开源代码"><a href="#github开源代码" class="headerlink" title="github开源代码"></a>github开源代码</h2><ul><li><p>unity</p><blockquote><p>效果未知，因为星数极少</p></blockquote><ul><li>自动驾驶场景的Unity仿真：<a href="https://github.com/CokerPad/auto-driving-Unity">链接</a></li><li>AutoDriveSimulator：<a href="https://github.com/HumorLogic/AutoDriveSimulator">链接</a></li></ul></li><li><p>c++</p><blockquote><p>效果未知，因为星数极少</p></blockquote><ul><li>自动驾驶模拟仿真实现：<a href="https://github.com/AGANCPP/AutonomousDriving">链接</a>，程序主要模块如上图所示</li></ul></li><li><p><strong>python</strong></p><blockquote><p>项目可以正常演示，较合适，但需要申请仿真服务器API接口的使用权限，下面有介绍</p></blockquote><ul><li>将算法与仿真平台相结合的开源项目：<a href="https://github.com/NEUAutonomousDriving408/CIVCAutonomousDriving">链接</a>，运行示意图如下：</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207200950488.png" alt="image-20220720095032346"></p><h2 id="仿真平台（不开源，需要申请使用）"><a href="#仿真平台（不开源，需要申请使用）" class="headerlink" title="仿真平台（不开源，需要申请使用）"></a>仿真平台（不开源，需要申请使用）</h2><ul><li>AD Chauffeur：<a href="https://www.adchauffeur.cn/">官网</a><ul><li>申请得到用户名和密码：</li></ul></li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207200958119.png" style="zoom:50%;"><ul><li>panosim：<a href="http://www.panosim.com/index.jsp">官网</a></li></ul><h2 id="调研结果"><a href="#调研结果" class="headerlink" title="调研结果"></a>调研结果</h2><p>推荐使用第三种方案，即<strong>python + 仿真平台API</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;自动驾驶仿真测试系统调研&quot;&gt;&lt;a href=&quot;#自动驾驶仿真测试系统调研&quot; class=&quot;headerlink&quot; title=&quot;自动驾驶仿真测试系统调研&quot;&gt;&lt;/a&gt;自动驾驶仿真测试系统调研&lt;/h1&gt;&lt;h2 id=&quot;调研方法&quot;&gt;&lt;a href=&quot;#调研方法&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Pytorch Ligntning 轻量级框架浅析</title>
    <link href="http://example.com/2023/08/05/projects/kinetics%20project/Lightning/"/>
    <id>http://example.com/2023/08/05/projects/kinetics%20project/Lightning/</id>
    <published>2023-08-05T03:14:26.387Z</published>
    <updated>2023-08-05T03:14:26.387Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pytorch-Ligntning-轻量级框架浅析"><a href="#Pytorch-Ligntning-轻量级框架浅析" class="headerlink" title="Pytorch Ligntning 轻量级框架浅析"></a>Pytorch Ligntning 轻量级框架浅析</h1><blockquote><p>该文章为基于<a href="https://pytorch-lightning.readthedocs.io/en/stable/starter/introduction.html">官方文档</a>的学习总结</p></blockquote><h2 id="使用该框架的优点（why-not-using-it-）"><a href="#使用该框架的优点（why-not-using-it-）" class="headerlink" title="使用该框架的优点（why not using it?）"></a>使用该框架的优点（why not using it?）</h2><ul><li>保持了全部的灵活性</li><li>更可读，将工程代码和研究代码解耦</li><li>更容易重现（reproduce）</li><li>更易扩展，且不需要改变模型</li></ul><h2 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h2><h3 id="定义-LightningModule"><a href="#定义-LightningModule" class="headerlink" title="定义 LightningModule"></a>定义 LightningModule</h3><p><strong>SYSTEM VS MODEL</strong></p><blockquote><p>一个lightning 模块不仅仅只是model，更是一个<strong>系统</strong></p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206151727525.png" alt="img" style="zoom:50%;"><p>实际上lightning模块仅仅是一个<code>torch.nn.Module</code>模块，该模块将所有的<strong>研究代码集中到了一个文件当中</strong>，使它包含了：</p><ul><li>The Train loop</li><li>The Validation loop</li><li>The Test loop</li><li>The Prediction loop</li><li>The Model or system of Models</li><li>The Optimizers and LR Schedulers</li></ul><p>通过Hooks特性，我们自定义<strong>训练的任何细节</strong>，详见：<a href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#lightning-hooks">Hooks</a></p><p><strong>FORWARD vs TRAINING_STEP</strong></p><p>lighting推荐将训练和推理相分离</p><ul><li>使用<code>forward</code>进行推理或预测</li><li>使用<code>training_step</code>进行训练</li></ul><h3 id="使用Lightning-Trainer来拟合数据"><a href="#使用Lightning-Trainer来拟合数据" class="headerlink" title="使用Lightning Trainer来拟合数据"></a>使用Lightning Trainer来拟合数据</h3><ul><li><p>首先需要定义数据集：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_module = UCF101DataLoader()</span><br></pre></td></tr></table></figure></li><li><p>初始化lightning模块和trainer，之后调用fit进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">classification_module = VideoClassificationLightningModule()</span><br><span class="line">trainer = pytorch_lightning.Trainer(gpus=[<span class="number">0</span>, <span class="number">1</span>], strategy=<span class="string">"ddp"</span>, max_epochs=<span class="number">30</span>,default_root_dir=<span class="string">"logs_ucf101"</span>, precision=<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line">trainer.fit(classification_module, data_module)</span><br></pre></td></tr></table></figure></li><li><p>trainer支持多种训练功能的自动化</p><ul><li>Epoch and batch iteration</li><li><code>optimizer.step()</code>, <code>loss.backward()</code>, <code>optimizer.zero_grad()</code> calls</li><li>Calling of <code>model.eval()</code>, enabling/disabling grads during evaluation</li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing.html">Checkpoint Saving and Loading</a></li><li>Tensorboard (see <a href="https://pytorch-lightning.readthedocs.io/en/stable/common/loggers.html">loggers</a> options)</li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu.html#multi-gpu-training">Multi-GPU</a> support</li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/accelerators/tpu.html">TPU</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/precision.html#amp">16-bit precision AMP</a> support</li></ul></li></ul><h2 id="基本特色"><a href="#基本特色" class="headerlink" title="基本特色"></a>基本特色</h2><h3 id="自动化优化"><a href="#自动化优化" class="headerlink" title="自动化优化"></a>自动化优化</h3><p>只要在<code>train_step（）</code>返回loss损失，lighting就会自动地帮我们反向传播，更新优化器等；对于GAN，强化学习这类涉及多个优化器的模型，我们也可以关闭自动优化自己控制：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    self.automatic_optimization = <span class="literal">False</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    <span class="comment"># access your optimizers with use_pl_optimizer=False. Default is True,</span></span><br><span class="line">    <span class="comment"># setting use_pl_optimizer=True will maintain plugin/precision support</span></span><br><span class="line">    opt_a, opt_b = self.optimizers(use_pl_optimizer=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    loss_a = self.generator(batch)</span><br><span class="line">    opt_a.zero_grad()</span><br><span class="line">    <span class="comment"># use `manual_backward()` instead of `loss.backward` to automate half precision, etc...</span></span><br><span class="line">    self.manual_backward(loss_a)</span><br><span class="line">    opt_a.step()</span><br><span class="line"></span><br><span class="line">    loss_b = self.discriminator(batch)</span><br><span class="line">    opt_b.zero_grad()</span><br><span class="line">    self.manual_backward(loss_b)</span><br><span class="line">    opt_b.step()</span><br></pre></td></tr></table></figure><h3 id="预测和部署"><a href="#预测和部署" class="headerlink" title="预测和部署"></a>预测和部署</h3><p><strong>进行预测的三种方式</strong></p><ul><li><p>提取子模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"><span class="comment"># to use as embedding extractor</span></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line">autoencoder = LitAutoEncoder.load_from_checkpoint(<span class="string">"path/to/checkpoint_file.ckpt"</span>)</span><br><span class="line">encoder_model = autoencoder.encoder</span><br><span class="line">encoder_model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"><span class="comment"># to use as image generator</span></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line">decoder_model = autoencoder.decoder</span><br><span class="line">decoder_model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure></li><li><p>使用forward函数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"><span class="comment"># using the AE to extract embeddings</span></span><br><span class="line"><span class="comment"># ----------------------------------</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LitAutoEncoder</span>(<span class="params">LightningModule</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.encoder = nn.Sequential(nn.Linear(<span class="number">28</span> * <span class="number">28</span>, <span class="number">64</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        embedding = self.encoder(x)</span><br><span class="line">        <span class="keyword">return</span> embedding</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">autoencoder = LitAutoEncoder()</span><br><span class="line">embedding = autoencoder(torch.rand(<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>))</span><br></pre></td></tr></table></figure></li><li><p>生产（production）:</p><ul><li>Onnx using <code>to_onnx()</code> method</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">autoencoder = LitAutoEncoder()</span><br><span class="line">input_sample = torch.randn((<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>))</span><br><span class="line">autoencoder.to_onnx(file_path=<span class="string">"model.onnx"</span>, input_sample=input_sample, export_params=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><ul><li>TorchScript using <code>to_torchscript()</code> method.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">autoencoder = LitAutoEncoder()</span><br><span class="line">autoencoder.to_torchscript(file_path=<span class="string">"model.pt"</span>)</span><br></pre></td></tr></table></figure></li></ul><h3 id="多种加速方式（accelerators）"><a href="#多种加速方式（accelerators）" class="headerlink" title="多种加速方式（accelerators）"></a>多种加速方式（accelerators）</h3><ul><li><p>CPU</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train on CPU / 什么都不设置，默认在cpu上</span></span><br><span class="line">trainer = Trainer()</span><br><span class="line"><span class="comment"># train on 8 CPUs</span></span><br><span class="line">trainer = Trainer(accelerator=<span class="string">"cpu"</span>, devices=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># train on 128 machines，8 devices per machine</span></span><br><span class="line">trainer = pl.Trainer(accelerator=<span class="string">"cpu"</span>, devices=<span class="number">8</span>, num_nodes=<span class="number">128</span>)</span><br></pre></td></tr></table></figure></li><li><p>GPU</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train on 1 GPU</span></span><br><span class="line">trainer = pl.Trainer(accelerator=<span class="string">"gpu"</span>, devices=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train on multiple GPUs across nodes (32 GPUs here)</span></span><br><span class="line">trainer = pl.Trainer(accelerator=<span class="string">"gpu"</span>, devices=<span class="number">4</span>, num_nodes=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train on gpu 1, 3, 5 (3 GPUs total)</span></span><br><span class="line">trainer = pl.Trainer(accelerator=<span class="string">"gpu"</span>, devices=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Multi GPU with mixed precision</span></span><br><span class="line">trainer = pl.Trainer(accelerator=<span class="string">"gpu"</span>, devices=<span class="number">2</span>, precision=<span class="number">16</span>)</span><br></pre></td></tr></table></figure></li><li><p>TPU</p></li><li><p>IPU</p></li></ul><h3 id="模型checkpoint"><a href="#模型checkpoint" class="headerlink" title="模型checkpoint"></a>模型checkpoint</h3><p><strong>保存训练超参</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLightningModule</span>(<span class="params">LightningModule</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, learning_rate, *args, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.save_hyperparameters()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># all init args were saved to the checkpoint</span></span><br><span class="line">checkpoint = torch.load(CKPT_PATH)</span><br><span class="line"><span class="built_in">print</span>(checkpoint[<span class="string">"hyper_parameters"</span>])</span><br><span class="line"><span class="comment"># {"learning_rate": the_value}</span></span><br></pre></td></tr></table></figure><p>使用self.save_hyperparameters()会自动保存传入init的超参数到checkpoint，可以从字典里的”hyper_parameters”键中找到超参</p><p><strong>恢复训练状态</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = LitModel()</span><br><span class="line">trainer = Trainer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># automatically restores model, epoch, step, LR schedulers, apex, etc...</span></span><br><span class="line">trainer.fit(model, ckpt_path=<span class="string">"some/path/to/my_checkpoint.ckpt"</span>)</span><br></pre></td></tr></table></figure><p><strong>恢复模型权重</strong></p><p>Lightning 会在每个epoch结束时自动保存模型，一旦训练完成就可以按照下面的方法加载checkpoint：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = LitModel.load_from_checkpoint(path_to_saved_checkpoint)</span><br></pre></td></tr></table></figure><p>下面的是手动加载的方式，与上面的方式等价：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the ckpt</span></span><br><span class="line">ckpt = torch.load(<span class="string">"path/to/checkpoint.ckpt"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># equivalent to the above</span></span><br><span class="line">model = LitModel()</span><br><span class="line">model.load_state_dict(ckpt[<span class="string">"state_dict"</span>])</span><br></pre></td></tr></table></figure><h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h3><p>对于每一个loop（training，validation，test，predict）我们都可以实现3个hooks来自定义数据流向：</p><ul><li>x_step</li><li>x_step_end(optional)</li><li>x_epoch_end(optional)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> data:</span><br><span class="line">    out = training_step(batch)</span><br><span class="line">    out = training_step_end(out)</span><br><span class="line">    outs.append(out)</span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure><p>在Lightning中与之等价的方式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    prediction = ...</span><br><span class="line">    <span class="keyword">return</span> prediction</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_epoch_end</span>(<span class="params">self, outs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> out <span class="keyword">in</span> outs:</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>如果使用dp/dpp2分布式模式，意味着每个batch的数据分散到了多个GPU中，有时我们可能需要将其集合起来进行处理，在这种情况下，可以实现<code>training_step_end()</code>方法来将所有devices的output进行处理来得到结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, batch, batch_idx</span>):</span></span><br><span class="line">    x, y = batch</span><br><span class="line">    y_hat = self.model(x)</span><br><span class="line">    loss = F.cross_entropy(y_hat, y)</span><br><span class="line">    pred = ...</span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"loss"</span>: loss, <span class="string">"pred"</span>: pred}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_step_end</span>(<span class="params">self, batch_parts</span>):</span></span><br><span class="line">    <span class="comment"># predictions from each GPU</span></span><br><span class="line">    predictions = batch_parts[<span class="string">"pred"</span>]</span><br><span class="line">    <span class="comment"># losses from each GPU</span></span><br><span class="line">    losses = batch_parts[<span class="string">"loss"</span>]</span><br><span class="line"></span><br><span class="line">    gpu_0_prediction = predictions[<span class="number">0</span>]</span><br><span class="line">    gpu_1_prediction = predictions[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># do something with both outputs(average maybe)</span></span><br><span class="line">    <span class="keyword">return</span> (losses[<span class="number">0</span>] + losses[<span class="number">1</span>]) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">training_epoch_end</span>(<span class="params">self, training_step_outputs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> out <span class="keyword">in</span> training_step_outputs:</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p>整个过程的流程（伪代码）如下，lightning将如下的细节为我们隐藏：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">outs = []</span><br><span class="line"><span class="keyword">for</span> batch_idx, train_batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader):</span><br><span class="line">    batches = split_batch(train_batch)</span><br><span class="line">    dp_outs = []</span><br><span class="line">    <span class="keyword">for</span> sub_batch <span class="keyword">in</span> batches:</span><br><span class="line">        <span class="comment"># 1</span></span><br><span class="line">        dp_out = training_step(sub_batch, batch_idx)</span><br><span class="line">        dp_outs.append(dp_out)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2</span></span><br><span class="line">    out = training_step_end(dp_outs)</span><br><span class="line">    outs.append(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># do something with the outputs for all batches</span></span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line">training_epoch_end(outs)</span><br></pre></td></tr></table></figure><h2 id="额外扩展"><a href="#额外扩展" class="headerlink" title="额外扩展"></a>额外扩展</h2><ul><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/datamodules.html#datamodules">LightningDataModule</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/callbacks.html#callbacks">Callbacks</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html#logging">Logging</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/index.html#accelerators">Accelerators</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/plugins.html#plugins">Plugins</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/loops.html#loop-customization">Loops</a></li></ul><h2 id="调试"><a href="#调试" class="headerlink" title="调试"></a>调试</h2><blockquote><p>lightning提供很多可以用来调试的工具</p></blockquote><ul><li><p>限制batches数量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># use only 10 train batches and three val batches per epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">10</span>, limit_val_batches=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># use 20% of total train batches and 10% of total val batches per epoch</span></span><br><span class="line">trainer = Trainer(limit_train_batches=<span class="number">0.2</span>, limit_val_batches=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>每个epoch随机选择较少数量的的batch来进行训练</p></li><li><p>过拟合batches</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Automatically overfit the same batches to your model for a sanity test</span></span><br><span class="line"><span class="comment"># use only 10 train batches</span></span><br><span class="line">trainer = Trainer(overfit_batches=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># use only 20% of total train batches</span></span><br><span class="line">trainer = Trainer(overfit_batches=<span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><p>每个epoch固定选择较少数量的的batch来进行训练</p></li><li><p>快速开发运行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># unit test all the code - hits every line of your code once to see if you have bugs,</span></span><br><span class="line"><span class="comment"># instead of waiting hours to crash somewhere</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># unit test all the code - hits every line of your code with four batches</span></span><br><span class="line">trainer = Trainer(fast_dev_run=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>对所有代码进行单元测试，看是否存在bug</p></li><li><p>验证检查间隔</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run validation every 25% of a training epoch</span></span><br><span class="line">trainer = Trainer(val_check_interval=<span class="number">0.25</span>)</span><br></pre></td></tr></table></figure><p>每1/4个epoch进行一次validation</p></li><li><p>性能测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Profile your code to find speed/memory bottlenecks</span></span><br><span class="line">Trainer(profiler=<span class="string">"simple"</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="其他有用的特性"><a href="#其他有用的特性" class="headerlink" title="其他有用的特性"></a>其他有用的特性</h2><ul><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/early_stopping.html">Automatic early stopping</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html#truncated-bptt-steps">Automatic truncated-back-propagation-through-time</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#batch-size-finder">Automatically scale your batch size</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/advanced/training_tricks.html#learning-rate-finder">Automatically find learning rate</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing.html#checkpoint-loading">Load checkpoints directly from S3</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/clouds/cluster.html">Scale to massive compute clusters</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/guides/data.html">Use multiple dataloaders per train/val/test/predict loop</a></li><li><a href="https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html#id4">Use multiple optimizers to do reinforcement learning or even GANs</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Pytorch-Ligntning-轻量级框架浅析&quot;&gt;&lt;a href=&quot;#Pytorch-Ligntning-轻量级框架浅析&quot; class=&quot;headerlink&quot; title=&quot;Pytorch Ligntning 轻量级框架浅析&quot;&gt;&lt;/a&gt;Pytorch Lig</summary>
      
    
    
    
    <category term="kinetics项目" scheme="http://example.com/categories/kinetics%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="轻量级框架" scheme="http://example.com/tags/%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%A1%86%E6%9E%B6/"/>
    
    <category term="lightning" scheme="http://example.com/tags/lightning/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/projects/kinetics%20project/code_learning/"/>
    <id>http://example.com/2023/08/05/projects/kinetics%20project/code_learning/</id>
    <published>2023-08-05T03:14:26.387Z</published>
    <updated>2023-08-05T03:14:26.387Z</updated>
    
    
    
    
    
  </entry>
  
  <entry>
    <title>vhr项目：学习记录1</title>
    <link href="http://example.com/2023/08/05/projects/java%20project/%E4%BA%BA%E4%BA%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
    <id>http://example.com/2023/08/05/projects/java%20project/%E4%BA%BA%E4%BA%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</id>
    <published>2023-08-05T03:14:26.387Z</published>
    <updated>2023-08-05T03:14:26.387Z</updated>
    
    <content type="html"><![CDATA[<h1 id="动态处理角色与资源的关系"><a href="#动态处理角色与资源的关系" class="headerlink" title="动态处理角色与资源的关系"></a>动态处理角色与资源的关系</h1><h2 id="用户类"><a href="#用户类" class="headerlink" title="用户类"></a>用户类</h2><ul><li>实现UserDetails接口（org.springframework.security中）</li><li>账户的锁定、密码的过期等等等接口均返回True，只处理了是否禁用账户的isEnabled()方法</li><li>Collection&lt;? extends GrantedAuthority&gt;解释：？类型实现了Collection接口，且一定是GrantedAuthority的子类</li></ul><h2 id="Java泛型"><a href="#Java泛型" class="headerlink" title="Java泛型"></a>Java泛型</h2><p><strong>即“参数化类型（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）</strong></p><h2 id="SpringBoot-web"><a href="#SpringBoot-web" class="headerlink" title="SpringBoot web"></a>SpringBoot web</h2><h3 id="资源控制器"><a href="#资源控制器" class="headerlink" title="资源控制器"></a>资源控制器</h3><ul><li>HTTP请求由控制器所处理，处理对/greeting下的路由的GET请求，它返回Greeting类的新实例</li><li>注解RestController表明该类是一个Restful控制器类</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;动态处理角色与资源的关系&quot;&gt;&lt;a href=&quot;#动态处理角色与资源的关系&quot; class=&quot;headerlink&quot; title=&quot;动态处理角色与资源的关系&quot;&gt;&lt;/a&gt;动态处理角色与资源的关系&lt;/h1&gt;&lt;h2 id=&quot;用户类&quot;&gt;&lt;a href=&quot;#用户类&quot; class</summary>
      
    
    
    
    <category term="java项目" scheme="http://example.com/categories/java%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="java web" scheme="http://example.com/tags/java-web/"/>
    
    <category term="springboot" scheme="http://example.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/projects/huawei%20project/%E4%BA%92%E8%81%94%E7%BD%91+%E4%BA%A7%E4%B8%9A%E8%B5%9B%E9%81%93%E5%8D%8E%E4%B8%BA%E5%91%BD%E9%A2%98%E5%88%86%E5%B7%A5/"/>
    <id>http://example.com/2023/08/05/projects/huawei%20project/%E4%BA%92%E8%81%94%E7%BD%91+%E4%BA%A7%E4%B8%9A%E8%B5%9B%E9%81%93%E5%8D%8E%E4%B8%BA%E5%91%BD%E9%A2%98%E5%88%86%E5%B7%A5/</id>
    <published>2023-08-05T03:14:26.385Z</published>
    <updated>2023-08-05T03:14:26.385Z</updated>
    
    <content type="html"><![CDATA[<h1 id="互联网＋项目"><a href="#互联网＋项目" class="headerlink" title="互联网＋项目"></a>互联网＋项目</h1><h2 id="项目内容介绍—我们要做的是什么"><a href="#项目内容介绍—我们要做的是什么" class="headerlink" title="项目内容介绍—我们要做的是什么"></a>项目内容介绍—我们要做的是什么</h2><blockquote><p>应通俗易懂，避免大量专业术语的使用</p></blockquote><p>包括：背景，行业诉求，项目方案，技术创新及突破点，与行业竞品的对比的差异点与技术壁垒，落地效果+落地场景，取得的成果(有数据支撑)</p><h3 id="命题解读"><a href="#命题解读" class="headerlink" title="命题解读"></a>命题解读</h3><p>我们的命题是”基于昇腾算力及CANN的创新媒体处理应用“。其中媒体指的是交通场景下的道路视频，通过对交通视频进行处理，我们可以将其应用于自动驾驶仿真系统。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207191653094.png" alt="image-20220719165336946" style="zoom:50%;"><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ol><li>自动驾驶汽车目前存在很多事故，影响严重</li><li>究其原因是技术存在壁垒，难以突破</li><li>我们的研究可以用于<strong>自动驾驶离线测试</strong>或者<strong>高级辅助驾驶系统</strong>：我们基于市面上常见的仿真系统，将源码进行修改，并将我们的<strong>核心算法</strong>嵌入其中</li></ol><h3 id="行业诉求"><a href="#行业诉求" class="headerlink" title="行业诉求"></a>行业诉求</h3><blockquote><p>我们通过行业调研得知</p></blockquote><p><strong>安全性</strong>：感知前方车辆的制动行为和换道行为对于预测潜在的危险事件具有重要意义。</p><p>而我们研究的<strong>车辆行为识别</strong>和<strong>车辆轨迹预测</strong>可以<strong>辅助路径规划和运动决策</strong>，可以有效确保自动驾驶的安全性。</p><h4 id="车辆行为识别"><a href="#车辆行为识别" class="headerlink" title="车辆行为识别"></a>车辆行为识别</h4><p>在构建安全可靠的自动驾驶系统和高级辅助驾驶系统时，为了分析交通场景的动态演变并<strong>做出合理的决策</strong>，需要自动感知车辆周围其他车辆的<strong>驾驶行为</strong>。而预测驾驶行为这一点目前依然是相当有挑战性的，若能提出一个高效的算法，提高预测精度，对于自动驾驶系统的稳定性和安全性都有较大提升。例如，感知前方车辆的制动行为和换道行为对于预测潜在的危险事件具有重要意义。</p><h4 id="车辆轨迹预测"><a href="#车辆轨迹预测" class="headerlink" title="车辆轨迹预测"></a>车辆轨迹预测</h4><p>为了确保安全，仅仅关注感知、规划和控制是不够的。<strong>高速、准确的轨迹预测</strong>对于后续的控制决策和确保自动驾驶的安全性非常重要。车辆的轨迹预测功能根据过去行驶的轨迹和周边环境如：静态交通设施和动态行驶的车辆、行走的行人等信息，预测视频中车辆未来的轨迹。这有助于构建范围更大、更为全面的智能交通系统。</p><h3 id="目前该领域存在的问题"><a href="#目前该领域存在的问题" class="headerlink" title="目前该领域存在的问题"></a>目前该领域存在的问题</h3><blockquote><p>这两大部分论文里都有，可以参考</p></blockquote><h4 id="车辆行为识别-1"><a href="#车辆行为识别-1" class="headerlink" title="车辆行为识别"></a>车辆行为识别</h4><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207191720085.png" alt="image-20220719172010016" style="zoom:50%;"><h4 id="车辆轨迹预测-1"><a href="#车辆轨迹预测-1" class="headerlink" title="车辆轨迹预测"></a>车辆轨迹预测</h4><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202207191720938.png" alt="image-20220719172054877" style="zoom:50%;"><h3 id="项目方案"><a href="#项目方案" class="headerlink" title="项目方案"></a>项目方案</h3><blockquote><p>高级辅助驾驶系统</p></blockquote><ol><li>项目调研：简述调研流程</li><li>项目计划：开发高级辅助驾驶系统的项目计划</li><li>项目实施：简要介绍我们的算法如何嵌入辅助驾驶系统</li><li>项目落地：期待的落地效果+落地场景</li></ol><h3 id="技术创新及突破点"><a href="#技术创新及突破点" class="headerlink" title="技术创新及突破点"></a>技术创新及突破点</h3><p>针对上述调研的存在的问题，我们提出了对应的改进</p><ol><li>复杂场景下车辆与行人轨迹预测：改进社会池化模块</li><li>复杂场景下车辆与行人轨迹预测：对行人朝向的方位角进行建模</li><li>基于3DCNN的车辆行为识别：使用多流输入，并在网络中进行深度融合</li><li>基于3DCNN的车辆行为识别：提出三维感受野增强模块</li><li>基于3DCNN的车辆行为识别：提出通道注意力特征融合模块</li></ol><h3 id="行业竞品的对比"><a href="#行业竞品的对比" class="headerlink" title="行业竞品的对比"></a>行业竞品的对比</h3><p><strong>用于汽车工业商业目的的模拟软件</strong></p><p>用于车辆动力学的 CarSim、用于复杂车辆模型和交通场景的 PanoSim、用于高级驾驶辅助系统（ADAS）的 PreScan。</p><h2 id="如何制作PPT"><a href="#如何制作PPT" class="headerlink" title="如何制作PPT"></a>如何制作PPT</h2><p><strong>我的想法</strong></p><p>我们PPT第一遍做最好不要套模板，定下主色调之后，我们PPT的主要内容是图片和文字，我们先把这个做好。</p><p><strong>PPT制作要点</strong></p><ul><li><p>材料准备：<strong>精炼</strong>，优势点，突破点突出，要把更多的时间<strong>投入加分项</strong>的介绍</p></li><li><p>评分规则：突出长处，弱化短处，但不要有缺失：商业分析，教育维度</p></li><li><p>更多思考：技术，行业，商业，社会</p></li></ul><h2 id="任务分工"><a href="#任务分工" class="headerlink" title="任务分工"></a>任务分工</h2><p>每个人的任务都分成两部分：包括文档撰写＋PPT制作。下面以任务点的形式领取任务：    </p><p>阶段性：</p><ul><li>初版日期：7/19~7/22</li></ul><p>分工：</p><ul><li><p>团队维度【张】</p></li><li><p>命题解读【田】<a href="https://cy.ncss.cn/mtcontest/detail?id=8a80808d81197da0018119acfaad04dc">链接</a></p></li><li><p><strong>背景及意义</strong>：政策，自动驾驶，事故【张】</p></li><li><p><strong>行业诉求</strong>【田】调研，安全性和实时性</p></li><li><p>目前该领域存在的问题：论文中已有【崔】</p></li><li><p>项目方案</p><ul><li><strong>调研</strong>：调研自动驾驶离线测试或者高级辅助驾驶系统【贺】<ul><li>目前提到的这些模拟软件在github上是否开源，或者有没有做类似东西的</li><li>…</li></ul></li><li>计划<em>【】</em></li><li>实施<em>【】【】</em>论文实验，融合：用了哪些框架（项目整体架构：前后端分离）</li><li><strong>落地</strong>【崔】落地效果+落地场景（简单设想）</li></ul></li><li><p>技术创新及突破点【贺】</p></li><li><p><strong>商业分析</strong>：我们的软件/系统怎么可以赚钱【许】【吴】【余】（具体这块儿我不太懂，可以参考b站往年互联网+比赛视频，<a href="https://www.bilibili.com/video/BV1z3411E7yX">链接</a>）</p><ul><li>行业竞品的对比</li><li>优势分析</li><li>风险分析</li><li>市场营销</li></ul></li><li><p><strong>教育维度</strong>【崔】</p><ul><li>项目符合将专业知识与产业实际问题有效结合，并转化为商业价值或社会价值</li><li>充分体现团队解决复杂问题的综合能力和高级思维，体现项目成长对团队成员创新创业精神</li><li>…</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;互联网＋项目&quot;&gt;&lt;a href=&quot;#互联网＋项目&quot; class=&quot;headerlink&quot; title=&quot;互联网＋项目&quot;&gt;&lt;/a&gt;互联网＋项目&lt;/h1&gt;&lt;h2 id=&quot;项目内容介绍—我们要做的是什么&quot;&gt;&lt;a href=&quot;#项目内容介绍—我们要做的是什么&quot; class</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/projects/huawei%20project/%E5%8D%8E%E4%B8%BA%E9%A1%B9%E7%9B%AE%EF%BC%9A%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95%E5%8F%8A%E5%A4%8D%E7%9B%98/"/>
    <id>http://example.com/2023/08/05/projects/huawei%20project/%E5%8D%8E%E4%B8%BA%E9%A1%B9%E7%9B%AE%EF%BC%9A%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95%E5%8F%8A%E5%A4%8D%E7%9B%98/</id>
    <published>2023-08-05T03:14:26.385Z</published>
    <updated>2023-08-05T03:14:26.387Z</updated>
    
    <content type="html"><![CDATA[<h1 id="pytorch-模型迁移复盘1"><a href="#pytorch-模型迁移复盘1" class="headerlink" title="pytorch 模型迁移复盘1"></a>pytorch 模型迁移复盘1</h1><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><h3 id="VPN连接"><a href="#VPN连接" class="headerlink" title="VPN连接"></a>VPN连接</h3><blockquote><p>目前，该问题已解决</p></blockquote><p>连接华为提供的服务器需要vpn，在连vpn时遇到了一些问题：</p><ul><li>IP访问地址未设置正确</li></ul><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205081923830.png" alt="img"></p><ul><li>需启用隧道验证功能和IPSEC安全协议，通过预设身份验证字来连接</li></ul><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205081926297.png" alt="img"></p><h3 id="数据集大小"><a href="#数据集大小" class="headerlink" title="数据集大小"></a>数据集大小</h3><blockquote><p>目前，该问题已解决</p></blockquote><p>因为数据集较大，imagenet有近140G，直接下载会较慢，通过OBS链接进行下载会快很多。下载后对数据集解压会出现硬盘存储空间不足的问题：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205081935125.png" alt="image-20220508193544091" style="zoom:67%;"><p>解决方法：</p><p>直接从gpu环境上scp一份解压好的上去</p><p><code>scp -r imagenet root@192.168.88.155:/opt/npu</code></p><blockquote><p><strong>Linux scp命令</strong>用于在Linux下进行远程拷贝文件的命令，和它类似的命令有<a href="https://www.coonote.com/linux/linux-cmd-cp.html">cp</a>，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，<a href="https://www.coonote.com/linux/linux-cmd-rsync.html">rsync</a>就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。</p></blockquote><blockquote><p>从本地服务器传到另一台服务器的docker容器而无需密码</p><p>nohup scp -i /home/lyc/.ssh/id_rsa -P 10035 -r ImageNet2012/train/ <a href="mailto:&#114;&#111;&#111;&#x74;&#64;&#x32;&#x30;&#50;&#x2e;&#49;&#x31;&#x37;&#46;&#x32;&#49;&#46;&#57;&#x33;">root@202.117.21.93</a>:/home/workspace/dataset/imagenet &gt; transfer_imagenet_to docker 2&gt;&amp;1 &amp;</p></blockquote><h3 id="代码版本不匹配"><a href="#代码版本不匹配" class="headerlink" title="代码版本不匹配"></a>代码版本不匹配</h3><blockquote><p>目前该问题已解决</p></blockquote><p>因为我用的代码是pytorch1.7, 其中有一些新的接口1.5不支持，因此在NPU的torch1.5环境上需要修改API使之能跑通。主要修改点是torch.cuda.amp.autocast这个接口，将torch原生的amp接口改成apex的amp接口。</p><h3 id="NPU环境不太好改"><a href="#NPU环境不太好改" class="headerlink" title="NPU环境不太好改"></a>NPU环境不太好改</h3><blockquote><p>目前环境未出现问题</p></blockquote><p>需要直接在裸机上跑，不能使用conda，因此想改变环境不太容易，目前的环境启动方法为：’’source /home/gp/test_op/setenv.sh’’。该文件的主要内容是设置一些NPU相关的环境变量。</p><h3 id="GPU训练僵化"><a href="#GPU训练僵化" class="headerlink" title="GPU训练僵化"></a>GPU训练僵化</h3><blockquote><p>目前，该问题未解决</p></blockquote><p>因为是多进程训练，当只有主进程输出的时候若其他进程意外退出，会导致整个程序僵死，而且其他进程出现了什么问题难以获知。因此可以将设置改为所有卡都进行输出，这样哪个卡报错从日志就可以获知。</p><p>如下是发现的问题：</p><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205081956604.png" alt="img"></p><ul><li><p>从日志可以发现损失变成了nan导致训练直接结束</p></li><li><p>一开始以为是Loss scale过大导致loss为nan，实则发现，loss scale是在获得损失值并判断它是否为nan之后，也就是模型采用的loss函数导致了其为nan,和混合精度没有关系，目前还在想办法解决这个问题</p></li></ul><h3 id="循环依赖"><a href="#循环依赖" class="headerlink" title="循环依赖"></a>循环依赖</h3><blockquote><p>目前，该问题已解决</p></blockquote><p>首先，因为想迁移到NPU的同时兼容GPU，所有在获得参数后将其保存在了主程序的函数（useNpu）中，并在之后用到cuda的地方进行判断，看从main.py中引入的useNpu是否为True，如果为真就使用适配NPU的API，否则不变。但是这样改了之后出现了循环依赖:</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205082017527.png" alt="image-20220508201747487" style="zoom:67%;"><p>原因是main中引用了datasets中的build_dataset函数，通过层层import，最终又引用回了main文件，所以又需要再次引用datasets中的build_dataset函数，因此导致了循环依赖。</p><ul><li>目前的修改方法主要有两种，将usenpu作为参数传给对应方法的默认参数，从而取代原先的import</li><li>去掉兼容GPU的功能，这样改兼容性差，不是很合理</li></ul><p>采用第一种方法可以完美解决问题</p><h3 id="unicode编码错误"><a href="#unicode编码错误" class="headerlink" title="unicode编码错误"></a>unicode编码错误</h3><blockquote><p>目前，该问题已解决</p></blockquote><p>当把循环依赖改好了后，出现了UnicodeDecodeError，我怀疑是我在注释里用了中文所以导致出现了问题，但是utf-8是支持中文的而且gpu跑就没有这个问题，所以有点困惑。因为之前是在服务器上改的，没有语法错误提示，我拉到本地IDE中同步一下看看代码有没有问题。</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202205091523594.png" alt="image-20220509152351457" style="zoom: 50%;">]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;pytorch-模型迁移复盘1&quot;&gt;&lt;a href=&quot;#pytorch-模型迁移复盘1&quot; class=&quot;headerlink&quot; title=&quot;pytorch 模型迁移复盘1&quot;&gt;&lt;/a&gt;pytorch 模型迁移复盘1&lt;/h1&gt;&lt;h2 id=&quot;遇到的问题&quot;&gt;&lt;a hre</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>安装和使用龙蜥操作系统</title>
    <link href="http://example.com/2023/08/05/projects/anolis/pa1/"/>
    <id>http://example.com/2023/08/05/projects/anolis/pa1/</id>
    <published>2023-08-05T03:14:26.384Z</published>
    <updated>2023-08-05T03:14:26.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="下载、安装和使用龙蜥操作系统"><a href="#下载、安装和使用龙蜥操作系统" class="headerlink" title="下载、安装和使用龙蜥操作系统"></a>下载、安装和使用龙蜥操作系统</h1><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/image-20230530154212164.png" alt="image-20230530154212164"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;下载、安装和使用龙蜥操作系统&quot;&gt;&lt;a href=&quot;#下载、安装和使用龙蜥操作系统&quot; class=&quot;headerlink&quot; title=&quot;下载、安装和使用龙蜥操作系统&quot;&gt;&lt;/a&gt;下载、安装和使用龙蜥操作系统&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://raw.</summary>
      
    
    
    
    <category term="os" scheme="http://example.com/categories/os/"/>
    
    <category term="anolis" scheme="http://example.com/categories/os/anolis/"/>
    
    
    <category term="os" scheme="http://example.com/tags/os/"/>
    
    <category term="anolis" scheme="http://example.com/tags/anolis/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2023/08/05/projects/basketball%20project/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%A6%81%E6%B1%82/"/>
    <id>http://example.com/2023/08/05/projects/basketball%20project/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%A6%81%E6%B1%82/</id>
    <published>2023-08-05T03:14:26.384Z</published>
    <updated>2023-08-05T03:14:26.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据集要求"><a href="#数据集要求" class="headerlink" title="数据集要求"></a>数据集要求</h1><h2 id="球员跟踪算法"><a href="#球员跟踪算法" class="headerlink" title="球员跟踪算法"></a>球员跟踪算法</h2><blockquote><p>数据集参考Market-1501</p></blockquote><img src="https://zheng-lab.cecs.anu.edu.au/Project/dataset.jpg" alt="img" style="zoom:50%;"><ul><li>需要1501个个体（ID）：训练集750，测试集751</li><li>指标map</li></ul><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/image-20230606194126482.png" alt="image-20230606194126482"></p><ul><li>总计标注32668 个bboxes</li><li>总计有6个摄像头对各个个体进行拍摄，需要保证每个标注个体至少被两个摄像头捕获（为了跨摄像机搜索）</li><li>需要提供2798张干扰图片：对准确率有负面影响的图片</li><li>需要提供3819张垃圾图片：对准确率没有影响的图片</li><li>query图片：3368张</li></ul><p>具体参考链接：</p><ul><li><a href="https://github.com/Wanggcong/Spatial-Temporal-Re-identification">参考1</a></li><li><a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Zheng_Scalable_Person_Re-Identification_ICCV_2015_paper.pdf">参考2</a></li></ul><p>数据集格式参考：</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/image-20230606195815919.png" alt="image-20230606195815919" style="zoom:50%;"><h2 id="行为识别"><a href="#行为识别" class="headerlink" title="行为识别"></a>行为识别</h2><blockquote><p>参考Kinetics 数据集</p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/image-20230606200551349.png" alt="image-20230606200551349" style="zoom:50%;"><ul><li>总计标注13个类别</li><li>每个类别标注400个剪辑片段，训练集：250，验证集：150，测试集：100</li><li>每个剪辑片段60张图片</li></ul><p>数据集参考链接：</p><ul><li><a href="https://www.deepmind.com/open-source/kinetics">参考1</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;数据集要求&quot;&gt;&lt;a href=&quot;#数据集要求&quot; class=&quot;headerlink&quot; title=&quot;数据集要求&quot;&gt;&lt;/a&gt;数据集要求&lt;/h1&gt;&lt;h2 id=&quot;球员跟踪算法&quot;&gt;&lt;a href=&quot;#球员跟踪算法&quot; class=&quot;headerlink&quot; title=&quot;球</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>scrum软件过程基础浅析</title>
    <link href="http://example.com/2023/08/05/projects/general%20notes/scrum/"/>
    <id>http://example.com/2023/08/05/projects/general%20notes/scrum/</id>
    <published>2023-08-05T03:14:26.384Z</published>
    <updated>2023-08-05T03:14:26.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="scrum软件过程基础浅析"><a href="#scrum软件过程基础浅析" class="headerlink" title="scrum软件过程基础浅析"></a>scrum软件过程基础浅析</h1><blockquote><p>就软件过程框架本身而言，scrum比较好理解，是一种迭代、循序渐进的开发方法，也明白这个框架充分重视了人作为开发主体的重要作用，即不是以文档驱动，而是故事点（代码任务或者说可演示的功能）驱动开发。但就实际而言，这个框架可能不太适合中国软件开发的“行情”，实际效果有待验证。</p></blockquote><h2 id="scrum简介"><a href="#scrum简介" class="headerlink" title="scrum简介"></a>scrum简介</h2><p>Scrum是一个轻量级的敏捷开发框架，是一个<strong>增量的、迭代的</strong>开发过程。其核心准则就是<strong>自我管理</strong>和<strong>迭代开发</strong>，可以最大化生产率。</p><p><strong>Scrum特点</strong></p><ol><li>持续的设计、开发、集成和测试</li><li>跨职能的团队成员</li><li>Sprint期间不允许需求变更</li><li>时间盒技术：<strong>迭代周期的期限是固定的</strong>，<strong>不延长迭代的时间</strong></li><li>严格定义的开发节奏</li></ol><p><strong>Scrum好处</strong></p><p>Scrum能让每个参与者都对自己所做的工作以及自己做出的贡献感到骄傲，并让他们发挥到最佳水平。</p><p><strong>Scrum与XP的关系</strong></p><p>Scrum注重的是<strong>管理和组织</strong>实践，而XP关注的是实际的<strong>编程实践</strong>，两者相互兼容且相互补充，如<strong>结对编程、测试驱动开发、持续集成</strong>等XP的最佳实践仍然可以在Scrum中使用。</p><h2 id="scrum目标"><a href="#scrum目标" class="headerlink" title="scrum目标"></a>scrum目标</h2><p>通过<strong>高透明性</strong>、<strong>检验</strong>和<strong>适应性</strong>来管理复杂性、不可预测性和变化。</p><h2 id="scrum框架"><a href="#scrum框架" class="headerlink" title="scrum框架"></a>scrum框架</h2><blockquote><p>p.s. 354很好记</p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206101002797.png" alt="image-20220610100246694" style="zoom:50%;"><h3 id="scrum的3个角色"><a href="#scrum的3个角色" class="headerlink" title="scrum的3个角色"></a>scrum的3个角色</h3><p><strong>scrum master</strong></p><p>做为团队和外部的接口，解决团队开发中的障碍,保证各个角色及职责的良好协作，保证开发过程按计划进行，组织会议，并更新燃尽图</p><p><strong>product owner</strong></p><p>负责提出和维护产品Backlog</p><p><strong>scrum team</strong></p><p>SCRUM团队负责在每个Sprint中将产品Backlog中的条目转化成为潜在可交付的功能增量。自组织，跨职能，一般5-9个人</p><h3 id="scrum的5个仪式"><a href="#scrum的5个仪式" class="headerlink" title="scrum的5个仪式"></a>scrum的5个仪式</h3><p><strong>发布计划会议</strong></p><blockquote><p>只是确立大致交付日期和成本，之后每次迭代开始前均需要依据项目进展情况重新进行调整</p></blockquote><ul><li><p>确立项目整体发布目标和预期结果</p></li><li><p>确定产品Backlog条目、重大风险和发布所包含的全部特性和功能</p></li><li><p>敏捷工作量估算：规模计量单位使用<strong>故事点</strong>，是一个相对值（区别于传统的人天估算）</p><ul><li>计算团队速度：一个迭代中团队完成的故事点总数</li><li>计算迭代周期数：所有故事总的故事点数/团队速度</li><li>计算项目成本：每个迭代的成本 * 迭代周期数</li></ul></li><li><p>根据工作量估算确立大致交付日期和费用</p></li></ul><p><strong>Sprint计划会议</strong></p><ul><li><p>确定做什么</p><p>介绍最高优先级的产品Backlog条目；<strong>选择产品Backlog条目</strong>，确定Sprint目标</p><ul><li>选多少：Sprint计划完成故事点数 = 团队速度 * 120%（120原则）</li><li>选什么：新用户故事占70%，bugs和技术债务占30%（70/30原则）</li></ul></li><li><p>确定怎么做</p><p>团队成员将产品Backlog<strong>分解</strong>为多个1天以内可以完成的任务，细分的任务构成Sprint Backlog</p></li></ul><p><strong>每日站会</strong></p><blockquote><p>这个图看起来挺有意思的，精准展现了每日站会，所以贴上。从中也可以看出，敏捷团队的规模只是5-6人左右（还有程序员真的是聪明绝顶（bushi）），中间红衣服的人最有可能是scrum master，纯属猜测。</p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206101025172.png" alt="image-20220610102500003" style="zoom:50%;"><p>由scrum master主持，每个开发成员会被问三个问题：</p><ul><li>昨天做了什么？</li><li>今天打算做什么？</li><li>工作中遇到了哪些问题？</li></ul><p>前两个问题的目的是维护任务状态，哪些已完成，哪些未完成。但注意，每日站会<strong>不是进度汇报</strong>，而是Scrum成员互相的承诺；<strong>不是系统设计讨论</strong>，遇到的问题应会后解决；会议还应注意时间和效率（10-15分钟），确保 <strong>“鸡” 的角色</strong>不允许在会议上发言过长。</p><blockquote><p>“鸡的角色”，描述得有点形象，有可能暗示只说不做，不了解任务实现难度，滔滔不绝的人。下面的图emmm很直观</p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206101038559.png" alt="image-20220610103840515" style="zoom:50%;"><p><strong>Sprint评审会议</strong></p><ul><li>团队按Sprint Backlog中的条目，为产品负责人或是用户逐个地介绍结果、演示新功能。演示不是验收，目的是收集反馈</li><li>如果产品负责人或客户想改变功能或对功能有新的想法，则添加新条目到产品Backlog中</li><li>将还没能解决的问题加入到问题Backlog列表</li></ul><p><strong>Sprint回顾会议</strong></p><blockquote><p><strong>通过总结以往的实践经验来提高团队生产力</strong></p></blockquote><ul><li><p>以头脑风暴的方式Review Sprint过程和结果，发现和列举存在的问题</p></li><li><p>参会人员投票决定需要在下个Sprint中解决的1-3个问题， 探讨解决方案，确定实践方式</p></li><li><p><strong>回顾是团队的定期自我审视</strong>（p.s. 审视这个词很妙）</p></li></ul><h3 id="scrum的4个工件"><a href="#scrum的4个工件" class="headerlink" title="scrum的4个工件"></a>scrum的4个工件</h3><p><strong>产品 Backlog</strong></p><p><strong>SprintBacklog</strong></p><p><strong>Sprint 燃尽图</strong></p><p><strong>发布燃尽图</strong></p><h2 id="scrum工作流总结"><a href="#scrum工作流总结" class="headerlink" title="scrum工作流总结"></a>scrum工作流总结</h2><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206101049881.png" alt="image-20220610104910789" style="zoom:50%;"><ul><li><p>前期</p><p>产品负责人整理业务需求，形成Product Backlog库</p></li><li><p>执行</p><ul><li>以Sprint为单位迭代式地完成Sprint Backlog</li><li>每个Sprint以Sprint Planning开始，通过每日例会跟踪进度和issue</li><li>Sprint结束时进行评审，交付可运行的产品</li></ul></li><li><p>后期</p><ul><li>每个Sprint完成后，通过Sprint回顾发现问题和改进点</li><li>制定下个Sprint要引入的新的实践</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;scrum软件过程基础浅析&quot;&gt;&lt;a href=&quot;#scrum软件过程基础浅析&quot; class=&quot;headerlink&quot; title=&quot;scrum软件过程基础浅析&quot;&gt;&lt;/a&gt;scrum软件过程基础浅析&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;就软件过程框架本身而言，s</summary>
      
    
    
    
    <category term="软件过程" scheme="http://example.com/categories/%E8%BD%AF%E4%BB%B6%E8%BF%87%E7%A8%8B/"/>
    
    
    <category term="scrum" scheme="http://example.com/tags/scrum/"/>
    
    <category term="敏捷" scheme="http://example.com/tags/%E6%95%8F%E6%8D%B7/"/>
    
  </entry>
  
  <entry>
    <title>PA1项目心得记录</title>
    <link href="http://example.com/2023/08/05/projects/general%20notes/pa1/"/>
    <id>http://example.com/2023/08/05/projects/general%20notes/pa1/</id>
    <published>2023-08-05T03:14:26.384Z</published>
    <updated>2023-08-05T03:14:26.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PA1-notes"><a href="#PA1-notes" class="headerlink" title="PA1 notes"></a>PA1 notes</h1><h2 id="Some-preparations"><a href="#Some-preparations" class="headerlink" title="Some preparations"></a>Some preparations</h2><blockquote><p>How to get all things done remotely?</p></blockquote><p>Because I have my linux server in my bedroom, which is far away for me to run graphic UI applications in my work place. (Obviously, commands through shell are fine).</p><p>So I STFW and found that mobaXterm actually support x11 forwarding, which can show the GNOME desktop. I made some configuration to realize it:</p><ul><li>change the remote environment to <strong>Gnome desktop</strong>:</li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303241703801.png" alt="image-20230324170347757" style="zoom: 50%;"><ul><li><p>Edit <strong>/etc/ssh/ssh_config</strong> to have the following settings</p><ul><li><p>ForwardAgent yes</p></li><li><p>ForwardX11 yes</p></li><li><p>ForwardX11Trusted yes</p></li></ul></li><li><p>Edit <strong>/etc/ssh/sshd_config</strong> to have the following setting</p><ul><li>X11Forwarding yes</li></ul></li><li><p>set xdmcp on gdm3</p><ul><li>vim /etc/gdm3/custom.conf</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303241705304.png" alt="img"></p><ul><li><p>apt install gnome-tweaks</p></li><li><p>reboot. (all things done!)</p></li></ul><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303241722650.png" alt="image-20230324172253275" style="zoom:50%;"><blockquote><p>multi thread compiling v.s. single thread compiling</p></blockquote><p>single thread:</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303241725857.png" alt="image-20230324172506827" style="zoom:50%;"><p>16 threads:</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303241726633.png" alt="image-20230324172657610" style="zoom:50%;"><blockquote><p>if we don’t change any file, object files should be the same, so there is no need compiling again!</p></blockquote><p>By using ccache the compiler time is longer, which is confusing</p><img src="C:/Users/sixwa/AppData/Roaming/Typora/typora-user-images/image-20230327203333113.png" alt="image-20230327203333113" style="zoom: 67%;"><img src="C:/Users/sixwa/AppData/Roaming/Typora/typora-user-images/image-20230327203613713.png" alt="image-20230327203613713" style="zoom: 67%;"><blockquote><p>How does can Super Mario runs on the linux machine?</p></blockquote><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303301937919.png" alt="image-20230330193733878" style="zoom:50%;"><ul><li>for super mario, it can’t figure out it runs on the real Red White devices or runs on the simulated “Red White devices”</li></ul><h3 id="NEMU"><a href="#NEMU" class="headerlink" title="NEMU"></a>NEMU</h3><blockquote><p>What is NEMU?</p></blockquote><ul><li><p>NEMU is a simulated computer system. Physical computer’s essential functions is implemented by programs in NEMU.</p></li><li><p>在NEMU中, 每一个硬件部件都由一个程序相关的数据对象来模拟, 例如变量, 数组, 结构体等;</p></li><li><p>对这些硬件部件的操作则通过对相应数据对象的操作来模拟</p></li></ul><h3 id="ISA"><a href="#ISA" class="headerlink" title="ISA"></a>ISA</h3><blockquote><p>Firstly… you need to choose ISA</p></blockquote><p>ISA is <strong>instruction set architecture</strong>, also called computer architecture, is an <strong>abstraction model</strong> of computer</p><p>A device that execute instructions described by that ISA such as a CPU, is called an <strong>implementation</strong>.</p><p>ISA defines supported <strong>instructions</strong>, <strong>data types</strong>, <strong>registers,</strong> the hardware supporting for managing main memory, <strong>fundamental features</strong>(such as memory consistency, addressing modes, virtual memory), and <strong>the input/output model</strong></p><p>因此, ISA的本质就是类似这样的规范. 所以ISA的存在形式既不是硬件电路, 也不是软件代码, 而是一本<strong>规范手册</strong>.</p><p>和螺钉螺母的生产过程类似, 计算机硬件是按照ISA规范手册构造出来的, 而程序也是按照ISA规范手册编写(或生成)出来的</p><h3 id="Goals"><a href="#Goals" class="headerlink" title="Goals"></a>Goals</h3><p>至于ISA规范里面都有哪些内容, 我们应该如何<strong>构造一个符合规范的计算机</strong>, <strong>程序应该如何遵守这些规范</strong>来在计算机上运行 is our goal.</p><h2 id="Chapter-of-Creating-the-World"><a href="#Chapter-of-Creating-the-World" class="headerlink" title="Chapter of Creating the World"></a>Chapter of Creating the World</h2><ul><li><p>storage(存储器): we need some place to store our program</p></li><li><p>CPU: we need someone to calculate(compute) CPU是负责处理数据的核心电路单元</p><p> 同时<strong>天下也没有免费的午餐</strong>, 存储器的<strong>大容量</strong>也是需要<strong>付出相应的代价的, 那就是速度慢</strong>, 这是先驱也无法违背的材料特性规律</p><ul><li>如果每完成一次累加都需要把它写回存储器, 然后又把它从存储器中读出来继续加, 这样就太不方便了.先驱为CPU创造了<strong>寄存器</strong>, 可以让CPU把正在处理中的数据暂时存放在其中.</li></ul></li></ul><blockquote><p>如果没有寄存器, 计算机还可以工作吗?</p></blockquote><ul><li><p>to let the CPU become the <strong>most loyal servant</strong>, pioneer designs “<strong>instructions</strong>“, to tell CPU to do what kind of operation to data</p><blockquote><p>能否让程序来<strong>自动控制</strong>计算机的执行?</p></blockquote></li><li><p>先驱和CPU作了一个简单的约定: 当执行完一条指令之后, 就<strong>继续执行</strong>下一条指令. </p></li><li><p>但CPU怎么知道现在执行到哪一条指令呢? 为此, 先驱为CPU创造了一个<strong>特殊的计数器, 叫”程序计数器”</strong></p></li></ul><p>从此以后, 计算机就只需要做一件事情:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) {</span><br><span class="line">  从PC指示的存储器位置取出指令;</span><br><span class="line">  执行指令;</span><br><span class="line">  更新PC;</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>一个<strong>足够简单的计算机</strong>:  我们只要将一段指令序列放置在存储器中, 然后让PC指向第一条指令, 计算机就会自动执行这一段指令序列, 永不停止</p><p>一个最简单的真实计算机需要满足哪些条件:</p><ul><li><strong>结构上</strong>, TRM有存储器, 有PC, 有寄存器, 有加法器</li><li><strong>工作方式上</strong>, TRM不断地重复以下过程: 从PC指示的存储器位置取出指令, 执行指令, 然后更新PC</li></ul><blockquote><p>计算机是个状态机</p></blockquote><p>既然计算机是一个<strong>数组逻辑电路,</strong> 那么我们可以把计算机划分成两部分, 一部分由所有<strong>时序逻辑部件</strong>(存储器, 计数器, 寄存器)构成, 另一部分则是剩余的<strong>组合逻辑部件(<strong>如加法器等). 这样以后, 我们就可以从状态机模型的视角来理解计算机的工作过程了: 在每个时钟周期到来的时候, 计算机</strong>根据当前时序逻辑部件的状态</strong>, 在组合逻辑部件的作用下, <strong>计算出并转移到下一时钟周期的新状态</strong>.</p><blockquote><p>程序是一个状态机</p></blockquote><p>程序是指令的集合。那么<strong>指令在状态机的模型里面是什么呢</strong>？</p><p>所以在状态机模型里面, 指令可以看成是<strong>计算机进行一次状态转移的输入激励</strong>.</p><p>假设某个计算机有4个8位的寄存器, 一个4位PC, 以及一段16字节的内存(也就是存储器)</p><p>那么这个计算机可以表示比特总数为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4</span>*<span class="number">8</span> + <span class="number">4</span> + <span class="number">16</span>*<span class="number">8</span> = <span class="number">164</span></span><br></pre></td></tr></table></figure><p>因此这个计算机总共可以有<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="14.295ex" height="2.099ex" role="img" focusable="false" viewBox="0 -846 6318.5 928"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(1165.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(2221.6,0)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(533,363) scale(0.707)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g></g><g data-mml-node="mo" transform="translate(3619,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msup" transform="translate(4674.8,0)"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="TeXAtom" transform="translate(533,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(1000,0)"></path></g></g></g></g></g></svg></mjx-container>种不同的状态</p><p>假设这个在这个计算机中, 所有指令的行为都是确定的, 那么给定<code>N</code>个状态中的任意一个, 其转移之后的新状态也是唯一确定的.</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202303302042331.png" style="zoom:50%;"><blockquote><p>通过状态机的视角来解释**”程序在计算机上运行”的本质**</p></blockquote><p>给定一个程序, 把它放到计算机的内存中, 就相当于在状态数量为<code>N</code>的状态转移图中指定了一个初始状态, 程序运行的过程就是从这个初始状态开始, 每执行完一条指令, 就会进行一次确定的状态转移. 也就是说, 程序也可以看成一个状态机! 这个状态机是上文提到的<strong>大状态机(状态数量为<code>N</code>)的子集</strong>.</p><p>例如：1+2+…+100</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PC: instruction    | // label: statement</span></span><br><span class="line"><span class="number">0</span>: mov  r1, <span class="number">0</span>         |  pc0: r1 = <span class="number">0</span>;</span><br><span class="line"><span class="number">1</span>: mov  r2, <span class="number">0</span>         |  pc1: r2 = <span class="number">0</span>;</span><br><span class="line"><span class="number">2</span>: addi r2, r2, <span class="number">1</span>     |  pc2: r2 = r2 + <span class="number">1</span>;</span><br><span class="line"><span class="number">3</span>: add  r1, r1, r2    |  pc3: r1 = r1 + r2;</span><br><span class="line"><span class="number">4</span>: blt  r2, <span class="number">100</span>, <span class="number">2</span>    |  pc4: <span class="keyword">if</span> (r2 &lt; <span class="number">100</span>) <span class="keyword">goto</span> pc2;   <span class="comment">// branch if less than</span></span><br><span class="line"><span class="number">5</span>: jmp <span class="number">5</span>              |  pc5: <span class="keyword">goto</span> pc5;</span><br></pre></td></tr></table></figure><p>的状态机转换为：</p><p>(0,x,x) -&gt; (1,0,x)-&gt;(2,0,0)-&gt;(3,0,1)-&gt;(4,1,1)-&gt;(2,1,1)-&gt;(3,1,2)-&gt;(4,3,2)-&gt;….-&gt;(2,4851,98)-&gt;(3,4851,99)-&gt;(4,4950,99)-&gt;(2,4950,99)-&gt;(3,4950,100)-&gt;(4,5050,100)-&gt;(5,5050,100)-&gt;….</p><ul><li>以代码(或指令序列)为表现形式的<strong>静态视角</strong><ul><li>描述精简</li><li>分支, 循环和函数调用的组合使得我们可以通过少量代码实现出很复杂的功能. </li><li>但这也可能会使得我们对程序行为的理解造成困难</li></ul></li><li>以状态机的状态转移为运行效果的<strong>动态视角</strong><ul><li>直接刻画了”程序在计算机上运行”的本质</li><li>但对于程序的局部行为, 尤其是从静态视角来看难以理解的行为, 状态机视角可以让我们清楚地了解相应的细节.</li></ul></li></ul><p> 因为在PA中你需要不断地和代码打交道. 如果你不能从<strong>微观视角理解某些关键代码的行为</strong>, 你也无法从<strong>宏观视角完全弄清楚程序究竟是如何运行的</strong>.</p><h2 id="RTFSC"><a href="#RTFSC" class="headerlink" title="RTFSC"></a>RTFSC</h2><p>在NEMU中模拟的计算机称为”<strong>客户(guest)计算机</strong>“, 在NEMU中运行的程序称为”<strong>客户程序</strong>“.</p><h3 id="框架代码初探"><a href="#框架代码初探" class="headerlink" title="框架代码初探"></a>框架代码初探</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ics2022</span><br><span class="line">├── abstract-machine   # 抽象计算机</span><br><span class="line">├── am-kernels         # 基于抽象计算机开发的应用程序</span><br><span class="line">├── fceux-am           # 红白机模拟器</span><br><span class="line">├── init.sh            # 初始化脚本</span><br><span class="line">├── Makefile           # 用于工程打包提交</span><br><span class="line">├── nemu               # NEMU</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure><h4 id="NEMU的四个主要模块"><a href="#NEMU的四个主要模块" class="headerlink" title="NEMU的四个主要模块"></a>NEMU的四个主要模块</h4><ul><li>monitor</li><li>CPU</li><li>memory</li><li>device</li></ul><p><strong>Monitor模块</strong></p><blockquote><p>监控客户计算机的运行状态而引入的</p></blockquote><ul><li>负责与GNU/Linux进行交互（读入客户程序）</li><li>有调试器的功能</li></ul><p>如果没有monitor，对NEMU的调试将极为困难</p><h4 id="NEMU源文件组织"><a href="#NEMU源文件组织" class="headerlink" title="NEMU源文件组织"></a>NEMU源文件组织</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">nemu</span><br><span class="line">├── configs                    # 预先提供的一些配置文件</span><br><span class="line">├── include                    # 存放全局使用的头文件</span><br><span class="line">│   ├── common.h               # 公用的头文件</span><br><span class="line">│   ├── config                 # 配置系统生成的头文件, 用于维护配置选项更新的时间戳</span><br><span class="line">│   ├── cpu</span><br><span class="line">│   │   ├── cpu.h</span><br><span class="line">│   │   ├── decode.h           # 译码相关</span><br><span class="line">│   │   ├── difftest.h</span><br><span class="line">│   │   └── ifetch.h           # 取指相关</span><br><span class="line">│   ├── debug.h                # 一些方便调试用的宏</span><br><span class="line">│   ├── device                 # 设备相关</span><br><span class="line">│   ├── difftest-def.h</span><br><span class="line">│   ├── generated</span><br><span class="line">│   │   └── autoconf.h         # 配置系统生成的头文件, 用于根据配置信息定义相关的宏</span><br><span class="line">│   ├── isa.h                  # ISA相关</span><br><span class="line">│   ├── macro.h                # 一些方便的宏定义</span><br><span class="line">│   ├── memory                 # 访问内存相关</span><br><span class="line">│   └── utils.h</span><br><span class="line">├── Kconfig                    # 配置信息管理的规则</span><br><span class="line">├── Makefile                   # Makefile构建脚本</span><br><span class="line">├── README.md</span><br><span class="line">├── resource                   # 一些辅助资源</span><br><span class="line">├── scripts                    # Makefile构建脚本</span><br><span class="line">│   ├── build.mk</span><br><span class="line">│   ├── config.mk</span><br><span class="line">│   ├── git.mk                 # git版本控制相关</span><br><span class="line">│   └── native.mk</span><br><span class="line">├── src                        # 源文件</span><br><span class="line">│   ├── cpu</span><br><span class="line">│   │   └── cpu-exec.c         # 指令执行的主循环</span><br><span class="line">│   ├── device                 # 设备相关</span><br><span class="line">│   ├── engine</span><br><span class="line">│   │   └── interpreter        # 解释器的实现</span><br><span class="line">│   ├── filelist.mk</span><br><span class="line">│   ├── isa                    # ISA相关的实现</span><br><span class="line">│   │   ├── mips32</span><br><span class="line">│   │   ├── riscv32</span><br><span class="line">│   │   ├── riscv64</span><br><span class="line">│   │   └── x86</span><br><span class="line">│   ├── memory                 # 内存访问的实现</span><br><span class="line">│   ├── monitor</span><br><span class="line">│   │   ├── monitor.c</span><br><span class="line">│   │   └── sdb                # 简易调试器</span><br><span class="line">│   │       ├── expr.c         # 表达式求值的实现</span><br><span class="line">│   │       ├── sdb.c          # 简易调试器的命令处理</span><br><span class="line">│   │       └── watchpoint.c   # 监视点的实现</span><br><span class="line">│   ├── nemu-main.c            # 你知道的...</span><br><span class="line">│   └── utils                  # 一些公共的功能</span><br><span class="line">│       ├── log.c              # 日志文件相关</span><br><span class="line">│       ├── rand.c</span><br><span class="line">│       ├── state.c</span><br><span class="line">│       └── timer.c</span><br><span class="line">└── tools                      # 一些工具</span><br><span class="line">    ├── fixdep                 # 依赖修复, 配合配置系统进行使用</span><br><span class="line">    ├── gen-expr</span><br><span class="line">    ├── kconfig                # 配置系统</span><br><span class="line">    ├── kvm-diff</span><br><span class="line">    ├── qemu-diff</span><br><span class="line">    └── spike-diff</span><br></pre></td></tr></table></figure><ul><li><p>为了支持不同的ISA, 框架代码把NEMU分成两部分: ISA无关的基本框架和ISA相关的具体实现。NEMU把ISA相关的代码专门放在<code>nemu/src/isa/</code>目录下, 并通过<code>nemu/include/isa.h</code>提供ISA相关API的声明. 这样以后, <code>nemu/src/isa/</code><strong>之外</strong>的其它代码就展示了<strong>NEMU的基本框架</strong>. </p></li><li><p>体现<strong>抽象的思想</strong>: 框架代码将ISA之间的差异<strong>抽象成API</strong>, 基本框架会调用这些API, 从而无需关心ISA的具体细节. 如果你将来打算选择一个不同的ISA来进行二周目的攻略, 你就能明显体会到抽象的好处了: <strong>基本框架的代码完全不用修改</strong>!</p></li><li><p>NEMU ISA相关说明文档：<a href="https://nju-projectn.github.io/ics-pa-gitbook/ics2022/nemu-isa-api.html">这里</a></p></li></ul><h3 id="配置系统和项目构建"><a href="#配置系统和项目构建" class="headerlink" title="配置系统和项目构建"></a>配置系统和项目构建</h3><h4 id="配置系统kconfig"><a href="#配置系统kconfig" class="headerlink" title="配置系统kconfig"></a>配置系统kconfig</h4><blockquote><p>为什么要使用配置系统？</p></blockquote><p>可配置选项的数量可能会非常多, 而且配置选项之间可能会存在关联。比如打开配置选项A之后, 配置选项B就必须是某个值. 直接让开发者去管理这些配置选项是很容易出错的, 比如修改选项A之后, 可能会忘记修改和选项A有关联的选项B. 配置系统的出现则是为了解决这个问题.</p><p>NEMU中的配置系统位于<code>nemu/tools/kconfig</code></p><p>kconfig定义了一套简单的语言, 开发者可以使用这套语言来编写”配置描述文件”.</p><p> 在”配置描述文件”中, 开发者可以描述:</p><ul><li>配置选项的属性, 包括类型, 默认值等</li><li>不同配置选项之间的关系</li><li>配置选项的层次关系</li></ul><p>当你键入<code>make menuconfig</code>的时候, 背后其实发生了如下事件:</p><ul><li><p>检查<code>nemu/tools/kconfig/build/mconf</code>程序是否存在, 若不存在, 则编译并生成<code>mconf</code></p></li><li><p>检查<code>nemu/tools/kconfig/build/conf</code>程序是否存在, 若不存在, 则编译并生成<code>conf</code></p></li><li><p>运行命令<code>mconf nemu/Kconfig</code>, 此时<code>mconf</code>将会解析<code>nemu/Kconfig</code>中的描述, 以菜单树的形式展示各种配置选项, 供开发者进行选择</p></li><li><p>退出菜单时, <code>mconf</code>会把开发者选择的结果记录到<code>nemu/.config</code>文件中</p></li><li><p>运行命令<code>conf --syncconfig nemu/Kconfig</code>, 此时<code>conf</code>将会解析<code>nemu/Kconfig</code>中的描述, 并读取选择结果<code>nemu/.config</code>, 结合两者来生成如下文件:</p><ul><li>可以被包含到C代码中的宏定义(<code>nemu/include/generated/autoconf.h</code>)</li><li>可以被包含到Makefile中的变量定义(<code>nemu/include/config/auto.conf</code>)</li><li>可以被包含到Makefile中的, 和”配置描述文件”相关的依赖规则(<code>nemu/include/config/auto.conf.cmd</code>), 为了阅读代码, 我们可以不必关心它</li><li>通过时间戳来维护配置选项变化的目录树<code>nemu/include/config/</code>, 它会配合另一个工具<code>nemu/tools/fixdep</code>来使用, 用于在更新配置选项后节省不必要的文件编译, 为了阅读代码, 我们可以不必关心它。</li></ul></li></ul><p>所以, 目前我们只需要关心配置系统生成的如下文件:</p><ul><li><code>nemu/include/generated/autoconf.h</code>, 阅读C代码时使用</li><li><code>nemu/include/config/auto.conf</code>, 阅读Makefile时使用</li></ul><h4 id="项目构建和Makefile"><a href="#项目构建和Makefile" class="headerlink" title="项目构建和Makefile"></a>项目构建和Makefile</h4><p><strong>与配置系统进行关联</strong></p><p>通过包含<code>nemu/include/config/auto.conf</code>, 与kconfig生成的变量进行关联. 因此在通过menuconfig更新配置选项后, Makefile的行为可能也会有所变化.</p><p><strong>文件列表</strong></p><p>通过filelist决定最终参与编译的源文件，它们会根据menuconfig的配置对如下4个变量进行维护:</p><ul><li><code>SRCS-y</code> - 参与编译的源文件的候选集合</li><li><code>SRCS-BLACKLIST-y</code> - 不参与编译的源文件的黑名单集合</li><li><code>DIRS-y</code> - 参与编译的目录集合, 该目录下的所有文件都会被加入到<code>SRCS-y</code>中</li><li><code>DIRS-BLACKLIST-y</code> - 不参与编译的目录集合, 该目录下的所有文件都会被加入到<code>SRCS-BLACKLIST-y</code>中</li></ul><p>Makefile会包含项目中的所有<code>filelist.mk</code>文件, 对上述4个变量的追加定义进行汇总, 最终会过滤出在<code>SRCS-y</code>中但不在<code>SRCS-BLACKLIST-y</code>中的源文件, 来作为最终<strong>参与编译的源文件的集合</strong>.</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Include all filelist.mk to merge file lists</span></span><br><span class="line">FILELIST_MK = <span class="variable">$(<span class="built_in">shell</span> find ./src -name "filelist.mk")</span></span><br><span class="line"><span class="keyword">include</span> <span class="variable">$(FILELIST_MK)</span></span><br><span class="line"><span class="comment"># Filter out directories and files in blacklist to obtain the final set of source files</span></span><br><span class="line">DIRS-BLACKLIST-y += $(DIRS-BLACKLIST)</span><br><span class="line">SRCS-BLACKLIST-y += $(SRCS-BLACKLIST) <span class="variable">$(<span class="built_in">shell</span> find $(DIRS-BLACKLIST-y)</span> -name <span class="string">"*.c"</span>)</span><br><span class="line">SRCS-y += <span class="variable">$(<span class="built_in">shell</span> find $(DIRS-y)</span> -name <span class="string">"*.c"</span>)</span><br><span class="line">SRCS = <span class="variable">$(<span class="built_in">filter</span>-out $(SRCS-BLACKLIST-y)</span>,$(SRCS-y))</span><br></pre></td></tr></table></figure><p>上述4个变量还可以与menuconfig的配置结果中的布尔选项进行关联, 例如<code>DIRS-BLACKLIST-$(CONFIG_TARGET_AM) += src/monitor/sdb</code>, 当我们在menuconfig中选择了<code>TARGET_AM</code>相关的布尔选项时, kconfig最终会在<code>nemu/include/config/auto.conf</code>中生成形如<code>CONFIG_TARGET_AM=y</code>的代码, 对变量进行展开后将会得到<code>DIRS-BLACKLIST-y += src/monitor/sdb</code>; 当我们在menuconfig中未选择<code>TARGET_AM</code>相关的布尔选项时, kconfig将会生成形如<code>CONFIG_TARGET_AM=n</code>的代码, 或者未对<code>CONFIG_TARGET_AM</code>进行定义, 此时将会得到<code>DIRS-BLACKLIST-n += src/monitor/sdb</code>, 或者<code>DIRS-BLACKLIST- += src/monitor/sdb</code>, 这两种情况都不会影响<code>DIRS-BLACKLIST-y</code>的值, 从而实现了如下效果:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在menuconfig中选中TARGET_AM时, nemu/src/monitor/sdb目录下的所有文件都不会参与编译.</span><br></pre></td></tr></table></figure><p><strong>编译和链接</strong></p><p>Makefile的编译规则在<code>nemu/scripts/build.mk</code>中定义:</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compilation patterns</span></span><br><span class="line"><span class="variable">$(OBJ_DIR)</span>/%.o: %.c</span><br><span class="line">@echo + CC <span class="variable">$&lt;</span></span><br><span class="line">@mkdir -p <span class="variable">$(<span class="built_in">dir</span> <span class="variable">$@</span>)</span></span><br><span class="line">@<span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> -c -o <span class="variable">$@</span> <span class="variable">$&lt;</span></span><br><span class="line"><span class="variable">$(<span class="built_in">call</span> call_fixdep, $(@:.o=.d)</span>, <span class="variable">$@</span>)</span><br><span class="line"></span><br><span class="line"><span class="variable">$(OBJ_DIR)</span>/%.o: %.cc</span><br><span class="line">@echo + CXX <span class="variable">$&lt;</span></span><br><span class="line">@mkdir -p <span class="variable">$(<span class="built_in">dir</span> <span class="variable">$@</span>)</span></span><br><span class="line">@<span class="variable">$(CXX)</span> <span class="variable">$(CFLAGS)</span> <span class="variable">$(CXXFLAGS)</span> -c -o <span class="variable">$@</span> <span class="variable">$&lt;</span></span><br><span class="line"><span class="variable">$(<span class="built_in">call</span> call_fixdep, $(@:.o=.d)</span>, <span class="variable">$@</span>)</span><br></pre></td></tr></table></figure><blockquote><p>Makefile 中的 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="2.389ex" height="2.034ex" role="img" focusable="false" viewBox="0 -705 1056 899"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="40" d="M56 347Q56 429 86 498T164 612T270 680T386 705Q522 705 622 603T722 349Q722 126 608 126Q541 126 513 176Q512 177 512 179T510 182L509 183Q508 183 503 177T487 163T464 146T429 132T385 126Q311 126 251 186T190 347Q190 448 251 508T385 568Q426 568 460 548T509 511T531 479H555Q580 479 582 478Q586 477 587 468Q588 454 588 338V260Q588 200 593 182T619 163Q641 163 655 178T674 223T680 273T682 325V330Q682 426 647 500Q611 569 544 618T388 668Q271 668 184 577T96 347Q96 216 180 121T396 26Q421 26 446 28T493 34T535 43T573 52T605 63T629 72T647 80T657 84H716Q722 78 722 74Q722 65 675 45T547 7T392 -11Q255 -11 156 90T56 347ZM274 347Q274 266 308 214T390 162Q420 162 449 182T498 235L504 245V449L498 459Q453 532 387 532Q347 532 311 483T274 347Z"></path></g></g><g data-mml-node="mo" transform="translate(778,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g></g></svg></mjx-container>^, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex" xmlns="http://www.w3.org/2000/svg" width="2.389ex" height="1.661ex" role="img" focusable="false" viewBox="0 -540 1056 734"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path></g><g data-mml-node="mo" transform="translate(778,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g></g></g></svg></mjx-container>? 符號</p></blockquote><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$@</span>  表示目標文件</span><br><span class="line"><span class="variable">$^</span>  表示所有的依賴文件</span><br><span class="line"><span class="variable">$&lt;</span>  表示第一個依賴文件</span><br><span class="line"><span class="variable">$?</span>  表示比目標還要新的依賴文件列表</span><br></pre></td></tr></table></figure><ul><li>call_fixdep 调用用于生成更合理的依赖关系</li></ul><p>链接命令：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$(BINARY)</span>: <span class="variable">$(OBJS)</span> <span class="variable">$(ARCHIVES)</span></span><br><span class="line">@echo + LD <span class="variable">$@</span></span><br><span class="line">@<span class="variable">$(LD)</span> -o <span class="variable">$@</span> <span class="variable">$(OBJS)</span> <span class="variable">$(LDFLAGS)</span> <span class="variable">$(ARCHIVES)</span> <span class="variable">$(LIBS)</span></span><br></pre></td></tr></table></figure><h3 id="准备第一个客户程序"><a href="#准备第一个客户程序" class="headerlink" title="准备第一个客户程序"></a>准备第一个客户程序</h3><blockquote><p>NEMU is a process that execute guest process</p></blockquote><p>We need to read guest process into our computer, monitor is responsible for this part.</p><p>When NEMU is starting, it will first call init_monitor() to do some initialization work.(在<code>nemu/src/monitor/monitor.c</code>中定义) </p><blockquote><p>kconfig generates 宏</p></blockquote><p>kconfig will define some CONFIG_xxx in ‘nemu/include/generated/autoconf.h’ according to the configuration we made in <code>kconfig</code>.</p><p>we can also test these defines using <strong>conditional compiling</strong>. For example, if <code>CONFIG_DEVICE</code> is not defined, device related code will not be compiled.</p><p>To write more compact code, we define a lot of test in <code>nemu/inlcude/generated/autoconf.h</code>:<code>IFDEF(CONFIG_DEVICE, init_device());</code> 而<code>MUXDEF(CONFIG_TRACE, "ON", "OFF")</code>则表示, 如果定义了<code>CONFIG_TRACE</code>, 则预处理结果为<code>"ON"</code>(<code>"OFF"</code>在预处理后会消失), 否则预处理结果为<code>"OFF"</code>.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_monitor</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>{</span><br><span class="line">  <span class="comment">/* Perform some global initialization. */</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Parse arguments. */</span></span><br><span class="line">  <span class="built_in">parse_args</span>(argc, argv);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Set random seed. */</span></span><br><span class="line">  <span class="built_in">init_rand</span>();j</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Open the log file. */</span></span><br><span class="line">  <span class="built_in">init_log</span>(log_file);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Initialize memory. */</span></span><br><span class="line">  <span class="built_in">init_mem</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Initialize devices. */</span></span><br><span class="line">  <span class="built_in">IFDEF</span>(CONFIG_DEVICE, <span class="built_in">init_device</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Perform ISA dependent initialization. */</span></span><br><span class="line">  <span class="built_in">init_isa</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Load the image to memory. This will overwrite the built-in image. */</span></span><br><span class="line">  <span class="keyword">long</span> img_size = <span class="built_in">load_img</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Initialize differential testing. */</span></span><br><span class="line">  <span class="built_in">init_difftest</span>(diff_so_file, img_size, difftest_port);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Initialize the simple debugger. */</span></span><br><span class="line">  <span class="built_in">init_sdb</span>();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">IFDEF</span>(CONFIG_ITRACE, <span class="built_in">init_disasm</span>(</span><br><span class="line">    <span class="built_in">MUXDEF</span>(CONFIG_ISA_x86,     <span class="string">"i686"</span>,</span><br><span class="line">    <span class="built_in">MUXDEF</span>(CONFIG_ISA_mips32,  <span class="string">"mipsel"</span>,</span><br><span class="line">    <span class="built_in">MUXDEF</span>(CONFIG_ISA_riscv32, <span class="string">"riscv32"</span>,</span><br><span class="line">    <span class="built_in">MUXDEF</span>(CONFIG_ISA_riscv64, <span class="string">"riscv64"</span>, <span class="string">"bad"</span>)))) <span class="string">"-pc-linux-gnu"</span></span><br><span class="line">  ));</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Display welcome message. */</span></span><br><span class="line">  <span class="built_in">welcome</span>();</span><br><span class="line">}</span><br></pre></td></tr></table></figure><ul><li>We can see that in the i<code>nit_monitor()</code>, all lines are  functions. And in <code>parse_args()</code>:</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">parse_args</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>{</span><br><span class="line">  <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">option</span> <span class="title">table</span>[] =</span> {</span><br><span class="line">    {<span class="string">"batch"</span>    , no_argument      , <span class="literal">NULL</span>, <span class="string">'b'</span>},</span><br><span class="line">    {<span class="string">"log"</span>      , required_argument, <span class="literal">NULL</span>, <span class="string">'l'</span>},</span><br><span class="line">    {<span class="string">"diff"</span>     , required_argument, <span class="literal">NULL</span>, <span class="string">'d'</span>},</span><br><span class="line">    {<span class="string">"port"</span>     , required_argument, <span class="literal">NULL</span>, <span class="string">'p'</span>},</span><br><span class="line">    {<span class="string">"help"</span>     , no_argument      , <span class="literal">NULL</span>, <span class="string">'h'</span>},</span><br><span class="line">    {<span class="number">0</span>          , <span class="number">0</span>                , <span class="literal">NULL</span>,  <span class="number">0</span> },</span><br><span class="line">  };</span><br><span class="line">  <span class="keyword">int</span> o;</span><br><span class="line">  <span class="keyword">while</span> ( (o = getopt_long(argc, argv, <span class="string">"-bhl:d:p:"</span>, table, <span class="literal">NULL</span>)) != <span class="number">-1</span>) {</span><br><span class="line">    <span class="keyword">switch</span> (o) {</span><br><span class="line">      <span class="keyword">case</span> <span class="string">'b'</span>: sdb_set_batch_mode(); <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">'p'</span>: <span class="built_in">sscanf</span>(optarg, <span class="string">"%d"</span>, &amp;difftest_port); <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">'l'</span>: log_file = optarg; <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">'d'</span>: diff_so_file = optarg; <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span>: img_file = optarg; <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Usage: %s [OPTION...] IMAGE [args]\n\n"</span>, argv[<span class="number">0</span>]);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t-b,--batch              run with batch mode\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t-l,--log=FILE           output log to FILE\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t-d,--diff=REF_SO        run DiffTest with reference REF_SO\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t-p,--port=PORT          run DiffTest with port PORT\n"</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    }</span><br><span class="line">  }</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure><blockquote><p>some notes about getopt_long()</p></blockquote><ul><li><p>getopt_long() works like getopt() except that it also accept long options :”–”.</p></li><li><p>longopts is a pointer to the first element of an array of struct option:</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">option</span>{</span></span><br><span class="line">    cosnt <span class="keyword">char</span> *name; <span class="comment">// name</span></span><br><span class="line">    <span class="keyword">int</span> has_arg;<span class="comment">// 0: no_argument; 1: required_argument; 2: optional_argument</span></span><br><span class="line">    <span class="keyword">int</span> *flag;<span class="comment">// NULL: getopt_long() return val; otherwise: getopt_long() return 0, flag points to a variable set to val if the option is found.</span></span><br><span class="line">    <span class="keyword">int</span> val; <span class="comment">// the value to return</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>The last element of the array has to be filled with zeros</p><p>接下来monitor会调用<code>init_isa()</code>函数(在<code>nemu/src/isa/$ISA/init.c</code>中定义), 来进行一些ISA相关的初始化工作.</p><h4 id="init-isa-函数的第一项工作：读入客户程序到内存里"><a href="#init-isa-函数的第一项工作：读入客户程序到内存里" class="headerlink" title="init_isa()函数的第一项工作：读入客户程序到内存里"></a><code>init_isa()</code>函数的第一项工作：读入客户程序到内存里</h4><ol><li>客户程序是什么？：程序本身是ISA相关的，因此内置程序放在<code>nemu/src/isa/$ISA/init.c</code>中。</li><li>内存是什么？：一段连续的地址空间，按字节编址（一个内存位置存放一个字节的数据）。 在C语言中我们就很自然地使用一个<code>uint8_t</code>类型的数组来对内存进行模拟。NEMU默认为客户计算机提供128MB的物理内存(见<code>nemu/src/memory/paddr.c</code>中定义的<code>pmem</code>)</li><li>需要将客户程序读入到内存的什么位置？</li></ol><p>约定. 具体地, 我们让monitor直接把客户程序读入到一个固定的内存位置<code>RESET_VECTOR</code>。其值在<code>nemu/include/memory/paddr.h</code>中定义.</p><blockquote><p>BIOS和计算机启动</p></blockquote><p>在真实的计算机系统中, 计算机启动后首先会把控制权交给BIOS, BIOS经过一系列初始化工作之后, 再从磁盘中将有意义的程序读入内存中执行.对这个过程的模拟需要了解很多超出本课程范围的细节, 我们在PA中做了简化: 采取约定的方式让CPU直接从约定的内存位置开始执行.</p><blockquote><p>初探操作系统启动</p></blockquote><p>如何得知操作系统在启动时，做了什么？</p><ul><li>在linux中，<code>sudo dmesg</code>可以输出操作系统的启动日志</li></ul><h4 id="init-isa-函数的第二项工作：是初始化寄存器"><a href="#init-isa-函数的第二项工作：是初始化寄存器" class="headerlink" title="init_isa()函数的第二项工作：是初始化寄存器"></a><code>init_isa()</code>函数的第二项工作：是初始化寄存器</h4><p> 在C语言中我们就很自然地使用相应的结构体来描述CPU的寄存器结构. </p><p>不同ISA的寄存器结构也各不相同, 为此我们把寄存器结构体<code>CPU_state</code>的定义放在<code>nemu/src/isa/$ISA/include/isa-def.h</code>中, 并在<code>nemu/src/cpu/cpu-exec.c</code>中定义一个全局变量<code>cpu</code>.</p><p>初始化寄存器的一个重要工作就是设置<code>cpu.pc</code>的初值, 我们需要将它设置成刚才加载客户程序的内存位置, 这样就可以让CPU从我们约定的内存位置开始执行客户程序了</p><p><strong>物理内存的起始地址</strong></p><p>x86的物理内存是从0开始编址的</p><p>例如mips32和riscv32的物理地址均从<code>0x80000000</code>开始。因此对于上面的两个，其CONFIG_MBASE，将会被定义为：<code>0x80000000</code>，将来CPU访问内存时，我们会将要访问的内存<strong>地址映射</strong>到**<code>pmem</code>中的相应偏移位置**，这是通过<code>nemu/src/memory/paddr.c</code>中的<code>guest_to_host()</code>函数实现的.</p><p>Monitor读入客户程序并对寄存器进行初始化后, 这时内存的布局如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">pmem:</span><br><span class="line"></span><br><span class="line">CONFIG_MBASE      RESET_VECTOR</span><br><span class="line">      |                 |</span><br><span class="line">      v                 v</span><br><span class="line">      -----------------------------------------------</span><br><span class="line">      |                 |                  |</span><br><span class="line">      |                 |    guest prog    |</span><br><span class="line">      |                 |                  |</span><br><span class="line">      -----------------------------------------------</span><br><span class="line">                        ^</span><br><span class="line">                        |</span><br><span class="line">                       pc</span><br></pre></td></tr></table></figure><h3 id="运行第一个客户程序"><a href="#运行第一个客户程序" class="headerlink" title="运行第一个客户程序"></a>运行第一个客户程序</h3><p>main()函数包含了monitor的初始化，并且会继续调用<code>engine_start</code>函数。代码会进入简易调试器的主循环。</p><p>键入c后，执行主循环<code>cpu_exec</code>， 它又会调用<code>execute()</code>。后者模拟了CPU的工作方式。它又会执行<code>exec_once()</code>：让CPU执行当前PC指向的一条指令，然后更新PC。</p><p><strong>不同的ISA有着不同的指令格式和含义</strong>, 因此<strong>执行指令的代码自然是ISA相关的</strong>. 这部分代码位于<code>nemu/src/isa/$ISA/inst.c</code>. 关于指令执行的详细说明需要涉及很多细节, 目前你无需关心, 我们将会在PA2中进行说明.</p><p><strong>何时退出指令的循环？</strong></p><ul><li><p>达到要求的循环次数.</p></li><li><p>客户程序执行了nemu_trap指令. 这是一条虚构的特殊指令, 它是为了在NEMU中让客户程序指示执行的结束而加入的, NEMU在ISA手册中选择了一些用于调试的指令, 并将nemu_trap的特殊含义赋予它们.</p><ul><li><p> 例如在riscv32的手册中, NEMU选择了ebreak指令来充当nemu_trap. 为了表示客户程序是否成功结束, nemu_trap指令还会接收一个表示结束状态的参数. 当客户程序执行了这条指令之后, NEMU将会根据这个结束状态参数来设置NEMU的结束状态, 并根据不同的状态输出不同的结束信息, 主要包括</p></li><li><p><code>HIT GOOD TRAP</code> - 客户程序正确地结束执行</p></li><li><p><code>HIT BAD TRAP</code> - 客户程序错误地结束执行</p></li><li><p><code>ABORT</code> - 客户程序意外终止, 并未结束执行</p></li></ul></li></ul><blockquote><p>怎么读代码？</p></blockquote><p>有没有工具能够帮你模拟这个巨大的状态机呢? 这时我们在PA0里面提到的一个工具就派上用场了, 它就是GDB. 在GDB中, 我们可以通过单步执行的方式让程序一次执行一条指令, 相当于让状态机一次只前进一步, 这样我们就可以观察程序任意时刻的状态了! 而且状态机前进的轨迹就是程序执行的真实顺序, 于是你就可以一边运行程序一边理解程序的行为了. 这对于一些指针相关的代码有着不错的效果, 尤其是函数指针, 因为你从静态代码上很可能看不出来程序运行的时候这个指针会指向哪个函数.</p><p>GDB还自带一个叫TUI的简单界面. 在一个高度较高的窗口中运行GDB后, 输入<code>layout split</code>就可以切换到TUI, 这样你就可以同时从源代码和指令的角度来观察程序的行为了. 不过为了看到源代码, 你还需要在编译NEMU时添加GDB调试信息, 具体操作见下面的提示框. 如果你想了解TUI的更多内容, STFW.</p><p>为了帮助你更高效地RTFSC, 你最好通过RTFM和STFW多认识GDB的一些命令和操作, 比如:</p><ul><li>单步执行进入你感兴趣的函数</li><li>单步执行跳过你不感兴趣的函数(例如库函数)</li><li>运行到函数末尾</li><li>打印变量或寄存器的值</li><li>扫描内存</li><li>查看调用栈</li><li>设置断点</li><li>设置监视点</li></ul><p> <strong>为NEMU编译时添加GDB调试信息</strong></p><p>menuconfig已经为大家准备好相应选项了, 你只需要打开它:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Build Options</span><br><span class="line">  [*] Enable debug information</span><br></pre></td></tr></table></figure><p>然后清除编译结果并重新编译即可. 尝试阅读相关代码, 理解开启上述menuconfig选项后会导致编译NEMU时的选项产生什么变化.</p><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/image-20230406194300166.png" alt="image-20230406194300166" style="zoom:50%;"><ul><li>ggdb3指的是debug的level为3级，会输出一些额外的信息</li><li>Og指的是优化debug体验，会减少一些优化级别，以加快编译</li></ul><h2 id="基础设施-简易调试器"><a href="#基础设施-简易调试器" class="headerlink" title="基础设施: 简易调试器"></a>基础设施: 简易调试器</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PA1-notes&quot;&gt;&lt;a href=&quot;#PA1-notes&quot; class=&quot;headerlink&quot; title=&quot;PA1 notes&quot;&gt;&lt;/a&gt;PA1 notes&lt;/h1&gt;&lt;h2 id=&quot;Some-preparations&quot;&gt;&lt;a href=&quot;#Some-pre</summary>
      
    
    
    
    <category term="ics2022" scheme="http://example.com/categories/ics2022/"/>
    
    <category term="pa作业" scheme="http://example.com/categories/ics2022/pa%E4%BD%9C%E4%B8%9A/"/>
    
    
    <category term="PA" scheme="http://example.com/tags/PA/"/>
    
    <category term="ics2022" scheme="http://example.com/tags/ics2022/"/>
    
  </entry>
  
  <entry>
    <title>混合精度训练初探</title>
    <link href="http://example.com/2023/08/05/projects/huawei%20project/apex/"/>
    <id>http://example.com/2023/08/05/projects/huawei%20project/apex/</id>
    <published>2023-08-05T03:14:26.384Z</published>
    <updated>2023-08-05T03:14:26.384Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自动半精度（混合精度）训练"><a href="#自动半精度（混合精度）训练" class="headerlink" title="自动半精度（混合精度）训练"></a>自动半精度（混合精度）训练</h1><h2 id="一-apex-与-amp"><a href="#一-apex-与-amp" class="headerlink" title="一. apex 与 amp"></a>一. apex 与 amp</h2><p>apex是英伟达构建的一个pytorch扩展，amp为其中提供混合精度的库</p><h2 id="二-fp16的问题"><a href="#二-fp16的问题" class="headerlink" title="二. fp16的问题"></a>二. fp16的问题</h2><h3 id="2-1-数据溢出（下溢）"><a href="#2-1-数据溢出（下溢）" class="headerlink" title="2.1 数据溢出（下溢）"></a>2.1 数据溢出（下溢）</h3><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204121831277.png" alt="image-20220412183129207" style="zoom: 67%;"><h3 id="2-2-舍入误差"><a href="#2-2-舍入误差" class="headerlink" title="2.2 舍入误差"></a>2.2 舍入误差</h3><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204121831120.jpeg" alt="preview" style="zoom: 50%;"><h2 id="三-解决方法"><a href="#三-解决方法" class="headerlink" title="三. 解决方法"></a>三. 解决方法</h2><h3 id="3-1-FP32权重备份"><a href="#3-1-FP32权重备份" class="headerlink" title="3.1 FP32权重备份"></a>3.1 FP32权重备份</h3><img src="https://raw.githubusercontent.com/coelien/image-hosting/master/img/202204121835152.jpeg" alt="preview" style="zoom: 67%;"><p>只有更新的时候采用F32</p><h3 id="3-2-loss-scale损失放大"><a href="#3-2-loss-scale损失放大" class="headerlink" title="3.2 loss scale损失放大"></a>3.2 loss scale损失放大</h3><p>根据链式法则，可以通过放大loss从而放大梯度来解决舍入误差</p><h3 id="3-3-提高算数精度"><a href="#3-3-提高算数精度" class="headerlink" title="3.3 提高算数精度"></a>3.3 提高算数精度</h3><p><strong>利用fp16进行乘法和存储，利用fp32来进行加法计算</strong>，来减少加法过程中的舍入误差，保证精度不损失</p><h2 id="四-快速使用"><a href="#四-快速使用" class="headerlink" title="四. 快速使用"></a>四. 快速使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line">model, optimizer = amp.initialize(model, optimizer, opt_level=<span class="string">"O1"</span>,loss_scale=<span class="number">128.0</span>) <span class="comment"># 这里是“欧一”，不是“零一”</span></span><br><span class="line"><span class="comment"># loss.backward() becomes:</span></span><br><span class="line"><span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">    scaled_loss.backward()</span><br></pre></td></tr></table></figure><p>opt_level 优先使用O2，若无法收敛则使用O1</p><p>如下是两个pytorch原生支持的apex混合精度和nvidia apex的loss scaler的具体实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line">    has_apex = <span class="literal">True</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"successfully import amp"</span>)</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    amp = <span class="literal">None</span></span><br><span class="line">    has_apex = <span class="literal">False</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"can not import amp from apex"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ApexScaler</span>:</span></span><br><span class="line">    state_dict_key = <span class="string">"amp"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, loss, optimizer, clip_grad=<span class="literal">None</span>, parameters=<span class="literal">None</span>, create_graph=<span class="literal">False</span></span>):</span></span><br><span class="line">        <span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">            scaled_loss.backward(create_graph=create_graph)</span><br><span class="line">        <span class="keyword">if</span> clip_grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), clip_grad)</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'state_dict'</span> <span class="keyword">in</span> amp.__dict__:</span><br><span class="line">            <span class="keyword">return</span> amp.state_dict()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">'load_state_dict'</span> <span class="keyword">in</span> amp.__dict__:</span><br><span class="line">            amp.load_state_dict(state_dict)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NativeScaler</span>:</span></span><br><span class="line">    state_dict_key = <span class="string">"amp_scaler"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># GradScaler对象用来自动做梯度缩放</span></span><br><span class="line">        self._scaler = torch.cuda.amp.GradScaler()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, loss, optimizer, clip_grad=<span class="literal">None</span>, parameters=<span class="literal">None</span>, create_graph=<span class="literal">False</span></span>):</span></span><br><span class="line">        self._scaler.scale(loss).backward(create_graph=create_graph)</span><br><span class="line">        <span class="keyword">if</span> clip_grad <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> parameters <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">            self._scaler.unscale_(optimizer)  <span class="comment"># unscale the gradients of optimizer's assigned params in-place</span></span><br><span class="line">            torch.nn.utils.clip_grad_norm_(parameters, clip_grad)</span><br><span class="line">        self._scaler.step(optimizer)</span><br><span class="line">        self._scaler.update()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">state_dict</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self._scaler.state_dict()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_state_dict</span>(<span class="params">self, state_dict</span>):</span></span><br><span class="line">        self._scaler.load_state_dict(state_dict)</span><br></pre></td></tr></table></figure><p>apex + 分布式：</p><p>apex ddp默认使用当前设备，torch ddp需要手动指定运行的设备，用法和torch类似，</p><p>但需注意</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model, optimizer = amp.initialize(model, optimizer, flags...)</span><br></pre></td></tr></table></figure><p>应在</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = apex.parallel.DistributedDataParallel(model)</span><br></pre></td></tr></table></figure><p>之前</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;自动半精度（混合精度）训练&quot;&gt;&lt;a href=&quot;#自动半精度（混合精度）训练&quot; class=&quot;headerlink&quot; title=&quot;自动半精度（混合精度）训练&quot;&gt;&lt;/a&gt;自动半精度（混合精度）训练&lt;/h1&gt;&lt;h2 id=&quot;一-apex-与-amp&quot;&gt;&lt;a href</summary>
      
    
    
    
    <category term="华为项目" scheme="http://example.com/categories/%E5%8D%8E%E4%B8%BA%E9%A1%B9%E7%9B%AE/"/>
    
    
    <category term="混合精度" scheme="http://example.com/tags/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6/"/>
    
    <category term="amp" scheme="http://example.com/tags/amp/"/>
    
  </entry>
  
</feed>
