[{"title":"coding笔记： 动态规划","url":"/2023/08/05/coding-solution/DP/","content":"动态规划基础理解动态规划的思考方式\n从集合的角度理解DP问题\n\n\n状态表示 f(i,j)（存的是所有选法的集合的最大值），考虑清楚需要几维来表示我们的问题\n\n集合：每一个状态都是表明一个集合，在背包问题里表示所有选法的集合\n条件：\n\n只考虑前i个物品\n总体积不超过 j\n\n\n属性：集合的最大值，最小值，元素数量\n\n\n\n状态计算 ，如何将每个状态计算出来\n\n目标：求f(N,V)\n\n状态计算一般表示集合的划分：把当前集合划分为若干个更小的子集，使得每一个子集我们都可以由前面更小的状态计算得到\n例如f(i,j)可以包含两类：\n\n左边类是不包含第i个物品的选法\n右边类是包含第i个物品的选法\n\n实际的最大值是两类取一个max\n\n\n\n\nDP问题的优化一般只是等价变形，所以写出朴素解法十分重要\nDP问题一定要结合题目来理解，上面的思考方式就像是骨架，根据具体问题填补具体的血肉\n背包模型01背包问题什么是01背包？\n\n每件物品最多只能用一次\n\n在背包容量的范围内如何挑选物品，让总价值最大\n朴素做法\n//枚举所有状态f[0,0]~f[n,m]//其中f[0,0-m]表示考虑0件物品，总体积不超过0~m的最大价值是多少//因此只需从1开始遍历即可for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m;j++){        f[i][j] = f[i-1][j];        if(j&gt;=v[i]) f[i][j] = max(f[i][j],f[i-1][j-v[i]] + w[i]);    }\n\n一维做法\n\n第i层的状态只依赖于第i-1层；不超过的总体积j只依赖于&lt;=j的状态，因此可以优化到一维来做\n\nint f[N];//直接去掉一维for(int i=1;i&lt;=n;i++)    for(int j=m;j&gt;=v[i];j--){        f[j] = max(f[j],f[j-v[i]]+w[i]);    }\n\n完全背包问题\n 每件物品可以用无限次\n\n解题思路\n分成若干组，分成k类：\n\n\n不妨设第i个物品选了k个\n曲线救国：\n\n去掉k个物品i\n求Max，f[i-1,j-k*v[i]]\n再加回来k个物品i\n\n综上，f[i,j] = f[i-1,j-k*v[i]] + k * w[i]\n朴素做法\n//最坏情况下：O(n*m^2))for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++)        for(int k=0;k*v[i]&lt;=j;k++)            f[i][j] = max(f[i][j],f[i-1][j-k*v[i]]+k*w[i]);\n\n二维做法\n//f[i,j] = Max(f[i-1][j],f[i-1,j-v]+w,f[i-1,j-2v]+2w,f[i-1,j-3v]+3w,...)//f[i,j-v] = Max(f[i-1][j-v],f[i-1,j-2v]+w,f[i-1,j-3v]+2w,...)//f[i,j] = Max(f[i-1][j],f[i,j-v]+w);//优化为二维for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++){        f[i][j] = f[i-1][j];        if(j&gt;=v[i]) f[i][j] = max(f[i][j],f[i][j-v[i]]+w[i]);    }\n\n一维做法\n完全背包问题的终极解法\nint f[N];for(int i=1;i&lt;=n;i++)    for(int j=v[i];j&lt;=m;j++)        f[j] = max(f[j],f[j-v[i]]+w[i]);\n\n多重背包问题\n每件物品最多有Si个\n\n解题思路\n枚举第i个物品选多少个，根据第i个物品选多少个来将我们所有的选法分成若干种类别：\n\n\n其实就是朴素版本的完全背包问题：f[i,j] = f[i-1,j-k*v[i]] + k * w[i]\n朴素版本\n//最坏情况下：O(n*m^2))for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++)        for(int k=0;k&lt;=s[i] &amp;&amp; k*v[i]&lt;=j ;k++)            f[i][j] = max(f[i][j],f[i-1][j-k*v[i]]+k*w[i]);\n\n 优化版本：二进制优化\n\n c++1s最多算1亿次，超过一亿次会超时\n\n 从0~s中的任何一个数都可以被拼凑出来（由1，2，4，2^k, … , c）。 \n将s个物品i拆分程log(s)个新的物品，新的物品只能用一次\n对所有这些新出来的物品做一遍01背包即可，时间复杂度为O(N*v*log(s))\n分组背包问题\n状态表示的集合：只能从前i组物品中选，且总体积不大于j的所有选法\n\n枚举第i组物品选不选，选哪个\n\n\n朴素解法\nfor(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m;j++){        f[i][j] = f[i-1][j];        for(int k=0;k&lt;s[i];k++){            if(j&gt;=v[i][k]) f[i][j] = max(f[i][j],f[i-1][j-v[i][k]]+w[i][k]);        }    }\n\n优化解法\nint f[N];//直接去掉一维for(int i=1;i&lt;=n;i++)    for(int j=m;j&gt;=0;j--)    \tfor(int k=0;k&lt;s[i];k++){            if(j&gt;=v[i,k]) f[j] = max(f[j],f[j-v[i,k]]+w[i,k]);        }\n\n线性DP数字三角形状态表示\n\n\n\n集合：从顶点到(i,j)的所有路径\n属性：MAX\n\n状态计算\n\n\n复杂度：状态数量*转移数量\nconst int  N = 510,inf = -1e9;int f[N][N];int d[N][N];void digi_Tran_Test(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++)        for(int j=1;j&lt;=i;j++)            scanf(\"%d\",&amp;d[i][j]);    for(int i=0;i&lt;=n;i++)        for(int j=0;j&lt;=i+1;j++)            f[i][j]= inf;    f[1][1] = d[1][1];    for(int i=2;i&lt;=n;i++)        for(int j=1;j&lt;=i;j++){            f[i][j] = max(f[i-1][j-1],f[i-1][j])+d[i][j];        }    int res = inf;    for(int i=1;i&lt;=n;i++)        res = max(res,f[n][i]);    cout&lt;&lt;res&lt;&lt;endl;}\n\n最长上升子序列\n可以按照顺序跳着选择\n\n状态表示\n\n集合：所有以第i个数为结尾的数值上升的子序列\n属性：子序列的最大长度\n\n状态计算\n\n\n朴素版\nconst int M = 1010;int sta[M];int sq[M];void maxLenIncSubTest() {    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++) scanf(\"%d\",&amp;sq[i]);    for(int i=1;i&lt;=n;i++) {        sta[i] = 1;        for (int j = 1; j &lt; i; j++) {            if(sq[j]&lt;sq[i])                sta[i] = max(sta[i],sta[j]+1);        }    }    int res = 0;    for(int i=1;i&lt;=n;i++)        if(res &lt; sta[i]) res = sta[i];    cout&lt;&lt;res&lt;&lt;endl;}\n\n优化版\n最长公共子序列状态表示\n\n集合：所有由第一个序列的前i个字母，和第二个序列的前j个字母的构成的公共子序列\n属性：公共序列的最大值\n\n状态计算\n\n求max是可以重复的，只要不漏掉某一元素即可\n\n\n\nconst int M = 1010;char a[M];char b[M];int st[M][M];void maxCommenSubTest(){    int n,m;    cin&gt;&gt;n&gt;&gt;m;    scanf(\"%s\",a+1);    scanf(\"%s\",b+1);    // A中前i个字符和B中前j个字符所构成的公共子序列的集合    for(int i=1;i&lt;=n;i++)        for(int j=1;j&lt;=m;j++){            st[i][j] = max(st[i][j-1],st[i-1][j]);            if(a[i]==b[j]) st[i][j] = max(st[i][j],st[i-1][j-1]+1);        }    cout&lt;&lt;st[n][m]&lt;&lt;endl;}\n\n\n\n编辑距离区间DP\n不同的合并顺序需要的体力是不同的\n\n状态表示\n\n集合：从第i堆石子到第j堆石子合并成一堆石子的合并方式\n属性：Min\n\n状态计算\n\n\n\n按区间长度从小到大枚举\n\n计数类DP整数划分问题\n\n数位统计DP状态压缩DP\n使用整数来表示状态，把这个整数看作是二进制数，每一位是0是1代表不同的情况，因此位数(n)最多取到20位（1e6种状态）\n\n\n\n\n\n\n\n树形DP\n接受了之后思维跨度就不高\n\n记忆化搜索\n每一道动规题都可以用递归的方法做\n\n","categories":["coding"],"tags":["动态规划"]},{"title":"coding笔记： acwing 1226 包子凑数","url":"/2023/08/05/coding-solution/acwing_1226/","content":"Acwing 1226 包子凑数Content小明几乎每天早晨都会在一家包子铺吃早餐。\n他发现这家包子铺有 N种蒸笼，其中第 i种蒸笼恰好能放 Ai个包子。\n每种蒸笼都有非常多笼，可以认为是无限笼。\n每当有顾客想买 X个包子，卖包子的大叔就会迅速选出若干笼包子来，使得这若干笼中恰好一共有 X个包子。\n比如一共有 3种蒸笼，分别能放 3、4和 5个包子。\n当顾客想买 11个包子时，大叔就会选 2笼 3个的再加 1笼 5个的（也可能选出 1笼 3个的再加 2笼 4个的）。\n当然有时包子大叔无论如何也凑不出顾客想买的数量。\n比如一共有 3种蒸笼，分别能放 4、5和 6个包子。\n而顾客想买 7 个包子时，大叔就凑不出来了。\n小明想知道一共有多少种数目是包子大叔凑不出来的。\nInput第一行包含一个整数 N。\n接下来 N 行，每行包含一个整数 Ai。\nOutput输出一个整数代表答案。\n如果凑不出的数目有无限多个，输出INF。\nSolution本质上是一个完全背包问题但是不同的是，它要求的是有多少种方案不存在。\n如果所有数A1~An的公约数d大于1，那么所有不能被d整除的数都凑不出来，即INF\n如果所有数A1~An的公约数d等于1，那么如果一个数很大，它必能凑出，即凑不出的数目为有限个\n如果两个数a,b互质，那么他们凑不出来的最大的数为(a-1)*(b-1)-1。因此由数，我们可以估计出凑不出来的最大的数的上界为10000。\n完全背包的变种+数论，代码如下：\n#include&lt;iostream&gt;using namespace std;const int N = 10010;bool f[110][N];int a[110];int gcd(int a, int b){    return (b==0)?a:gcd(b,a%b);}int main(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;++i)        scanf(\"%d\",&amp;a[i]);    int d = a[1];    for(int i=2;i&lt;=n;++i){        d = gcd(d,a[i]);    }    if(d&gt;1) puts(\"INF\");    else{        f[0][0] = true;        for(int i=1;i&lt;=n;++i)            for(int j=0;j&lt;N;++j){                f[i][j] = f[i-1][j];                if(j&gt;=a[i]) f[i][j] |= f[i][j-a[i]];            }        int res = 0;        for(int i=0;i&lt;N;++i){            if(!f[n][i]) res++;        }        cout&lt;&lt;res&lt;&lt;endl;    }    return 0;}\n\n","categories":["coding","动态规划"],"tags":["动态规划","数论"]},{"title":"coding笔记： acwing 1295 X的因子链","url":"/2023/08/05/coding-solution/acwing_1295/","content":"Acwing 1295 X的因子链Content输入正整数 X，求 X的大于 1的因子组成的满足任意前一项都能整除后一项的严格递增序列的最大长度，以及满足最大长度的序列的个数。\nInput输入包含多组数据，每组数据占一行，包含一个正整数表示 X\nOutput对于每组数据，输出序列的最大长度以及满足最大长度的序列的个数。\nSolution\n算术基本定理\n\n$X = p_1^{a_1}p_2^{a_2}…*p_k^{a_k}$\n每個大於1的自然數，要麼本身就是質數，要麼可以寫為2個或以上的質數的積\n显然，满足要求的序列最大长度为。难的是如何求出序列的个数\n\nX的所有质因子的排列数\n\n有重复的数该怎么求呢？（以$2^23^35$为例）\n\n假设所有数互不相同，那么总共排列有6！个\n把一样的排列归到一族里去，每一族里的元素有多少个呢？2！*3！个\n那么一共有个不同的组\n\n推广：\n\n总排列数=$\\frac{(a_1+a_2+…+a_k)!}{a_1!a_2!…*a_k!}$（多重集合的排列数问题）\n\n\n分解质因数\n\n组数比较大，直接分解可能会超时\n可以预求出每个数的最小质因子(筛法求素数)，分解时分别求N的质因子P，N/P的质因子，以此类推。因此是logN的复杂度\n\n筛法求素数\n\n\n求出1~n中的所有质数，以及每一个数的一个最小质因子\n\n// 线性筛法：O(N)int primes[N];int min_p[N];bool st[N];int cnt = 0;void getPrimes(int n){    for(int i=2;i&lt;=n;++i){        if(!st[i]) min_p[i]=i, primes[cnt++] = i;        for(int j=0; primes[j] &lt;= n/i; ++j){            st[primes[j]*i] = true;            min_p[primes[j]*i] = primes[j];            // pj一定不大于i的最小质因子            if(i%primes[j] == 0) break;        }    }}\n\nCode#include &lt;iostream&gt;using namespace std;typedef long long LL;const int M = (1&lt;&lt;20) + 10;int primes[M];int minp[M];bool st[M];int cnt = 0;void getPrimes(int n){    for(int i=2;i&lt;=n;++i){        if(!st[i]) minp[i]=i,primes[cnt++]=i;        for(int j=0;primes[j]*i&lt;=n;++j){            st[primes[j]*i] = true;            minp[primes[j]*i] = primes[j];            if(i%primes[j] == 0) break;        }    }}void acwing_1296(){    getPrimes(1&lt;&lt;20);    // for(int i=0;i&lt;20;++i) printf(\"%d \",primes[i]);    int fact[30];    int sum[30];    int x;    while(scanf(\"%d\",&amp;x)!=-1){        int k = 0, total = 0;        while(x!=1){            int p = minp[x];            // cout&lt;&lt;p&lt;&lt;endl;            fact[k] = p;            sum[k]=0;            while(x%p==0){                x/=p;                ++sum[k];                ++total;            }            ++k;        }        LL res = 1;        // cout&lt;&lt;total&lt;&lt;endl;        for(int i=1;i&lt;=total;++i) res*=i;        for(int i=0;i&lt;k;++i)            for(int j=1;j&lt;=sum[i];++j){                res/=j;            }        printf(\"%d %lld\\n\",total, res);    }}int main(){    //acwing_1246();    acwing_1296();}\n\n","categories":["coding","math"],"tags":["数论","组合数学","质因数分解","求质数"]},{"title":"coding笔记： acwing 1296 聪明的燕姿","url":"/2023/08/05/coding-solution/acwing_1296/","content":"acwing 1296 聪明的燕姿Description城市中人们总是拿着号码牌，不停寻找，不断匹配，可是谁也不知道自己等的那个人是谁。\n可是燕姿不一样，燕姿知道自己等的人是谁，因为燕姿数学学得好！\n燕姿发现了一个神奇的算法：假设自己的号码牌上写着数字 S，那么自己等的人手上的号码牌数字的所有正约数之和必定等于 S。\n所以燕姿总是拿着号码牌在地铁和人海找数字（喂！这样真的靠谱吗）。\n可是她忙着唱《遇见》，想拜托你写一个程序能够快速地找到所有自己等的人。\nInput输入包含 k组数据。\n对于每组数据，输入包含一个号码牌 S。\nOutput对于每组数据，输出有两行。\n第一行包含一个整数 m，表示有 m 个等的人。\n第二行包含相应的 m个数，表示所有等的人的号码牌。\n注意：你输出的号码牌必须按照升序排列。\nSolution\n求所有公约数之和\n\n\n每个约数均不相同，且是选法数量之一。\n\n\n\n$S = (p_1^0+p_1^1+…+p_1^{a1})(p_2^0+p_2^1+…+p_2^{a2})…*(p_k^0+p_k^1+…+p_k^{ak})$\nfor(int j = 1+pri, t = pri; j&lt;=x; t*=pri, j+=t){            if(x%j==0){                // printf(\"%d %d %d %d %d\\n\",x, pri, a, pri_a, sum_pr);                dfs(x/j,i+1,tmp * t);            }}\n\n\n上面的代码可以同时求出总和和每一项的值（等差数列求和）\n避免使用pow函数(溢出风险+复杂度高)\n终止条件: j&gt;x\n\n\n一种优化的判定质数的方法\n\n初始版\nbool is_prime(int n){    if(n&lt;N) return !st[n];    for(int i=0;primes[i]&lt;=n/primes[i];i++)        if(n%primes[i]==0) return false;    return true;}\n\n利用已知信息+\nbool is_prime(int n){    if(n&lt;N) return !st[n];    for(int i=2;i&lt;=n/i;++i)        if(n%i==0)            return false;    return true;}\n\n只使用质数来判定\nbool is_prime(int n){    if(n&lt;N) return !st[n];    for(int i=0;primes[i]&lt;=n/primes[i];i++)        if(n%primes[i]==0) return false;    return true;}\n\n\n只有第三种才能AC，但感觉需要防止越界（i&lt;cnt），但不加也可以AC\n后两种方法都需要先预处理出质数\n核心思想：我们可以发现n的所有约数都是成对出现的，即若d为n的约束，那么n/d也为n的约数。所以我们不需要枚举所有数，只需要枚举的质数即可，也就是说d只需枚举到即可\n\n\ndfs遍历顺序\n\n\n依次枚举p，a\np(2,3,5,7,…)\na(1,2,3,) // 在代码中未显示地枚举，而是用乘积代替，本质上是一个意思\nif(S mod j == 0)\ndfs(…)\n\n\n\n\n优化（剪枝）\n\n\n如果，且pi比之前的质因子大的话（需要满足等式条件）直接可以将pi作为结果的因子\n如果，我们只需要遍历小于的质因子即可（因为）\n\ncode#include&lt;iostream&gt;#include&lt;cmath&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;using namespace std;const int N = 50010;int primes[N];int cnt = 0;bool st[N];int res[N], len;void getPrimes(int n){    primes[1] = true;    for(int i=2;i&lt;=n;++i){        if(!st[i]) primes[cnt++] = i;        for(int j=0; primes[j]*i&lt;=n;++j){            st[primes[j]*i] = true;            if(i%primes[j] == 0) break;        }    }}bool is_prime(int n){    if(n&lt;N) return !st[n];    for(int i=0;primes[i]&lt;=n/primes[i];i++)        if(n%primes[i]==0) return false;    return true;}void dfs(int x, int idx, int tmp){    if(x == 1) {        res[len++] = tmp;        return;    }    if(x-1&gt;(idx==0?1:primes[idx-1]) &amp;&amp; is_prime(x-1)){        res[len++] = tmp*(x-1);    }    for(int i = idx;i&lt;cnt;++i){         int pri = primes[i];        if(pri &gt;= sqrt(x))            break;        for(int j = 1+pri, t = pri; j&lt;=x; t*=pri, j+=t){            if(x%j==0){                dfs(x/j,i+1,tmp * t);            }        }    }    }int main(){    getPrimes(N-1);    int x;    while(cin&gt;&gt;x){        len = 0;        dfs(x,0,1);        printf(\"%ld\\n\",len);        sort(res,res+len);        for(int i=0;i&lt;len;++i){            printf(\"%d \",res[i]);        }        if(len) printf(\"\\n\");    }}\n\n","categories":["coding","math"],"tags":["math","dfs","剪枝","公约数之和"]},{"title":"coding笔记： acwing 1303 斐波那契前 n 项和","url":"/2023/08/05/coding-solution/acwing_1303/","content":"Acwing 1303 斐波那契前 n 项和Content大家都知道 Fibonacci 数列吧，f1=1,f2=1,f3=2,f4=3,…,fn=fn−1+fn−2。现在问题很简单，输入 n 和 m，求 fn的前 n 项和 Sn mod m。\nInput共一行，包含两个整数 n 和 m。\nOutput输出前 n 项和 Sn mod m 的值。\nCode这道题其实很有意思，其计算通式为 。它是一种求斐波那契数列的变体，结合了线性代数和快速幂的思想。解题的难点在于如何构造矩阵A。\n求斐波那契数列（logn）令，。\n由，可得\n\n同理可以推广到前n项和。\n求斐波那契数列前n项和（logn）令，。\n由，可得\n\n#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;const int N = 3;typedef long long LL;int n,m;void mul(int f[N], int a[][N]){    int temp[N] = {0};    for(int i=0;i&lt;N;++i){        for(int j=0;j&lt;N;++j){            temp[i] = (temp[i] + (LL)f[j] * a[j][i]) % m;        }    }    memcpy(f,temp,sizeof temp);}void mul(int a[][N]){    int temp[N][N]={0};    for(int i=0;i&lt;N;++i){        for(int j=0;j&lt;N;++j){            for(int k=0;k&lt;N;++k){                temp[i][j] = (temp[i][j] + (LL)a[i][k] * a[k][j]) % m;            }        }    }    memcpy(a,temp,sizeof temp);}int main(){    scanf(\"%d%d\",&amp;n,&amp;m);    int a[N][N] = {        {0,1,0},        {1,1,1},        {0,0,1}    };    int f1[N] = {1,1,1};    n--;    while(n){        if(n&amp;1) mul(f1,a);        mul(a);        n&gt;&gt;=1;    }    cout&lt;&lt;f1[2]&lt;&lt;endl;    return 0;}\n\n","categories":["coding","math"],"tags":["快速幂","矩阵乘法"]},{"title":"coding笔记： acwing 3305 作物杂交","url":"/2023/08/05/coding-solution/acwing_3305/","content":"Acwing 3305 作物杂交Content作物杂交是作物栽培中重要的一步。\n已知有 N 种作物 (编号 1 至 N)，第 i 种作物从播种到成熟的时间为 Ti。\n作物之间两两可以进行杂交，杂交时间取两种中时间较长的一方。\n如作物 A 种植时间为 5 天，作物 B 种植时间为 7 天，则 AB 杂交花费的时间为 7 天。\n作物杂交会产生固定的作物，新产生的作物仍然属于 N 种作物中的一种。\n初始时，拥有其中 M 种作物的种子 (数量无限，可以支持多次杂交)。\n同时可以进行多个杂交过程。\n求问对于给定的目标种子，最少需要多少天能够得到。\n如存在 4 种作物 ABCD，各自的成熟时间为 5 天、7 天、3 天、8 天。\n初始拥有 AB 两种作物的种子，目标种子为 D，已知杂交情况为 A×B→C，A×C→D。\n则最短的杂交过程为：\n第 1 天到第 7 天 (作物 B 的时间)，A×B→C。\n第 8 天到第 12 天 (作物 A 的时间)，A×C→D。\n花费 12 天得到作物 D 的种子。\nInput输入的第 1 行包含 4 个整数 N,M,K,T，N 表示作物种类总数 (编号 1 至 N)，M 表示初始拥有的作物种子类型数量，K 表示可以杂交的方案数，T 表示目标种子的编号。\n第 2 行包含 N 个整数，其中第 i 个整数表示第 i 种作物的种植时间 Ti。\n第 3 行包含 M 个整数，分别表示已拥有的种子类型 Kj，Kj 两两不同。\n第 4 至 K+3 行，每行包含 3 个整数 A,B,C，表示第 A 类作物和第 B 类作物杂交可以获得第 C 类作物的种子。\n1≤N≤2000,2≤M≤N,1≤K≤105,1≤T≤N,1≤Ti≤100,1≤Kj≤M,\n\nOutput输出一个整数，表示得到目标种子的最短杂交时间。\nCode\ninitial version of the solution (the following picture is great, there’s no need drawing again)\n\n\n\n\nthe first version actually has two dimensions as illustrated by the picture above\nit is essentially a DP solution!\nhow to store edges is the key\n\n\nsecond version, I optimize the first dimension\n\nComplexity: , where N is the seed number, and M is the Process number\n#include&lt;iostream&gt;#include&lt;cstring&gt;#include&lt;vector&gt;using namespace std;struct Process{\tint a,b,c;};const int N = 2010;int mature_time[N];int f[N];vector&lt;Process&gt; ps;void bellmanfold(int n){\tfor(int i=1;i&lt;n;++i){\t\tfor(auto pro: ps){\t\t\tif(max(f[pro.a],f[pro.b])+max(mature_time[pro.a],mature_time[pro.b])&lt;f[pro.c]){\t\t\t\tf[pro.c] = max(f[pro.a],f[pro.b])+max(mature_time[pro.a],mature_time[pro.b]);\t\t\t}\t\t}\t}}int main(){\tint n,m,k,t;\tscanf(\"%d%d%d%d\",&amp;n,&amp;m,&amp;k,&amp;t);\tfor(int i=1;i&lt;=n;++i){\t\tscanf(\"%d\",&amp;mature_time[i]);\t}\tmemset(f,0x3f,sizeof f);\tfor(int i=0;i&lt;m;++i){\t\tint x;\t\tscanf(\"%d\",&amp;x);\t\tf[x]=0;\t}\tfor(int i=0;i&lt;k;++i){\t\tint a,b,c;\t\tscanf(\"%d%d%d\",&amp;a,&amp;b,&amp;c);\t\tps.push_back({a,b,c});\t}\tbellmanfold(n);\tprintf(\"%d\\n\",f[t]);\treturn 0;}\n\n\nThird version, use QUEUE to optimize the solution!\n\nComplexity: normally , worstly \n#include&lt;iostream&gt;#include&lt;cstring&gt;#include&lt;vector&gt;#include&lt;queue&gt;using namespace std;struct Process{\tint a,b,c;\tProcess *ne=nullptr;\tProcess(int a, int b, int c, Process* ne):a(a),b(b),c(c),ne(ne){}};const int N = 2010;int mature_time[N];int f[N];Process* ps[N]; // build a neighbor tablequeue&lt;int&gt; que;bool inQue[N];void insert(int a, int b, int c){\tProcess * np = new Process(a,b,c,ps[a]);\tps[a] = np;\tnp = new Process(b,a,c,ps[b]);\tps[b] = np;}void spfa(){\twhile(!que.empty()){\t\tint cu = que.front();\t\tque.pop();\t\tinQue[cu] = false;\t\tfor(auto i = ps[cu]; i!=nullptr; i = i-&gt;ne){\t\t\tif(max(f[i-&gt;a],f[i-&gt;b])+max(mature_time[i-&gt;a],mature_time[i-&gt;b])&lt;f[i-&gt;c]){\t\t\t\tf[i-&gt;c] = max(f[i-&gt;a],f[i-&gt;b])+max(mature_time[i-&gt;a],mature_time[i-&gt;b]);\t\t\t\tif(!inQue[i-&gt;c]){\t\t\t\t\tque.push(i-&gt;c);\t\t\t\t\tinQue[i-&gt;c] = true;\t\t\t\t}\t\t\t}\t\t}\t}}int main(){\tint n,m,k,t;\tscanf(\"%d%d%d%d\",&amp;n,&amp;m,&amp;k,&amp;t);\tfor(int i=1;i&lt;=n;++i){\t\tscanf(\"%d\",&amp;mature_time[i]);\t}\tmemset(f,0x3f,sizeof f);\tfor(int i=0;i&lt;m;++i){\t\tint x;\t\tscanf(\"%d\",&amp;x);\t\tf[x]=0;\t\tque.push(x);\t}\tfor(int i=0;i&lt;k;++i){\t\tint a,b,c;\t\tscanf(\"%d%d%d\",&amp;a,&amp;b,&amp;c);\t\tinsert(a,b,c);\t}\tspfa();\tprintf(\"%d\\n\",f[t]);\treturn 0;}\n\n","categories":["coding","graph"],"tags":["graph","bellmanfold","spfa"]},{"title":"coding笔记：AcWing 1299 五指山","url":"/2023/08/05/coding-solution/acwing_1299/","content":"coding笔记：AcWing 1299 五指山Content大圣在佛祖的手掌中。\n我们假设佛祖的手掌是一个圆圈，圆圈的长为 n，逆时针记为：0,1,2,…,n−1，而大圣每次飞的距离为 d。\n现在大圣所在的位置记为 x，而大圣想去的地方在 y。\n要你告诉大圣至少要飞多少次才能到达目的地。\n注意：孙悟空的筋斗云只沿着逆时针方向翻。\nInput有多组测试数据。\n第一行是一个正整数 T，表示测试数据的组数；\n每组测试数据包括一行，四个非负整数，分别为如来手掌圆圈的长度 n，筋斗所能飞的距离 d，大圣的初始位置 x和大圣想去的地方 y。\nOutput对于每组测试数据，输出一行，给出大圣最少要翻多少个筋斗云才能到达目的地。\n如果无论翻多少个筋斗云也不能到达，输出 Impossible。\nSolution这道题简单在数学公式较好得到，利用的都是现成的公式：比如扩展gcd，比如不定方程的通解。只要在数学知识上补充相应的概念，这道题还是好解的，否则很难。\nfirst attempt-纯暴力(O(N))#include&lt;iostream&gt;using namespace std;int main(){    int t;    cin&gt;&gt;t;    while(t--){        int n,d,x,y;        cin&gt;&gt;n&gt;&gt;d&gt;&gt;x&gt;&gt;y;        int i = x;        int count = 0;        bool arr = true;        while(true){            if(i == y){                break;            }else if(i == x &amp;&amp; count &gt; 0){                arr = false;                break;            }            i = (i+d) % n;            ++count;        }        if(arr)            cout&lt;&lt;count&lt;&lt;endl;        else            cout&lt;&lt;\"Impossible\"&lt;&lt;endl;    }    return 0;}\n\nsecond attempt-扩展gcd可将题目抽象为数学公式：\nx+c*d = k*n+y\n即c*d + k*n = y-x  (k可正可负，我们不关心)\n根据数学常识我们知道，上式如果能够成立，y-x必须是(d,n)最大公约数的倍数，否则无解。\n因此我们可以使用扩展gcd算法先求出c0*d + k0*n = (d,n)时的解，再同比例扩大(y-x)/(d,n)即可\n但是题目要求我们必须求出C的最小值，因此根据C的通解：c = c0 +u*n/(n,d)\n我们可以求出C的最小值（正值的最小值）：(c0 % (n/gcd)+n/gcd) %(n/gcd)\n#include&lt;iostream&gt;using namespace std;typedef long long LL;int ext_gcd(int a, int b, LL &amp;x, LL &amp;y){    if(!b){        x = 1;        y = 0;        return a;    }    int d = ext_gcd(b, a%b, y,x);    y -= a/b*x;    return d;}int main(){    int t;    cin&gt;&gt;t;    while(t--){        int n,d,x,y;        LL c,k;        cin&gt;&gt;n&gt;&gt;d&gt;&gt;x&gt;&gt;y;        int gcd = ext_gcd(d,n,c,k);        if((y-x) % gcd){            cout&lt;&lt;\"Impossible\"&lt;&lt;endl;        }else{            c = c * (y-x) / gcd;            c = (c % (n/gcd)+n/gcd) %(n/gcd);            cout&lt;&lt;c&lt;&lt;endl;        }    }    return 0;}\n\n","categories":["coding","math"],"tags":["math","裴蜀定理","扩张gcd"]},{"title":"coding笔记： acwing二刷","url":"/2023/08/05/coding-solution/acwing%E4%BA%8C%E5%88%B7/","content":"acwing二刷基础算法\n快速排序\n\nAcWing 785. 快速排序给定你一个长度为 n的整数数列。\n请你使用快速排序对这个数列按照从小到大进行排序。\n并将排好序的数列按顺序输出。\n输入格式输入共两行，第一行包含整数 n。\n第二行包含n个整数（所有整数均在 1∼e9 范围内），表示整个数列。\n输出格式输出共一行，包含n个整数，表示排好序的数列。\n数据范围1≤n≤100000\n输入样例：53 1 2 4 5\n\n输出样例：1 2 3 4 5\n\n//785. 快速排序#include&lt;iostream&gt;using namespace std;const int  N = 100010;int a[N];void quick_sort(int le,int ri){    if(le&gt;=ri) return;    int x = a[le+ri&gt;&gt;1];    int l = le - 1, r = ri+1;    while(l&lt;r) {        do { ++l; } while (a[l] &lt; x);        do { --r; } while (a[r] &gt; x);        if (l &lt; r) swap(a[r], a[l]);    }    quick_sort(le,r);    quick_sort(r+1,ri);}int main(){    int n;    scanf(\"%d\",&amp;n);    for(int i=0;i&lt;n;i++) scanf(\"%d\",&amp;a[i]);    quick_sort(0,n-1);    for(int i=0;i&lt;n;i++) printf(\"%d \",a[i]);    return 0;}\n","categories":["coding"],"tags":["acwing二刷"]},{"title":"coding笔记：二分算法","url":"/2023/08/05/coding-solution/binarysearch/","content":"二分算法整数二分\n整数二分因为涉及+1，-1，所以为了防止死循环，需要考虑边界情况。\n当我们定义一个性质，该性质可以将数据二分时（即存在边界时），二分算法是可以将该边界找出来的。\n\n主要思想\n假设在整个区间内部是可以找到答案的，我们对整个区间不断进行二分\n每次都要选择答案所在的区间去进行下一步搜索（每次会把整个区间的大小缩小一半）\n二分一定会保证区间里有答案的，但是存在特例，即原问题无解的情况（无解一定和题目有关）\n在原问题无解的情况下，若没有遇到数组边界，找到的区间一定是满足条件的，但不是query；而如果遇到数组边界，那么就可能不会满足找到的区间一定是满足条件的（以整数的范围这道题为例）\n\n\n\n该图即为寻找满足check的最右端端点示意图\n\n上图对应的代码即为二分模板1的代码，如下所示：\nbool check(int mid) {return false;}double function(double){return 0.0;}// 二分模板1int bsearch1(int l,int r){    // 考虑边界，l+1=r时，算法是否正确    // l+1=r时,需要修改mid=l,会陷入死循环    // 所以修改mid=(l+r+1)/2,遇到边界时，mid=r,可以顺利退出    // r会小于l的可能仅在最后一句，但遇到边界且不满足条件时，计算的mid不可能=l,所以退出循环时r不可能小于l,即l=r    // 返回r,l均可    while (l&lt;r){        int mid = l+r+1 &gt;&gt;1;        // 若check 代表满足条件        if(check(mid)) l = mid;        else r = mid-1;    }    return l;}// 二分模板2int bsearch2(int l,int r){    // 寻找不满足的断点    // 考虑边界，l+1=r时，算法是正确的    // 退出循环时，l==r的原理同上    while(l&lt;r){        int mid = l+r&gt;&gt;1;        if(check(mid)) l = mid+1;        else r = mid;    }    return l;}\n\n浮点数二分\n较整数二分简单，因为不需要考虑边界（因为没有整除，每次都可以完美地将边界缩小一半）\n思想与整数二分一样，只要满足时时刻刻答案都在我们的区间即可； \n但我们的区间足够小时，我们就可以认为已经找到了答案；\n有两种方式可以去写浮点数二分的循环条件：一个是固定循环100次，如果原来区间长度为1时，结束时区间长度即为；或是指定一个很小的数epsilon，当区间长度小于这个数即可退出。\n\ndouble fbsearch(double l,double r,double target){    // 浮点数二分查找    while(r-l&gt;1e-8){        double mid = (l+r)/2;        double val = function(mid);        if (val&gt;=target) r = mid;        else l = mid;    }    return l;}\n\n\n\n应用：数的三次方根求数的三次方根可以使用二分查找来做。因为函数是单调的，所以很容易判断mid和target的大小关系，从而缩小查找范围，代码如下：\ndouble fbiSearch(double l, double r, double target, double (*pf)(double)) {    while (r - l &gt; 1e-7) {        double mid = (l + r) / 2;        if (pf(mid) &lt;= target) l = mid;        else r = mid;    }    return r;}double calTrip(double x){    return x*x*x;}int findRoot3(){    double n;    double (*pf)(double)=calTrip;    cin&gt;&gt;n;    if(n&lt;0) printf(\"-%.6f\",fbiSearch(0,ceil(-n),-n,calTrip));    else printf(\"%.6f\",fbiSearch(0,ceil(n),n,calTrip));    return 0;}\n\n简要介绍下引入的函数指针，有了函数指针就可以方便地将计算方法传入二分查找算法来找解。double (*pf)(double)=calTrip;可以定义一个函数指针，非常有用。\n","categories":["coding"],"tags":["二分查找"]},{"title":"C++ 面向对象","url":"/2023/08/05/coding-solution/c++%20primer_OOP/","content":"C++ 面向对象拷贝控制\n类可以在创建此类型对象时做什么，类在控制该类型对象拷贝、赋值、移动或销毁时做什么。类通过一些特殊的成员函数进行这些拷贝控制操作：拷贝构造函数、移动构造函数、拷贝赋值运算符、移动赋值运算符以及析构函数。\n\n\n难点是首先认识到什么时候需要定义这些操作\n\n拷贝、控制和销毁拷贝构造函数class Foo{    public:    \tFoo();    \tFoo(const Foo&amp;);// 第一个参数是自身类型的引用，其他参数（如果有的话）都有默认值}\n\n拷贝初始化\n\n通常使用拷贝构造函数完成（有时也会使用移动构造函数）\n\n发生在：\n\nstring s2 = \"9-999999-999-99\";或string nines = string(100,'9');\n将一个对象作为实参传递给非引用类型的形参\n从一个返回类型为非引用类型的函数返回一个对象\n用{}初始化一个数组中的元素，或一个聚合类的成员\n某些类类型会对它们所分配的对象使用拷贝初始化：初始化标准库容器或是调用其insert、push成员\n\n\n由此可以看出拷贝构造函数是极其有用的\n\n\n\n为什么拷贝构造函数自己的参数必须是引用类型?\n\n\n因为如果是非引用类型，我们必须拷贝它的实参，所以又必须调用拷贝构造函数，如此循环\n\n拷贝初始化的限制：初始值要求使用一个explicit的构造函数来进行类型转换时，就只能直接使用，而不能隐式使用\n\n\n拷贝赋值运算符class Foo{    public:    \tFoo&amp; operator=(const Foo&amp;);// （标准库）通常要求返回一个指向其左侧运算对象的引用}\n\n\n若一个未定义自己的拷贝赋值运算符，编译器会为他生成一个合成拷贝赋值运算符：\n\n\n\n析构函数\n析构函数释放对象所使用的资源并销毁对象的非static数据成员\n\n没有返回值，也不接受参数\n\n销毁类类型的成员需要成员执行自己的析构函数，销毁内置类型不需要做什么\n\n什么时候会调用析构函数？\n\n变量离开其作用域时被销毁\n对象被销毁时，其成员被销毁\n容器被销毁时，其元素被销毁\n对于动态分配的对象，当对它的指针应用delete运算符时被销毁\n\n\n析构函数函数体自身并不直接销毁成员，是在隐含的析构阶段被销毁的\n\n\n三/五法则\n需要析构函数的类也需要拷贝与赋值操作\n\nHasPtr p(\"somevalue\");f(p);HasPtr q(p); //p和q的ps成员均指向无效内存！\n\nHasPtr::~HasPtr(){ delete ps;}HasPtr f(HasPtr&amp; hp){    HasPtr ret = hp;    return ret; // ret被销毁 导致hp的指针成为野指针}\n\n\n需要拷贝操作的类也需要赋值操作，反之亦然\n\n例如一个类为每个对象分配一个唯一的序号，需要自定义拷贝赋值运算符来避免将序号赋予目的对象；\n使用=default\n显式地要求编译器生成合成的版本\n\n阻止拷贝\n例如，iostream类阻止了拷贝，以避免多个对象写入或读取相同的IO缓冲。\n\n定义删除的函数\n\n虽然声明了它们，但不能以任何方式使用它们\n\nstruct NoCopy{    NoCopy()=default;    NoCopy(const NoCopy&amp;) = delete;    NoCopy &amp;operator=(const NoCopy&amp;)=delete;    ~NoCopy() = default;}\n\n\n我们尽量不要删除析构成员，若删除可以动态分配这种类型的对象（但不能释放这些对象）\n\n合成的拷贝控制成员可能是删除的\n\n如果一个类有数据成员不能默认构造、拷贝、复制或销毁，则对应的成员函数将被定义为删除的\n\n如果具有引用成员或是无法默认构造的const成员的类，编译器不会为其合成默认构造函数\n\n如果一个类有const成员，则它不能使用合成的拷贝赋值运算符\n\n对于有引用成员的类，将新值赋值给引用成员，改变的是所引用对象的值，而不是引用本身，不会与右侧运算对象指向相同的对象，不能使用合成的拷贝赋值运算符\n\n\n拷贝控制与资源管理\n管理类外资源的类必须定义拷贝控制成员\n\n\n首先确定此类型对象的拷贝语义\n\n类的行为像一个值\n它应该有自己的状态，拷贝副本与原对象是完全独立的\n\n类的行为像一个指针\n共享状态，副本和原对象使用相同的底层数据\n\n\n\n\n行为像值的类class HasPtr{public:    HasPtr(const std::string &amp;s = std::string()):ps(new std::string(s)),i(0){}    HasPtr(const HasPtr&amp;p):        ps(new std::string(*(p.ps))),i(p.i) {}    HasPtr&amp; operator=(const HasPtr&amp;);    ~Hasptr() {delete ps;}private:    std::string *ps;    int i;}\n\n类值拷贝赋值运算符\n\n通常组合了析构和拷贝构造函数的操作\n\nHasPtr::HasPtr&amp; operator=(const HasPtr&amp; p){    auto newp = new std::string(*(p.ps));    delete ps;    ps = newp;    i = p.i;    return *this;}\n\n\n之所以先拷贝，再delete是为了保证：将一个对象赋予它自身时，赋值运算符需要正确工作\n\n行为像指针的类\n使用shared_ptr来管理类的资源（该类负责记录有多少用户共享它所指向的对象以及释放资源）\n有时，我们希望直接管理资源：\n使用引用计数\n\n\n\n引用计数\n\n除了初始化对象外，每个构造函数还有创建一个引用计数，用来记录目前有多少对象正在与当前正在创建的对象共享状态\n拷贝构造函数不分配新的计数器，而是拷贝给定对象的数据成员，包括计数器，并进行递增操作。\n析构函数递减计数器，若变为0，析构函数释放状态\n拷贝赋值运算符，递增右侧对象的计数器，递减左侧对象的计算器，如果左侧计数器为0，意味着必须销毁状态\n\n\n在哪里存放引用计数？\n\n\n将计数器保存在动态内存中\n\nclass HasPtr{public:    HasPtr(const std::string&amp; s = std::string()):    \t\tps(new std::string(s)), i(0), use(new std::size_t(1)){}    HasPtr(const HasPtr&amp; p):ps(p.ps),i(p.i),use(p.use){ ++*use;}    HasPtr&amp; operator=(const HasPtr&amp;);    ~HasPtr();private:    std::string * ps;    std::size_t * use; //记录有多少个对象共享*ps的成员    int i;}\n\n\n析构函数不能无条件地delete ps\n\nHasPtr::~HasPtr(){    if(--*use == 0){        delete ps;        delete use;    }}\n\n\n赋值运算符必须处理自赋值\n\nHasPtr&amp; operator=(const HasPtr&amp; rhs){    ++*rhs.use;    if(--*use == 0){        delete ps;        delete use;    }    ps = rhs.ps;    use = rhs.use;    i = rhs.i;    return *this;}\n\n交换操作\n对于分配了资源的类，swap可能会是一种重要的优化手段\n\n\n一般我们交换两个类值HasPtr的代码可能如下：\n\nHasPtr temp = v1;v1 = v2;v2 = temp;\n\n这种赋值实现的交换存在多次动态内存分配\n\n我们更希望swap交换指针，而不是分配新副本：\n\nstring *temp = v1.ps;v1.ps = v2.ps;v2.ps = temp;\n\n\n编写自己的swap函数来重载默认行为：\n\nclass HasPtr{    friend void swap(HasPtr&amp;, HasPtr&amp;);};inlinevoid swap(HasPtr&amp; lhs, HasPtr&amp; rhs){    using std::swap;    swap(lhs.ps,rhs.ps);    swap(lhs.i, rhs.i);}\n\n\n在赋值运算符中使用swap\n\n\n拷贝和交换技术\n\nHasPtr&amp; HasPtr::operator=(HasPtr rhs){    swap(*this, rhs);    return *this;}\n\n自动是异常安全的，且能处理自赋值\n动态内存管理类\n设计简化版的vector\n\nclass StrVec{public:    StrVec():elements(nullptr),first_free(nullptr),cap(nullptr){}    StrVec(const StrVec&amp;);    StrVec &amp;operator=(const StrVec&amp;);    ~StrVec();    void push_back(const std::string&amp;);    size_t size() const{return first_free - elements;}    size_t capacity() const{return cap-elementes;}    std::string *begin() const{return elements;}    std::string *end() const{return first_free;}private:    Static std::allocator&lt;std::string&gt; alloc;    void chk_n_alloc(){        if(size()==capacity()) reallocate();    }        std::pair&lt;std::string*, std::string*&gt; alloc_n_copy(const std::string*, const std::string*);    void free();    void reallocate();    std::string *elements;    std::string *first_free;    std::string *cap;}\n\nvoid StrVec::push_back(const string &amp;s){    chk_n_alloc();    // 在first_free指向的元素中构造s的副本    alloc.construct(first_free++,s);}\n\n\n用allocator分配内存时，必须记得内存是未构造的（原始内存）；\n\nalloc_n_copy成员\nstd::pair&lt;std::string*, std::string*&gt;StrVec::alloc_n_copy(const std::string* b, const std::string* e){    auto data = alloc.allocate(e-b);    return {data, uninitialized_copy(b,e,data)};}\n\n\npair.first：指向分配的内存的开始位置\npair.second：指向最后一个构造元素之后的位置\n\nfree成员\nvoid StrVec::free(){    if(elements){        for(auto p = first_free;p!=elements;){            alloc.destroy(--p);        }        alloc.deallocate(elements, cap-elements);    }}\n\n拷贝控制成员\nStrVec::StrVec(const StrVec &amp;s){    auto newdata = alloc_n_copy(s.begin(),s.end());    elements = newdata.first;    first_free = cap = newdata.second;}StrVec::~StrVec(){ free(); }StrVec&amp; StrVec::operator=(const StrVec &amp; rhs){    auto newdata = alloc_n_copy(rhs.begin(),rhs.end());    free();    elements = newdata.first;    first_free = cap = newdata.second;    return *this;}\n\n移动构造函数和std::move\n\n将资源从给定对象移动，而不是拷贝到正在创建的对象\n\nreallocate成员\nvoid StrVec::reallocate(){    auto newcapacity = size() ? 2*size():1;    auto newdata = alloc.allocate(newcapacity);    auto dest = newdata;    auto elem = elements;    for(size_t i=0; i!=size(); ++i)        alloc.construct(dest++,std::move(*elem++));    free();    elements = newdata;    first_free = dest;    cap = elements+newcapacity;}\n\n对象移动\n\n\n进行不必要的拷贝代价很高，所以引入了移动的概念\n\n右值引用\n必须绑定到右值的引用（窃取状态）\n不能将一个右值绑定到左值上\n\nint i = 42;int &amp;&amp;rr = i; //wrong!\n\n\n左值持久，右值短暂\n\n右值只能绑定到临时对象：要么将要被销毁，要么该对象没有其他用户\n使用右值的代码可以地接管所引用对象的资源\n标准库move函数\n可以显式地将一个左值转换为对应的右值引用类型\n通过move来获得绑定到左值上的右值引用\n\nint &amp;&amp;rr3 = std::move(rr1);\n\n\n我们可以销毁一个移后源原对象，也可以赋予他新值，但不能使用其值\n\n移动构造函数和移动赋值运算符\n必须记得将原对象的资源置为NULL，否则析构时会释放掉我们刚刚移动的内存\n\nStrVec::StrVec(StrVec &amp;&amp;s) noexcept:elements(s.elements),first_free(s.first_free),cap(s.cap){    s.elements = s.first_free = s.cap = nullptr;}\n\n\n移动操作窃取而不分配任何资源，所以通常不会抛出任何异常\n必须显式告诉标准库我们的移动构造函数可以安全地使用：noexcept\n\nStrVec&amp; StrVec::operator=(StrVec &amp;&amp; rhs) noexcept{    if(this != &amp;rhs){ // 处理自赋值        free();        elements = rhs.elements;        first_free = rhs.first_free;        cap = rhs.cap;        rhs.elements = rhs.first_free = rhs.cap = nullptr;    }    return *this;}\n\n\n移后源对象必须可析构，用户不能对其值进行任何假设\n\n合成的移动操作\n定义了一个移动构造函数的类也必须定义自己的拷贝操作，否则这些成员默认地被定义为删除的\n移动右值，拷贝左值\n当既有移动构造又有拷贝构造时，编译器使用函数匹配规则来确定使用哪个：\n\n不能隐式的将右值引用绑定到一个左值\n\nbut we could bind const lvalue reference to rvalue\n\n\nconst auto&amp; ptr3 = ptr + 5; // correct! const save us a lot!\n\n如果没有移动构造函数，右值也会被拷贝\n\n\n\n因为我们可以将Foo&amp;&amp;转换为一个const Foo&amp;，所以可以使用拷贝构造函数\n\n拷贝并交换赋值运算符\n\n拷贝并交换挺有意思的\n\nHasPtr::HasPtr(HasPtr &amp;&amp;p) noexcept: ps(p.ps), i(p.i){    p.ps = 0;}HasPtr&amp; HasPtr::operator=(HasPtr rhs){    swap(*this, rhs);    return *this;}\n\n\n这时，如果右侧运算对象是一个右值引用，会调用移动构造函数\n这时，如果右侧运算对象是一个左值，会调用拷贝构造函数\nswap会交换两个运算对象的状态\n\nRULE of FIVE：所有的五个拷贝控制成员应该被看作一个整体\n移动迭代器\nvoid StrVec::reallocate(){    auto newcapacity = size() ? 2*size():1;    auto newdata = alloc.allocate(newcapacity);    auto dest = newdata;    auto elem = elements;    for(size_t i=0; i!=size(); ++i)        alloc.construct(dest++,std::move(*elem++));    free();    elements = newdata;    first_free = dest;    cap = elements+newcapacity;}\n\n\n使用uninitialized_copy来构造新分配的内存比循环更简单。\n\n移动迭代器会解引用出右值引用：\n\n\nvoid StrVec::reallocate(){    auto newcapacity = size() ? 2*size():1;    auto newdata = alloc.allocate(newcapacity);    auto last = uninitialized_copy(make_move_iterator(begin()),                                  make_move_iterator(end()),                                  newdata);    free();    elements = newdata;    first_free = last;    cap = elements+newcapacity;}\n\n注：不要随意使用移动操作，只有当你确信需要且是安全的，才可以使用std::move\n在成员函数中使用右值引用void push_back(const X&amp;);void push_back(X&amp;&amp;);\n\n\n\n引用限定符\n\n阻止向右值进行赋值，强制左侧运算对象是一个作值\n\nFoo &amp;operator=(const Foo&amp;) &amp;;\n\n\n可以用来区分重载版本\n\n\n\n\n编译器会通过对象的左值右值属性来确定使用哪个版本\n\n\n\n重载运算与类型转换\n为什么要重载运算？\n\n使得程序更易于编写和阅读，不用的话，冗长而不清晰，示例如下：\n\n\n\n可以被重载的运算符\n\n\n\n\n尽量使用与内置类型一致的含义（返回值也要兼容），首先应该考虑这个类提供哪些操作\n执行IO操作\n检测相等性\n包含内在的单序比较\n\n\n\n\n何时选择为成员，何时为非成员？\n\n\n=，【】，（），-&gt;必须是成员\n改变对象状态的运算符或者与给定类型密切相关的运算符，如递增递减，通常为成员\n具有对称性的运算符，如算数，相等性，关系，位运算通常是普通的非成员函数\n\n输入输出运算符重载输出运算符ostream &amp;operator&lt;&lt;(ostream &amp;os, const Sales_data &amp;item){    os &lt;&lt; item.isbn()&lt;&lt; \" \"...    return os;}\n\n\n输出运算符尽量减少格式化操作：使得用户 有权控制输出的细节\n必须是非成员函数，而且一般被声明为友元\n\n重载输入运算符istream &amp;operator&gt;&gt;(istream &amp;is, Sales_data &amp;item){    double price;    is&gt;&gt; item.bookNo &gt;&gt; items.units_sold &gt;&gt; price;    if(is) // 检测输入是否成功        item.revenue = item.units_sold * price;    else        item = Sales_data();    return is;}\n\n\n输入运算符必须处理输入可能失败的情况\n\n当发生读取操作错误时，输入运算符应该负责从错误中恢复\n\n\n算数和关系运算符\n\n\n\n相等运算符\n若有判等操作，应该定义\n更容易使用标准库和算法\n相等运算符和不等运算符中的一个应该把工作委托给另一个\n\n赋值运算符\n第三种赋值运算符：\n\nvector&lt;string&gt; v;v = {\"a\",\"an\",\"the\"};StrVec &amp;StrVec::operator=(std::initializer_list&lt;std::string&gt;){    auto data = alloc_n_copy(il.begin, il.end());    free();    elements = data.first;    first_free =data.second;    return * this;}\n\n下标运算符通常会定义两个版本：\n\n返回普通引用\n返回常量引用\n\nclass StrVec{    std::string&amp; operator[](std::size_t n){        return elements[n];    }    const std::string&amp; operator[](std::size_t n) const{        return elements[n];    }};\n\n面向对象程序设计\n基于三个基本概念：数据抽象、继承和动态绑定\n\n为什么要使用继承和动态绑定？\n\n可以更容易地定义与其他类相似但不完全相同的新类\n再用这些彼此相似的类进行编程时，可以一定程度上忽略它们的区别，以统一的方式使用它们的对象\n\n一个适合OOP好的例子\n\n书店中不同书籍的定价策略可能不同。\n打折、原价、超过数量打折、前多少打折\n\n基类和派生类虚函数\n\n基类希望它的派生类自定义适合自身的版本\n派生类必须对虚函数进行声明，可以显式注明它将使用哪个成员改写基类的虚函数：\n\ndouble net_price(std::size_t) const override;\n\n动态绑定\n\n能使用同一段代码分别处理Quote和Bulk_quote的对象\n\n\n\n\n\n\n根据实际传入item的对象类型决定执行net_price的哪个版本\n\n\n\n访问控制\n派生类能访问基类的共有成员、保护成员， 但不能访问私有成员\n派生类到基类的类型转换\n可以将基类的指针或引用绑定到派生类对象中的基类部分：\n\n\n\n如图，Bulk有两个子对象。\n\n派生类的声明\n\n包含类名，但不包含它的派生列表\n\nclass Bulk_quote;\n\n派生类构造函数\n\n派生类必须使用基类的构造函数来初始化它的基类部分\n首先初始化基类的部分，然后按照声明的顺序依次初始化派生类的成员\n\n遵循基类的接口\n\n每个类负责定义各自的接口\n派生类不要直接初始化基类的成员\n\n静态成员的继承\n\n整个继承体系只存在该成员的唯一定义\n\n类型转换和继承静态类型与动态类型\nBult_quote bulk;Quote&amp; item = bulk;\n\n\nQuote&amp; 为静态类型\nBulk_quote为动态类型\n引用或指针的静态类型和动态类型不同正是c++支持多态性的根本所在\n\n不能将基类隐式转换为派生类\n但是如果确定是安全的，可以用static_cast来强制转换（不推荐）\n在对象之间不存在类型转换\n\n\n\nbulk的Bulk_quote部分被切掉了\n\n\n\n虚函数\n对非虚函数的调用在编译时进行绑定，通过对象进行的函数调用也在编译时绑定\n当且仅当通过指针或引用调用虚函数时，才会在运行时解析该调用。\n\noverride和final说明符\nc++11中可以使用override说明符来说明派生类中的虚函数。\n\n使得意图更加明确\n让编译器为我们发现一些错误\n\n若定义为final，任何尝试覆盖该函数的操作都将引发错误\n\n\n回避虚函数的机制\n\n通常当一个派生类的虚函数调用它覆盖的基类的虚函数版本时会需要回避\n否则会导致无限递归（被解析为对自身的调用）\n\n抽象基类含有纯虚函数的类是抽象基类：\nclass Disc_quote: public Quote{public:    Disc_quote() = default;    Disc_quote(const std::string&amp; book, double price,               std::size_t qty, double disc):    \t\t\tQuote(book, price),    \t\t\tquantity(qty),discount(disc){}    double net_price(std::size_t) const = 0;protected:    std::size_t quantity = 0;    double discount =0.0;}\n\n\n我们不能直接创建一个抽象基类的对象\n\n加入Disc_quote是重构的典型示例\n\n\n访问控制与继承\n\n派生访问说明符目的是控制派生类用户对于基类成员的访问权限\nstruct Priv_Derv: private Base{    ...}\n\n\n意思是说base的所有成员对于派生类的用户来说都是不可访问的\n\n派生类内对基类成员的访问权限只与基类中的访问说明符有关\n\n但是派生类的派生类会受到派生访问说明符的影响：\n\n\nstruct Derived_from_Private: public Priv_Derv{    int use_base(){        // ERROR! 因为Base::prot_mem在Priv_Derv中是private的        return prot_mem;    }}\n\n派生类向基类转换的可访问性\n\n只用公有继承，用户代码才可以使用派生类到基类的转换\n无论什么继承，D的成员函数都可以使用派生类到基类的转换\n公有和受保护的继承，D的派生类的成员和友元可以使用派生类到基类的转换\n\n\n\n友元与继承\n\n友元关系不能继承也不能传递\n\n\n\n\n尽管看起来有点奇怪，但f3是正确的：如果Base对象内嵌在其派生类对象中也是OK的\n\n可以改变个别成员的可访问性\n\n\n\n通过using声明，我们可以将该类的直接或间接基类中的任何可访问成员标记出来\n\n默认的继承保护级别\n\n\n\n唯一差别是默认成员访问说明符和默认派生访问说明符\nstruct默认public继承\nclass默认private继承\n\n继承中的类作用域\n派生类的作用域位于基类作用域之内（有意思的是派生类和基类的定义相互分离）\n名字解析过程：\n\n\n\n\n我们能使用哪些类型仍然是静态类型决定的\n\nBulk_quote bulk;Bulk_quote *bulkp = &amp;bulk;Quote *itemP = &amp;bulk;bulkP-&gt;discount_policy();// rightitemP-&gt;discount_policy();// wrong!\n\n\n尽管在bulk中确实含有一个discount_policy成员，但是该成员对于itemP确实不可见的。因为Quote不包含该成员，所以无法通过Quote的引用或指针调用它\n\n在内层作用域重新定义外层的名字可以隐藏同名的基类成员，使用Base::mem可以使用被隐藏的成员\n\n\n\n名字查找先于类型检查\n\n\n声明在内层作用域的函数不用重载声明在外层作用域的函数，如果同名，会隐藏该基类成员\n\n\n\n\n因为解析的时候会先进行名字查找，而派生类已经定义了，所以查找会终止\n\n\n虚函数与作用域\n\n\n如果基类与派生类虚函数接受的实参不同，是无法通过基类的引用或是指针调用派生类的虚函数的\n\n非虚函数不会进行动态绑定，实际调用的函数版本由指针的静态类型决定\n\n\n\n覆盖重载的函数\n\n\n如果派生类希望所有的重载版本对他都是可见的，那么它就需要覆盖所有版本或者一个都不覆盖\n\n为重载的成员提供一条using语句指定名字即可，这样就无需覆盖基类中的每一个重载版本了，对派生类没有重新定义的重载版本的访问实际上是using声明点的访问。\n\n\n构造函数与拷贝控制虚析构函数\n动态分配继承体系中的对象，应该将析构函数定义为虚函数\n\nclass Quote{public:    virtual ~Quote()=default;}\n\n\n析构函数的虚属性会被继承，所以只要析构函数是虚函数，就能确保我们delete指针时，运行正确的析构版本\n\n合成拷贝控制与继承\n\n\n如果基类中的默认构造、拷贝构造、拷贝赋值或析构是删除的，则派生类中对应的成员将是被删除的\n如果我们需要执行移动操作，应该首先在基类中去定义\n\n\n\n派生类的拷贝控制成员\n当派生类定义了拷贝或是移动操作时，该操作负责拷贝或移动包括基类部分成员在内的所有对象\n\n\n\n\n派生类赋值运算符：\n\n//Base::operator=(const Base&amp;)D &amp;D::operator=(const D&amp;rhs){    Base::operator=(rhs);    //assign values to sub classes    //set-assignment and resourse deletion need to be taken care of    return *this;}\n\n\n派生类析构函数：只需要销毁派生类自己分配的资源\n在构造函数和析构函数中调用虚函数：如果这么做了，则我们应该执行与构造函数或析构函数所属类型相对应的虚函数版本。\n\n继承的构造函数\nc++11新标准中，构造函数是可以继承的\n一个类只继承其直接基类的构造函数\n\nclass Bulk_quote: public Disc_quote{public:    using Disc_quote::Disc_quote; //继承Disc_quote的构造函数    double net_price(std::size_t) const;}\n\n\n作用于构造函数时，using语句令编译器产生代码。对基类的每一个构造函数，编译器都生成一个对应的派生类构造函数。形如： derived(params):base(args){}\n\n\n\n\n定义在派生类中的构造函数会替换继承而来的构造函数\n\n容器与继承\n\n在容器中放置（智能）指针而非对象\n\n\n\n\n在第二个push_back中，传入的是Bulk_quote类型的智能指针。c++会把派生类的智能指针转换为基类指针（自动转换）\n\n编写Basket类\n对应C++面向对象编程来说，我们无法直接使用对象进行面向对象编程，而是必须使用引用和指针（有点好笑）\n经常定义一些辅助类来处理这种复杂情况（涉及指针）\n\n\n回顾下之前的类定义：\n\n\n\n\n\n\n\n\n\n\n\nclass Basket{public:    void add_item(const std::shared_ptr&lt;Quote&gt; &amp;sale){        items.insert(sale);    }    double total_receipt(std::ostream&amp;) const;private:    static bool compare(const std::shared_ptr&lt;Quote&gt; &amp;lhs,                        const std::shared_ptr&lt;Quote&gt; &amp;rhs){        return lhs-&gt;isbn()&lt;rhs-&gt;isbn();    }    std::multiset&lt;std::shared_ptr&lt;Quote&gt;, decltype(compare)*&gt; items{compare};};\n\n\nmultiset保存多个报价，按照compare成员排序\n\ntotal_receipt将购物篮中的内容逐项打印成清单，并返回购物篮中所有物品的总价格\n\n\ndouble Basket::total_receipt(std::ostream&amp; os) const{\tdouble sum = 0.0;    for(auto iter = items.cbegin(); iter!=items.cend(); iter = items.upper_bound(*iter)){        sum += print_total(os, **iter, items.count(*iter));    }    os&lt;&lt;\"Total Sale: \"&lt;&lt;sum&lt;&lt;endl;    return sum;}\n\n\nupper_bound可以令我们跳过与当前关键字相同的所有元素，他返回一个迭代器，指向所有与iter相等的元素中最后一个元素的下一个位置\nprint_total调用了虚函数，其结果依赖于**iter的动态类型\n\n隐藏指针目前Basket的用户依然必须处理动态内存：\nBasket bsk;bsk.add_item(make_shared&lt;Quote&gt;(\"123\",45));bsk.add_item(make_shared&lt;Bulk_quote&gt;(\"345\",45,3,.15));\n\n下一步修改add_item，让Basket进行内存分配：\nvoid add_item(const Quote&amp; sale);void add_item(Quote&amp;&amp; sale);\n\n但是问题是，add_item不知道要分配的类型，所以如下的分配是有误的：\nnew Quote(sale)\n\n如果sale实际指向的是Bulk_quote对象，那么该对象将被迫切掉一部分\n模拟虚拷贝class Quote{public:    virtual Quote* clone() const &amp; {return new Quote(*this);}    virtual Quote* clone() &amp;&amp; {return new Quote(std::move(*this));}    // other is same};class Bulk_quote: public Quote{    Bulk_quote* clone() const &amp;{        return new Bulk_quote(*this);    }    Bulk_quote* clone() &amp;&amp; {return new Bulk_quote(std::move(*this));}};class Basket{public:    void add_item(const Quote&amp; sale){        items.insert(std::shared_ptr&lt;Quote&gt;(sale.clone()));    }    void add_item(Quote&amp;&amp; sale){        items.insert(std::shared_ptr&lt;Quote&gt;(std::move(sale).clone()));    }}\n\n\n尽管sale类型是右值引用类型，但是sale本身是个左值，因此用move把一个右值引用绑定到sale上\n\n文本查询程序再探初始版本实现需求在一个给定文件中查询单词，查询结果是单词在文件中出现次数及其所在行的列表：\n\n\n\n\n数据结构从定义一个保存输入文件的类开始：TestQuery\nvector用来保存输入文件的文本\nmap用来关联每个单词和它出现的行号set\n这个类里有个执行查询的操作：查找map，检查给定的单词是否出现，涉及这个函数的难点是应该返回什么内容，我们需要知道它出现了多少次，行号，以及每行的文本。\n返回这些内容的最简单的方法是定义另一个类：QueryResult来保存查询结构，该类有一个print函数，完成结果打印工作。\n先编写使用这个程序的类：\n\n文本查询程序类的定义\n\n\nQueryResult需要共享保存输入文件的vector和保存单词关联的行号set\n\nTextQuery构造函数\n\n\n调用reset更新lines引用的shared_ptr，并使其指向这个新分配的set\n\nQueryResult类\n\n\n\nquery函数\n\n\n使用find而不是下标可以避免将单词添加到wm中\n\n打印结果\n\n\n\n优化版本实现功能\n单词查询：得到匹配某个给定string 的所有行\n\n逻辑非查询：得到不匹配查询条件的所有行\n\n逻辑或查询：返回匹配两个条件中任意一个的行\n\n逻辑与查询：返回全部匹配两个条件的行\n\n同时可混合使用：如fiery &amp; bird | wind\n\n\n面向对象解决方案将不同查询建模成相互独立的类：\n\nWordQuery\nNotQuery\nOrQuery\nAndQuery\n\n它们共享一个公共基类\n它们只包含两个操作：\n\neval：接受一个TextQuery并返回一个QueryResult\nrep：返回基础查询的string表示形式\n\n抽象基类\n\n将层次关系隐藏于接口类中\n首先必须建立查询命令，可以使用如下代码，来实现之前描述的复合查询：\n\nQuery q = Query(\"fiery\") &amp; Query(\"bird\") &amp; Query(\"wind\");\n\n\n我们会定义一个接口类Query，隐藏整个继承体系。它将保存一个Query_base指针，该指针绑定到Query_base的派生类对象上。eval用于求查询的结果，rep用于生成查询的string版本\n用户通过Query对象的操作间接地创建并处理Query_base对象\n&amp;运算符生成一个绑定到新的AndQuery对象上的query对象\n|运算符生成一个绑定到新的OrQuery对象上的query对象\n~运算符生成一个绑定到新的NotQuery对象上的query对象\n\n\n\n\n\n类工作机理\n构建代表用户查询的对象是该应用程序的核心\n\n\n\n代码实现Query_base类\nclass Query_base{    friend class Query;protected:    using line_no = TextQuery::line_no;    virual ~Query_base() = default;private:    virtual QueryResult eval(const TextQuery&amp;) const = 0;    virtual std::string rep() const = 0;}\n\n\n我们不希望用户或是派生直接使用querybase，所以没有public成员\n\nQuery类\nclass Query{    friend Query operator~(const Query &amp;);    friend Query operator|(const Query &amp;, const Query &amp;);    friend Query operator&amp;(const Query &amp;, const Query &amp;);public:    Query(const std::string &amp;);    QueryResult eval(const TextQuery &amp;t) const{        return q-&gt;eval(t);    }    std::string rep(const){return q-&gt;rep();}private:    Query(std::shared_ptr&lt;Query_base&gt; query): q(query) { }    std::shared_ptr&lt;Query_base&gt; q;}\n\nQuery的输出运算符\n\n\nWordQuery类\nclass WordQuery: public Query_base{    friend class Query;    WordQuery(const std::string &amp;s): query_word(s){}    QueryResult eval(const TextQuery &amp;t) const    {return t.query(query_word);}    std::string rep() const {return query_word;}    std::string query_word;}\n\ninlineQuery::Query(const std::string &amp;s): q(new WordQuery(s)){}\n\nNotQuery类\nclass NotQuery: public Query_base{    friend Query operator~(const Query &amp;);    NotQuery(const Query &amp;q): query(q){}    QueryResult eval(const TextQuery &amp;) const;    std::string rep() const {return \"~(\" + query.rep() + \")\";}    Query query;}inline Query operator~(const Query &amp;operand){    return std::shared_ptr&lt;Query_base&gt;(new NotQuery(operand));}// 隐式使用接受一个shared_ptr&lt;Query_base&gt;的Query构造函数\n\n","categories":["Books","C++ primer","C++ OOP"],"tags":["C++","面向对象"]},{"title":"如何阅读问题并得到可行解","url":"/2023/08/05/coding-solution/code_forces_01/","content":"如何去阅读问题陈述基本规则\n得到纯数学模型\n\n更短\n\n更简单\n\n数据的限制\n\n实例样本：验证得到模型的整确性\n\n查看备注note\n\n尝试去找熟悉的模式或范式(模板等）\n\n努力去找一些奇怪的事情，你没有预期的那种（maybe cornerstone）\n\n将模型划分为独立的部分\n\n书写新的描述，在纸上，用手\n\n\n样例1569. Networking the “Iset”\n给定无向图，求出图的直径最短的连通图(生成树)。\n如何去得到解决方案\n”全部回忆“\n\n回想曾经解决过的相似问题\n\n”从特殊到一般“\n\n为了解决一般的问题，我们需要解决其所有的特殊情况，并尝试将他们推广到主问题（一般问题）的解法。也就是说，如果我不知道如何去解决一个复杂的问题，那么我们应该去简化它，并找到最简单版本的解\n\n如果你得到了一个树的问题，可以考虑一个变种，将树退化为路径来进行解决\n如果一个问题有权重，那么可以考虑所有权重都有相同的值或都为1，或是只有两种有区别的权重。\n\n\n“大胆假设”\n\n当得到假设之后，尝试去证明它（通过大量的测试）。\n\n“为了解决一个问题，你需要像问题一样思考”\n\n把自己带入到问题的角色当中，想象处理输入集是自己的工作，并思考在这种情况下，自己该如何行动。可以考虑用可视化的方法来辅助理解。\n\n“一起想”\n\n只有在组队打比赛的时候有用。\n\n“挑选一个方法”\n\n假设问题可以通过挑选的方法解决，我们基于该方法去思考解决方案。\n\n“输出并查看”\n“谷歌”\n\n","categories":["coding"],"tags":["code_forces"]},{"title":"如何去练习竞赛性质的编程？","url":"/2023/08/05/coding-solution/code_forces_02/","content":"Competitive Programming\n如何去练习竞赛性质的编程？\n\n意见或指导Radewoosh’s blog他认为你需要将生命的一部分给予CP。他所指的不是时间，而是一部分思维(a part of their minds)。在不断练习以及观察我们进步的时候，我们在其中希望变得更加优秀，并获得真正意义的快乐。这也意味着让自己思考各种问题或在现实生活的许多方面看到算法解释。\n他还认为每当我们有以下想法的时候，我们都应该练习。“it will be cool to solve every problem on this website”，这种想法越多帮助越大。\n如果哪方面比较薄弱，我们就应该在这方面多进行练习(see your weakness)。\n他的建议是把CP放在心里，并有真实的渴望去练习。而不要勉强自己，以一种组织化的方式去完成任务。\n-is-this-fft-‘s blog作者把每天的虚拟比赛当作是例行工作并变得懒惰。只是完成它们，但总体上对更难的问题缺乏兴趣。可能外在看起来没有任何变化，但内在作者不再对学习付出认真的努力，并对问题进行更加深入的思考。\n\n有可能你欺骗自己说你花了很多时间和精力练习，但是却没有做真正有意义的练习。\n\n作者认为动机在练习当中十分重要，它认为真正重要的动机(motivations)是，对于解决问题本身具有强烈的兴趣。有另外一些动机，如找到好工作，只能算是做CP而不做其他事的原因。\n\nPick a problem with difficulty rating f(your rating). Pretend to solve it for* n minutes, then read the editorial.\n\n作者认为，”solve the problem”的意思是想出一个解法，有可能的话去实现它；而不是去实现一个解决方案。假装，可能是指我们在解决问题时只进行了几次不负责任的尝试，或者说我们并没有全身心地投入到问题里。作者给出的建议是，忘记题解，开始不带一丝一毫去看题解的想法去解决问题。停止去思考“花了多长时间再去看题解”，而是去判断“我是否应该去阅读题解”。\n古德哈特定律(Goodhart’s law)\n‘当一项评价指标成为目标时，他就不再是一个好的测量指标了’。我们不能单单以刷题数量作为我们的目标。若是如此，我们就会偏向于做简单的题，而达不到练习的效果。\nCF使用Tips\nproblem rating是使用codeforces最好的方式，做略高于符合自己rating的题目是比较有挑战性的。\n\nCF进阶从新手到专家评分1400只需要完成三件事：\n\n快速写出直接模拟\n快速写出暴力算法\n在脑中或纸上将问题分成不同的情况\n\n练习方法\n解决 AtCoder Beginner Contests 中的B、C问题(solve all problems of B and C)\n\nR500 – R700 – R900 – R1400 \n\n为了方便知道哪些问题尚未解决可以使用下面的链接来查看: AtCoder Problems\n\n尝试在15分钟内思考B问题的所有可能解法（尽全力），若不行再去查看题解\n\n尝试在30分钟内思考C问题的所有可能解法（尽全力），若不行再去查看题解\n\n只解决题目不是目的，目的是锻炼解决问题的能力：利用筛选和排序，寻找最简单的代码进行学习\n\n\n从专家到Top 10%为了评分1900，我们需要知道主流的算法\n\n\ncode faster：对于R1100的问题用5分钟解决，对于R1400的问题用10分钟解决\n\n这里作者推荐解决 AtCoder Beginner Contests 中的C、D问题。其中C问题在10min内解决，D问题在20min内解决。\n\n如果你觉得你在哪方面比较弱，就应该在对应方面多加练习\n\n\n","categories":["coding"],"tags":["code_forces"]},{"title":"C++标准库","url":"/2023/08/05/coding-solution/c++%20primer_std/","content":"C++标准库动态内存动态分配的对象的生存期与它们在哪里创建是无关的，只有当显式地被释放时，这些对象才会被销毁。\n静态内存\n用来保存局部地static对象、类static数据成员、以及定义在任何函数之外地变量。\n栈内存\n栈内存用来保存定义在函数内的非static对象\n\n分配在静态内存或是栈内存中的对象由编译器自动创建或销毁\n\n堆、自由空间\n程序用堆来存储动态分配的对象，即程序运行时分配的对象；其生存期由程序来控制，不用时，我们的代码必须显式销毁它们\n动态内存与智能指针\n使用新标准库的智能指针可以更好地管理动态内存，在memory头文件中\n\n\nshared_ptr：允许多个指针指向同一个对象\nunique_ptr：独占所指向的对象\n\nshared_ptr类shared_ptr和unique_ptr都支持的操作\n\nshared_ptr sp 空智能指针\np 用作条件判断，若指向一个对象则为true\n*p 解引用\np-&gt;mem\np.get()\nswap(p,q)\n\n仅shared_ptr支持的操作\n\nmake_shared (args) 指向一个动态分配的T类型的对象，返回一个shared_ptr\nshared_ptr p(q)  p是shared_ptr q的拷贝\np = q 递减p的引用次数，递增q的引用次数\np.unique() 若p.use_count()为1，返回true\np.use_count() 返回与p共享对象的智能指针数量\n\nmake_shared函数\n\n最安全的分配和使用动态内存的方法\n\nshared_ptr&lt;int&gt; p3 = make_shared&lt;int&gt;(42);shared_ptr&lt;string&gt; p4 = make_shared&lt;string&gt;(10,'9');auto p6 = make_shared&lt;vector&lt;string&gt;&gt;();\n\nshared_ptr的拷贝和赋值\n当进行拷贝和赋值时，每个shared_ptr都会记录有多少个其他shared_ptr指向相同的对象\nshared_ptr自动销毁所管理的对象\n\n使用析构函数\n\nshared_ptr会自动释放相关联的内存\nvoid use_factory(T arg){    shared_ptr&lt;Foo&gt; p = factory(arg);    //use p}\n\n当p被销毁时，p所指向的对象也会被销毁(如果没有其他指针指向它)\nshared_ptr&lt;Foo&gt; use_factory(T arg){    shared_ptr&lt;Foo&gt; p = factory(arg);    return p;}\n\n在这种情况下，return向其调用者返回一个p的拷贝。引用计数器++，所以不会销毁p所指的对象\n使用动态生存期资源的类\n\n程序不知道自己需要使用多少对象\n程序不知道所需对象的准确类型\n程序需要在多个对象间 共享数据\n\n\n容器类出于第一个原因使用动态内存；\n\n目前为止，我们使用的类中，分配的资源与对应对象的生存期一致，但某些类分配的资源具有与原对象相独立的生存期。例如，如果两个类共享底层的数据，当某个类被销毁时，我们不能单方面地销毁底层数据：\nBlob&lt;string&gt; b1;{    Blob&lt;string&gt; b2 = {\"a\",\"an\",\"the\"};    b1 = b2;}\n\n\n使用shared_ptr共享数据\n\nclass StrBlob{    private:    \tstd::shared_ptr&lt;std::vector&lt;std::string&gt;&gt; data;}\n\nStrBlob::StrBlob(initializer_list&lt;string&gt; il):\t\t\t\tdata(make_shared&lt;vector&lt;string&gt;&gt;(il)){}\n\n直接管理内存使用new动态分配和初始化对象\n在自由空间分配的内存是无名的, 因此new无法为其分配的对象命名, 而是返回一个指向该对象的指针:\nint * p  = new int // p指向一个动态分配的,未初始化的无名对象\n默认初始化和值初始化\n\n\n括号包围的初始化器\nauto p1 = new auto(obj)// c++11标准\n\n用new分配const对象\nconst string * pcs = new const string;\n\n\nconst对象必须进行初始化, 定义了默认构造函数的类类型可以隐式初始化。\n\n内存耗尽\n#include&lt;new&gt;int *p1 = new int; //分配失败， 抛出std::bad_allocint *p2 = new (nothrow) int; //分配失败，返回空指针\n\n调用者必须记得释放内存\nFoo* factory(T arg){    return new Foo(arg);}\n\n动态数组","categories":["Books","C++ primer","C++ 标准库"],"tags":["C++","std"]},{"title":"coding笔记： 问题空间搜索浅析","url":"/2023/08/05/coding-solution/dfs&bfs/","content":"问题空间搜索DFS\n执着的算法\n\n\n思想\n会尽可能往深了搜，搜不到了就回溯，每一次回溯完之后判断当前是不是所有的路径均已遍历，若均已遍历，再进行回溯，否则搜索未遍历的路径\n\n两个重要概念\n\n回溯\n注意恢复现场\n\n剪枝\n最优性剪枝：当前的路径判断一定不如最优解，就可以剪枝了\n可行性剪枝：提前判断当前方案一定是不合法的，那么下面的子树就可以不用进行搜索了\n\n\n\n顺序：重要的是顺序，即我们要用一个什么样的顺序将某一道题的所有方案全部遍历一遍\n\n举例：\n\n\n全排列问题—最经典DFS的问题\nconst int N = 10;int path[N];bool st[N];//求1-n的全排列数量void dfs(int h,int n){    if(h==n){        for(int i=0;i&lt;n;i++)            printf(\"%d \",path[i]);        puts(\"\");    }    for(int i=1;i&lt;=n;i++){        if(!st[i]){            path[h] = i;            st[i] = true;            dfs(i,h+1,n);            st[i] = false;        }    }}\n\nn-皇后问题\n\n第一种搜索顺序：枚举每一行这个皇后应该放到哪一列上去（经过了某种程度的优化，因为两个皇后不可能在同一行），与全排列的搜索顺序完全一致，同一对角线上的元素必定满足上图的直线方程，所以可以用截距b作为直线的编号。\n\n\n\n\n\nconst int N = 20;bool col[N];bool diag[2*N],udiag[2*N];char Q[N][N];// 无需对queencnt计数，比视频里的方法快了4，5msvoid initBoard(int n){    for(int i = 1;i&lt;=n;i++) {        for (int j = 1; j &lt;=n; j++)            Q[i][j] = '.';    }}void nqueen_dfs(int r,int n){    for(int i=1;i&lt;=n;i++){        if(!col[i]&amp;&amp;!diag[i+r]&amp;&amp;!udiag[i-r+n]){                        col[i] = diag[i+r]= udiag[i-r+n] = true;            Q[r][i] = 'Q';                        if(r==n){                for(int k=1;k&lt;=n;k++){                    for(int j=1;j&lt;=n;j++){                        printf(\"%c\",Q[k][j]);                    }                    puts(\"\");                }                puts(\"\");                Q[r][i] = '.';                col[i] = diag[i+r]= udiag[i-r+n] = false;                return;            }                        nqueen_dfs(r+1,n);            Q[r][i] = '.';            col[i] = diag[i+r]= udiag[i-r+n] = false;        }    }}\n\n\n第二种搜索顺序： 更加原始的一种搜索方式，对于每一个格子，选择是否放皇后， 挨个枚举所有格子，当枚举到最后一个格子(N^2)的时候即得到答案\n\n对于这种思路我们应该如何处理呢？\n  \n\n\n\nBFS\n稳重的算法\n\n\n思想\n每次扩展一层，只有当前层全搜索过了之后，才会去搜索下一层，第一次搜到的话一定是最短的\n\n\nDFS和BFS对比\n\n\n搜索方式\n数据结构\n占用空间\n最短路性质\n应用场景\n\n\n\nDFS\nstack\nO(h)\n不可以搜到最短路\n对空间要求高的\n\n\nBFS\nqueue\nO(2^h)\n可以搜到最短路（边权重为1时）\n最小步数，最短距离，最少操作次数\n\n\n\n举例：\n\n走迷宫—最短路问题；dp问题实际上是没有环的最短路\n\n基本框架\n将初始状态放入队列\n只有队列不空便循环:\n每次把队头拿出来\n扩展队头\n\n\n\n\n\n//迷宫问题--如何将框架应用起来//数据准备与初始化int g[N][N]; // store the mapint d[N][N]; // store the distance to the start entryint bfs()\n\n","categories":["coding"],"tags":["dfs","bfs"]},{"title":"coding笔记： 快排的应用","url":"/2023/08/05/coding-solution/k-thNumber/","content":"快排的应用第k个数给定一个长度为 n 的整数数列，以及一个整数 k，请用快速选择算法求出数列从小到大排序后的第 k个数。\n输入格式\n第一行包含两个整数 n 和 k\n第二行包含 n 个整数（所有整数均在 1∼10^9 范围内），表示整数数列。\n输出格式\n输出一个整数，表示数列的第 k 小数。\n数据范围\n1≤n≤1000001≤k≤n\n输入样例\n5 32 4 1 5 3\n\n输出样例\n3\n\n主要思想如果先排序再取第k个数，会导致的复杂度，因此采用快速选择算法，基于快排的模板进行修改即可：\nint findKthNumber(int q[],int l,int r,int k){    if(l==r) return q[l];    int mid = l+r&gt;&gt;1;    int x = q[mid];    int i = l-1,j = r+1;    while(i&lt;j){        do{i++;}while(q[i]&lt;x);        do{j--;}while(q[j]&gt;x);        if(i&lt;j) swap(q[i],q[j]);    }    int lol = j-l+1;    if(k&lt;=lol) return findKthNumber(q,l,j,k);    else return findKthNumber(q,j+1,r,k-lol);}\n\n\n\n\n如上图所示，修改点在于如何递归地处理子问题：在（l,r）中寻找第k个数。\n而快排给出了找到良好分界点的方式，即j左边的数包括j自身都小于等于x，j右边的数都大于等于x。\n因此蓝色区间的数都小于等于红色区间的数，从而如果k小于等于蓝色区间的数的个数，那么第k个数一定在蓝色区间中；反之，如果k大于蓝色区间的数的个数，那么第k个数一定大于等于x,即在红色区间中可以找到。\n\n疑惑与解释最难理解的地方其实在于边界处，如果k==lol，即第k个数刚好是蓝色区间的个数，我们是否可以直接返回x呢？答案是否定的。原因在于j这个点其实决定了蓝色区间的长度，但是这不代表x就处于j这个位置，即[l..j]可能都小于x，因此第k个数不一定就是x，下图是一个实例，直观解释了这一点：\n\n\n上图中x是236，j=22指向192这个数，lol=2=k，可见215，192都小于x(236)，236，244都大于等于x，但是返回的却不是第k个数。k=lol只能说明下一步要去寻找蓝色区间里最大的数。\n","categories":["coding"],"tags":["快速选择","快排"]},{"title":"coding笔记：高精度加减乘除","url":"/2023/08/05/coding-solution/highaccuracy/","content":"高精度算数主要思想\n如何存储大数？使用数组（vector）\n\n怎么存储？低位在前，高位在后\n之所以这样是因为进位容易，不需要将数组整体向后移动一位\n\n模拟人工算数流程\n\n\n加法vector&lt;int&gt; highAccAdd(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    int c = 0;    vector&lt;int&gt; C;    if (A.size()&lt;B.size()) return highAccAdd(B,A);    for(int i=0;i&lt;A.size();i++){        if(i&lt;B.size()) c+= B[i];        c += A[i];        C.push_back(c%10);        c /= 10;    }    if(c) C.push_back(1);    return C;}\n\n减法\n减法我们规定只能大数减小数，否则不够借位；\n小数减大数可以转化为负的大数减小数\n(c+10)%10合并了c&lt;0时借位和&gt;0时不用借位的情况；\n\nbool biggerThan(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    if(A.size()!=B.size()) return A.size()&gt;B.size();    else{        for(int i=A.size()-1;i&gt;=0;i--)            if(A[i]!=B[i]) return A[i]&gt;B[i];    }    return true;}\n\nvector&lt;int&gt; highAccMinus(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    int c = 0;    vector&lt;int&gt; C;    // 我们假设A一定大于B,且均为正数    for(int i=0;i&lt;A.size();i++){        c+=A[i];        if(i&lt;B.size()) c-=B[i];        C.push_back((c+10)%10);        if(c&lt;0) c=-1;        else c=0;    }    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n乘法\n高精度乘法实际上是一个大数乘以小数\n注意要去除前导零；\n\nvector&lt;int&gt; highAccMul(vector&lt;int&gt;&amp;A,int b){    int c = 0;    vector&lt;int&gt; C;    for(int i=0;i&lt;A.size()||c;i++){        if(i&lt;A.size()) c+=A[i]*b;        C.push_back(c%10);        c/=10;    }    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n除法\n模拟手工除法，注意这次是从高位开始循环，不同于之前的算数\n每次的借位可以使用c来存储，使用c*10+A[i]来表示当前的被除数\n\nvector&lt;int&gt; highAccDiv(vector&lt;int&gt;&amp;A,int b,int*r){    int c=0;    vector&lt;int&gt;C;    for(int i=A.size()-1;i&gt;=0;i--){        c= c*10+A[i];        C.push_back(c/b);        c%=b;    }    *r = c;    reverse(C.begin(),C.end());    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n","categories":["coding"],"tags":["高精度"]},{"title":"coding笔记：KMP算法","url":"/2023/08/05/coding-solution/kmp/","content":"KMP算法浅析\nKMP算法在各种参考书中均有讲解，但均较为复杂，且不易于理解其中原理，现佐以笔记，记录自己的学习心得\n因为kmp算法相对抽象，因此本文大多辅以图像方便理解\n参考视频：https://www.bilibili.com/video/BV1MY4y1Y7Nh\n\n问题描述给定一个模式串 S，以及一个模板串 P，所有字符串中只包含大小写英文字母以及阿拉伯数字。\n模板串 P 在模式串 S 中多次作为子串出现。\n求出模板串 P 在模式串 S 中所有出现的位置的起始下标。\n输入格式\n第一行输入整数 N，表示字符串 P 的长度。\n第二行输入字符串 P。\n第三行输入整数 M，表示字符串 S 的长度。\n第四行输入字符串 S。\n输出格式\n共一行，输出所有出现位置的起始下标（下标从 0 开始计数），整数之间用空格隔开。\n数据范围\n1≤N≤1051≤M≤106\n核心思想\n\n如图，假设现在已匹配了j个字符，但是第j+1个字符不匹配，即，这里S为红色的目标串，P为蓝色的模式串。不匹配时，需将模式传尽可能少的往后移动（我的理解是为了防止漏掉正解），使得移动后的模式串仍与目标串匹配且长度为next[j]，这里采用的思想是不浪费过去已匹配的信息的同时确保找到所有的解，这里只需简单的令即可减少无用的重复匹配次数，然后再判断P[next[j]+1]和S[i]是否相等，不相等则重复上述步骤直到j=0。\n最大前后缀相等长度\n上述的next[j]的定义为：P[1,j]的前缀和后缀相等的最大长度，之所有取最大前文也有解释，是为了确保找到所有解。\nnext数组求解既然问题的关键在于求解next数组，那么找到行之有效的算法是很必要的。这里的思想为归纳法：假设我们已经求解出了next[1,i-1]，现在求出next[i]即可归纳求出整个next数组。依旧可以看上面的图，因为next[i-1]已知，我们可以把模式串移到对应的位置，判断P[i]是否等于P[next[i-1]+1]。若相等说明next[i] = next[i-1] + 1；若不等令P[next[next[i-1]]+1]和P[i]再进行判断，若一直不满足，那么直到next[…] = 0，说明P[1,i]的前缀和后缀相等的最大长度为0，因此next[i]则为0。\nnext[i] = next[i-1] + 1\n下面用反证法解释下为什么该式是成立的：若存在一个更长的前缀和后缀相等的子串，那么同时去掉一个刚匹配的字符，则剩下的串比next[i-1]也要长，这与假设next[i-1]已经是最长的相互矛盾，因此next[i]所存的就是P[1,i]的前缀和后缀相等的最大长度。\n// 求解next数组for(int i=1,j=0;i&lt;=n;i++){    while(j &amp;&amp; P[j+1]==P[i]) j = ne[j];    if(P[j+1]==P[i]) j++;    ne[i] = j;}// kmp匹配for(int i=1,j=0;i&lt;=m;i++){    while(j &amp;&amp; P[j+1]==S[i]) j = ne[j];    if(P[j+1]==S[i]) j++;    if(j==n){        print(\"%d \", i-n);        j = ne[j];    }}\n\n\n\nKMP算法应用字符串的循环节next数组的解法可以让我们求出字符串的循环节：n-next[n]\n\n\n由图，因为绿色字符串的前缀和后缀相等的最大长度为next[n]，因此我们可以将该串向后移动n-next[n]，使得重叠部分恰好相等。又因为下面的串是平移的，因此上面串的第一段就等于下面串的第一段且长度为n-next[n]，又下面串的第一段与上面串的重叠部分相等（第二段），因此上面串的第一段和第二段相等，以此类推上面串的所有段都相等且以n-next[n]为长度进行循环，因此是字符串的循环节。\n不具有循环节的串\n例如，“abcdefgh”,不重复的串是不可能有循环节的，若是以其作为模式串，next[i]均为0，kmp算法最多比较O(m+n)次\n循环节最多的串\n例如，“aaaaaaa”，每个字符都相等的串的循环次数最多，若是以其为模式串，kmp算法最多比较匹配O(2m)次\n\n详细证明可参考博客\n\n字符串所有前后缀相等的子串\n\n这个求解实际和循环节的求解是完全相似的。每次我们将字符串向后平移(实际上是令j = next[j])，求出next数组后我们可以很方便的求出其所有前缀与后缀相等的子串P[:next[j]], j = next[j] util j = 0\n现证明该算法为什么能找到所有前后缀相等的子串\n假设存在长度为k的前后缀未能通过上述递归式找到。我们先去找长度大于k的长度为i_t的前后缀，假设找到了且为图中第一段的next[n]，那么下一段next[next[n]]即是以next[n]为结尾的最长的前后缀，因为k也是前后缀，但是k比next[next[n]]长与next[next[n]]的定义相互矛盾，所以k必然不存在，因此算法找到了所有前后缀相等的子串。\n","categories":["coding"],"tags":["KMP"]},{"title":"coding笔记：前缀和和差分","url":"/2023/08/05/coding-solution/%E5%89%8D%E7%BC%80%E5%92%8C%E5%92%8C%E5%B7%AE%E5%88%86/","content":"前缀和和差分基础浅析前缀和\n定义：使用s[N]表示数组q[N]的前缀和数组，s[i]表示q[1-i]的元素的和\n公式：\n注意，下标范围为1-N，且s[0]=0\n\n差分\n定义：前缀和的逆运算，假想一个d[N]，使得q[N]是d的前缀和数组，那么d[N]就称为q的差分。\n公式：\n注意，d下标范围为1-N\n\n前缀和和差分的应用求一段数的和O(1)\n\n只需要事先处理得到q数组的前缀和s数组，就可以通过在O(1)时间内完成一段数的求和\n\n对一段数加上某个数O(1)\n\n假设我们已经有了差分数组，我们只需要对其求一遍前缀和即可得到原数组，时间复杂度为O(n)\n我们对d[i]加上c后，a[i]~最后都会加上c（根据前缀和的定义），所有如果想要给一段数(l,r)都加上c，就只需要d[l]+c，d[r+1]-c\n\n对子矩阵求和O(1)\n\n对一维进行扩展可以得到二维区间和=，图像直观解释如下图：\n\n\n对二维区间加上某个数O(1)\n画图可以清楚的解释该算法：\n\n\n代码如下：\ntemplate&lt;int n,int m&gt;void diffAdd2D(int (&amp;diff) [n][m], int x1,int y1,int x2,int y2,int c){    diff[x1][y1]+=c;    diff[x1][y2+1]-=c;    diff[x2+1][y1]-=c;    diff[x2+1][y2+1]+=c;}\n\n注：在代码里我使用了二维数组传参的一种优美方法（使用模板推导出二维数组维度），在函数调用时无须指明维度大小，在函数体内也可以直接索引，从而可以减少代码量。\n同理可以进行推广到三维甚至多维数组，代码如下：\ntemplate&lt;int n, int m, int q&gt;void test3Dimens(int (&amp;test)[n][m][q], int x1,int y1,int z1,int c){    test[x1][y1][z1]-=c;}const int Q = 110;int test3D[Q][Q][Q];int multiDimenTest(){    test3D[1][2][3]=6;    test3Dimens(test3D,1,2,3,6);    cout&lt;&lt;test3D[1][2][3];    return 0;}\n\n推广：3D空间求和O(1)\n\n应该不会考类似的题，但是对于拓展思维应该还是有用的\n\ntemplate&lt;int n, int m, int q&gt;void 3D_Sum(int (&amp;test)[n][m][q], int x1,int y1,int z1,int x2,int y2,int z2){    return test[x2][y2][z2]-test[x2][y1-1][z2]-test[x1-1][y2][z2]-test[x2][y2][z1-1]+test[x2][y1-1][z1-1]+test[x1-1][y2][z1-1]+test[x1-1][y1-1][z2]-test[x1-1][y1-1][z1-1];}\n\n","categories":["coding"],"tags":["前缀和","差分"]},{"title":"coding笔记：典型数据结构之数组模拟浅析","url":"/2023/08/05/coding-solution/%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"典型数据结构之数组模拟浅析\n这里默认已经对基本的数据结构有所了解，因此重点在于数组模拟练习与总结。对于算法题而讲，使用数据模拟的好处不言而喻（速度快），是STL外的一大解题利器。\n\n\n变量和代码解释都写在了注释里，可以方便之后的回顾。p.s. 为了方便，有的简单的注释就直接用英语打了，可以减少输入法的繁琐切换。\n\n链表单链表\n数据准备及初始化\n\n//单链表const int N = 100010 //就实际工程而言，定死可能不太优美，注意优化方案int e[N];// store the value of the nodesint ne[N];// store the ptrs of next node int head;// store the index of head nodeint idx;// store the current available indexvoid init(){    head = -1;//注意：一开始链表为空，使用-1来辨识空结点    idx = 0;}\n\n\n数据操纵\n\n//insert to the head of the listvoid add_to_head(int x){    e[idx] = x;    ne[idx] = head;    head = idx++;}//insert the node after the k(index) nodevoid insert_k(int k, int x){    e[idx] = x;    ne[idx] = ne[k];    ne[k] = idx++;}//remove the node after the k(index) nodevoid remove_k(int k){    ne[k] = ne[ne[k]];}\n\n\n应用：删除倒数第二个结点 O(n)\n\n用一个额外的pre来保存当前遍历结点的前两个结点，只要当前结点的下一结点非空就一直遍历，否则退出循环，代码如下：\nvoid remove_l2(){    int pre = -1;    int cnt=0;    int cu = head;    while(ne[cu]!=-1){        cnt++;        if(cnt&gt;1){            if(pre==-1) pre = head;            else pre = ne[pre];        }        cu = ne[cu];\t}    remove_k(pre);}\n\n双链表\n数据准备与初始化\n\nint e[N];int l[N]; //store the pre idex of current nodeint r[N]; //store the next idex of current nodeint idx; // store the current available nodevoid init(){    r[0]=1; // 默认0号点为左边界，1号点为右边界    l[1]=0;    idx = 2;}\n\n\n数据操纵\n\n// insert a node at the head of the listvoid insert_left(int x){    insert_k_right(0,x);}//insert a node at the end of the listvoid insert_right(int x){    insert_k_left(1,x);}//insert a node to the k(index) node 's leftvoid insert_k_left(int k, int x){    insert_k_right(l[k],x);}//insert a node to the k(index) node 's rightvoid insert_k_right(int k, int x){    e[idx] = x;    r[idx] = r[k];    l[idx] = k;    l[r[k]]=idx;    r[k] = idx++;}// delete the k(index) node void delete_k(int k){    l[r[k]] = l[k];    r[l[k]] = r[k];}\n\n栈\n先进后出\n\n\n数据准备与初始化\n\nint stk[N];int tt=0;\n\n\n数据操纵\n\n//push to the top of stackvoid push(int x){    stk[++tt]=x;}//pop the top of the stackvoid pop(){    if(tt&gt;0) tt--;}//check if the stack is emptybool isEmpty(){    if(tt) return false;    else return true;}//query the top of the stackint top(){    return stk[tt];}\n\n一种可能的优化：面向对象的封装+任意类型的数据\n#include&lt;iostream&gt;const int N = 100010;template&lt;class T&gt;class Stack {    T stk[N];    int tt;public:    Stack(){        init();    }    //init    void init() { tt = 0; }    // pop    T pop() { return stk[tt--]; }    // push    void push(T x) { stk[++tt] = x; }    // isempty    bool isEmpty() {        if (tt &gt; 0) return false;        else return true;    }    void printStack(){        printf(\"--------------\\n\");        for(int i =1;i&lt;=tt;i++) printf(\"%c \",stk[i]);        printf(\"--------------\\n\");    }    // top    T queryTop() { return stk[tt]; }};\n\n队列\n先进先出\n\n\n数据准备与初始化\n\nint q[N];int hh,tt;//指向队头和队尾元素void init(){    hh=0;    tt=-1;}\n\n\n数据操纵\n\n//向队尾插入一个数void push(int x){    q[++tt] = x;}//从队头弹出一个数int pop(){    if(!isEmpty()) return q[hh++];    else printf(\"error\");}//判断队列是否为空bool isEmpty(){    if(hh&gt;tt) return true;    else return false;}//查询队头元素int top(){    if(!isEmpty()) return q[hh];    else printf(\"error\");}\n\nTrie\n概念：用于高效存储和查找字符串集合的数据结构\n\n数据准备与初始化\n\n\nint son[N][26]; //假设只有大写字母A-Z,存储当前结点的所有子结点int cnt[N]; //记录以i为结尾的字符串的个数int idx; //存储当前可用的索引//下标为0的点既是根结点又是空结点void init(){    idx = 1;}\n\n\n数据操纵\n\nchar str[N];// add a string to the trievoid insert(char str[]){    if(!str[0]) return;    int cu = 0;    for(int i=0;str[i];i++){        int k = str[i]-'A';        if(!son[cu][k]) son[cu][k] = idx++;        cu = son[cu][k];    }    cnt[cu]++;}// query the number of occurances of the string in the trieint find_occur(char str []){    if(!str[0]) return 0;    int cu = 0;    for(int i=0;str[i];i++){        int k = str[i]-'A';        if(!son[cu][k]) return 0;        cu = son[cu][k];    }    return cnt[cu];}\n\n并查集\n概念：可以快速处理并维护\n\n将两个集合合并\n询问两个元素是否在一个集合中\n\n\n如果使用暴力解法，合并两个集合需要O(n)的时间，而并查集可以在O(1)的时间内近似完成这两个操作。\n\n数据准备与初始化\n\n\nint fa[N]; // store the parent index of each node// only the root node has the property of fa[root]=root'void init(){    int num;    cin&gt;&gt;num;    for(int i=1;i&lt;=num;i++) fa[i]=i;}\n\n\n数据操作\n\n// find the set(root) index which num x is inint find_root(int x){    //if current node is not root    if(fa[x]!=x) fa[x]=find_root(fa[x]); // path compression    return x;}// combine two sets which num a/b is invoid combine(int a, int b){    int r_a = find_root(a);    int r_b = find_root(b);    if(r_a != r_b) fa[a]= b;}// query whether two num are in the same setbool inSameSet(int a, int b){    return find_root(a)==find_root(b);}\n\n堆\n在STL中也称为优先队列priority queue\n\n数据准备与初始化\n\n\nint heap[N];//heap is a 完全二叉树int size;int cnt; // cnt the num of insertint cti[N],itc[N]; // preserve a count to index mapping and a index to count mapping// cause 2*i is the left node index and 2*i+1 is the right node index// so we have to start at the index 1\n\n\n数据操纵\n\n// swapvoid myswap(int x, int y){    swap(heap[x],heap[y]);    swap(cti[itc[x]],cti[itc[y]]);    swap(itc[x],itc[y]);}// build a heapvoid buildHeap(){    for(int i = size/2;i;i--){        down(i);    }}// upvoid up(int x){    if(x/2 &amp;&amp; heap[x/2]&gt;heap[x]){        myswap(x/2,x);        up(x/2);    }}// downvoid down(int x){    int min_i = x;    if(2*x&lt;=size &amp;&amp; heap[min_i]&gt;heap[2*x]) min_i = 2*x;    if(2*x+1&lt;=size &amp;&amp; heap[min_i]&gt;heap[2*x+1]) min_i = 2*x + 1;    if(min_i!=x) {        myswap(min_i,x);        down(min_i);    }}// insert a numvoid insert(int num){    heap[++size] = num;    itc[size] = ++cnt;    cti[cnt] = size;    up(size);}// output the min num of the heapint min_val(){    return heap[1];}// delete the min num of the heapvoid delete_min(){    myswap(1,size--);    down(1);}// delete the kth insert numvoid delete_k(int k){    // put the num at position size of the heap(end) to the position cti[k]    // if we don't know the itc(index to count mapping)    // we can't update the new cti[itc[size]] which is actually cti[k]    // so we need a two way mapping    int tmp = cti[k]; // store this value because the function below it may change its value    myswap(tmp, size--);    up(tmp),down(tmp);}// modify the kth insert num to xvoid modify_k(int k, int x){    heap[cti[k]] = x;    up(cti[k]),down(cti[k]);}\n\n哈希表开放寻址法\n\n以开放寻址为主例，因为开的空间小，且写起来简单；拉链法仅贴出代码\n\n\n数据准备与初始化\nint h[N];//列表长度取&gt;操作集合2倍大小的最小质数，不容易起冲突int null = 0x3f3f3f3f;// 该数大于10^9，一般看作最大整型，这里取不可能出现的数作为空值// 使用下面的函数即可得到N的大小为200003void find_min_prime(int x){    for(int i=x;;i++){        bool flag = true;        for(int j=2;j*j&lt;i;j++){            if(i%j==0) {                flag=false;                break;            }        }        if(flag) {            printf(\"%d\",i);            break;        }    }}void init(){    memset(h,0x3f,sizeof h);//将所有entry置为null}\n数据操纵\n\n\n// find the index where the num should be(exists if h[index] not null) int find(int x){    int k = (x%N+N)%N; // not to make it negative, compute the hash Which is often the mod operation.     while(h[k]!=null &amp;&amp; h[k]!=x){        k++;        if(k==N) k=0;    }    return k;}// query whether the num is in the hash tablebool hasNum(int x){    if(h[find(x)]!=null) return true;    else return false;}// insert a num into hash tablevoid insert(int x){    if(!hasNum(x)) h[find(x)]= x;   }\n\n拉链法\n\n数据准备与初始化\n\nint h[N] // N = 100003 int e[N],ne[N],idx;memset(h,-1,sizeof h);//-1代表为空\n\n\n数据操纵\n\n//拉链法// insert a num into hash table, can be duplicate in this situationint insert(int x){    int k = (x%N+N)%N;    e[idx] = x;    ne[idx] = h[k];    h[k]= idx++;}// query whether the num is in the hash tablebool hasNum(int x){    int k = (x%N+N)%N;    int cu = h[k];    while(cu!=-1) {        if(e[cu]==x) return true;        cu = ne[cu];    }    return false;}\n\n","categories":["coding"],"tags":["数据结构","数组模拟"]},{"title":"coding笔记：Acwing知识点总结","url":"/2023/08/05/coding-solution/acwing%E6%80%BB%E7%BB%93/","content":"Acwing 知识点总结\n在这个总结里主要讲算法模板和思路，具体的题目代码见刷题.md\n\n第一讲 基础算法排序快排主要思想\n快排属于分治算法，分治算法都有三步：\n\n分成子问题\n递归处理子问题\n子问题合并\n\n寻找一个哨兵，将小于这个哨兵的元素放于其左边，大于他的元素放于其右；递归的排序其左区间和右区间即可完成排序，快排没有子问题合并这一步\nthink point\n\n如何选取哨兵的位置？\n哨兵的位置应该随机选取，或是取中间：若是取左边作为哨兵，若数组本身就是有序的，每次分划的时间为O(n)，之后的子问题规模即为0和n-1，总共的复杂度即为，而取中间作为哨兵可以保证每次可以把区间分为长度近似相等的两部分，因而复杂度为递归深度*O(n)即为\n\n每次划分两部分后，最终哨兵的位置是否需要获知？\n根据每次分划后是否需要知道哨兵的位置，可以有两种思路来进行快排：\n\n\n哨兵最终位置未知\n第一种思路是acwing的模板思路，缺点是有一些坑，不好理解(i,j位置不能互换，不然可能陷入死循环等)但是代码较为整洁，适合笔试用\nvoid quicksort(int q[], int l, int r) {    if (l&gt;=r) return;    // 使用区间中点作为哨兵    int mid = l+r &gt;&gt;1;//    swap(q[mid],q[l]);    int x = q[mid], i = l-1, j= r+1;    //忽略了哨兵的位置，我不在乎哨兵的位置具体在哪里    //我只知道，j右边的数都大于等于哨兵，j左边的数都小于等于哨兵    //之所以不取等于是防止数组越界，还有可以更好地划分子问题    //缺点是可能会有很多次无效交换    while(i&lt;j) {        do i++; while (q[i] &lt; x);        do j--; while (q[j] &gt; x);        if (i &lt; j) swap(q[i], q[j]);    }    quicksort(q,l,j);    quicksort(q,j+1,r);}\n\n算法证明：\n明显地，j右边的数大于等于x,i左边的数小于等于x。现需证明while结束时，q[l..j]均&lt;=x，若成立，即可证明j这个端点可以划分整个区间。因为i&gt;=j，所以q[1..j-1]均&lt;=x。因为退出循环前的i&lt;j判断为false，所以最后一次交换不执行，所以q[j]必然&lt;=x。综上可以证明q[l..j]均&lt;=x，所以j这个端点可以划分整个区间。\n哨兵最终位置已知\n第二种是数据结构教材的官方思路，优点是步骤明确，方便理解，较少坑，缺点是代码冗长\nvoid quicksort2(int q[], int l, int r) {    if (l&gt;=r) return;    // 首先保存哨兵的值    int pio = q[l];    int i = l;    int j = r;    while(i&lt;j){        // 之所以可以取=，是因为之前有判断，一定不会越界        while(i&lt;j &amp;&amp; q[j]&gt;=pio) j--;        if(i&lt;j) q[i] = q[j];        else break;        while(i&lt;j &amp;&amp; q[i]&lt;=pio) i++;        if(i&lt;j) q[j] = q[i];    }    //哨兵的位置是确定的=i=j，所以只需要对其左边和右边分别进行排序即可    q[i] = pio;    quicksort2(q,l,i-1);    quicksort2(q,i+1,r);}\n\n算法改进\n\n实际上是对于某类特殊数据的算法增强\n\n如果数组的每个数据都相同时，上面的第一种思路可以pass，但是第二种思路会超过时限，究其原因为：分化后的子问题规模即为0和n-1，总共的复杂度即为，所以对于这种情况需要特殊处理，而且不能简单地将中点与左端点交换（实际上没有改变算法流程），第二种思路地修改点如下：\nwhile(i&lt;j){        // 之所以可以取=，是因为之前有判断，一定不会越界        while(i&lt;j &amp;&amp; q[j]&gt;pio) j--;        if(i&lt;j) q[i++] = q[j];        else break;        while(i&lt;j &amp;&amp; q[i]&lt;pio) i++;        if(i&lt;j) q[j--] = q[i];    }\n\n经测试，第二种思路改进后速度较第一种思路能快上一点点\n\n\n快排应用—快速选择\n主要思想\n如果先排序再取第k个数，会导致的复杂度，因此采用快速选择算法，基于快排的模板进行修改即可：\nint findKthNumber(int q[],int l,int r,int k){    if(l==r) return q[l];    int mid = l+r&gt;&gt;1;    int x = q[mid];    int i = l-1,j = r+1;    while(i&lt;j){        do{i++;}while(q[i]&lt;x);        do{j--;}while(q[j]&gt;x);        if(i&lt;j) swap(q[i],q[j]);    }    int lol = j-l+1;    if(k&lt;=lol) return findKthNumber(q,l,j,k);    else return findKthNumber(q,j+1,r,k-lol);}\n\n\n\n\n如上图所示，修改点在于如何递归地处理子问题：在（l,r）中寻找第k个数。\n而快排给出了找到良好分界点的方式，即j左边的数包括j自身都小于等于x，j右边的数都大于等于x。\n因此蓝色区间的数都小于等于红色区间的数，从而如果k小于等于蓝色区间的数的个数，那么第k个数一定在蓝色区间中；反之，如果k大于蓝色区间的数的个数，那么第k个数一定大于等于x,即在红色区间中可以找到。\n\n疑惑与解释\n最难理解的地方其实在于边界处，如果k==lol，即第k个数刚好是蓝色区间的个数，我们是否可以直接返回x呢？答案是否定的。原因在于j这个点其实决定了蓝色区间的长度，但是这不代表x就处于j这个位置，即[l..j]可能都小于x，因此第k个数不一定就是x，下图是一个实例，直观解释了这一点：\n\n\n上图中x是236，j=22指向192这个数，lol=2=k，可见215，192都小于x(236)，236，244都大于等于x，但是返回的却不是第k个数。k=lol只能说明下一步要去寻找蓝色区间里最大的数。\n归排主要思想\n首先把待排序数组分成子问题（排序两个长度近似相等的数组），递归处理子问题直到只剩一个元素，两个数组排序完成后需要合并成一个新的排序好的数组，这就是第三步：子问题合并。代码如下：\n#include &lt;iostream&gt;using namespace std;const int N = 1e6 + 10;int n;int q[N];int temp[N];void mergesort(int q[], int l, int r) {    if (l &gt;= r) return;    int mid = l + r &gt;&gt; 1;    mergesort(q, l, mid), mergesort(q, mid + 1, r);    int k = l, i = l, j = mid + 1;    while (i &lt;= mid &amp;&amp; j &lt;= r) {        if (q[i] &lt;= q[j]) temp[k++] = q[i++];        else temp[k++] = q[j++];    }    while (i &lt;= mid) temp[k++] = q[i++];    while (j &lt;= r) temp[k++] = q[j++];    for (int i = l; i &lt; r + 1; i++)        q[i] = temp[i];}int main() {    scanf(\"%d\",&amp;n);    for(int i=0;i&lt;n;i++) scanf(\"%d\",&amp;q[i]);    mergesort(q,0,n-1);    for (int i=0;i&lt;n;i++) printf(\"%d \",q[i]);    return 0;}\n\n归并排序应用—逆序对数量\n这个题目相当于套在了归并排序的大框框里。注意合并两个已排序子序列时如何去计算逆序对数量。\n二分整数二分\n整数二分因为涉及+1，-1，所以为了防止死循环，需要考虑边界情况。\n当我们定义一个性质，该性质可以将数据二分时（即存在边界时），二分算法是可以将该边界找出来的。\n\n主要思想\n\n假设在整个区间内部是可以找到答案的，我们对整个区间不断进行二分\n每次都要选择答案所在的区间去进行下一步搜索（每次会把整个区间的大小缩小一半）\n二分一定会保证区间里有答案的，但是存在特例，即原问题无解的情况（无解一定和题目有关）\n在原问题无解的情况下，若没有遇到数组边界，找到的区间一定是满足条件的，但不是query；而如果遇到数组边界，那么就可能不会满足找到的区间一定是满足条件的（以整数的范围这道题为例）\n\n该图即为寻找满足check的最右端端点示意图\n\n上图对应的代码即为二分模板1的代码，如下所示：\nbool check(int mid) {return false;}double function(double){return 0.0;}// 二分模板1int bsearch1(int l,int r){    // 考虑边界，l+1=r时，算法是否正确    // l+1=r时,需要修改mid=l,会陷入死循环    // 所以修改mid=(l+r+1)/2,遇到边界时，mid=r,可以顺利退出    // r会小于l的可能仅在最后一句，但遇到边界且不满足条件时，计算的mid不可能=l,所以退出循环时r不可能小于l,即l=r    // 返回r,l均可    while (l&lt;r){        int mid = l+r+1 &gt;&gt;1;        // 若check 代表满足条件        if(check(mid)) l = mid;        else r = mid-1;    }    return l;}// 二分模板2int bsearch2(int l,int r){    // 寻找不满足的断点    // 考虑边界，l+1=r时，算法是正确的    // 退出循环时，l==r的原理同上    while(l&lt;r){        int mid = l+r&gt;&gt;1;        if(check(mid)) l = mid+1;        else r = mid;    }    return l;}\n\n浮点数二分\n较整数二分简单，因为不需要考虑边界（因为没有整除，每次都可以完美地将边界缩小一半）\n思想与整数二分一样，只要满足时时刻刻答案都在我们的区间即可； \n但我们的区间足够小时，我们就可以认为已经找到了答案；\n有两种方式可以去写浮点数二分的循环条件：一个是固定循环100次，如果原来区间长度为1时，结束时区间长度即为；或是指定一个很小的数epsilon，当区间长度小于这个数即可退出。\n\ndouble fbsearch(double l,double r,double target){    // 浮点数二分查找    while(r-l&gt;1e-8){        double mid = (l+r)/2;        double val = function(mid);        if (val&gt;=target) r = mid;        else l = mid;    }    return l;}\n\n应用：数的三次方根\n求数的三次方根可以使用二分查找来做。因为函数是单调的，所以很容易判断mid和target的大小关系，从而缩小查找范围，代码如下：\ndouble fbiSearch(double l, double r, double target, double (*pf)(double)) {    while (r - l &gt; 1e-7) {        double mid = (l + r) / 2;        if (pf(mid) &lt;= target) l = mid;        else r = mid;    }    return r;}double calTrip(double x){    return x*x*x;}int findRoot3(){    double n;    double (*pf)(double)=calTrip;    cin&gt;&gt;n;    if(n&lt;0) printf(\"-%.6f\",fbiSearch(0,ceil(-n),-n,calTrip));    else printf(\"%.6f\",fbiSearch(0,ceil(n),n,calTrip));    return 0;}\n\n简要介绍下引入的函数指针，有了函数指针就可以方便地将计算方法传入二分查找算法来找解。double (*pf)(double)=calTrip;可以定义一个函数指针，非常有用。\n高精度算数主要思想\n\n如何存储大数？使用数组（vector）\n\n怎么存储？低位在前，高位在后\n之所以这样是因为进位容易，不需要将数组整体向后移动一位\n\n模拟人工算数流程\n\n\n加法\nvector&lt;int&gt; highAccAdd(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    int c = 0;    vector&lt;int&gt; C;    if (A.size()&lt;B.size()) return highAccAdd(B,A);    for(int i=0;i&lt;A.size();i++){        if(i&lt;B.size()) c+= B[i];        c += A[i];        C.push_back(c%10);        c /= 10;    }    if(c) C.push_back(1);    return C;}\n\n减法\n\n减法我们规定只能大数减小数，否则不够借位；\n小数减大数可以转化为负的大数减小数\n(c+10)%10合并了c&lt;0时借位和&gt;0时不用借位的情况；\n\nbool biggerThan(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    if(A.size()!=B.size()) return A.size()&gt;B.size();    else{        for(int i=A.size()-1;i&gt;=0;i--)            if(A[i]!=B[i]) return A[i]&gt;B[i];    }    return true;}\n\nvector&lt;int&gt; highAccMinus(vector&lt;int&gt;&amp;A,vector&lt;int&gt;&amp;B){    int c = 0;    vector&lt;int&gt; C;    // 我们假设A一定大于B,且均为正数    for(int i=0;i&lt;A.size();i++){        c+=A[i];        if(i&lt;B.size()) c-=B[i];        C.push_back((c+10)%10);        if(c&lt;0) c=-1;        else c=0;    }    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n乘法\n\n高精度乘法实际上是一个大数乘以小数\n注意要去除前导零；\n\nvector&lt;int&gt; highAccMul(vector&lt;int&gt;&amp;A,int b){    int c = 0;    vector&lt;int&gt; C;    for(int i=0;i&lt;A.size()||c;i++){        if(i&lt;A.size()) c+=A[i]*b;        C.push_back(c%10);        c/=10;    }    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n除法\n\n模拟手工除法，注意这次是从高位开始循环，不同于之前的算数\n每次的借位可以使用c来存储，使用c*10+A[i]来表示当前的被除数\n\nvector&lt;int&gt; highAccDiv(vector&lt;int&gt;&amp;A,int b,int*r){    int c=0;    vector&lt;int&gt;C;    for(int i=A.size()-1;i&gt;=0;i--){        c= c*10+A[i];        C.push_back(c/b);        c%=b;    }    *r = c;    reverse(C.begin(),C.end());    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}\n\n前缀和和差分前缀和\n\n定义：使用s[N]表示数组q[N]的前缀和数组，s[i]表示q[1-i]的元素的和\n公式：\n注意，下标范围为1-N，且s[0]=0\n\n差分\n\n定义：前缀和的逆运算，假想一个d[N]，使得q[N]是d的前缀和数组，那么d[N]就称为q的差分。\n公式：\n注意，d下标范围为1-N\n\n前缀和和差分的应用求一段数的和O(1)\n\n只需要事先处理得到q数组的前缀和s数组，就可以通过在O(1)时间内完成一段数的求和\n\n对一段数加上某个数O(1)\n\n假设我们已经有了差分数组，我们只需要对其求一遍前缀和即可得到原数组，时间复杂度为O(n)\n我们对d[i]加上c后，a[i]~最后都会加上c（根据前缀和的定义），所有如果想要给一段数(l,r)都加上c，就只需要d[l]+c，d[r+1]-c\n\n对子矩阵求和O(1)\n\n对一维进行扩展可以得到二维区间和=，图像直观解释如下图：\n\n\n对二维区间加上某个数O(1)\n画图可以清楚的解释该算法：\n\n\n代码如下：\ntemplate&lt;int n,int m&gt;void diffAdd2D(int (&amp;diff) [n][m], int x1,int y1,int x2,int y2,int c){    diff[x1][y1]+=c;    diff[x1][y2+1]-=c;    diff[x2+1][y1]-=c;    diff[x2+1][y2+1]+=c;}\n\n注：在代码里我使用了二维数组传参的一种优美方法（使用模板推导出二维数组维度），在函数调用时无须指明维度大小，在函数体内也可以直接索引，从而可以减少代码量。\n同理可以进行推广到三维甚至多维数组，代码如下：\ntemplate&lt;int n, int m, int q&gt;void test3Dimens(int (&amp;test)[n][m][q], int x1,int y1,int z1,int c){    test[x1][y1][z1]-=c;}const int Q = 110;int test3D[Q][Q][Q];int multiDimenTest(){    test3D[1][2][3]=6;    test3Dimens(test3D,1,2,3,6);    cout&lt;&lt;test3D[1][2][3];    return 0;}\n\n推广：3D空间求和O(1)\n\n应该不会考类似的题，但是对于拓展思维应该还是有用的\n\ntemplate&lt;int n, int m, int q&gt;void 3D_Sum(int (&amp;test)[n][m][q], int x1,int y1,int z1,int x2,int y2,int z2){    return test[x2][y2][z2]-test[x2][y1-1][z2]-test[x1-1][y2][z2]-test[x2][y2][z1-1]+test[x2][y1-1][z1-1]+test[x1-1][y2][z1-1]+test[x1-1][y1-1][z2]-test[x1-1][y1-1][z1-1];}\n\n双指针算法指向两个序列\n维护某种次序，例如归并排序合并两个有序序列的操作。\n\n指向一个序列（更常见）\n两个指针维护的是一段区间，例如快排\n\n代码模板\nfor(i=0,j=0;i&lt;n;i++){    while(j&lt;i &amp;&amp; check(i,j)) j++;    //每道题的具体处理逻辑}\n\n核心思想\n\n运用了某些单调的性质，可以把朴素算法O(n2)优化到O(n)\n\n算法应用\n\n把一行字符串中的每个单词分别输出出来，且每个单词占一行\n\n#include &lt;iostream&gt;#include &lt;string.h&gt;int main(){    char str[1000];    gets(str);    int n = strlen(str);    for(int i=0;i&lt;n;i++){        int j=i;        while(j&lt;n &amp;&amp; str[j]!=' ') j++;        for(int k=i;k&lt;j;k++) cout&lt;&lt;str[k];        cout&lt;&lt;endl;        i=j;    }    return 0;}\n\n\n找出最长的不包含重复数字的连续子序列\n\n可以先想暴力的算法，再进行优化\n暴力：先枚举终点，再枚举起点 O(n2)\n优化：当区间终点向后移动时，区间起点也一定向后移动\n可以开一个大数组，动态地确定一下当前区间每个数出现多少次。当加入一个数，如果出现次数&gt;1，则说明重复了，需要更新起点的位置。当数据很大时可以用哈希表来做。\n位运算求整数N其二进制表示中第k位数字是几\n\n个位是第0位，十位是第1位\n\n\n先把第k位移到最后一位:n&gt;&gt;k\n看看个位是几:x&amp;1\n\nlowbit(x)：返回x的最后一位1\n公式：x &amp; -x = x &amp; (~x+1)\n\nc++中一个整数的负数是原数的补码，即-x=~x+1\n\n直观解释如下图：\n\n\n应用：统计整数的二进制表示中1的个数\n每一次把它的最后一位1去掉，当x=0时，说明没有1了，减了多少次就说明有多少个1。\n离散化\n特指整数的离散化，而且是保序的离散化\n总共的取值范围跨度很大，但是我们只用到了其中的一小部分，非常稀疏。\n\n值域比较大，但是数的个数比较小。过程如图所示：\n\n\n\na[]中可能有重复元素，所以需要去重\n\n//把一个数组排序+去重vector&lt;int&gt; alls;sort(alls.begin(),alls.end());// unique将所有元素去重，并且范围去重后元素的尾端点alls.erase(unique(alls.begin(),alls.end()),alls.end());\n\n\n如何算出a[i]离散化后的值？\n\n通过二分求出离散化后的值：找到第一个大于等于x的位置\nint find(int x){    int l=0,r=alls.size()-1;    while(l&lt;r){        int mid = l+r&gt;&gt;1;        if(alls[mid]&gt;=x) r = mid;        else l = mid+1;    }    return r+1;//映射到1,2,...,n}\n\n应用：求区间所有数的和\n结合前缀和和离散化，将每一个可能用到的下标存到vector alls中，操作的新下标即离散后化的值，每个操作在新数组上进行\n区间合并\n将所有有交集的区间进行合并，输出合并后的区间个数\n\n贪心的思想\n按照区间的左端点排序，扫描所有区间，当前区间和前面维护的区间的位置关系如下图：\n\n\n 可以使用pair来存储区间端点，使用vector来存储所有区间。使用st,ed表示当前维护区间的端点，若遍历区间与维护区间没有交集，就可以将维护区间加入result数组中去，否则更新维护区间的端点。\n第二讲 数据结构\n这里默认已经对基本的数据结构有所了解，因此重点在于数组模拟练习与总结。对于算法题而讲，使用数据模拟的好处不言而喻（速度快），是STL外的一大解题利器。\n\n\n变量和代码解释都写在了注释里，可以方便之后的回顾。p.s. 为了方便，有的简单的注释就直接用英语打了，可以减少输入法的繁琐切换。\n\n链表单链表\n数据准备及初始化\n\n//单链表const int N = 100010 //就实际工程而言，定死可能不太优美，注意优化方案int e[N];// store the value of the nodesint ne[N];// store the ptrs of next node int head;// store the index of head nodeint idx;// store the current available indexvoid init(){    head = -1;//注意：一开始链表为空，使用-1来辨识空结点    idx = 0;}\n\n\n数据操纵\n\n//insert to the head of the listvoid add_to_head(int x){    e[idx] = x;    ne[idx] = head;    head = idx++;}//insert the node after the k(index) nodevoid insert_k(int k, int x){    e[idx] = x;    ne[idx] = ne[k];    ne[k] = idx++;}//remove the node after the k(index) nodevoid remove_k(int k){    ne[k] = ne[ne[k]];}\n\n\n应用：删除倒数第二个结点 O(n)\n\n用一个额外的pre来保存当前遍历结点的前两个结点，只要当前结点的下一结点非空就一直遍历，否则退出循环，代码如下：\nvoid remove_l2(){    int pre = -1;    int cnt=0;    int cu = head;    while(ne[cu]!=-1){        cnt++;        if(cnt&gt;1){            if(pre==-1) pre = head;            else pre = ne[pre];        }        cu = ne[cu];\t}    remove_k(pre);}\n\n双链表\n数据准备与初始化\n\nint e[N];int l[N]; //store the pre idex of current nodeint r[N]; //store the next idex of current nodeint idx; // store the current available nodevoid init(){    r[0]=1; // 默认0号点为左边界，1号点为右边界    l[1]=0;    idx = 2;}\n\n\n数据操纵\n\n// insert a node at the head of the listvoid insert_left(int x){    insert_k_right(0,x);}//insert a node at the end of the listvoid insert_right(int x){    insert_k_left(1,x);}//insert a node to the k(index) node 's leftvoid insert_k_left(int k, int x){    insert_k_right(l[k],x);}//insert a node to the k(index) node 's rightvoid insert_k_right(int k, int x){    e[idx] = x;    r[idx] = r[k];    l[idx] = k;    l[r[k]]=idx;    r[k] = idx++;}// delete the k(index) node void delete_k(int k){    l[r[k]] = l[k];    r[l[k]] = r[k];}\n\n栈\n先进后出\n\n\n数据准备与初始化\n\nint stk[N];int tt=0;\n\n\n数据操纵\n\n//push to the top of stackvoid push(int x){    stk[++tt]=x;}//pop the top of the stackvoid pop(){    if(tt&gt;0) tt--;}//check if the stack is emptybool isEmpty(){    if(tt) return false;    else return true;}//query the top of the stackint top(){    return stk[tt];}\n\n一种可能的优化：面向对象的封装+任意类型的数据\n#include&lt;iostream&gt;const int N = 100010;template&lt;class T&gt;class Stack {    T stk[N];    int tt;public:    Stack(){        init();    }    //init    void init() { tt = 0; }    // pop    T pop() { return stk[tt--]; }    // push    void push(T x) { stk[++tt] = x; }    // isempty    bool isEmpty() {        if (tt &gt; 0) return false;        else return true;    }    void printStack(){        printf(\"--------------\\n\");        for(int i =1;i&lt;=tt;i++) printf(\"%c \",stk[i]);        printf(\"--------------\\n\");    }    // top    T queryTop() { return stk[tt]; }};\n\n队列\n先进先出\n\n\n数据准备与初始化\n\nint q[N];int hh,tt;//指向队头和队尾元素void init(){    hh=0;    tt=-1;}\n\n\n数据操纵\n\n//向队尾插入一个数void push(int x){    q[++tt] = x;}//从队头弹出一个数int pop(){    if(!isEmpty()) return q[hh++];    else printf(\"error\");}//判断队列是否为空bool isEmpty(){    if(hh&gt;tt) return true;    else return false;}//查询队头元素int top(){    if(!isEmpty()) return q[hh];    else printf(\"error\");}\n\n单调栈和单调队列主要思路\n先想一个朴素做法\n再想队列或栈中哪些元素是没有用的，然后把所有这些没有用的元素删掉\n再看一下有没有单调性，怎么去优化这个问题\n\n应用场景\n单调栈：给定一个序列，求序列中的每一个数左边离它最近的，且比它小的数在什么地方\n\n\n\n主要思想即，比当前遍历元素大的栈中的数永远不会再用到。每个元素进栈一次，最多出栈一次，因此时间复杂度为O(N)。\n//暴力做法for(int i=0;i&lt;n;i++)    for(j=i-1;j&gt;=0;j--)        if(a[i]&gt;a[j]){            cout&lt;&lt;a[j]&lt;&lt;endl;            break;        }#include&lt;stack&gt;//单调栈做法int main(){    int n;    cin&gt;&gt;n;    stack&lt;int&gt; st;    for(int i=0;i&lt;n;i++){        int x;        cin&gt;&gt;x;        while(st.size() &amp;&amp; x &lt;= st.top()){            st.pop();        }        if(!st.size())            cout&lt;&lt;-1&lt;&lt;' ';        else            cout&lt;&lt;st.top()&lt;&lt;' ';        st.push(x);    }}\n\n\n单调队列：求一个滑动窗口里的最大值或最小值\n\n\n\n主要思想是使用一个队列来维护窗口里的所有数（下标），只有前面一个数比后面的一个数大，我们就可以断定，前面的点一定没有用，因此可以把这个点删掉。只要有逆序对，我们就可以把大的点删掉，把所有这些点删掉的话，整个数列就会变为一个严格单调上升的队列，其最小值正是队头。\n//暴力做法:O(Nk)//遍历队列中的所有数//优化#include&lt;queue&gt;using namespace std;const int N = 1000010;int a[N];int main(){    int n,k;    scanf(\"%d%d\",&amp;n,&amp;k);    for(int i=0;i&lt;n;i++) scanf(\"%d\",&amp;a[i]);    queue&lt;int&gt; que;    for(int i=0;i&lt;n;i++){        int head = que.front();        if(que.size()&amp;&amp;i-k==head) que.pop();        while(que.size&amp;&amp;a[que.back()]&gt;= a[i]) que.pop_back();        que.push(i);        if(i&gt;=k-1) printf(\"%d \",que.front());    }}\n\n\n\nTrie\n概念：用于高效存储和查找字符串集合的数据结构\n\n数据准备与初始化\n\n\nint son[N][26]; //假设只有大写字母A-Z,存储当前结点的所有子结点int cnt[N]; //记录以i为结尾的字符串的个数int idx; //存储当前可用的索引//下标为0的点既是根结点又是空结点void init(){    idx = 1;}\n\n\n数据操纵\n\nchar str[N];// add a string to the trievoid insert(char str[]){    if(!str[0]) return;    int cu = 0;    for(int i=0;str[i];i++){        int k = str[i]-'A';        if(!son[cu][k]) son[cu][k] = idx++;        cu = son[cu][k];    }    cnt[cu]++;}// query the number of occurances of the string in the trieint find_occur(char str []){    if(!str[0]) return 0;    int cu = 0;    for(int i=0;str[i];i++){        int k = str[i]-'A';        if(!son[cu][k]) return 0;        cu = son[cu][k];    }    return cnt[cu];}\n\n并查集\n概念：可以快速处理并维护\n\n将两个集合合并\n询问两个元素是否在一个集合中\n\n\n如果使用暴力解法，合并两个集合需要O(n)的时间，而并查集可以在O(1)的时间内近似完成这两个操作。\n\n数据准备与初始化\n\n\nint fa[N]; // store the parent index of each node// only the root node has the property of fa[root]=root'void init(){    int num;    cin&gt;&gt;num;    for(int i=1;i&lt;=num;i++) fa[i]=i;}\n\n\n数据操作\n\n// find the set(root) index which num x is inint find_root(int x){    //if current node is not root    if(fa[x]!=x) fa[x]=find_root(fa[x]); // path compression    return x;}// combine two sets which num a/b is invoid combine(int a, int b){    int r_a = find_root(a);    int r_b = find_root(b);    if(r_a != r_b) fa[a]= b;}// query whether two num are in the same setbool inSameSet(int a, int b){    return find_root(a)==find_root(b);}\n\n堆\n在STL中也称为优先队列priority queue\n\n数据准备与初始化\n\n\nint heap[N];//heap is a 完全二叉树int size;int cnt; // cnt the num of insertint cti[N],itc[N]; // preserve a count to index mapping and a index to count mapping// cause 2*i is the left node index and 2*i+1 is the right node index// so we have to start at the index 1\n\n\n数据操纵\n\n// swapvoid myswap(int x, int y){    swap(heap[x],heap[y]);    swap(cti[itc[x]],cti[itc[y]]);    swap(itc[x],itc[y]);}// build a heapvoid buildHeap(){    for(int i = size/2;i;i--){        down(i);    }}// upvoid up(int x){    if(x/2 &amp;&amp; heap[x/2]&gt;heap[x]){        myswap(x/2,x);        up(x/2);    }}// downvoid down(int x){    int min_i = x;    if(2*x&lt;=size &amp;&amp; heap[min_i]&gt;heap[2*x]) min_i = 2*x;    if(2*x+1&lt;=size &amp;&amp; heap[min_i]&gt;heap[2*x+1]) min_i = 2*x + 1;    if(min_i!=x) {        myswap(min_i,x);        down(min_i);    }}// insert a numvoid insert(int num){    heap[++size] = num;    itc[size] = ++cnt;    cti[cnt] = size;    up(size);}// output the min num of the heapint min_val(){    return heap[1];}// delete the min num of the heapvoid delete_min(){    myswap(1,size--);    down(1);}// delete the kth insert numvoid delete_k(int k){    // put the num at position size of the heap(end) to the position cti[k]    // if we don't know the itc(index to count mapping)    // we can't update the new cti[itc[size]] which is actually cti[k]    // so we need a two way mapping    int tmp = cti[k]; // store this value because the function below it may change its value    myswap(tmp, size--);    up(tmp),down(tmp);}// modify the kth insert num to xvoid modify_k(int k, int x){    heap[cti[k]] = x;    up(cti[k]),down(cti[k]);}\n\n哈希表存储结构开放寻址法\n\n以开放寻址为主例，因为开的空间小，且写起来简单；拉链法仅贴出代码\n\n\n数据准备与初始化\n\nint h[N];//列表长度取&gt;操作集合2倍大小的最小质数，不容易起冲突int null = 0x3f3f3f3f;// 该数大于10^9，一般看作最大整型，这里取不可能出现的数作为空值// 使用下面的函数即可得到N的大小为200003void find_min_prime(int x){    for(int i=x;;i++){        bool flag = true;        for(int j=2;j*j&lt;i;j++){            if(i%j==0) {                flag=false;                break;            }        }        if(flag) {            printf(\"%d\",i);            break;        }    }}void init(){    memset(h,0x3f,sizeof h);//将所有entry置为null}\n\n\n数据操纵\n\n// find the index where the num should be(exists if h[index] not null) int find(int x){    int k = (x%N+N)%N; // not to make it negative, compute the hash Which is often the mod operation.     while(h[k]!=null &amp;&amp; h[k]!=x){        k++;        if(k==N) k=0;    }    return k;}// query whether the num is in the hash tablebool hasNum(int x){    if(h[find(x)]!=null) return true;    else return false;}// insert a num into hash tablevoid insert(int x){    if(!hasNum(x)) h[find(x)]= x;   }\n\n拉链法\n\n数据准备与初始化\n\nint h[N] // N = 100003 int e[N],ne[N],idx;memset(h,-1,sizeof h);//-1代表为空\n\n\n数据操纵\n\n//拉链法// insert a num into hash table, can be duplicate in this situationint insert(int x){    int k = (x%N+N)%N;    e[idx] = x;    ne[idx] = h[k];    h[k]= idx++;}// query whether the num is in the hash tablebool hasNum(int x){    int k = (x%N+N)%N;    int cu = h[k];    while(cu!=-1) {        if(e[cu]==x) return true;        cu = ne[cu];    }    return false;}\n\n字符串哈希\n字符串前缀哈希法\n\n首先，要预处理出所有前缀的哈希：\n\n\nnote: h[1]=前缀的哈希值\n如何求字符串哈希值？\n\n\n\n把字符串看作一个P进制的数\n把P进制数转换为10进制数\n取模，就可以把任何一个字符串映射为0~Q-1之间的数\n\n注意：\n\n不要把某个字母映射成0\n\n假定我们rp足够好，不存在冲突\n\np=131或13331，Q=2^64时，99.9%都不会出现冲突\n\n预处理前缀哈希：h(i) = h(i-1)*p + str(i)\n\n利用前缀哈希可以求出所有子串的哈希值: h(R) -h[L-1]*p^(R-L+1)\n\n另外用unsigned long long来存Q，即可以省略取模这步（因为会溢出）\n\n\n字符串哈希的作用？\n\n除了不能求循环节，其他好像都代替KMP\n\n快速判断两个字符串是否相同：O(1)\ntypedef unsigned long long ULL;const int N = 100010, P=131;int n,m;char str[N];ULL h[N],p[N];ULL get(int l, int r){    return h[r]-h[l-1]*p[r-l+1];}int main(){    scanf(\"%d%d%s\",&amp;n,&amp;m,str+1);    p[0]=1;    for(int i=1;i&lt;=n;i++){        p[i] = p[i-1]*P;        h[i] = h[i-1]*P+str[i];    }    while(m--){        int l1,r1,l2,r2;        scanf(\"%d%d%d%d\",&amp;l1,&amp;r1,&amp;l2,&amp;r2);                if(get(l1,r1)==get(l2,r2)) puts(\"Yes\");        else puts(\"No\");    }    return 0;    }\n\nSTLvectorvector&lt;int&gt; a;a.size();a.empty();a.clear();//清空a.front()/back();a.push_back()/pop_back();a.begin()/end();//end为最后一个数的后面一个数//系统为某一程序分配空间时，所需时间与空间大小无关，但与申请次数有关//所以vector通过倍增尽可能减少申请次数//遍历for(vector&lt;int&gt;::interator i = a.begin();i!=a.end();i++) cout&lt;&lt;*i&lt;&lt;' ';//前面一大串类型可以直接写为auto，比较省事//范围遍历for(auto x:a) cout&lt;&lt;x&lt;&lt;' ';//比较运算//a&lt;b(字典序)\n\npairpair&lt;int,string&gt;p;//支持比较运算,字典序p={20,\"abc\"};\n\nstringstring a = \"sdf\";a+=\"uyiu\";a.substr(1,2);//从1开始，长度为2的子串//c_str()：返回string对应的字符数组的头指针printf(\"%s\\n\",a.c_str());\n\nqueue//从队尾插入，从队头删除push()front()back()pop()\n\npriority_queuepriority_queue&lt;int&gt; heap;//定义小根堆priority_queue&lt;int,vector&lt;int&gt;,greater&lt;int&gt;&gt; heap;push()top() //返回堆顶元素pop();\n\nstackpush()top()pop()\n\ndeque双端队列，加强版vector，但速度慢\n#include&lt;deque&gt;front()/back();push_back()/pop_back();push_front()/pop_front();begin()/end()\n\nset基于平衡二叉树，本质上动态维护一个有序序列，支持begin()/end()\nset&lt;int&gt;s;//不能有重复元素s.insert(); //插入一个数log(n)s.find();s.count();//返回某个数的个数s.erase();// 输入是一个数x，删除所有x的复杂度为O(k+log(n))// 输入是一个迭代器，删除这个迭代器s.lower_bound()/upper_bound();// lower_bound返回大于等于x的最小的数的迭代器// upper_bound返回大于x最小的数的迭代器multiset&lt;int&gt;ms;//可以有重复元素\n\nmap基于平衡二叉树，本质上动态维护一个有序序列\ninsert();//插入的是一个pairerase();//输入是pair或迭代器find();[]//时间复杂度是log(n)map&lt;string, int&gt; a;a[\"hht\"] = 1;cout&lt;&lt;a[\"hht\"]&lt;&lt;endl;\n\nunordered_set哈希表，绝大部分操作时间复杂度为O(1)\n//凡是和排序有关的操作都是不支持的\n\nbitset压位：若需要开一个空间为10000*10000 bool数组 10^8B=100mb 若题目很不巧，空间为64mb，我们就可以用bitset来存，可以节省8位空间。\nbitset&lt;10000&gt; s;~,&amp;,|,^&lt;&lt;,&gt;&gt;count()返回有多少个1any()判断是否至少有一个1none判断是否全为0set()把所有位，置为1set(k,v)把第k位变成vreset()把所有位，置为0flip(k)把第k位取反\n\nKMP\nKMP算法在各种参考书中均有讲解，但均较为复杂，且不易于理解其中原理，现佐以笔记，记录自己的学习心得\n因为kmp算法相对抽象，因此本文大多辅以图像方便理解\n参考视频：https://www.bilibili.com/video/BV1MY4y1Y7Nh\n\n问题描述\n给定一个模式串 S，以及一个模板串 P，所有字符串中只包含大小写英文字母以及阿拉伯数字。\n模板串 P 在模式串 S 中多次作为子串出现。\n求出模板串 P 在模式串 S 中所有出现的位置的起始下标。\n输入格式\n第一行输入整数 N，表示字符串 P 的长度。\n第二行输入字符串 P。\n第三行输入整数 M，表示字符串 S 的长度。\n第四行输入字符串 S。\n输出格式\n共一行，输出所有出现位置的起始下标（下标从 0 开始计数），整数之间用空格隔开。\n数据范围\n1≤N≤10^51≤M≤10^6\n核心思想\n先想暴力枚举怎么做的\n\nfor(int i=1;i&lt;=n;i++){    bool flag = true;    int t_i = i;    for(int j=1;j&lt;=m;j++,t_i++){        if(S[t_i]!=P[j]){            flag = false;            break;        }    }}\n\n复杂度：O(nm)，浪费了额外信息\n\n如何去优化的\n\n\n\n如图，假设现在已匹配了j个字符，但是第j+1个字符不匹配，即，这里S为红色的目标串，P为蓝色的模式串。不匹配时，需将模式传尽可能少的往后移动（我的理解是为了防止漏掉正解），使得移动后的模式串仍与目标串匹配且长度为next[j]，这里采用的思想是不浪费过去已匹配的信息的同时确保找到所有的解，这里只需简单的令即可减少无用的重复匹配次数，然后再判断P[next[j]+1]和S[i]是否相等，不相等则重复上述步骤直到j=0。\n最大前后缀相等长度\n上述的next[j] = u 的定义为：**P[1,j]的前缀和后缀相等的最大长度(不包括本身)**，之所有取最大前文也有解释，是为了确保找到所有解。\nnext数组求解既然问题的关键在于求解next数组，那么找到行之有效的算法是很必要的。这里的思想为归纳法：假设我们已经求解出了next[1,i-1]，现在求出next[i]即可归纳求出整个next数组。依旧可以看上面的图，因为next[i-1]已知，我们可以把模式串移到对应的位置，判断P[i]是否等于P[next[i-1]+1]。若相等说明next[i] = next[i-1] + 1；若不等令P[next[next[i-1]]+1]和P[i]再进行判断，若一直不满足，那么直到next[…] = 0，说明P[1,i]的前缀和后缀相等的最大长度为0，因此next[i]则为0。\nnext[i] = next[i-1] + 1\n下面用反证法解释下为什么该式是成立的：若存在一个更长的前缀和后缀相等的子串，那么同时去掉一个刚匹配的字符，则剩下的串比next[i-1]也要长，这与假设next[i-1]已经是最长的相互矛盾，因此next[i]所存的就是P[1,i]的前缀和后缀相等的最大长度。\n// 求解next数组// 注：next[1]=0如果第一个字符匹配失败了for(int i=2,j=0;i&lt;=n;i++){    while(j &amp;&amp; P[j+1]!=P[i]) j = ne[j];    if(P[j+1]==P[i]) j++;    ne[i] = j;}// kmp匹配for(int i=1,j=0;i&lt;=m;i++){    while(j &amp;&amp; P[j+1]!=S[i]) j = ne[j];    if(P[j+1]==S[i]) j++;    if(j==n){        print(\"%d \", i-n);        j = ne[j];    }}\n\nKMP算法应用字符串的循环节\nnext数组的解法可以让我们求出字符串的循环节：n-next[n]\n\n\n由图，因为绿色字符串的前缀和后缀相等的最大长度为next[n]，因此我们可以将该串向后移动n-next[n]，使得重叠部分恰好相等。又因为下面的串是平移的，因此上面串的第一段就等于下面串的第一段且长度为n-next[n]，又下面串的第一段与上面串的重叠部分相等（第二段），因此上面串的第一段和第二段相等，以此类推上面串的所有段都相等且以n-next[n]为长度进行循环，因此是字符串的循环节。\n\n不具有循环节的串\n\n例如，“abcdefgh”,不重复的串是不可能有循环节的，若是以其作为模式串，next[i]均为0，kmp算法最多比较O(m+n)次\n\n循环节最多的串\n\n例如，“aaaaaaa”，每个字符都相等的串的循环次数最多，若是以其为模式串，kmp算法最多比较匹配O(2m)次\n\n详细证明可参考博客\n\n字符串所有前后缀相等的子串\n\n\n这个求解实际和循环节的求解是完全相似的。每次我们将字符串向后平移(实际上是令j = next[j])，求出next数组后我们可以很方便的求出其所有前缀与后缀相等的子串P[:next[j]], j = next[j] util j = 0\n现证明该算法为什么能找到所有前后缀相等的子串\n假设存在长度为k的前后缀未能通过上述递归式找到。我们先去找长度大于k的长度为i_t的前后缀，假设找到了且为图中第一段的next[n]，那么下一段next[next[n]]即是以next[n]为结尾的最长的前后缀，因为k也是前后缀，但是k比next[next[n]]长与next[next[n]]的定义相互矛盾，所以k必然不存在，因此算法找到了所有前后缀相等的子串。\n第三讲 搜索DFS\n执着的算法\n\n\n思想\n会尽可能往深了搜，搜不到了就回溯，每一次回溯完之后判断当前是不是所有的路径均已遍历，若均已遍历，再进行回溯，否则搜索未遍历的路径\n\n两个重要概念\n\n回溯\n注意恢复现场\n\n剪枝\n最优性剪枝：当前的路径判断一定不如最优解，就可以剪枝了\n可行性剪枝：提前判断当前方案一定是不合法的，那么下面的子树就可以不用进行搜索了\n\n\n\n顺序：重要的是顺序，即我们要用一个什么样的顺序将某一道题的所有方案全部遍历一遍\n\n举例：\n\n\n全排列问题—最经典DFS的问题\nconst int N = 10;int path[N];bool st[N];//求1-n的全排列数量void dfs(int h,int n){    if(h==n){        for(int i=0;i&lt;n;i++)            printf(\"%d \",path[i]);        puts(\"\");    }    for(int i=1;i&lt;=n;i++){        if(!st[i]){            path[h] = i;            st[i] = true;            dfs(i,h+1,n);            st[i] = false;        }    }}\n\nn-皇后问题\n\n第一种搜索顺序：按全排列思路枚举8皇后问题。枚举每一行这个皇后应该放到哪一列上去（经过了某种程度的优化，因为两个皇后不可能在同一行），与全排列的搜索顺序完全一致，同一对角线上的元素必定满足上图的直线方程，所以可以用截距b作为直线的编号。我们可以用剪枝的思想来优化算法，即提前判断当前方案肯定是不合法的，就没必要搜索下去了。O(n*n!)\n\n\n\n\n\nconst int N = 20;bool col[N];bool diag[2*N],udiag[2*N];char Q[N][N];// 无需对queencnt计数，比视频里的方法快了4，5msvoid initBoard(int n){    for(int i = 1;i&lt;=n;i++) {        for (int j = 1; j &lt;=n; j++)            Q[i][j] = '.';    }}void nqueen_dfs(int r,int n){    for(int i=1;i&lt;=n;i++){        if(!col[i]&amp;&amp;!diag[i+r]&amp;&amp;!udiag[i-r+n]){                        col[i] = diag[i+r]= udiag[i-r+n] = true;            Q[r][i] = 'Q';                        if(r==n){                for(int k=1;k&lt;=n;k++){                    for(int j=1;j&lt;=n;j++){                        printf(\"%c\",Q[k][j]);                    }                    puts(\"\");                }                puts(\"\");                Q[r][i] = '.';                col[i] = diag[i+r]= udiag[i-r+n] = false;                return;            }                        nqueen_dfs(r+1,n);            Q[r][i] = '.';            col[i] = diag[i+r]= udiag[i-r+n] = false;        }    }}\n\n\n第二种搜索顺序： 更加原始的一种搜索方式，对于每一个格子，选择是否放皇后， 挨个枚举所有格子，当枚举到最后一个格子(N^2)的时候即得到答案。O()\n\n对于这种思路我们应该如何处理呢？\n//挨个枚举所有格子，放是一个分支，不放是另一个分支  void dfs(int x, int y, int s){    if(y==n) y=0,x++;    if(x==n){        if(s==n){            for(int i=0;i&lt;n;i++) puts(g[i]);            puts(\"\");        }    }    // 不放皇后    dfs(x,y+1,s);    // 放皇后    if(!row[x] &amp;&amp; !col[y] &amp;&amp; !dg[x+y] &amp;&amp; !udg[x-y+n]){        g[x][y]='Q';        row[x] = col[y] = dg[x+y] = udg[x-y+n] = true;        dfs(x,y+1,s+1);        row[x] = col[y] = dg[x+y] = udg[x-y+n] = false;        g[x][y]='.';    }    }\n\nBFS\n稳重的算法\n\n\n思想\n每次扩展一层，只有当前层全搜索过了之后，才会去搜索下一层，第一次搜到的话一定是最短的\n\n\nDFS和BFS对比\n\n\n\n搜索方式\n占用空间\n数据结构\n最短路性质\n应用场景\n\n\n\nDFS\nO(h)\nstack\n不可以搜到最短路\n对空间要求高的\n\n\nBFS\nO(2^h)\nqueue\n可以搜到最短路（边权重为1时）\n最小步数，最短距离，最少操作次数\n\n\n\n举例：\n\n走迷宫—最短路问题；dp问题实际上是没有环的最短路\n\n基本框架\n将初始状态放入队列\n只有队列不空便循环:\n每次把队头拿出来\n扩展队头\n\n\n\n\n\n\n\n//迷宫问题--如何将框架应用起来#include&lt;queue&gt;//数据准备与初始化int g[N][N]; // store the mapint d[N][N]; // store the distance to the start entry,初始化为-1代表没访问过int dir[5]={-1,0,1,0,-1}int bfs(){    queue&lt;int&gt; que;    que.push({0,0});    memset(d,-1,sizeof d);    d[0][0]=0;    while(que.size()){        auto cu = que.front();        for(int i=0;i&lt;4;i++){            int x = cu.first +dir[i];            int y = cu.second+dir[i+1];            if(x&lt;n &amp;&amp; x&gt;=0 &amp;&amp; y&lt;m &amp;&amp; y&gt;=0 &amp;&amp; d[x][y]==-1 &amp;&amp; g[x][y]==0){                d[x][y] = d[cu.first][cu.second]+1;                que.push({x,y});            }        }            }    return d[n-1][m-1];}int main(){    cin&gt;&gt;n&gt;&gt;m;        for(int i=0;i&lt;n;i++)        for(int j=0;j&lt;m;j++)            cin&gt;&gt;g[i][j];    cout&lt;&lt;bfs()&lt;&lt;endl;    return 0;}\n\n第四讲 图论\n树是一种特殊的图，即树是无环连通图，所以只讲图这个更广泛的数据结构就可以了\n\n树和图的存储无向图\n边是无方向的，对于每一个无向边，可以建两条边：建一条由a到b的，再建一条由b到a的，因此无向图是一种特殊的有向图，我们只需考虑有向图就可以了\n有向图\n\n有向图有度数的概念：入度和出度\n\n\n邻接矩阵\n\n开个二维数组即可，适合存储稠密图（浪费空间）\n\n邻接表\n\nn个点每个点都有一个单链表，存储从该点可以到的所有的点\n考虑最坏情况需要开的数组大小（来存单链表），如果是完全无向无图（n个点），每个点都可以到达其他所有点（n-1个边），所以总共要开的大小\n插入一条新的边（头插法）\n#include&lt;iostream&gt;using namespace std;const int N = 100010,M = N*2;// 如果是树的话可以这么做int h[N],e[M],ne[M],idx;void add(int a, int b){    e[idx] = b;    ne[idx] = h[a];    h[a] = idx++;} void init(){    memset(h,-1,sizeof h);}\n\n树和图的遍历深度搜索\nbool st[N];//存储哪些点已经被遍历过了// u 表示当前已经遍历到的点void dfs(int u){    st[u] = true;//标记一下，这个点已经被搜过了    for(int i=h[u];i!=-1;i=ne[i]){        int j = e[i];// 找到i这个索引所对应的图的结点的编号是多少        if(!st[j]) dfs(j);    }}\n\n\n实例：树的重心\n\n宽度搜索\n求从1号点到n号点的最短路，如果无解，输出-1：\n\n\nint bfs(){    int hh=0,tt=0;    q[0]=1;    memset(d,-1,sizeof d);    d[1]=0;    while(hh&lt;=tt){        int t = q[hh++];        for(int i=h[t];i!=-1;i=ne[i]){            int j = e[i];            if(d[j]==-1){                d[j] = d[t] + 1;                q[++tt] = j;            }        }    }    return d[n];}\n\n\n实例：求拓扑序\n\n\n有向无环图才会有拓扑序列，所以也被称为拓扑图，且不一定是唯一的\n\n求解思路\n所有入度为0的点都可以排在当前最前面的位置；\n枚举t的所有出边t-&gt;j，删掉t-&gt;j，入度d[j]–，如果d[j]==0，就让j入队。\n最短路\n难点在于建图，而不在算法的原理上：给你一个背景，如何把问题抽象成最短路，侧重于实现思路，而不侧重于原理\n\n最短路问题总结见下图：(参考acwing视频)\n\n\n单源最短路\n一个点到其他所有点的最短路\n\n所有边权都是正数\n\nn为点数，m为边数\n\n\n朴素dijkstra算法：O(n^2)\n\n*如果是稠密图(m ~ n^2)*，尽量使用朴素dijkstra算法，其算法流程如下：\n\n初始化：dist[1]=0, dist[i] = 正无穷，S=当前已确定最短路的点的集合{}\nn次迭代：\nfor i : 1~n 在不在S中的点中找到最小值\n将距离最短的点加入S（基于贪心的思想）\n使用t更新其他点的距离\n\n\n\n因为是稠密图，所有推荐用邻接矩阵来存，存在重边的话，就只保留距离最短的那条边即可\n#include&lt;cstring&gt;using namespace std;const int N = 510;int n,m;int g[N][N];int dist[N];bool st[N];int dijkstra(){    memset(dist,0x3f,sizeof dist);    dist[1] = 0;    for(int i=0;i&lt;n;i++){        int t = -1;        for(int j=1;j&lt;=n;j++)            if(!st[j]&amp;&amp;(t==-1||dist[t]&gt;dist[j]))                t= j;        st[t] = true;        for(int j=1;j&lt;=n;j++)            dist[j] = min(dist[j],dist[t]+g[t][j]);    }        if(dist[n]==0x3f3f3f3f) return -1;    return dist[n];}int main(){    scanf(\"%d%d\", &amp;n,&amp;m);    memset(g, 0x3f, sizeof g);    while(m--){        int a,b,c;        scanf(\"%d%d%d\",&amp;a,&amp;b,&amp;c);        g[a][b] = min(g[a][b],c);    }    int t = dijkstra();    printf(\"%d\\n\",t);    return 0;}\n\n\n堆优化版的dijkstra算法：O(mlogn)\n\n如果是稀疏图(m ~ n)，用邻接表来存，那么应该用堆优化版dijkstra算法\n\n\n\n堆\n\n手写堆\n\n优先队列（直接用STL即可，有可能有冗余）\n\n\n\n\nconst int N = 150010;int h[N],e[N],ne[N],w[N],idx;typedef pair&lt;int,int&gt; PII;int dijkstra(){    memset(dist, 0x3f, sizeof dist);    dist[1]=0;    priority_queue&lt;PII,vector&lt;PII&gt;,greater&lt;PII&gt;&gt; heap;    heap.push({0,1});    while(heap.size()){        auto t = heap.top();        heap.pop();        int ver = t.second;        int dis = t.first;        if(st[ver]) continue;        st[ver] = true;        for(int i = h[ver];i!=-1;i=ne[i]){            int j  = e[i];            if(dist[j]&gt;dis+w[i]){                heap.push({dist[j],j});            }                            }    }        if(dist[n]==0x3f3f3f3f) return -1;    return dist[n];}\n\n\n\n存在负权边\n\n若能求出最短路，对应路径内中一定没有负权回路\n\n\nBellman-Fold ：O(nm)\n\n外层循环n次，内层循环所有边，一个比较朴素的算法。\n实际意义：迭代k次，dist[]存的是经过不超过k条边的从1到其他点的最短路距离，若第n次依然有更新，说明存在负权回路\n应用场景：有边数限制的最短路（有负环也就无所谓了）\nint bellman_ford(){    memset(dist,0x3f,sizeof dist);    for(int i=0;i&lt;k;i++){        memcpy(backup,dist,sizeof dist);        for(int j=0;j&lt;m;j++){            int a = edges[j].a;            int b = edges[j].b;            int w = edges[j].w;            dist[b] = min(dist[b],backup[a]+w);        }    }        if(dist[n]&gt;0x3f3f3f3f/2) return -1;    return dist[n];}\n\n\nSPFA： 一般O(m) ，最坏O(nm) \n\n没有负环就可以用SPFA，99%情况下都可以用。\n在同一次迭代，dist[b]要想变小，只有可能是dist[a]变小了。因此用一个队列，队列存的是所有变小的结点。只要队列不空，我们就取出队头，再更新t的所有出边。主要思路就是，更新过谁再拿它来更新别人。\nint spfa(){    memset(dist,0x3f, sizeof dist);    dist[1]=0;    queue&lt;int&gt;q;    q.push(1);    //存的是当前的数是不是在队列当中，防止存重复    st[1] = true;        while(q.size()){        int t = q.front();        q.pop();        st[t] = false;        for(int i=h[t];i!=-1;i=ne[i]){            int j = e[i];            if(dist[j]&gt;dist[t]+w[i]){                dist[j] = dist[t] + w[i];                if(!st[j]) {                    q.push(j);                    st[j] = true;                }            }        }    }    if(dist[n]==0x3f3f3f3f) return -1;    return dist[n];}\n\nspfa求负环\n若cnt[x]&gt;=n，说明存在负环。\n\n\n至少有两个点是相同的，意味着路径上存在着一个负环。（一定会变小，不然不会存在这个环）\n多源汇总最短路\n不止一个起点，任选两个点，从其中一个点到另一个点的最短路问题\n\nFloyd算法：O(n^3)\n采用动态规划的思想：d[i,j]存储所有边，floyd算法包含三重循环：\n\n第一重：k从1到n\n第二重：i从1到n\n第三重：j从1到n:\nd(i,j) = min(d(i,j), d(i,k) + d(k,j))\n\n\n\n最小生成树\n对应的图基本都是无向图\n\nPrim算法朴素版：稠密图。O(n^2)\n 算法流程和dijkstra算法流程非常类似 。首先把所有距离初始化为正无穷。接下来是n次迭代：\n\n找到集合外距离最近的点。(集合S表示当前已经在连通块中的所有点。)\n把t加入到集合中去。\n用t更新其他点到集合的距离。（最短距离）\n\n\n\n选择的点所对应的边(最短的边)加入生成树中去\n#include &lt;cstring&gt;const int N = 510,INF = 0x3f3f3f3f;int n,m;int g[N][N];int dist[N];bool st[N];int prim(){    memset(dist,0x3f,sizeof dist);    int res = 0;    for(int i=0;i&lt;n;i++){        int t = -1;        for(int j=1;j&lt;=n;j++){            if(!st[j]&amp;&amp;(t==-1||dist[t]&gt;dist[j]))                t=j;        }        if(i &amp;&amp; dist[t]==INF) return INF;        if(i) res += dist[t];        st[t] = true;        for(int j=1;j&lt;=n;j++){            dist[j] = min(dist[j],g[t][j]);        }    }    return res;}int main(){    scanf(\"%d%d\",&amp;n,&amp;m);    memset(g,0x3f,sizeof g);    while(m--){        int a,b,c;        scanf(\"%d%d%d\",&amp;a,&amp;b,&amp;c);        g[a][b]=g[b][a]=min(g[a][b],c);    }        int t = prim();    if(t==INF) puts(\"impossible\");    else printf(\"%d\\n\",t);}\n\n堆优化版: 稀疏图。O(mlogn) 一般不会用到。\nKruskal算法O(mlogm)\n经验论：若是稀释图用kruskal算法，稠密图用Prim算法\n\n将所有边按权重从小到大排序（快排，算法瓶颈O(mlogm)）\n枚举每条边，若当前a,b不连通，将这条边加入集合中（并查集,O(m)）\n\n简单而优美的算法\n//只需要把每条边存下来就可以了，不需要用邻接表或邻接矩阵const int N = 100010;int n,m;int p[N];struct Edge{    int a,b,w;    bool operator&lt;(const Edge &amp;W) const{        return w&lt;W.w;    }}edges[N];int find(x){    if(x!=p[x]) p[x] = find(p[x]);    return p[x];}int main(){    scanf(\"%d%d\",&amp;n,&amp;m);    for(int i=0;i&lt;m;i++){        int a,b,w;        scanf(\"%d%d%d\",&amp;a,&amp;b,&amp;w);        edges[i] = {a,b,w};    }        sort(edges,edges+m);        for(int i=1;i&lt;=n;i++) p[i]=i;    int res = 0, cnt = 0;    for(int i=0;i&lt;m;i++){        int a = edges[i].a,b = edges[i].b,w=edges[i].w;        a = find(a),b = find(b);        if(a!=b){            res+=w;            cnt++;            p[a] =b;        }    }        if(cnt&lt;n-1) puts(\"impossible\");    else printf(\"%d\\n\",res);        return 0;}\n\n二分图概念：可以将所有点划分到两个集合，使得所有边都是在集合之间的，集合内部没有边。\n染色法给定一个图，判断它是不是二分图。\n\n时间复杂度：O(n+m)\n重要性质：一个图是二分图当且仅当图中不含奇数环。\n深度优先遍历：若在染色过程中出现了矛盾，就说明不是二分图\n\n遍历每个点，如果该点未染色，那么深度遍历该点：dfs(i,1)\nconst int N = 100010, M = 200010;int n,m;int h[N],e[M],ne[M],idx;int color[N];void add(int a, int b){    e[idx] = b;    ne[idx] = h[a];    h[a] = idx++;}bool dfs(int u, int c){    color[u] = c;    for(int i = h[u];i!=-1;i=ne[i]){        int j = e[i];        if(!color[j]) {            if(!dfs(j,3-c)) return false;        }        else if(color[j]==c) return false;    }    return true;}int main(){    scanf(\"%d%d\",&amp;n,&amp;m);    memset(h,-1,sizeof h);        while(m--){        int a,b;        scanf(\"%d%d\",&amp;a,&amp;b);        add(a,b),add(b,a);    }    bool flag;    for(int i=1;i&lt;=n;i++)        if(!color[i]){            if(!dfs(i,1)){                flag = false;                break;            }        }    if(flag) puts(\"Yes\");    else puts(\"No\");}\n\n匈牙利算法\n时间复杂度：O(nm)\n\n给定一个二分图，求最大匹配的数量。匹配成功：没有两条边共用一个点\n\n存的时候，只需要存左边指向右边的边即可，match存的是右边点当前匹配的点， \n\n\n\n\nconst int N = 510, M= 100010;int n2,n2,m;int h[N],e[M],ne[M],idx;//match存的是右边的点对应的点int match[N];//判重，每次不要重复搜一个点bool st[N];bool find(int x){    for(int i=h[x];i!=-1;i=ne[i]){        int j = e[i];        if(!st[j]){            st[j] = true;            if(!match[j]||find(match[j])){                match[j] = x;                return true;            }        }    }        return false;       }int main(){    scanf(\"%d%d%d\",&amp;n1,&amp;n2,&amp;m);    memset(h,-1,sizeof h);        while(m--){        int a,b;        scanf(\"%d%d\",&amp;a,&amp;b);        add(a,b);    }        int res = 0;    for(int i=1;i&lt;=n1;i++){        //表示这些右边的点还没有考虑过（保证每个右边的点只考虑一遍）        memset(st,false,sizeof st);        if(find(i)) res ++;    }    printf(\"%d\\n\",res);}\n\n\n\n第五讲 数论质数质数和和数是针对严格大于1的整数定义的，如果只包含1和本身两个约数，就被称为质数，否则为和数。\n质数的判定\n\n试除法 O(n)\n\nbool is_prime(int n){    if(n&lt;2) return false;    for(int i=2;i&lt;n;i++)        if(n%i==0) return false;    return true;}\n\n我们可以发现n的所有约数都是成对出现的，即若d为n的约束，那么n/d也为n的约数。所以我们不需要枚举所有数，只需要枚举的数即可，也就是说d只需枚举到即可\n\n优化 O()\n\n不推荐使用sqrt(n)这个函数，也不推荐i*i&lt;=n的写法，因为可能存在溢出风险，所以推荐写法为：i&lt;=n/i\n分解质因数\n\n试除法 O(n)\n\n从小到大尝试n的所有因数，因为每次都会把因子除干净，所以不用担心满足n%i==0的数i会是和数。\nvoid divide(int n){    for(int i=2;i&lt;n;i++){        if(n%i==0){ // i 一定是质数            int cnt = 0;            while(n%i==0){                n/=i;                cnt++;            }            printf(\"%d %d\",i,cnt);        }    }}\n\n\n优化 最坏O()\n\nhints: n中最多只包含一个大于sqrt(n)的质因子，所以可以枚举所有小于sqrt的质因子，如果最后剩下的因子n，若大于1直接输出即可。\n\n优化 O(logn)\n\n求从1~n的所有质数\n\n筛法 O(nlogn)\n\nbool st[N]; //为false代表没有被筛掉int prime[N];void get_prime(int n){    int cnt = 0;     for(int i=2;i&lt;=n;i++){         if(!st[i]){             prime[cnt++]=i;         }         for(int j=i+i;j&lt;=n;j+=i) st[j] = true;     }}\n\n\n优化：埃氏筛法 O(nloglogn)\n\n根据基本分解定理，每个数只需要被素数筛掉就可以了，所有可以把第二个循环放到if里。\nbool st[N]; //为false代表没有被筛掉int prime[N];void get_prime(int n){    int cnt = 0;     for(int i=2;i&lt;=n;i++){         if(!st[i]){             prime[cnt++]=i;             for(int j=i+i;j&lt;=n;j+=i) st[j] = true;         }           }}\n\n\n线性筛法\n\nvoid get_primes(int n){    for(int i=2;i&lt;=n;i++){        if(!st[i]) primes[cnt++] = i;        for(int j = 0;primes[j] &lt;= n/i ; j++){            st[primes[j]*i] = true;             if(i%primes[j] == 0) break;        }    }}\n\n正确性证明：\n论断：如果是和数，只会被最小质因子筛掉，且一定能被筛掉\n\n 从小到大枚举所有质数，每一次把当前质数同i的乘积筛掉\n\n第一次出现i%primes[j] == 0发生时意味着primes[j]一定是i的最小质因子，那么primes[j]也一定是primes[j]*i的最小质因子\n\n若我们没有枚举到i的任何一个质因子，说明primes[j]一定小于i的所有质因子，所有primes[j]也一定是primes[j]*i的最小质因子\n\n对于一个和数x，假设pj是x的最小质因子，当i（一定会）枚举到x/pj时，就会把x筛掉\n\n\n线性筛法为什么是线性的？\n   每个数都只有一个最小质因子，每个数也只用最小质因子来筛，所以每个数只会被筛一次，所以是线性的。不加break就可能重复筛。\n约数求所有约数\n\n试除法+优化\n\nvector&lt;int&gt; get_divisors(int n){    vector&lt;int&gt; res;    for(int i=1;i&lt;=n/i;i++){        if(n%i == 0){            res.push_back(i);            if(i!=n/i) res.push_back(n/i);        }    }    sort(res.begin(),res.end());    return res;}\n\n求一个数的约数个数\n\n\nn的每一个约数d就和我们从到的一种选法一一对应，所以约数个数为所有选法数量：$(\\alpha_1+1)(\\alpha_2+1)…(\\alpha_{k-1}+1)(\\alpha_k+1)$\nint main(){    int n;    cin&gt;&gt;n;    unordered_map&lt;int,int&gt; map;        while(n--){        int x;        cin&gt;&gt;x;        for(int i=2; i&lt;=x/i; i++){            int cnt = 0;            while(x%i==0){                cnt++;                x/=i;            }            map[i]+=cnt;        }        if(x&gt;1) map[x]+=1;    }    LL res = 1;    for(auto prime:map) res = res * (prime.second+1) % mod;    cout&lt;&lt;res&lt;&lt;endl;}\n\n\n\n求一个数的约数之和\n\n\n每个约数均不相同，且是选法数量之一。\nwhile(a--) t = t*p+1可以方便的求等比数列的和，其中a为指数，p为底数，也可以用公式做（尝试）\nint main(){    int n;    cin&gt;&gt;n;    unordered_map&lt;int,int&gt; map;        while(n--){        int x;        cin&gt;&gt;x;        for(int i=2; i&lt;=x/i; i++){            int cnt = 0;            while(x%i==0){                cnt++;                x/=i;            }            map[i]+=cnt;        }        if(x&gt;1) map[x]+=1;    }    LL res = 1;    for(auto prime:map) {        LL temp = 0;        prime.second+=1;        while (prime.second--) {            temp = (temp * prime.first + 1) % mod;        }        res = res * temp % mod;    }    cout&lt;&lt;res&lt;&lt;endl;}\n\n求最大公约数\n\n辗转相除法\n\n核心：（a，b）= （b，a mod b)\nint gcd(int a,b){    return b ? gcd(b,a mod b) : a;}\n\n欧拉函数概念：\n记号为，表示为1~n中与n互质的数的个数\n例如。\n欧拉公式：\n首先对n分解质因数 $p_1^{\\alpha_1}p_2^{\\alpha_2}…p_k^{\\alpha_k}，根据公式即可计算出结果\\phi(n) = n(1-1/p_1)(1-1/p_2)…*(1-1/p_k) $\n证明：\n使用容斥原理可以证明\n\n 从1~n中去掉的所有倍数\n 加上所有的倍数（加回多减的）\n 减去所有$pipjpk$的倍数\n 以此类推\n\n把欧拉公式展开和容斥原理的式子是等价的：\n\n\n可画图理解：\n\n筛法求欧拉函数 O(n)\n\n 某些情况下，需要求出1~n中每一个数的欧拉函数。若用公式法需要O(N*sqrt(N))的复杂度\n 若用线性筛法，可以用O(n)的复杂度计算出每一个数的欧拉函数\n\nvoid get_eulers(int n){    for(int i=2;i&lt;=n;i++){        if(!st[i]) {            // 如果一个数i是质数，那么欧拉函数就是i-1            primes[cnt++] = i;            phi[i] = i-1;        }        for(int j = 0;primes[j] &lt;= n/i ; j++){            st[primes[j]*i] = true;            if(i%primes[j] == 0) {                phi[primes[j]*i] = primes[j]*phi[i];                break;            }            phi[primes[j]*i] = (primes[j]-1)*phi[i];        }    }}\n\n应用场景：欧拉定理\n若a与n互质，\n\n注：等于号代表同余\n\n欧拉定理的特例：费马小定理\n若n为质数，假设a与n互质，那么有\n快速幂\n在**O(log k)**的情况下快速地求出的结果。\n\n核心思路：反复平方法\n\n\n我们先要预处理出来这些值：\n\n\n如何组合成ak?\n把拆成若干个上面的预处理出来的数的乘积的形式（用2进制表示即可），即把k换成2进制即可。\n\n\n\n\n所有问题等价于：底数相同，将k表示成以2为底的指数的和\n typedef Long Long LL;int qmi(int a , int k, int p){    int res = 1;    while(k){        if(k&amp;1) res = (LL)res*a%p;        k&gt;&gt;=1;        //每个数都是前面的数的平方模p        a=(LL)a*a%p;    }}\n\n快速幂求乘法逆元\n\n其实本质上就是一个快速幂\n\n证明：\n希望把除法变乘法：\n左右两边同乘以b：\n因而 \n之后可以用费马定理来解决，但注意m要为质数，且b与m互质\n因而 \n所以b的模m的逆元为 \n扩展欧几里得算法裴蜀定理\n有任意一对正整数a、b，那么一定存在整数x、y，使得ax+by = gcd(a,b)。a,b所能凑出来的所有数都是最大公约数的倍数，所以能凑出来的最小的数就是最大公约数。\n\n注：x，y可取负整数\n\n解决什么问题\n为裴蜀定理构造解\nint ext_gcd(int a, int b, int &amp;x, int &amp;y){     if(!b){         x = 1,y=0;         return a;     }     int ans = ext_gcd(b,a%b,y,x);     y -= a/b *x;     return ans;}\n\n简单应用：求解线性同余方程  \n等价于，所以若(a,-m)|b成立则有解，可以用扩展欧几里得算法算出x；否则无解\n中国剩余定理\n求解一元线性同余方程组，m1-k两两互质\n\n\n\n通解的构造方法：\n\n\n求逆元ti可以用扩展欧几里得算法解出：\n\n\n通解构造的正确性可通过带入法进行验证。\n高斯消元\n线性代数相关知识\n\n一般可以再O(n^3)的时间复杂度内，求解n个方程n个未知数的多元线性方程组。\n解的情况\n\n无解：通过行变换推出0=非0，矛盾\n无穷多组解：0=0，n个未知数，n-1个方程\n唯一解：完美阶梯形\n\n注：初等行变换不改变方程组的解，而且可以将方程组变为上三角的形式：\n\n\n算法流程\n\n从不固定的方程里，枚举每一列，找出绝对值最大的这一行（处理精度问题）\n将这行换到上面去\n将该行第一个数变为1\n将下面所有行的当前列消成0\n若有唯一解，那么用消元法即可得到解\n\n//因为c++浮点数存的时候是有误差的，所以不能直接判断0，而是应该判断是不是小于一个很小的数const double eps = 1e-6;double a[N][N] ;int gauss(){    int c,r;    // 从第0行，第0列开始枚举    for(c=0,r=0;c&lt;n;c++){        int t = r;        for(int i = t; i&lt;n;i++)            if(fabs(a[i][c])&gt;fabs(a[t][c]))                t = i;        if(fabs(a[t][c])&lt;eps) continue;    \tfor(int i=c;i&lt;=n;i++) swap(a[t][i],a[r][i]);    \tfor(int i=n;i&gt;=c;i--) a[r][i] /= a[r][c];        for(int i=r+1;i&lt;n;i++)            if(a[i][c] &gt; eps)                for(int j=n;j&gt;=c;j--)                    a[i][j] -= a[r][j] * a[i][c];        r++;                   }         if(r&lt;n){        for(int i=r;i&lt;n;i++)            if(fabs(a[i][n])&gt;eps)                return 2; //无解        return 1; //有无穷多组解    }    return 0;//有唯一解}\n\n组合数公式法\n由公式，可以计算出组合数：\nint p;int C(int a, int b){    int res = 1;    for(int i=1,j=a;i&lt;=b;i++,j--){        res = (LL)res*j % p;        res = (LL)res *qmi(i,p-2) % p;    }    return res;}\n\n递推式法\n\n10万组询问，a,b范围较小：1&lt;= a,b&lt;=2000\n\n根据递推式，先预处理出所有的 组合数（两重循环即可），到时候查表即可在O(ab)的时间复杂度下完成计算。\n\n\n#include&lt;iostream&gt;using namespace std;const int K = 2010;const int mod = 1e9+7;typedef long long LL;int com[K][K];int main(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;K;i++){        com[i][0]=1;        com[i][i]=1;        for(int j=1;j&lt;i;j++){            com[i][j] = (com[i-1][j]+com[i-1][j-1])%mod;        }    }    while(n--){        int a,b;        scanf(\"%d%d\",&amp;a,&amp;b);        printf(\"%d\\n\",com[a][b]);    }    return 0;}\n\n预处理公式法\n\n1万组询问，a,b范围适中：1&lt;=a,b&lt;=1e5\n\n根据公式，预处理出中间的一步:阶乘。用fact[i]表示i! mod 10^9+7，infact[i]表示 mod 10^9+7\n也可以用查表的方式O(NlogN)来求 \n#include&lt;iostream&gt;using namespace std;typedef long long LL;const int mod = 1e9+7;const int N = 100010;int fact[N];int qmi(int a , int k, int p){    int res = 1;    while(k){        if(k&amp;1) res = (LL)res * a % p;        k&gt;&gt;=1;        a = (LL)a * a % p;    }    return res;}int main(){    fact[0]=1;    for(int i=1;i&lt;=N;i++)        fact[i] = (LL)i*fact[i-1] % mod;    int n;    scanf(\"%d\",&amp;n);    while(n--){        int a,b;        scanf(\"%d%d\",&amp;a,&amp;b);        int infact1 = qmi(fact[a-b],mod-2,mod);        int infact2 = qmi(fact[b],mod-2,mod);        int com = (LL)fact[a] * infact1 % mod * infact2 % mod;        printf(\"%d\\n\",com);        // printf(\"%d %d %d\\n\",fact[a],infact[a-b],infact[b]);    }            return 0;}\n\n卢卡斯定理\n\n20组询问，a,b范围巨大：1&lt;=a,b&lt;=10^18，1&lt;=p&lt;=10^5\n\n$C^b_a = C^{b%p}{a%p}*C^{b/p}{a/p} (%p)$\n算法复杂度为O()，前半部分为递归层数，后半部分为每层递归里求组合数的复杂度；\n证明可参考该博客\n#include&lt;iostream&gt;using namespace std;typedef long long LL;int qmi(int a, int k, int p){    int res = 1;    while(k){        if(k&amp;1) res = (LL)res * a %p;        k&gt;&gt;=1;        a =(LL)a * a % p;    }    return res;}int C(int a, int b,int p){    if(b&gt;a) return 0;    int res = 1;    for(int j=1,i=a;j&lt;=b;j++,i--){        res =  (LL)res * i % p;        res = (LL)res * qmi(j,p-2,p) % p;    }    return res;}int lukas(LL a, LL b, int p){    if(a&lt;p &amp;&amp; b&lt;p) return C(a,b,p);    return (LL)C(a%p,b%p,p) * lukas(a/p,b/p,p) % p;}int main(){    int n;    cin&gt;&gt;n;    while(n--){        LL a,b;        int p;        scanf(\"%ld%ld%d\",&amp;a,&amp;b,&amp;p);        printf(\"%d\\n\",lukas(a,b,p));    }    return 0;}\n\n分解质因数+高精度\n先把分解质因数 ，即$p_1^{\\alpha_1}p_2^{\\alpha_2}…*p_k^{\\alpha_k}$，之后只需要实现一个高精度乘法即可。\n\n对每一个数分解质因数，效率较低O(NlogN)\n改进：先处理出所有的质因子（筛素数），再求出这个质因子的次数是多少。由公式，求p次数的方法为，先看分子里p的个数，再看分母里p的个数，差值即为真正的p的个数。那么如何得到阶乘里p的个数呢？通过下面的算法可以巧妙地计算出阶乘里p的个数：\n\n\n\n\n\n#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;const int N  = 5010;int prime[N];bool st[N];int cnt=0;// 暴力解法// 分别求出1~n的质因子p的数量再相加：O(NlogN)int get(int n, int p){    for(int i=1;i&lt;=n;i++){        int t = i;        while(t%p==0){           t/=p;           cnt[i]++;        }    }    int res = 0;    for(int i=1;i&lt;=n;i++){        res += cnt[i];    }}// 优化// 计算出阶乘里p的个数O(logN)int get(int n, int p){    int res = 0;    while(n){        res += n/p;        n/=p;    }    return res;}// 筛素数void get_prime(int n){     st[1] = true;     for(int i=2;i&lt;=n;i++){         if(!st[i]){             prime[cnt++]=i;         }         for(int j=0;prime[j]&lt;=n/i;j++){             st[prime[j]*i] = true;             if(i%prime[j]==0) break;         }              }}vector&lt;int&gt; multiply(vector&lt;int&gt;  a, int b){    int c = 0;    vector&lt;int&gt; C;    for(int i=0; i&lt;a.size()||c;i++){        if(i&lt;a.size()) c+=a[i]*b;        C.push_back(c%10);        c/=10;    }    while(C.size()&gt;1&amp;&amp;C.back()==0) C.pop_back();    return C;}int main(){    vector&lt;int&gt; base;    base.push_back(1);    get_prime(N);    int a,b;    cin&gt;&gt;a&gt;&gt;b;    for(int i=0;i&lt;cnt;i++){        int p = prime[i];        int k = get(a,p)-get(b,p)-get(a-b,p);        while(k--) base = multiply(base,p);    }        for(int i=base.size()-1;i&gt;=0;i--) printf(\"%d\",base[i]);    return 0;}\n\n卡特兰数\n满足条件的01序列\n\n给定 n 个 0 和 n 个 1，它们将按照某种顺序排成长度为 2n 的序列，求它们能排列成的所有序列中，能够满足任意前缀序列中 0 的个数都不少于 1 的个数的序列有多少个。\n\n\n每一个数列都对应一个从（0，0）到（6，6）的路径，反过来也成立。\n$C_{2n}^{n}-C^{n-1}{2n}=1/(n+1)*C^n{2n}$\n 应用\n火车进站问题\n合法括号序列问题\n容斥原理对于n个圆，计算其所占的面积  ，数字代表i个圆的交集的组合。\n对于集合来讲，集合的个数也满足上式。\n上式一共有多少项？\n从n个数里挑任意多个数的方案数\n所以一共有项，所以时间复杂度为\n为什么是+、-、+、-？\n\n\n根据组合恒等式，对于集合中的某个数x，它在k个集合中出现过，它只会在右边的等式里计算一次。\n实际应用\n给定一个整数 n 和 m个不同的质数，请你求出 1∼n中能被 p1,p2,…,pm 中的至少一个数整除的整数有多少个。\n时间复杂度O(2^m)\n#include&lt;iostream&gt;using namespace std;const int N = 20;int p[N];int main(){    int n,m;    cin&gt;&gt;n&gt;&gt;m;    int res =0;    for(int i=0;i&lt;m;i++) scanf(\"%d\",&amp;p[i]);    for(int i=1;i&lt;1&lt;&lt;m;i++){        int t = 1;        int cnt = 0;        for(int j=0;j&lt;m;j++){            if(i&gt;&gt;j&amp;1) {                cnt++;                t*=p[j];                if ((LL)t*p[j]&gt;n) {                    t=-1;                    break;                }            }        }        if(t!=-1){            if(cnt % 2) res += n/t;            else res -= n/t;    \t}    }    cout&lt;&lt;res&lt;&lt;endl;    return 0;}\n\n博弈论公平组合游戏ICG若一个游戏满足：\n\n由两名玩家交替行动；\n在游戏进程的任意时刻，可以执行的合法行动与轮到哪名玩家无关;\n不能行动的玩家判负；则称该游戏为一个公平组合游戏。下面介绍的Nim游戏即为公平组合游戏。但围棋等游戏不满足2，3，判胜条件比较复杂。\n\n有向图游戏给定一个有向无环图，图中由唯一的一个起点，在起点上有一枚棋。两名玩家交替地把这枚棋子沿有向边进行移动，每次可以移动一步，无法移动者判负。任何一个公平组合游戏都可以转化为有向图游戏。具体方法：\n\n把每个局面看成图中的一个节点，并且从每一个局面沿着（有向边）合法行动能够到达下一个局面。\n\nNim游戏给定n堆石子，两位玩家轮流操作，每次操作可以从任意一堆石子中拿走任意数量的石子，最后无法进行操作的人视为失败。\n\n先手必胜状态：可以走到某一个必败状态\n\n先手必败状态：every state you go is a win state, i.e. 走不到任何一个必败状态\n\nso how to judge the win or lose state ?\n\n\n定理：对于n堆石子(a1,a2,a3,…,an)，如果a1^a2^…^an=0，先手必败，否则先手必胜provement:\n\n0^0^0^…^0=0\na1^a2^…^an = x != 0, can go to all 0 state: retrieve ai-ai^x\na1^a2^…^an=0, can go to none 0 state\n\n思考题：台阶Nim游戏hint: xor what numbers\n集合-Nim游戏\n\nMex 运算：设S为一个非负整数集合。定义mex(S)为求出不属于集合S的最小非负整数的运算，即：mex(S)=min{x}，x属于自然数且x不属于S\n\nSG函数：\n\n\n局面（状态）\nSG（终点）=0；\n每个状态的 SG（x）=mex{SG(y1),SG(y2),…,SG(yk)}; 其中y1-k为从x经过某些操作能到的局面（状态）\n若SG(x)!=0，必胜，否则必败。因为任何一种非0状态一定可以走到0状态，而从0状态只能走到非0状态。出生决定了最终的结果，即如果我一开始不是0，那么我未来永远都不是0；\nextentison: if there is more than one graph. if one can operate on any graph, he will lose. Suppose we have n graphs to use, we xor all the SG values of the beginning nodes.if SG(x1)^SG(x2)^…^SG(xn) ==0 lose, otherwise will win. \n\nThe provement is the same as the nim games;\n\n\nSet Nim GameGiven n piles of stones and a digit set of K different positive numbers. There are two players who can alternatively pick stones from any piles of stones. But the number of stones taken each time must belong to the digit set. The one who can’t make any actions will lose.(restrict the numbers of stones taken)\n\n\n\n#include&lt;cstring&gt;using namespace std;const int N = 10010;int sg(int x){    if(f[x]!=-1) return f[x];    unordered_set&lt;int&gt; S;    for(int i=0;i&lt;m;i++){        int sum = s[i];        if(x&gt;=sum) S.insert(sg(x-sum));    }    for(int i=0;;i++)        if(!S.count(i))            return f[x] = i;}\n\n第六讲 动态规划基础理解动态规划的思考方式\n从集合的角度理解DP问题\n\n\n状态表示 f(i,j)（存的是所有选法的集合的最值），考虑清楚需要几维来表示我们的问题\n\n集合：每一个状态都是表明一个集合，在背包问题里表示所有选法的集合\n条件：\n\n只考虑前i个物品\n总体积不超过 j\n\n\n属性：集合的最大值，最小值，元素数量\n\n\n\n状态计算 ，如何将每个状态计算出来\n\n目标：求f(N,V)\n\n状态计算一般表示集合的划分：把当前集合划分为若干个更小的子集，使得每一个子集我们都可以由前面更小的状态计算得到\n例如f(i,j)可以包含两类：\n\n左边类是不包含第i个物品的选法\n右边类是包含第i个物品的选法\n\n实际的最大值是两类取一个max\n\n\n\n\nDP问题的优化一般只是等价变形，所以写出朴素解法十分重要\nDP问题一定要结合题目来理解，上面的思考方式就像是骨架，根据具体问题填补具体的血肉\n背包模型01背包问题什么是01背包？\n\n每件物品最多只能用一次\n\n在背包容量的范围内如何挑选物品，让总价值最大\n朴素做法\n//枚举所有状态f[0,0]~f[n,m]//其中f[0,0-m]表示考虑0件物品，总体积不超过0~m的最大价值是多少//因此只需从1开始遍历即可for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m;j++){        f[i][j] = f[i-1][j];        if(j&gt;=v[i]) f[i][j] = max(f[i][j],f[i-1][j-v[i]] + w[i]);    }\n\n一维做法\n\n第i层的状态只依赖于第i-1层；不超过的总体积j只依赖于&lt;=j的状态，因此可以优化到一维来做\n\nint f[N];//直接去掉一维for(int i=1;i&lt;=n;i++)    for(int j=m;j&gt;=v[i];j--){        f[j] = max(f[j],f[j-v[i]]+w[i]);    }\n\n完全背包问题\n 每件物品可以用无限次\n\n解题思路\n分成若干组，分成k类：\n\n\n不妨设第i个物品选了k个\n曲线救国：\n\n去掉k个物品i\n求Max，f[i-1,j-k*v[i]]\n再加回来k个物品i\n\n综上，f[i,j] = f[i-1,j-k*v[i]] + k * w[i]\n朴素做法\n//最坏情况下：O(n*m^2))for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++)        for(int k=0;k*v[i]&lt;=j;k++)            f[i][j] = max(f[i][j],f[i-1][j-k*v[i]]+k*w[i]);\n\n二维做法\n//f[i,j] = Max(f[i-1][j],f[i-1,j-v]+w,f[i-1,j-2v]+2w,f[i-1,j-3v]+3w,...)//f[i,j-v] = Max(f[i-1][j-v],f[i-1,j-2v]+w,f[i-1,j-3v]+2w,...)//f[i,j] = Max(f[i-1][j],f[i,j-v]+w);//优化为二维for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++){        f[i][j] = f[i-1][j];        if(j&gt;=v[i]) f[i][j] = max(f[i][j],f[i][j-v[i]]+w[i]);    }\n\n一维做法\n完全背包问题的终极解法\nint f[N];for(int i=1;i&lt;=n;i++)    for(int j=v[i];j&lt;=m;j++)        f[j] = max(f[j],f[j-v[i]]+w[i]);\n\n多重背包问题\n每件物品最多有Si个\n\n解题思路\n枚举第i个物品选多少个，根据第i个物品选多少个来将我们所有的选法分成若干种类别：\n\n\n其实就是朴素版本的完全背包问题：f[i,j] = f[i-1,j-k*v[i]] + k * w[i]\n朴素版本\n//最坏情况下：O(n*m^2))for(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m,j++)        for(int k=0;k&lt;=s[i] &amp;&amp; k*v[i]&lt;=j ;k++)            f[i][j] = max(f[i][j],f[i-1][j-k*v[i]]+k*w[i]);\n\n 优化版本：二进制优化\n\n c++1s最多算1亿次，超过一亿次会超时\n\n 从0~s中的任何一个数都可以被拼凑出来（由1，2，4，2^k, … , c）。 \n将s个物品i拆分程log(s)个新的物品，新的物品只能用一次\n对所有这些新出来的物品做一遍01背包即可，时间复杂度为O(N*v*log(s))\n#include &lt;iostream&gt;using namespace std;const int N = 11100,M=2010;int v[N];int w[N];int f[N];void backpack_multi_bin_Test() {    int n, m;    cin &gt;&gt; n &gt;&gt; m;    //如果用三重循环，4亿的计算量很可能会爆掉    //思路：将s[i]个相同的物品分解为多个不同的物品且每个物品只能取一次    int cnt = 0;    for (int i = 1; i &lt;= n; i++) {        int a,b,s;        cin &gt;&gt; a &gt;&gt; b &gt;&gt; s;        int j;        for (j = 1; j &lt;= s; j *= 2) {            cnt++;            s-=j;            v[cnt] = j * a;            w[cnt] = j * b;        }        if(s){            cnt++;            v[cnt] = s*a;            w[cnt] = s*b;        }    }    for(int i=1;i&lt;=cnt;i++)        for(int j=m;j&gt;=v[i];j--){            f[j] = max(f[j], f[j-v[i]]+w[i]);        }    cout&lt;&lt;f[m]&lt;&lt;endl;}\n\n\n\n分组背包问题有n组物品，同一组内的物品最多只能选一个\n\n状态表示的集合：只能从前i组物品中选，且总体积不大于j的所有选法\n\n枚举第i组物品选不选，选哪个\n\n\n朴素解法\nfor(int i=1;i&lt;=n;i++)    for(int j=0;j&lt;=m;j++){        f[i][j] = f[i-1][j];        for(int k=0;k&lt;s[i];k++){            if(j&gt;=v[i][k]) f[i][j] = max(f[i][j],f[i-1][j-v[i][k]]+w[i][k]);        }    }\n\n优化解法\nint f[N];//直接去掉一维for(int i=1;i&lt;=n;i++)    for(int j=m;j&gt;=0;j--)    \tfor(int k=0;k&lt;s[i];k++){            if(j&gt;=v[i,k]) f[j] = max(f[j],f[j-v[i,k]]+w[i,k]);        }\n\n线性DP数字三角形从顶部出发，在每一结点可以选择移动至其左下方的结点或移动至右下方的结点，一直走到底层。要求找到一条路径上的数字的和最大。\n状态表示\n\n\n\n集合：从顶点到(i,j)的所有路径\n属性：MAX\n\n状态计算\n\n\n复杂度：状态数量*转移数量\nconst int  N = 510,inf = -1e9;int f[N][N];int d[N][N];void digi_Tran_Test(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++)        for(int j=1;j&lt;=i;j++)            scanf(\"%d\",&amp;d[i][j]);    for(int i=0;i&lt;=n;i++)        for(int j=0;j&lt;=i+1;j++)            f[i][j]= inf;    f[1][1] = d[1][1];    for(int i=2;i&lt;=n;i++)        for(int j=1;j&lt;=i;j++){            f[i][j] = max(f[i-1][j-1],f[i-1][j])+d[i][j];        }    int res = inf;    for(int i=1;i&lt;=n;i++)        res = max(res,f[n][i]);    cout&lt;&lt;res&lt;&lt;endl;}\n\n最长上升子序列给定一个数列，求数值严格单调递增的子序列的长度最长是多少\n\n可以按照顺序跳着选择\n\n状态表示\n\n集合：所有以第i个数为结尾的数值上升的子序列\n属性：子序列的最大长度\n\n状态计算\n\n\n以倒数第二个数在哪个位置来进行划分，需满足数值严格单调上升（即第i个数大于倒数第二个数）\n朴素版\nconst int M = 1010;int sta[M];int sq[M];void maxLenIncSubTest() {    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++) scanf(\"%d\",&amp;sq[i]);    for(int i=1;i&lt;=n;i++) {        sta[i] = 1;        for (int j = 1; j &lt; i; j++) {            if(sq[j]&lt;sq[i])                sta[i] = max(sta[i],sta[j]+1);        }    }    int res = 0;    for(int i=1;i&lt;=n;i++)        if(res &lt; sta[i]) res = sta[i];    cout&lt;&lt;res&lt;&lt;endl;}\n\n优化版\n如果数列过长，会爆掉，因此需要找到一个优化的算法。存所有不同长度的所有严格上升子序列的结尾的最小值。\n\n\n我们可以证明，随着长度的增加，结尾的最小值必然严格上升。假设长度为6的最小值等于长度为5的最小值，又严格上升子序列，因此第5个数比之前的长度为5的最小值还要小，产生了矛盾。因此长度为6的最小值一定大于长度为5的最小值。\n对于当前的数ai，找到序列中最大的小于ai的数，假设是q[4]，则q[5]&gt;=ai，也就是说ai不能接到长度&gt;=5的子序列后边。也就是说以ai为结尾的子序列长度最大即为5。找出小于ai的最大的一个数可以用二分来做。\nint find_pos(int le, int ri, int tar){    while(le&lt;ri){        int mid = le + ri + 1 &gt;&gt; 1;        if (q[mid] &lt; tar)            le = mid;        else ri = mid -1;    }    return le;}void maxlenII(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++) scanf(\"%d\",&amp;nums[i]);    q[0] = -pintf;    int qLen = 0;    for(int i=1;i&lt;=n;i++){        int pos = find_pos(0,qLen,nums[i]);        q[pos+1] = nums[i];        if(pos+1&gt;qLen)  qLen = pos + 1;    }    cout&lt;&lt;qLen&lt;&lt;endl;}\n\n最长公共子序列既是a的子序列，又是b的子序列的字符串长度的最大值。\n状态表示\n\n集合：所有由第一个序列的前i个字母，和第二个序列的前j个字母的构成的公共子序列\n属性：公共序列的最大值\n\n状态计算\n\n求max是可以重复的，只要不漏掉某一元素即可\n\n\n\nconst int M = 1010;char a[M];char b[M];int st[M][M];void maxCommenSubTest(){    int n,m;    cin&gt;&gt;n&gt;&gt;m;    scanf(\"%s\",a+1);    scanf(\"%s\",b+1);    // A中前i个字符和B中前j个字符所构成的公共子序列的集合    for(int i=1;i&lt;=n;i++)        for(int j=1;j&lt;=m;j++){            st[i][j] = max(st[i][j-1],st[i-1][j]);            if(a[i]==b[j]) st[i][j] = max(st[i][j],st[i-1][j-1]+1);        }    cout&lt;&lt;st[n][m]&lt;&lt;endl;}\n\n最短编辑距离给定两个字符串A和B，现在要将A经过若干操作变为B，可进行的操作：\n\n删除\n插入\n替换\n\n求变换所需的最小操作次数。\n状态表示\n\n集合：将A的前i个字符变为B的前j个字符的所有操作集合\n属性：操作次数最小值\n\n状态计算\n\n\nfor(int i=1;i&lt;=n;i++)        for(int j=1;j&lt;=m;j++){            if(a[i]==b[j]) st[i][j] = st[i-1][j-1];            else{                st[i][j] = min(st[i-1][j] + 1,st[i-1][j-1]+1);                st[i][j] = min(st[i][j],st[i][j-1]+1);            }        }\n\n编辑距离给定n个字符串，以及m次询问，每次询问给出一个字符串和操作上限，求给定的n个字符串中有多少个串可以在操作上限次数内变成询问给出的字符串。\nfor(int i=1;i&lt;=n;i++)         scanf(\"%s\",strs[i]+1);for(int i=1;i&lt;=m;i++){        char tar[K];        int max_edits;        scanf(\"%s%d\",tar+1,&amp;max_edits);        int count = 0;        for(int j = 1;j&lt;=n;j++)            if(findMinDis(strs[j],tar)&lt;=max_edits) count++;        cout&lt;&lt;count&lt;&lt;endl;}\n\n区间DP石子合并n堆石子排成一排，每次只能合并相邻的两堆，合并的代价为这两堆石子的质量之和，求合并所需的最小代价。\n\n不同的合并顺序需要的体力是不同的\n\n状态表示\n\n集合：从第i堆石子到第j堆石子合并成一堆石子的合并方式\n属性：Min\n\n状态计算\n\n\n\tfor(int i=1;i&lt;=n;i++) cin&gt;&gt;m[i];    for(int i=1;i&lt;=n;i++) s[i] = s[i-1] + m[i];    // st[i][j] 表示将第i~j堆石子合并起来的所有方案代价集合的最小代价    // 要注意状态计算的顺序    for(int i=1;i&lt;=n;i++)         for (int j = i; j &lt;= n; j++)             st[i][j] = pinf;    // 这种遍历方式可以保证区间内的所有可能st均已得到\t// 按区间长度从小到大枚举    for(int i=n;i&gt;=1;i--)        for(int j=i;j&lt;=n;j++) {            if(i==j) st[i][i] = 0;            for (int k = i; k &lt;= j - 1; k++) {                st[i][j] = min(st[i][j], st[i][k] + st[k + 1][j] + s[j] - s[i-1]);//                printf(\"%d %d : %d \", i,j,st[i][j]);            }//            printf(\"\\n\");        }    cout&lt;&lt;st[1][n]&lt;&lt;endl;\n\n计数类DP整数划分问题一个正整数可以表示为若干正整数之和，形如：n=n1+n2+…+nk，其中n1≥n2≥…≥nk，求出n有多少种不同的划分方法。\n可以把这个问题作为完全背包问题，背包容量为N，每个物品的体积为1~N，不限个数，问恰好装满背包的方案数。\n\n\n// 朴素版\tfor(int i=0;i&lt;=n;i++) f[i][0] = 1;    for(int i =1;i&lt;=n;i++)        for(int j=1;j&lt;=n;j++){            for(int k=0;k*i&lt;=j;k++){                f[i][j] = (f[i][j] + f[i-1][j-k*i]) % mod;            }        // f[i][j] = f[i-1][j];        // if(j&gt;=i) f[i][j] = (f[i][j] + f[i][j-i]) % mod;        }    cout &lt;&lt; f[n][n]&lt;&lt;endl;// 二维优化版\tfor(int i=0;i&lt;=n;i++) f[i][0] = 1;    for(int i =1;i&lt;=n;i++)        for(int j=1;j&lt;=n;j++){            f[i][j] = f[i-1][j];            if(j&gt;=i) f[i][j] = (f[i][j] + f[i][j-i]) % mod;         }// 一维优化版fo[0] = 1;for(int i=1;i&lt;=n;i++)    for(int j=i;j&lt;=n;j++){        fo[j] = (fo[j] + fo[j-i]) % mod;    }cout &lt;&lt; fo[n] &lt;&lt; endl;\n\n数位统计DP计数问题给定两个整数，求a和b之间所有数字中0~9的出现次数\n\n技巧1：计算a和b之间的所有数字中x的出现次数，可以转换为1b中所有数字中x的次数减去1（a-1）中x的次数\n技巧2：计算1n中x的次数，可以通过x在1n中每一位出现的次数求和得到，由题，n可以表示为‘abcdegfh’。\n\n假设我们要求x在第5位出现的次数：\n即求出，满足条件1&lt;=abcdxfgh&lt;=n的数有多少个，我们需要分情况进行讨论。\n\n若前4位 mmmm=0000(abcd-1)，无论后三位（nnn=000999）取何值，均满足条件：（abcd * 1000)\n若前4位 mmmm=abcd\n若第5位e&lt;x : (0)\ne=x: (nnn=000~fgh, fgh+1)\ne&gt;x: (nnn=000~999,1000)\n\n\n\n特例情况：x=0时需要特殊讨论，即前4位mmmm=1~(abcd-1）并且0不能出现在第一位。其他情况不变\n#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int get_cnt(vector&lt;int&gt; nums, int le,int ri){    int res = 0;    for(int i=ri;i&gt;=le;i--){        res = res * 10 + nums[i];    }    return res;}int power_10(int num){    int res = 1;    for(int i=0;i&lt;num;i++) res *= 10;    return res;}int count_num(int num, int h){    if(!num) return 0;    vector&lt;int&gt; nums;    while(num){        nums.push_back(num%10);        num/=10;    }    int l = nums.size();    int res = 0;    for(int i=0;i&lt;=l-1-!h;i++){        if(i&lt;l-1) {            res += get_cnt(nums, i + 1, l - 1) * power_10(i);            if(!h) res -= power_10(i);        }        if(nums[i]&gt;h) res += power_10(i);        else if(nums[i]==h)            res += get_cnt(nums,0,i-1)+1;    }    return res;}void cntNumTest(){    int a,b;    while(scanf(\"%d%d\",&amp;a,&amp;b),a||b){        if(a&gt;b) swap(a,b);        for(int i=0;i&lt;10;i++)            printf(\"%d \",count_num(b,i)-count_num(a-1,i));        puts(\"\");    }}int main() {    cntNumTest();//    mendleanDreamTest();//    IntDivTest();    return 0;}\n\n状态压缩DP\n使用整数来表示状态，把这个整数看作是二进制数，每一位是0是1代表不同的情况，因此位数(n)最多取到20位（1e6种状态）\n\n蒙德里安的梦想求把NM的棋盘分割成若干个12的长方形，有多少种方案。\n\n\n#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;const int M = 13;bool st[1 &lt;&lt; M];long long fm[M][1 &lt;&lt; M];void mendleanDreamTest() {    int n, m;    while (scanf(\"%d%d\", &amp;n, &amp;m), n || m) {        memset(fm,0,sizeof fm);        for (int i = 0; i &lt; 1 &lt;&lt; n; i++) {            st[i] = true;            int cnt = 0;            for (int j = 0; j &lt; n; j++) {                if (i &gt;&gt; j &amp; 1) {                    if (cnt &amp; 1) st[i] = false;                    cnt = 0;                } else cnt++;            }            if (cnt &amp; 1) st[i] = false;        }        fm[0][0] = 1;        for (int i = 1; i &lt;= m; i++)            for (int j = 0; j &lt; 1 &lt;&lt; n; j++)                for (int k = 0; k &lt; 1 &lt;&lt; n; k++) {                    if ((j &amp; k) == 0 &amp;&amp; st[j | k])                        fm[i][j] += fm[i - 1][k];                }        cout &lt;&lt; fm[m][0] &lt;&lt; endl;    }}int main() {//    cntNumTest();    mendleanDreamTest();//    IntDivTest();    return 0;}\n\n最短Hamilton路径\nHamilton路径：从0到n-1不重不漏地经过每一个点恰好一次\n\n给定n个结点的带权无向图，求起点0到终点n-1的最短Hamilton路径\n\n\n#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;const int Q = 21;int a[Q][Q];int hamil[1&lt;&lt;Q][Q];void hamiltonTest() {    int n;    cin &gt;&gt; n;    for(int i=0;i&lt;n;i++)        for(int j=0;j&lt;n;j++)            scanf(\"%d\", &amp;a[i][j]);    memset(hamil,0x3f, sizeof hamil);    hamil[1][0]=0;    for(int i=0;i&lt;1&lt;&lt;n;i++)        for(int j=0;j&lt;n;j++){             if(i&gt;&gt;j&amp;1){                 for(int k=0;k&lt;n;k++){                     if(j!=k &amp;&amp; i&gt;&gt;k&amp;1){                         hamil[i][j] = min(hamil[i][j],hamil[i-(1&lt;&lt;j)][k] + a[k][j]);                     }                 }             }        }    cout&lt;&lt;hamil[(1&lt;&lt;n)-1][n-1]&lt;&lt;endl;}int main() {    hamiltonTest();//    cntNumTest();//    mendleanDreamTest();//    IntDivTest();    return 0;}\n\n树形DP\n接受了之后思维跨度就不高\n\n没有上司的舞会有N名职员，他们的关系为一颗以校长为根的树，父节点就是子结点的直接上司。\n每个职员有一个快乐指数，用整数Hi给出，要求邀请一部分职员参会，使得所有的参会职员的快乐指数总和最大，限制是职员不能与其直接上司参会。\n思路：因为是树形DP，所以状态可以设置为f[i,j]，在以i为根节点的子树中选择（j=1）或不选择(j=0)根节点的所有选法的最大值\n#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;const int P= 6010;int hapi[P];int h[P],e[P],ne[P],idx;int mem[P][2];void insert(int a, int b){    e[idx] = b;    ne[idx] = h[a];    h[a] = idx++;}int proc_node2(int node, int choose){    if(mem[node][choose]) return mem[node][choose];    int res = 0;    if(choose==1){        res+=hapi[node];        for(int i = h[node];i!=-1;i=ne[i]) {            int j = e[i];            res += proc_node2(j, 0);        }    }else{        for(int i = h[node];i!=-1;i=ne[i]) {            int j = e[i];            res += max(proc_node2(j, 0), proc_node2(j, 1));        }    }    mem[node][choose] = res;    return res;}void treeDpTest3(){    int n;    cin&gt;&gt;n;    for(int i=1;i&lt;=n;i++) cin&gt;&gt;hapi[i];    int root = 1;    memset(h,-1, sizeof h);    for(int i=1;i&lt;=n-1;i++){        int l,k;        cin&gt;&gt;l&gt;&gt;k;        insert(k,l);        if(l==root) root = k;    }    int res = max(proc_node2(root,1),proc_node2(root,0));    cout&lt;&lt;res&lt;&lt;endl;}int main() {    treeDpTest3();    return 0;}\n\n记忆化搜索\n每一道动规题都可以用递归的方法做\n\n滑雪给定一个R行C列的矩阵，表示一个矩形网格滑雪场。矩阵中第i行第j列的点表示区域的高度。只有某相邻区域的高度低于自己目前的高度才可滑动到该区域\n#include&lt;cstring&gt;#include&lt;iostream&gt;using namespace std;const int U = 310;int board[U][U];int lens[U][U];int R,C;int find_len(int r, int c){    if(lens[r][c]!=-1) return lens[r][c];    int di[5]={0,1,0,-1,0};    for(int i = 0;i&lt;4;i++){        int x = r + di[i];        int y = c + di[i+1];        if(board[x][y]&lt;board[r][c] &amp;&amp; x&lt;R &amp;&amp; x&gt;=0 &amp;&amp; y&lt;C &amp;&amp;y&gt;=0)            lens[r][c] = max(find_len(x,y) + 1,lens[r][c]);    }    if(lens[r][c]==-1) lens[r][c] = 1;    return lens[r][c];}void skiTest(){    cin&gt;&gt;R&gt;&gt;C;    for(int i=0;i&lt;R;i++)        for (int j = 0; j &lt; C; j++)            scanf(\"%d\",&amp;board[i][j]);    memset(lens,-1,sizeof lens);    int res = 0;    for(int i=0;i&lt;R;i++)        for (int j = 0; j &lt; C; j++)            if(lens[i][j]==-1)                res = max(res,find_len(i,j));    cout&lt;&lt;res&lt;&lt;endl;}int main() {    skiTest();    return 0;}\n\n第七讲 贪心算法\n证明困难，没有常用的套路\n\n对于区间问题：\n\n左端点排序\n右端点排序\n双关键字排序\n\n\n\n如上图，局部极值不一定是权重最优解，因此只有一个问题是单峰的，才可以用贪心算法来解\n区间选点给定 N个闭区间[ai,bi], 请你在数轴上选择尽量少的点，使得每个区间内至少包含一个选出的点。输出选择的点的最小数量。\n算法思路\n将每个区间按右端点从小到大排序\n从前往后依次枚举每个区间：\n如果当前区间中已经包含选点，则直接pass\n否则，选择当前区间的右端点\n\n\n\n#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int N = 1e5+10;struct Range {    int l, r;    int operator&lt;(Range &amp;ran) const {        return r &lt; ran.r;    }}ranges[N];void interSecPntTest() {    int n;    cin &gt;&gt; n;    for(int i=0;i&lt;n;i++){        int a, b;        scanf(\"%d%d\", &amp;a, &amp;b);        ranges[i] = {a,b};    }    sort(ranges,ranges+n);    int ed = -2e9;    int res = 0;    for(int i=0;i&lt;n;i++){        if(ed&lt;ranges[i].l){            res++;            ed = ranges[i].r;        }    }    cout&lt;&lt;res&lt;&lt;endl;}int main() {    interSecPntTest();    return 0;}\n\n算法证明\nAns &lt;= Cnt\n\n整个算法流程保证了，选出Cnt个点的方案是合法方案，因此有上面的不等式\n\nAns &gt;= Cnt\n\n选出Cnt个点，实际上是找出了Cnt个不重叠区间，因此选点方案的最小数量至少为Cnt，即Ans&gt;=Cnt\n由上，即可证明Ans==Cnt\n最大不相交区间的数量给定N个闭区间[ai,bi]，请你在数轴上选择若干区间，使得选中的区间之间互不相交（包括端点）。求可选取区间的最大数量。\n算法思路做法和上一题完全一样\n算法证明\nAns是最大不相交区间的数量，Cnt是算法选择的点的数量（Cnt个不重叠区间）\n\n\nAns &gt;= Cnt\n\n选出Cnt个点的方案一定是合法方案，所以Ans&gt;=Cnt\n\nAns &lt;= Cnt\n\n反证法：假设Ans&gt;Cnt，意味着我们可以选出比Cnt更多个互不相交区间；由每一个区间至少包含一个我们选择出来的点，那么根据假设我们至少要选出来Ans个点，这与实际我们最少选出Cnt个点相矛盾，因此Ans &lt;= Cnt\n区间分组给定N个闭区间[ai,bi]，请你将这些区间分成若干组，使得每组内部的区间两两之间没有交集，并使得组数尽可能小。输出最小组数。\n算法思路\n将所有区间按左端点从小到大排序\n从前往后处理每个区间\n判断能否将其放到某个现有的组中\n不能放入(不存在一个组可以放入)，则开新组，然后再将其放进去；\n可以放入：L[i] &gt; Max_r，将其放进去，并更新当前Max_r\n\n\n\n\n\n#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;using namespace std;const int N = 1e5+10;struct Range {    int l, r;    int operator&lt;(Range &amp;ran) const {        return l &lt; ran.l;    }}ranges[N];void interGroupTest(){    int n;    cin &gt;&gt; n;    for(int i=0;i&lt;n;i++){        int a, b;        scanf(\"%d%d\", &amp;a, &amp;b);        ranges[i] = {a,b};    }    priority_queue&lt;int, vector&lt;int&gt;,greater&lt;int&gt;&gt; que;    sort(ranges,ranges+n);    for(int i=0;i&lt;n;i++){        if(que.empty() || ranges[i].l &lt;= que.top()){            que.push(ranges[i].r);        }        else{            que.pop();            que.push(ranges[i].r);        }    }    cout&lt;&lt;que.size()&lt;&lt;endl;}int main() {//    interSecPntTest();    interGroupTest();    return 0;}\n\n\n算法证明\nAns是相互补充的的区间的组的最小组数，cnt是算法的组数\n\n\nAns &lt;= Cnt\n\n按照算法得到的组数一定是一种合法的方案，而Ans是方案的最小值，因此Ans &lt;= Cnt\n\nAns &gt;= Cnt\n\n算法开新组的条件是该区间与每个组都有交集，因此Cnt其实是最少开的组的数量（不能更少，否则会有交集），因此Ans &gt;= Cnt\n区间覆盖问题给定N个闭区间[ai,bi]以及一个线段区间[s,t]，请你选择尽量少的区间，将指定线段区间完全覆盖。输出最小区间数，如果无法完全覆盖则输出-1。\n算法思路\n将所有区间按照左端点从小到大排序\n从前往后依次枚举每个区间，在所有能覆盖开始点的区间中选择右端点最大的区间，若右端点&gt;end，算法退出\n若能选出，将start更新成右端点最大值\n若找不到满足对应条件的区间，输出-1\n\n\n\n#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int N = 1e5 + 10;struct Range {    int l, r;    int operator&lt;(const Range &amp;ran) const {        return l &lt; ran.l;    }} ranges[N];void interCoverTest() {    int s, t;    cin &gt;&gt; s &gt;&gt; t;    int n;    cin &gt;&gt; n;    for (int i = 0; i &lt; n; i++) {        int a, b;        scanf(\"%d%d\", &amp;a, &amp;b);        ranges[i] = {a, b};    }    sort(ranges, ranges + n);    int res = 0;    for (int i = 0; i &lt; n; i++) {                int max_r = -2e9;        int j;        for (j = i; j &lt; n &amp;&amp; ranges[j].l &lt;= s; j++) {            if (ranges[j].r &gt; max_r)                max_r = ranges[j].r;        }        if (max_r == -2e9) {            cout &lt;&lt; \"-1\" &lt;&lt; endl;            return;        }        s = max_r;        i = j-1;        res++;        if(s&gt;=t) break;    }    if(s&gt;=t) cout &lt;&lt; res &lt;&lt; endl;    else cout&lt;&lt;\"-1\";}int main() {//    interSecPntTest();//    interGroupTest();    interCoverTest();    return 0;}\n\n霍夫曼树-合并果子每一次合并消耗的体力等于两堆果子的重量之和。总耗体力等于每次合并耗的体力之和。设计出合并次序方案，使得消耗的体力最少\n算法思路叶节点到根结点一共有多长，对叶节点就要加多少遍。因此每次挑两个值最小的点相合并，他们深度一定最深，可以互为兄弟。\n#include&lt;iostream&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;using namespace std;const int M = 10010;int fruits[M];void comb_fruitTest(){    int n;    cin&gt;&gt;n;    priority_queue&lt;int,vector&lt;int&gt;,greater&lt;&gt;&gt; que;    for(int i=0;i&lt;n;i++) {        scanf(\"%d\",&amp;fruits[i]);        que.push(fruits[i]);    }    int min_cost = 0;    while(que.size()&gt;1){        int s1 = que.top();        que.pop();        int s2 = que.top();        que.pop();        min_cost += s2+s1;        que.push(s1+s2);    }    cout&lt;&lt;min_cost&lt;&lt;endl;}int main() {//    interSecPntTest();//    interGroupTest();//    interCoverTest();    comb_fruitTest();    return 0;}\n\n\n\n算法证明\n深度最深：假设最小的两个点为a,f，那么b,f交换后一定收益为正\n\n\n\n\n可以互为兄弟：a,b,c,d顺序可以交换，不影响全局最优解\n\n合并剩下n-1个果子的最优解一定是合并n个果子的最优解吗？\n即f(n) = f(n-1)+a+b成立吗？\n因为合并果子一定可以先合并最小两个点作为最优解，所以对于所有方案都可以把（a+b）去掉不影响最值，因此原问题就可以变为n-1个点的huffman问题，所以合并剩下n-1个果子的最优解一定是合并n个果子的最优解\n\n\n排序不等式\n可能会爆int，所以用Long Long来做\n\n算法思路按照从小到大的顺序排队，总时间最小\n#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int N = 100010;int q[N];typedef long long LL;void MinWaitTimeTest(){    int n;    cin&gt;&gt;n;    for(int i=0;i&lt;n;i++) scanf(\"%d\",&amp;q[i]);    sort(q,q+n);    LL res = 0;    for(int i=0;i&lt;n-1;i++){        res += q[i]*(n-i-1);    }    cout&lt;&lt;res&lt;&lt;endl;}int main(){    MinWaitTimeTest();    return 0;}\n\n算法证明调整法\n若不是排好序的，那么一定存在ti&gt;ti+1,若我们将ti和ti+1交换位置，那么交换前比交换后多了ti-ti+1&gt;0，也就是说交换完后总时间就会降低。\n绝对值不等式算法思路按照从小到大排序，取中位数\n#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int N = 100010;int q[N];void MinDistTest(){    int n;    cin&gt;&gt;n;    for (int i = 0; i &lt; n; i++) scanf(\"%d\", &amp;q[i]);    sort(q,q+n);    int res =0;    for(int i=0;i&lt;n;i++){        res += abs(q[n/2]-q[i]);    }    cout&lt;&lt;res&lt;&lt;endl;}int main() {//    MinWaitTimeTest();    MinDistTest();    return 0;}\n\n算法证明分组法\n\n只要x位于a,b之间，就可以取到最小值。分组后对每一个组都可以取到最小值，同时取即是总共的最小值，即取到正中间即可。\n推公式\n基于不等式来证明贪心问题\n\n耍杂技的牛\n#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;const int C = 50010;typedef pair&lt;int, int&gt; pii;pii ent[C];void MinRiskTest() {    int n;    cin &gt;&gt; n;    for (int i = 0; i &lt; n; i++) {        int w, s;        scanf(\"%d%d\", &amp;w, &amp;s);        ent[i] = {w + s, s};    }    sort(ent, ent + n);    int res = -2e9;    int sum = 0;    for (int i = 0; i &lt; n; i++) {        int s = ent[i].second;        int w = ent[i].first - s;        res = max(res, sum - s);        sum += w;    }    cout&lt;&lt;res&lt;&lt;endl;}int main() {//    MinWaitTimeTest();//    MinDistTest();    MinRiskTest();    return 0;}\n\n算法思路按照wi+si从小到大的顺序排，最大的危险系数一定是最小的\n算法证明只要最优解不是严格从小到大递增的，我们一定可以找到第i个位置上的牛和第i+1位置上的牛他们满足，交换完这两个牛后，我们可以证明，这两个危险系数的最大值一定会严格变小\n","categories":["coding"],"tags":["算法总结"]},{"title":"coding笔记：数论","url":"/2023/08/05/coding-solution/%E6%95%B0%E8%AE%BA/","content":"数论质数质数和和数是针对严格大于1的整数定义的，如果只包含1和本身两个约数，就被称为质数，否则为和数。\n质数的判定\n\n试除法 O(n)\n\nbool is_prime(int n){    if(n&lt;2) return false;    for(int i=2;i&lt;n;i++)        if(n%i==0) return false;    return true;}\n\n我们可以发现n的所有约数都是成对出现的，即若d为n的约束，那么n/d也为n的约数。所以我们不需要枚举所有数，只需要枚举的数即可，也就是说d只需枚举到即可\n\n优化 O()\n\n不推荐使用sqrt(n)这个函数，也不推荐i*i&lt;=n的写法，因为可能存在溢出风险，所以推荐写法为：i&lt;=n/i\n分解质因数\n\n试除法 O(n)\n\n从小到大尝试n的所有因数，因为每次都会把因子除干净，所以不用担心满足n%i==0的数i会是和数。\nvoid divide(int n){    for(int i=2;i&lt;n;i++){        if(n%i==0){ // i 一定是质数            int cnt = 0;            while(n%i==0){                n/=i;                cnt++;            }            printf(\"%d %d\",i,cnt);        }    }}\n\n\n优化 最坏O()\n\nhints: n中最多只包含一个大于sqrt(n)的质因子，所以可以枚举所有小于sqrt的质因子，如果最后剩下的因子n，若大于1直接输出即可。\n求从1~n的所有质数\n\n筛法 O(nlogn)\n\nbool st[N]; //为false代表没有被筛掉int prime[N];void get_prime(int n){    int cnt = 0;     for(int i=2;i&lt;=n;i++){         if(!st[i]){             prime[cnt++]=i;         }         for(int j=i+i;j&lt;=n;j+=i) st[j] = true;     }}\n\n\n优化：埃氏筛法 O(nloglogn)\n\n根据基本分解定理，每个数只需要被素数筛掉就可以了，所有可以把第二个循环放到if里。\n\n线性筛法\n\nvoid get_primes(int n){    for(int i=2;i&lt;=n;i++){        if(!st[i]) primes[cnt++] = i;        for(int j = 0;primes[j] &lt;= n/i ; j++){            st[primes[j]*i] = true;            if(i%primes[j] == 0) break;        }    }}\n\n正确性证明：\n论断：如果是和数，只会被最小质因子筛掉，且一定能被筛掉\n\n从小到大枚举所有质数，每一次把当前质数同i的乘积筛掉\n\n第一次出现i%primes[j] == 0发生时意味着primes[j]一定是i的最小质因子，那么primes[j]也一定是primes[j]*i的最小质因子\n\n若我们没有枚举到i的任何一个质因子，说明primes[j]一定小于i的所有质因子，所有primes[j]也一定是primes[j]*i的最小质因子\n\n对于一个和数x，假设pj是x的最小质因子，当i（一定会）枚举到x/pj时，就会把x筛掉\n\n\n线性筛法为什么是线性的？\n   每个数都只有一个最小质因子，每个数也只用最小质因子来筛，所以每个数只会被筛一次，所以是线性的。不加break就可能重复筛。\n约数求所有约数\n\n试除法+优化\n\nvector&lt;int&gt; get_divisors(int n){    vector&lt;int&gt; res;    for(int i=1;i&lt;=n/2;i++){        if(n%i == 0){            res.push_back(i);            if(i!=n/i) res.push_back(n/i);        }    }    sort(res.begin(),res.end());    return res;}\n\n求一个数的约数个数\n\n\nn的每一个约数d就和我们从到的一种选法一一对应，所以约数个数为所有选法数量：$(\\alpha_1+1)(\\alpha_2+1)…(\\alpha_{k-1}+1)(\\alpha_k+1)$\n```**求一个数的约数之和**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202206251729585.png\" alt=\"image-20220625172930529\" style=\"zoom:50%;\" /&gt;每个约数均不相同，且是选法数量之一。`while(a--) t = t*p+1`可以方便的求等比数列的和，其中a为指数，p为底数，也可以用公式做（尝试）**求最大公约数**&gt; 辗转相除法核心：**（a，b）= （b，a mod b)**```c++int gcd(int a,b){    return b ? gcd(b,a mod b) : a;}\n\n欧拉函数概念：\n为1~n中与n互质的数的个数\n欧拉公式：\n首先对n分解质因数 $p_1^{\\alpha_1}p_2^{\\alpha_2}…p_k^{\\alpha_k}，根据公式即可计算出结果\\phi(n) = n(1-1/p_1)(1-1/p_2)…*(1-1/p_k) $\n证明：\n使用容斥原理可以证明\n\n 从1~n中去掉\n加上所有的倍数\n减去所有$pipjpk$的倍数\n以此类推\n\n\n 某些情况下，需要求出1~n中每一个数的欧拉函数\n\n筛法求欧拉函数 O(n)\nvoid get_eulers(int n){    for(int i=2;i&lt;=n;i++){        if(!st[i]) {            primes[cnt++] = i;            phi[i] = i-1;        }        for(int j = 0;primes[j] &lt;= n/i ; j++){            st[primes[j]*i] = true;            if(i%primes[j] == 0) {                phi[primes[j]*i] = primes[j]*phi[i];                break;            };            phi[primes[j]*i] = (primes[j]-1)*phi[i];        }    }}\n\n应用：欧拉定理\n若a与n互质，\n\n注：等于号代表同余\n\n欧拉定理的特例：费马小定理\n若n为质数，假设a与n互质，那么有\n快速幂在O(log k)的情况下快速地求出的结果。\n把拆成若干个预处理出来的数的乘积的形式（用2进制表示即可），即把k换成2进制即可。\n typedef Long Long LL;int qmi(int a , int k, int p){    int res = 1;    while(k){        if(k&amp;1) res = (LL)res*a%p;        k&gt;&gt;=1;        a=(LL)a*a%p;    }}\n\n快速幂求乘法逆元\n\n其实本质上就是一个快速幂\n\n证明：\n希望把除法变乘法：\n左右两边同乘以b：\n因而 \n之后可以用费马定理来解决，但注意m要为质数，且b与m互质\n因而 \n所以b的模m的逆元为 \n扩展欧几里得算法裴蜀定理\n有任意一对正整数a、b，那么一定存在整数x、y，使得ax+by = gcd(a,b)\n\n注：x，y可取负整数\n\n解决什么问题\n为裴蜀定理构造解\nint ext_gcd(int a, int b, int &amp;x, int &amp;y){     if(!b){         x = 1,y=0;         return a;     }     int ans = ext_gcd(b,a%b,y,x);     y -= a/b *x;     return ans;}\n\n简单应用：求解线性同余方程  \n等价于，所以若(a,-m)|b成立则有解，可以用扩展欧几里得算法算出x；否则无解\n中国剩余定理\n求解一元线性同余方程组\n\n\n\n通解的构造方法：\n\n\n求逆元ti可以用扩展欧几里得算法解出：\n\n\n通解构造的正确性可通过带入法进行验证。\n高斯消元\n线性代数相关知识\n\n一般可以再O(n^3)的时间复杂度内，求解n个方程n个未知数的多元线性方程组。\n解的情况\n\n无解：通过行变换推出0=非0，矛盾\n无穷多组解：0=0，n个未知数，n-1个方程\n唯一解：完美阶梯形\n\n注：初等行变换不改变方程组的解，而且可以将方程组变为上三角的形式：\n\n\n算法流程\n\n枚举每一列，找出绝对值最大的这一行\n将这行换到上面去\n将该行第一个数变为1\n将下面所有行的当前列消成0\n若有唯一解，那么用消元法即可得到解\n\ndouble a[N][N] ;int gauss(){    int c,r;    for(int i=r;i&lt;n;i++){            }}\n\n组合数公式法\n由公式，可以计算出组合数：\nint p;int C(int a, int b){    int res = 1;    for(int i=1,j=a;i&lt;=b;i++,j--){        res = res*j % p;        res = res *qmi(i,p-2) % p;    }    return res;}\n\n递推式法\n\n10万组询问，a,b范围较小：1&lt;= a,b&lt;=2000\n\n根据递推式，先预处理出所有的 组合数（两重循环即可），到时候查表即可在O(ab)的时间复杂度下完成计算。\n\n\n预处理公式法\n\n1万组询问，a,b范围适中：1&lt;=a,b&lt;=1e5\n\n根据公式，预处理出中间的一步:阶乘。用fact[i]表示i! mod 10^9+7，infact[i]表示 mod 10^9+7\n也可以用查表的方式O(NlogN)来求 \n卢卡斯定理\n\n20组询问，a,b范围巨大：1&lt;=a,b&lt;=10^18，1&lt;=p&lt;=10^5\n\n$C^b_a = C^{b%p}{a%p}*C^{b/p}{a/p} (%p)$\n算法复杂度为O()，前半部分为递归层数，后半部分为每层递归里求组合数的复杂度；\n证明可参考该博客\nint lukas(int a,int b){    if(a&lt;p &amp;&amp; b&lt;p) return C(a,b);    return (LL)C(a%p,b%p) * lucas(a/p,b/p) % p;}\n\n分解质因数+高精度\n先把分解质因数 ，即$p_1^{\\alpha_1}p_2^{\\alpha_2}…*p_k^{\\alpha_k}$，之后只需要实现一个高精度乘法即可。\n\n对每一个数分解质因数，效率较低O(NlogN)\n\n改进：先处理出所有的质因子，再求出这个质因子的次数是多少。由公式，求p次数的方法为，先看分子里p的个数，再看分母里p的个数，差值即为真正的p的个数。那么如何得到阶乘里p的个数呢？通过下面的算法可以巧妙地计算出阶乘里p的个数：\n\n\n// 暴力解法// 分别求出1~n的质因子p的数量再相加：O(NlogN)int get(int n, int p){    for(int i=1;i&lt;=n;i++){        int t = i;        while(t%p==0){           t/=p;           cnt[i]++;        }    }    int res = 0;    for(int i=1;i&lt;=n;i++){        res += cnt[i];    }}// 优化// 计算出阶乘里p的个数O(logN)int get(int n, int p){    int res = 0;    while(n){        res += n/p;        n/=p;    }    return res;}\n\n卡特兰数$C_{2n}^{n}-C^{n-1}{2n}=1/(n+1)*C^n{2n}$\n 应用\n火车进站问题\n合法括号序列问题\n容斥原理对于n个圆，计算其所占的面积  ，数字代表i个圆的交集的组合。\n对于集合来讲，集合的个数也满足上式。\n上式一共有多少项？\n从n个数里挑任意多个数的方案数\n所以一共有项，所以时间复杂度为\n为什么是+、-、+、-？\n\n\n根据组合恒等式，对于集合中的某个数x，它在k个集合中出现过，它只会在右边的等式里计算一次。\n实际应用\n博弈论Nim游戏\n给定n堆石子，两位玩家轮流操作，每次操作可以从任意一堆石子中拿走任意数量的石子，最后无法进行操作的人视为失败。\n\n先手必胜状态：可以走到某一个必败状态\n先手必败状态：走不到任何一个必败状态\n\n定理：对于n堆石子(a1,a2,a3,…,an)，如果a1^a2^…^an=0，先手必败，否则先手必胜\n思考题：台阶Nim游戏\n集合-Nim游戏\n局面（状态）\nSG（终点）=0；\nSG（x）=mex{SG(y1),SG(y2),…,SG(yk)};\n若SG(x)!=0，必胜，否则必败。\n","categories":["coding"],"tags":["数论"]},{"title":"coding笔记：快排算法","url":"/2023/08/05/coding-solution/quicksort/","content":"快速排序分析题目描述给定你一个长度为 n 的整数数列。\n请你使用快速排序对这个数列按照从小到大进行排序。\n并将排好序的数列按顺序输出。\n样例输入格式输入共两行，第一行包含整数 n。\n第二行包含 n个整数（所有整数均在 1∼1e9范围内），表示整个数列。\n输出格式输出共一行，包含 n 个整数，表示排好序的数列。\n数据范围1≤n≤100000\n输入样例：53 1 2 4 5\n\n输出样例：1 2 3 4 5\n\n主要思想快排属于分治算法，分治算法都有三步：\n\n分成子问题\n递归处理子问题\n子问题合并\n\n寻找一个哨兵，将小于这个哨兵的元素放于其左边，大于他的元素放于其右；递归的排序其左区间和右区间即可完成排序\nthink point\n如何选取哨兵的位置？\n哨兵的位置应该随机选取，或是取中间：若是取左边作为哨兵，若数组本身就是有序的，每次分划的时间为O(n)，之后的子问题规模即为0和n-1，总共的复杂度即为，而取中间作为哨兵可以保证每次可以把区间分为长度近似相等的两部分，因而复杂度为递归深度*O(n)即为\n\n每次划分两部分后，最终哨兵的位置是否需要获知？\n根据每次分划后是否需要知道哨兵的位置，可以有两种思路来进行快排：\n\n\n哨兵最终位置未知\n第一种思路是acwing的模板思路，缺点是有一些坑，不好理解(i,j位置不能互换，不然可能陷入死循环等)但是代码较为整洁，适合笔试用\nvoid quicksort(int q[], int l, int r) {    if (l&gt;=r) return;    // 使用区间中点作为哨兵    int mid = l+r &gt;&gt;1;//    swap(q[mid],q[l]);    int x = q[mid], i = l-1, j= r+1;    //忽略了哨兵的位置，我不在乎哨兵的位置具体在哪里    //我只知道，j右边的数都大于等于哨兵，j左边的数都小于等于哨兵    //之所以不取等于是防止数组越界，还有可以更好地划分子问题    //缺点是可能会有很多次无效交换    while(i&lt;j) {        do i++; while (q[i] &lt; x);        do j--; while (q[j] &gt; x);        if (i &lt; j) swap(q[i], q[j]);    }    quicksort(q,l,j);    quicksort(q,j+1,r);}\n\n算法证明：\n明显地，j右边的数大于等于x,i左边的数小于等于x。现需证明while结束时，q[l..j]均&lt;=x，若成立，即可证明j这个端点可以划分整个区间。因为i&gt;=j，所以q[1..j-1]均&lt;=x。因为退出循环前的i&lt;j判断为false，所以最后一次交换不执行，所以q[j]必然&lt;=x。综上可以证明q[l..j]均&lt;=x，所以j这个端点可以划分整个区间。\n哨兵最终位置已知\n第二种是数据结构教材的官方思路，优点是步骤明确，方便理解，较少坑，缺点是代码冗长\nvoid quicksort2(int q[], int l, int r) {    if (l&gt;=r) return;    // 首先保存哨兵的值    int pio = q[l];    int i = l;    int j = r;    while(i&lt;j){        // 之所以可以取=，是因为之前有判断，一定不会越界        while(i&lt;j &amp;&amp; q[j]&gt;=pio) j--;        if(i&lt;j) q[i] = q[j];        else break;        while(i&lt;j &amp;&amp; q[i]&lt;=pio) i++;        if(i&lt;j) q[j] = q[i];    }    //哨兵的位置是确定的=i=j，所以只需要对其左边和右边分别进行排序即可    q[i] = pio;    quicksort2(q,l,i-1);    quicksort2(q,i+1,r);}\n\n算法改进\n实际上是对于某类特殊数据的算法增强\n\n如果数组的每个数据都相同时，上面的第一种思路可以pass，但是第二种思路会超过时限，究其原因为：分化后的子问题规模即为0和n-1，总共的复杂度即为，所以对于这种情况需要特殊处理，而且不能简单地将中点与左端点交换（实际上没有改变算法流程），第二种思路地修改点如下：\nwhile(i&lt;j){        // 之所以可以取=，是因为之前有判断，一定不会越界        while(i&lt;j &amp;&amp; q[j]&gt;pio) j--;        if(i&lt;j) q[i++] = q[j];        else break;        while(i&lt;j &amp;&amp; q[i]&lt;pio) i++;        if(i&lt;j) q[j--] = q[i];    }\n\n经测试，第二种思路改进后速度较第一种思路能快上一点点\n\n","categories":["coding"],"tags":["快排"]},{"title":"coding笔记：最短路","url":"/2023/08/05/coding-solution/%E6%9C%80%E7%9F%AD%E8%B7%AF/","content":"最短路\n难点在于建图，而不在算法的原理上：给你一个背景，如何把问题抽象成最短路，侧重于实现思路，而不侧重于原理\n\n常见的最短路问题单源最短路\n一个点到其他点的所有最短路\n\n所有边权都是正数\nn为点数，m为边数\n\n朴素dijkstra算法：O(n^2)\n如果是稠密图(m ~ n^2)，尽量使用朴素dijkstra算法，其算法流程如下：\n\n初始化：dist[1]=0, dist[i] = 正无穷，S=当前已确定最短路的点的集合{}\nn次迭代：for i : 1~n 在没有确定的点中找到最小值，将距离最短的点加入S，使用t更新其他点的距离\n\n因为是稠密图，所有推荐用邻接矩阵来存，存在重边的话，就只保留距离最短的那条边即可\nint \n\n堆优化版的dijkstra算法：O(mlogn)\n如果是稀疏图(m ~ n)，用邻接表来存，那么应该用堆优化版dijkstra算法\n存在负权边\n若能求出最短路，对应路径内中一定没有负权回路\n\nBellman-Fold ：O(nm)\n外层循环n次，内层循环所有边，一个比较朴素的算法。\n实际意义：迭代k次，dist[]存的是不超过k条边的最短路距离，若第n次依然有更新，说明存在负权回路\nSPFA： 一般O(m) ，最坏O(nm) \n没有负环就可以用SPFA，99%情况下都可以用。\n若cnt[x]&gt;=n，说明存在负环\n多源汇总最短路\n不止一个起点，任选两个点，从其中一个点到另一个点的最短路问题\n\nFloyd算法：O(n^3)\n采用动态规划的思想：d[i,j]存储所有边，floyd算法包含三重循环：\n\n第一重：k从1到n\n第二重：i从1到n\n第三重：j从1到n:\nd(i,j) = min(d(i,j), d(i,k) + d(k,j))\n\n\n\n总结最短路问题总结见下图：(参考acwing视频)\n\n\n","categories":["coding"],"tags":["graph","最短路"]},{"title":"C++基础","url":"/2023/08/05/coding-solution/c++%20primer_basic/","content":"c++基础变量和基本类型变量初始值\n初始化不是赋值：\n\n\n列表初始化\n\n\n\nc++11新标准\n\n默认初始化\n\n\n分离式编译\n将程序分割为若干文件，每个文件可独立编译。\n如果要在多个文件里使用同一个变量，就必须将声明和定义分离。此时，变量的定义必须出现且只能出现在一个文件中，而其他用到该变量的文件必须对其进行声明。\n作用域\n同一个名字在不同的作用域可以指向不同的实体\n\n\n复合类型基于其他类型定义的类型（引用，指针等）\n引用\n“引用”通常指的是左值引用，右值引用是c++11新标准\n定义引用时，是把引用和初始值对象bind在一起，而不是将初始值拷贝给引用。无法令引用重新绑定到另外一个对象，因此引用必须初始化。引用只能绑定在对象上，而不能与字面值绑定。\n指针\n指针本身就是一个对象，可以赋值&amp;拷贝。且无需定义时赋值。\n**空指针**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141027006.png\" alt=\"image-20230214102744969\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141028075.png\" alt=\"image-20230214102846034\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141029729.png\" alt=\"image-20230214102929664\" style=\"zoom:50%;\" /&gt;**void*指针**可以存放任意对象的地址，但不能直接操作其所指对象。**复合类型声明**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141036532.png\" alt=\"image-20230214103604481\" style=\"zoom:50%;\" /&gt;**指向指针的指针**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141037939.png\" alt=\"image-20230214103716894\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141037768.png\" alt=\"image-20230214103754721\" style=\"zoom:50%;\" /&gt;**指向指针的引用**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141038714.png\" alt=\"image-20230214103844673\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141040973.png\" alt=\"image-20230214104041922\" style=\"zoom:50%;\" /&gt;### const 限定符**为什么要用const限定符？**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141042570.png\" alt=\"image-20230214104256517\" style=\"zoom:50%;\" /&gt;const对象必须进行初始化：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141043707.png\" alt=\"image-20230214104327674\" style=\"zoom:50%;\" /&gt;**编译器如何处理const？**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141045649.png\" alt=\"image-20230214104541612\" style=\"zoom:50%;\" /&gt;为了避免对同一变量的重复定义，默认情况下，const对象被设定为仅在文件内有效。若想要共享const 变量：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141050428.png\" alt=\"image-20230214105008379\" style=\"zoom:50%;\" /&gt;**const的引用（常量引用）**常量引用不能修改其所引用的常量&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141054588.png\" alt=\"image-20230214105435558\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141055958.png\" alt=\"image-20230214105515932\" style=\"zoom:50%;\" /&gt;但对const的引用可能引用一个并非const的对象，允许通过其他手段改变它的值。**const的引用初始化**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141057000.png\" alt=\"image-20230214105711959\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141058187.png\" alt=\"image-20230214105806146\" style=\"zoom:50%;\" /&gt;**编译器是如果处理这种情况的？**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141059952.png\" alt=\"image-20230214105941891\" style=\"zoom:50%;\" /&gt;**指针和const**- 指向常量的指针&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141104076.png\" alt=\"image-20230214110444036\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141106500.png\" alt=\"image-20230214110620450\" style=\"zoom:50%;\" /&gt;- const 指针不变的指针本身的值，而非所指向的那个值。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302141108143.png\" alt=\"image-20230214110859103\" style=\"zoom:50%;\" /&gt;**顶层const &amp; 底层const**顶层const：表示指针本身是一个常量底层const：表示指针所指对象是一个常量&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160929459.png\" alt=\"image-20230216092934328\" style=\"zoom:50%;\" /&gt;**常量表达式**值不会改变且在编译过程中就能得到计算结果例如：字面值，常量表达式初始化的const对象**constexpr变量**c++11新标准：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160935408.png\" alt=\"image-20230216093514355\" style=\"zoom:50%;\" /&gt;类型有所限制，需要为字面值类型：- 算术类型- 引用- 指针&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160937123.png\" alt=\"image-20230216093747081\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160939110.png\" alt=\"image-20230216093934066\" style=\"zoom:50%;\" /&gt;### 处理类型**类型别名**传统方法使用typedef来定义类型别名c++11新标准使用了别名声明来定义类型的别名：`using SI=Sales_item;`&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160946472.png\" alt=\"image-20230216094646420\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160946157.png\" alt=\"image-20230216094621115\" style=\"zoom:50%;\" /&gt;**auto类型说明符**要知道表达式的类型有时并不容易，所有c++11引入了auto。一条声明语句只能有一个基本数据类型。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160950827.png\" alt=\"image-20230216095029779\" style=\"zoom:50%;\" /&gt;**decltype类型指示符**选择并返回操作数的数据类型&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302160959564.png\" alt=\"image-20230216095916533\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161001578.png\" alt=\"image-20230216100113527\" style=\"zoom:50%;\" /&gt;而auto一般会忽略顶层const和引用。decltype如果使用的是表达式，它返回表达式结果对应的类型：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161005956.png\" alt=\"image-20230216100549920\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161007880.png\" alt=\"image-20230216100713837\" style=\"zoom:50%;\" /&gt;![image-20230216100302778](https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161003839.png)### 自定义数据结构一般，自定义数据结构会保存在单独的.h文件中，但是这个会导致某个头文件被多次包含。预处理器可以确保头文件多次包含仍能安全工作。预处理器是在编译前执行的一段程序。常见预处理功能：- #include：用指定头文件的内容替代 #include- 头文件保护符：需要用到预处理变量（**必须唯一**）  - #define：将一个名字设定为预处理变量  - #ifdef: 当且仅当变量已定义时为真  - #ifndef: 当且仅当变量未定义时为真  一旦检查为真，则执行后续操作直到遇到#endif为止。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161035228.png\" alt=\"image-20230216103540178\" style=\"zoom: 67%;\" /&gt;如果#ifndef检查结果为**假**，**编译器将忽略**#ifndef到#endif之间的部分。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161038915.png\" alt=\"image-20230216103811852\" style=\"zoom:50%;\" /&gt;## 字符串、向量和数组**using声明**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161041445.png\" alt=\"image-20230216104154399\" style=\"zoom:50%;\" /&gt;### string#### 定义和初始化&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161049553.png\" alt=\"image-20230216104948488\" style=\"zoom:50%;\" /&gt;拷贝初始化：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161050995.png\" alt=\"image-20230216105050969\" style=\"zoom:50%;\" /&gt;直接初始化：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161050519.png\" alt=\"image-20230216105059491\" style=\"zoom:50%;\" /&gt;#### string对象上的操作&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161053640.png\" alt=\"image-20230216105306553\" style=\"zoom:50%;\" /&gt;**读取未知数量的string对象**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161058425.png\" alt=\"image-20230216105809383\" style=\"zoom:50%;\" /&gt;**使用getline读取一整行**- 注意getline不会存换行符到string里**string::size_type类型**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161104405.png\" alt=\"image-20230216110408376\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161107291.png\" alt=\"image-20230216110740235\" style=\"zoom:50%;\" /&gt;#### 处理string对象中的字符&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161109173.png\" alt=\"image-20230216110909071\" style=\"zoom: 50%;\" /&gt;**使用for range处理每个字符**（c++ 11）&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161114270.png\" alt=\"image-20230216111425244\" style=\"zoom:50%;\" /&gt;如果想在for中改变字符值，需要将循环变量定义为引用类型**如何只处理一部分字符？**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161119835.png\" alt=\"image-20230216111913794\" style=\"zoom:50%;\" /&gt;下标运算符的返回值是该位置字符的引用。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302161122996.png\" alt=\"image-20230216112221945\" style=\"zoom:50%;\" /&gt;SOME string### vectorvector是一个类模板。可以把模板看作为编译器生成类或函数编写的一份说明。**实例化：**编译器根据模板创建类或函数的过程引用不是对象，所有不存在包含引用的vector#### 定义和初始化&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302180935709.png\" alt=\"image-20230218093530626\" style=\"zoom:50%;\" /&gt;一般情况下：- 如果用圆括号，提供的值是用来构造vector对象的- 如果用花括号，表示我们想列表初始化该vector对象&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302180945381.png\" alt=\"image-20230218094509308\" style=\"zoom:50%;\" /&gt;如上例，只有v5使用了列表初始化注：不能用下标去访问不存在的元素，否则会产生缓冲区溢出。### 迭代器一种通用的机制来访问容器的对象。所有标准库容器都可以使用迭代器。#### 使用迭代器- begin：返回指向第一个元素的迭代器- end：返回指向容器“尾元素的下一位置”的迭代器（尾后迭代器，表示我们已经处理完了容器中的所有元素）如果容器为空，则begin和end返回的是同一个迭代器。**迭代器运算符**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181005718.png\" alt=\"image-20230218100531646\" style=\"zoom:50%;\" /&gt;c++程序员习惯地使用!=，因为这种编程风格在所有容器上均有效。所有标准库容器都定义了==和!=，而其中的大多数都没有定义&lt;。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181014039.png\" alt=\"image-20230218101424954\" style=\"zoom:67%;\" /&gt;这种风格又被称为泛型编程。如果对象只需读操作而无须写操作的的话，最好使用常量类型。c++11增加了cbegin()，得到const_iterator类型的返回值**访问迭代器所指对象的成员**`(*it).empty()`可以访问成员，注意（）必不可少。使用箭头运算符可以简化表达式，`it-&gt;empty()`**一些限制**不能在range for中向vector对象添加元素，否则会使该对象的迭代器失效。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181028445.png\" alt=\"image-20230218102827400\" style=\"zoom:50%;\" /&gt;#### 迭代器运算&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181031493.png\" alt=\"image-20230218103105378\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181032776.png\" alt=\"image-20230218103251746\" style=\"zoom: 67%;\" /&gt;**二分使用迭代器运算**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181049323.png\" alt=\"image-20230218104928261\" style=\"zoom:50%;\" /&gt;### 内置数组&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181052977.png\" alt=\"image-20230218105241936\" style=\"zoom:50%;\" /&gt;#### 定义和初始化**字符数组的特殊性**我们可以使用字符串字面值对此类数组进行初始化，一定要注意字面值结尾还有一个空字符。**不允许拷贝和赋值**&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181057506.png\" alt=\"image-20230218105716467\" style=\"zoom:50%;\" /&gt;**理解复杂的数组声明**因为数组本身是对象，所有允许定义数组的指针和数组的引用。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181105048.png\" alt=\"image-20230218110517014\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181104959.png\" alt=\"image-20230218110452905\" style=\"zoom:50%;\" /&gt;&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181108098.png\" alt=\"image-20230218110843045\" style=\"zoom:50%;\" /&gt;#### 指针和数组使用数组的时候，编译器一般会把它转化为指针。&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181111322.png\" alt=\"image-20230218111152263\" style=\"zoom:50%;\" /&gt;使用数组最为一个auto变量的初始值时，推断得到的类型为指针：&lt;img src=\"https://raw.githubusercontent.com/coelien/image-hosting/master/img/202302181112612.png\" alt=\"image-20230218111251575\" style=\"zoom:50%;\" /&gt;值得注意的是，当使用decltype关键字时, 不会进行转换，其返回的类型为10个整数构成的数组。```c++decltype(ia) ia3 = {0,1,2,3,4,5,6,7,8,9};\n\n指针也是迭代器\n指向数组元素的指针拥有更多的功能。\nint arr[] = {0,1,2,3};int * p  = arr;++p; // p 指向 arr[1]\n\n使用指针也能遍历数组中的元素，但要获取指向数组尾元素下一位置的指针：\nint *e = &amp;arr[10]; // 唯一用处：提供地址以初始化efor(int *b = arr; b!=e;b++) cout &lt;&lt;*b&lt;&lt;endl;\n\n尽管可以得到尾后指针，但是这种方法不是很安全，所有c++11引入了两个名为begin和end的函数，使用数组作为他们的参数：\nint *beg = begin(arr);int *last = end(arr);\n\n下标和指针\n对数组使用下标运输符时，其实是对数组元素的指针执行下标运算。\n只要指针指向的是数组中的元素，都可以执行下标运算。\nint *p= &amp;ia[2];int j = p[1];int k = p[-2];\n\n但需要保证结果地址必须指向原来指针所指同一数组的元素。\n\n\nc风格字符串\nctring库\n\n\n\n\n传入此类函数的指针必须指向以空字符作为结束的数组\n\n使用strcpy充满安全风险，极易引发严重错误：\n\n\n\n\n与旧代码的接口\n若程序某处需要c风格字符串：const char * str = s.c_str()\n允许使用数组来初始化vector对象：vector&lt;int&gt; ivec(begin(int_arr),end(int_arr))\n\n多维数组\n数组的数组\n\n初始化\n\n\n内层嵌套的花括号并非必须，但是形式上更为简洁。\n多维数组的下标引用\nint (&amp;row)[4] = ia[1]; // 把row绑定到ia的第二个4元素数组上\n使用范围for处理多维数组\nsize_t cnt = 0;// 因为要改变元素的值，所以要声明为引用类型for( auto &amp;row : ia)    for( auto &amp;col: row){        col = cnt;        ++cnt;    }// 第一层循环也必须声明为引用类型，为了防止自动转换为int*类型，导致第二层循环报错\n\n指针和多维数组\n多维数组名转换得到的指针实际上是指向第一个内层数组的指针\n表达式基础左值和右值\n\n左值可以位于赋值语句的左侧，而右值却不能（c中），c++会更复杂\n\n当一个对象被用作右值时，用的是对象的值（内容）；当对象被用作左值时，用的对象的身份（在内存中的位置）。\n\n需要右值的地方可以用左值来代替\n反之不行，不能把右值当作左值使用\n\n要用到左值的运算符：\n\n赋值运算符：非常量左值作为左侧运算对象，得到的结果仍然是左值\n取地址符：作用于一个左值运算对象，返回一个指向该运算对象的指针（该指针是一个右值）\n解引用运算符，下标运算符\n递增递减运算符\n\n使用关键字decltype时，如果表达式结果时左值，得到引用类型。\n算术运算符\nc++11，规定商一律向0取整\n取模运算：\nm%(-n) = m%n\n(-m)%n = -(m%n)\n\n\n\n\n\n逻辑与关系运算符短路求值\n当且仅当左侧运算对象无法确定表达式结果时，才会去计算右侧运算对象的值。\n赋值运算符满足右结合律\nint ival, jval;ival = jval = 0;\n\n多重赋值语句的每一个对象，其类型或者与右边对象的类型相同，或可由右边对象类型转换得到\nstring s1,s2;s1 =s2 = \"OK\";\n\n赋值语句通常会出现在条件中（优先级低）\nint i;while((i=get_value())!=42) //不断读取循环直到42为止\n\n递增递减运算符除非必须，否则不用递增递减运算符的后置版本。\n前置版本将对象本身作为左值返回，而后置版本则将对象原始值的副本作为右值返回（需要将原始值存下来以便返回未修改的内容）\n混用解引用和递增运算符\nauto pbeg = v.begin();while(pbeg != v.end &amp;&amp; *pbeg &gt;=0)    cout&lt;&lt;*pbeg++&lt;&lt;endl;\n\n++优先级较高，因此等价于*(pbeg++)。即把pbeg的值+1，然后返回pbeg初始值的副本作为其求职结果，此时解引用的运算对象是pbeg未增加之前的值。\n因为简洁，上述写法优于：\ncout&lt;&lt;*pbeg&lt;&lt;endl;++pbeg;\n\n位运算符\n作用于整数类型的运算对象\n\n\nbitset可以表示任意大小的二进制位集合\n\n^ 位异或\n\n| 位或\n\n\n强烈建议将位运算符用于处理无符号类型\nunsigned char bits = 0233;~bits; // 先将char类型的对象提升为int类型，再按位取反\n\nsizeof运算符返回一条表达式或一个类型名字所占的字节数，其所得值是size_t类型的常量表达式\n\nsizeof (type)\nsizeof expr\n\nsizeof 并不会实际计算其运算对象的值：\nSales_data data, *p;sizeof(Sales_data);sizeof data;sizeof p;sizeof *p;\n\n\nc++11允许我们通过作用域运算符来获取类成员的大小：\n\nsizeof Sales_data::revenue;\n\n\n对数组执行sizeof得到整个数组所占空间的大小\n对string或vector对象执行sizeof不会计算对象中的元素占用了多少空间\n\n类型转换显示转换命名的强制类型转换：\ncast-name&lt;type&gt;(expression);\ncast-name:\n\nstatic_cast\n只要不包含底层const，都可以用；\n需要将一个较大的算数类型赋值给较小的类型时；\n对于编译器无法自动执行的类型转换，如找回存在于void*指针：\nvoid* p = &amp;d;double *dp = static_cast&lt;double *&gt;(p);\ndynamic_cast\n\nconst_cast\n只能改变运算对象的底层const；\nconst char *pc;char *p = const_cast&lt;char*&gt;(pc);// correct, but writing to p is undefined\n\n需要对象本身并不是一个常量；\nchar *q = static_cast&lt;char*&gt;(pc);//wrongstatic_cast&lt;string&gt;(cp); //correct, 可以将字符串字面值转换成string类型;const_cast&lt;string&gt;(cp); // wrong\n\nconst_cast常常用于函数重载中\n\nreinterpret_cast\n为运算对象的位模式提供较低层次上的重新解释\n\n\n注：\n尽量避免强制类型转换（充满风险）\n语句悬垂else\n\n\n\n\nswitch\nswitch的case标签必须是整型常量表达式\n\n\ndefault标签\n如果没有任意一个case标签能匹配上switch表达式的值，就执行\ntry语句块和异常处理何为异常？\n\n存在于运行时的反常行为\n\nc++中的异常处理包括：\n\nthrow表达式\n异常检测部分使用throw表达式表示它遇到了无法处理的问题。\n\ntry语句块\n异常处理部分，以try关键字开始，并以一个或多个catch子句结束。try抛出异常，而catch进行处理\n\n一套异常类\n用于在throw表达式和catch字句之间传递异常的具体信息\n\n\nthrow表达式if(item1.isbn()!=item2.isbn())    throw runtime_error(\"Data must refer to same ISBN\");\n\ntry语句块\n\n注：编写异常安全的代码十分困难\n在异常发生期间，正确执行了“清理工作”的程序被称为异常安全的代码。必须时刻清楚，异常何时发生，如何确保对象有效、资源无泄漏、程序处于合理状态等。\n标准异常异常类定义在了4个头文件中：\n\nexception头文件\nstdexcept头文件\nexception\nruntime_error\nrange_error\noverflow_error\nunderflow_error\nlogic_error\ndomain_error\ninvalid_argument\nlength_error\nout_of_range\n\n\nnew头文件\ntype_info头文件\n\n函数函数基础局部对象\n名字的作用域\n是程序文本的一部分\n\n对象的生命周期\n是程序执行过程中该对象存在的一段时间\n\n\n自动对象\n\n形参\n普通局部变量\n\n局部静态对象\n\n在程序执行第一次经过对象定义语句时初始化，直到程序终止时才被销毁\n\n\n\n函数声明\n变量（只能被定义一次的实体）在头文件中声明，在源文件中定义\n函数也应在头文件中声明，在源文件中定义\n定义函数的源文件应该把含有函数声明的头文件包含进来\n\n参数传递\n【引用传递】如果形参是引用类型：它将绑定到对应的实参上\n【值传递】否则：将实参的值拷贝后赋给形参\n\n注：在c++中，强烈建议用引用类型的形参代替指针\n使用引用可以避免拷贝\n有的类类型（包括IO类型）根本就不支持拷贝操作，函数只能通过引用形参访问该类型对象：\nbool isShorter(const string &amp;s1, const string &amp;s2){    return s1.size() &lt; s2.size();}// 当函数无需修改引用形参的值的时候最好使用常量引用\n\n使用引用形参令函数同时返回多个值\n\n\nconst形参和实参\n用实参初始化形参时，会忽略掉（形参）顶层const。\n\nC++允许我们使用字面值初始化常量引用\n\n引用尽量使用常量引用，使用普通引用会极大地限制函数所能接受的实参类型，从而导致错误：\n\n\n\n\n数组形参定义和使用作用在数组上的函数时，数组有两个特殊性质：\n\n不允许拷贝数组\n使用数组时会将其转化为指针\n\n尽管不能以值传递的形式传递数组，但是我们可以把形参写成类似数组的形式：\n\nvoid print(const int *);\nvoid print(const int []);\nvoid print(const int [10]);\n\n上面三种表示是等价的。\n管理数组实参的方法：\n\n使用标记指定数组长度：要求数组本身包含一个结束标记。典型示例：C风格字符串：\n\nvoid print( const char *cp){    if(cp) // 若cp不是空指针        while(*cp) // 若cp所指字符不是空字符            cout&lt;&lt;*cp++;}\n\n该方法时候那些有明显结束标记且该标记不会与普通数据混淆的情况。\n\n使用标准库规范：传递指向数组首元素和尾后元素的指针：\n\nvoid print(const int *beg, const int *end){    while(beg!=end)        cout&lt;&lt;*beg++&lt;&lt;endl;}int j[2] = {0,1};print(begin(j),end(j))\n\n\n显示传递一个表示数组大小的形参\n\n\n\n传递多维数组\n传递的本质上是一个指向数组的指针，维度大小不能省略：\nvoid print(int (*matrix) [10], int rowSize){...}\n\n上面的语句将matrix声明为指向包含10个整型元素的数组的指针。\n等价定义：\nvoid print(int matrix[][10], int rowSize){...}\n\nmain：处理命令行选项\nint main(int argc, char *argv[]){...}\n\n第二个形参argv是一个数组，它的元素是指向C风格字符串的指针。第一个形参表示数组中字符串的数量。\n等价定义：\nint main(int argc, char **argv){...}\n\n其中argv指向char*。\n\n\n\n当使用argv中的实参时，从argv[1]开始\n\n含有可变形参的函数为了能编写处理不同数量实参（数量未知）的函数，c++11提供了两种方法：\n\n所有实参类型相同：传递一个名为initializer_list；的标准库类型\n类型不同：可变参数模板\n\ninitializer_list形参\n\n\n其元素永远是常量值，无法改变。\nvoid error_msg(initializer_lists&lt;string&gt; il){    for(auto beg = il.begin();beg != il.end();++beg)        cout&lt;&lt;*beg&lt;&lt;\" \";    cout&lt;&lt;endl;}\n\n\n\n\n\n返回类型及return语句值是如何被返回的？\n\n如果返回string\n\nstring make_plural(size_t ctr, const string &amp;word,                  const string &amp;ending){    return (ctr&gt;1)?word+ending :word;}\n\n意味着返回值将被拷贝到调用点，因此该函数返回一个未命名的临时string对象或是word的一个副本；\n\n如果返回引用\n\nconst string &amp;shorterString(const string &amp;s1, const string &amp;s2){    return s1.size()&lt;=s2.size()?s1:s2;}\n\n不管是调用函数还是返回结果，都不会真正拷贝string对象。\n不用返回局部对象的引用或是指针\n否则会引发未定义的行为：\n\n\n引用返回左值\n函数的返回类型决定了函数调用是否是左值：调用一个返回引用的函数得到左值，其他得到右值。\n\n\n列表初始化返回值 \n\n可以返回类类型，甚至内置类型\n\nc++11规定，可以返回花括号包围的值的列表。\n\n\n列表初始化，your best helper！\n主函数main的返回值\n\n我们允许main函数没有return而直接结束，编译器会隐式地插入一条返回0的return语句\ncstdlib头文件定义了两个预处理变量：\nEXIT_FAILURE\nEXIT_SUCCESS\n\n\n\n返回数组指针\n数组不能被拷贝，所以函数不能返回数组。但是函数可以返回数组的指针或引用。\n使用类型别名可以简化该过程：\ntypedef int arrT[10]; // arrT是一个类型别名，表示含有10个整数的数组using arrT = int[10]; // 等价声明arrT* func(int i); // 返回一个指向包含10个整型的数组的指针\n\n注意第一个typedef表达的含义，推荐用using，比较直观\n声明一个返回数组指针的函数\nType (*function(parameter_list))[dimension]\n例：int (*func(int i))[10];\n由此可以看出，使用类型别名是很方便的；\n使用尾置返回类型\n\n对复杂类型比较有效\n\nc++11新标准有一种可以简化上述func声明的方法：尾置返回类型，任何函数的定义都能使用尾置返回：\nauto func(int i) -&gt; int (*) [10]\n这种表达也比较清楚，值得推荐。\n使用decltype\n这个方法比较取巧，你得首先知道返回的指针将指向哪个数组：\nint odd[]{1,3,5,7,9};int even[]{0,2,4,6,8};decltype(odd) *arrPtr(int i){    return (i%2)? &amp;odd: &amp;even;}\n\n函数重载\n函数名字相同但是形参列表不同我们称之为重载。\n\n比如分别根据名字、电话、账户号码查找记录：\nRecord lookup(const Account&amp;);Record lookup(const Phone&amp;);Record lookup(const Name&amp;);\n\n编译器根据实参类型确定应该调用哪一个函数。\n重载和const\n有无const无法区分两个同名，同类型函数：\nRecord lookup(Phone);Record lookup(const Phone);\n\n上面两个声明是等价的。\n但如果形参是指针或是引用，则通过区分其指向的是常量还是非常量对象可以实现重载：\nRecord lookup(Account&amp;);Record lookup(const Account&amp;);Record lookup(Account*);Record lookup(const Account*);\n\n上面的几个函数都能作用于非常量对象。但只有带const形参的才能接受常量对象。\n何时不应该重载函数？\n\n应服务于代码的可读性，使程序更容易理解\n\nconst_cast和重载\n对于shorter string这一函数来讲，我们如果送入的是两个非常量引用，函数的返回值却是string常量引用，这显然是不符合逻辑的，可以使用const_cast实现重载：\nconst string &amp;shorter(const string &amp;s1, const string &amp;s2){    return s1.size()&lt;=s2.size()?s1:s2;}string &amp;shorter(string &amp;s1, string &amp;s2){    auto &amp;r = shorter(const_cast&lt;const string&amp;&gt;(s1),                      const_cast&lt;const string&amp;&gt;(s2));    return const_cast&lt;string&amp;&gt;(r);}\n\n重载与作用域\n通常情况下，在局部作用域声明函数不是一个很好的选择。因为外层作用域的同名实体会被隐藏。\n\n\n特殊用途语言特性默认实参\n尽量让不怎么使用默认值的形参出现在前面，而让那些经常使用默认值的形参出现在后面。\n\n对于函数声明，通常的习惯是将其放在头文件中并且一个函数只声明一次\n\n局部变量不能作为默认实参，函数，全局变量等可以：\n\n\nsz wd = 80;char def = '';sz ht();string screen(sz = ht(), sz = wd, char = def);\n\n内联函数将规模较小的操作定义成函数有诸多好处：\n\n理解更容易\n行为统一\n修改容易\n可重复使用\n\n但也有缺点：\n\n调用函数会慢一点（保存寄存器，返回时恢复，拷贝实参等）\n\n使用内联函数可避免函数调用的开销\n\n定义为内联函数(inline)\n\n\n适合于规模较小\n流程直接\n频繁调用的函数\n\n\n\nconstexpr函数\n指能用于常量表达式的函数\n\n函数的返回类型及所有形参的类型都得是字面值类型。函数体必须有且只有一条return语句。\n允许constexpr函数返回值并非一个常量：\nconstexpr size_t scale(size_t cnt){ return new_sz() * cnt;}//需要传入常量表达式\n\n\n\n注：内联函数和constexpr函数通常定义于头文件内\n调试帮助assert 预处理宏\n\nassert(expr)\n\n\n对expr求值，若表达式为假，终止程序运行\n\n为真则什么都不做\n\n常用于检查不能发生的条件\n\n\nNDEBUG 预处理变量\n可以使用#define语句定义NDEBUG，从而关闭调试状态\n\n__func__：当前调试的函数的名字\n__FILE__：当前文件名\n__LINE__：当前行号\n__TIME__：文件编译时间\n__DATE__：文件编译日期\n\n实参类型转换\n精确匹配\n类型相同\n从数组类型、函数类型转换成对应的指针类型\n\n\n通过const转换实现的匹配\n通过类型提升实现的匹配\n通过算数类型转换、指针转换实现\n\n函数指针函数指针指向的是函数而非对象，指向某种特定的函数类型。\n函数类型\n由它的返回类型和形参类型共同决定，与函数名无关；\n例如：\nbool lengthCompare(const string&amp;, const string&amp;);\n\n的类型为bool(const string&amp;, const string&amp;)\n想要声明该函数的指针，只需指针替换函数名即可：\nbool (*pf)(const string&amp;, const string&amp;);\n\n使用函数指针\n当我们把函数名作为一个值使用时，该函数自动地转换成指针。下面两个方式，将lengthCompare的地址赋给pf是等价的：\npf = lengthCompare;pf = &amp;lengthCompare;\n\n此外，使用函数指针时，无需提前解引用指针。\n在不同函数类型的指针间不存在转换规则，但是可以为函数指针赋0或是nullptr\n函数指针形参\n\n\n直接使用函数指针过程冗长且烦琐。类型别名或decltype能让我们简化使用了函数指针的代码：\n// Func and Func2是函数类型typedef bool Func(const string&amp;, const string&amp;);typedef decltype(lengthCompare) Func2;// FuncP and FuncP2是指向函数的指针typedef bool (*FuncP)(const string&amp;, const string&amp;);typedef decltype(lengthCompare) *FuncP2;\n\n可以使用上述简化useBigger的表达：\nvoid useBigger(const string&amp;, const string&amp;, Func); // 自动将Func表示的函数转换为指针void useBigger(const string&amp;, const string&amp;, FuncP2);\n\n这两种声明是等价的。\n函数指针返回值\n与形参不同的是，返回值必须写成指针形式，编译器不会自动将函数返回类型当成对应的指针类型进行处理，想声明一个返回函数指针的函数，最简单的方法是使用类型别名：\nusing F = int(int*, int);//F是函数类型，不是指针using PF= int(*)(int*, int);//PF是指针类型\n\n声明返回值是函数指针的函数：\nPF fl(int);F *fl(int);\n\n上面两个声明都是正确的。\n当然也可以直接声明fl，但可读性较差：\nint (*fl(int))(int*,int);\n\n使用尾置返回类型不失一个可行解：\nauto fl(int) -&gt; int (*)(int*,int);\n\n将auto或是decltype用于函数指针类型\ndecltype(sumLength) *getFcn(const string &amp;);\n\n\n当decltype作用于函数时，它返回的是函数类型，而非指针，所以需要显示地加上*。\n\n类\n类的基本思想是数据抽象和封装\n数据抽象是一种依赖于接口与实现分离的编程技术\n类的接口：用户所能执行的操作\n类的实现：类的数据成员、负责接口实现的函数体、定义类的各种私有函数\n封装实现了类的接口和实现的分离，因为封装后的类隐藏了它的实现细节，用户只能使用接口\n\n定义抽象数据类型引入this指针\n成员函数通过一个名为this的额外隐式参数来访问调用它的那个对象：\n\n\n\n引入const成员函数\n紧随参数列表之后的const关键字可以修改隐式this指针的类型：\n\nstd::string isbn() const{return bookNo;}\n\n默认情况下this的类型是指向类类型非常量版本的常量指针。例如在Sales_data的成员函数中，this的类型为Sales_data * const。这意味着我们不能把this指针绑定到一个常量对象上。也就是说，我们不能在一个常量对象上调用普通的成员函数。所有我们应该把this指针声明成const Sales_data * const。在isbn函数体内部不会改变this所指对象，所以参数列表之后加上const关键字有助于提高灵活性。该函数称为常量成员函数。\n\n\n类作用域和成员函数\n值得注意的是，即使bookNo定义在isbn之后，isbn也还是能够使用bookNo。因为编译器分两步处理类：首先编译成员的声明，然后才轮到成员函数体（如果有的话）。\n\n在类的外部定义成员函数的话，定义必须与声明匹配\n\n\n定义一个返回this对象的函数\n\n定义类的相关非成员函数\n\n构造函数比较复杂，它没有返回类型。构造函数不能被声明为const的，因此，构造函数在const对象的构造过程中可以向其写值。\n合成的默认构造函数\n\n编译器创建的构造函数\n\n对于普通的类来讲，必须定义它自己的默认构造函数\n原因包含：\n\n一旦我们定义了其他构造函数，那么除非我们再定义一个默认的构造函数，否则类将没有默认构造函数。\n编译器创建的构造函数可能执行错误的操作：例如定义在块中的内置类型和复合类型的对象被默认初始化后，其值将是未定义的。\n\n\n\n\n有时候，编译器不能为某些类合成默认的构造函数：如果类中包含另一个其他类类型的成员，且这个成员的类型没有默认构造函数。那么编译器将无法初始化该成员。\n\n定义Sales_data的构造函数\n\n默认构造函数\n\nSales_data() = default;要求编译器生成构造函数\n\n构造函数的初始化列表\n\n\n\n\n在类外部定义构造函数\n\nSales_data::Sales_data(std::istream &amp;is){    read(is, *this);}\n\n拷贝、赋值和析构\n拷贝何时发生？初始化变量、以值传递的方式返回一个对象等\n如果我们不主动定义拷贝、赋值和析构，编译器会为我们合成\n但是某些类不能依赖于合成的版本：\n管理动态内存的类\n\n\n\n访问控制与封装\n在c++中，使用访问说明符来加强类的封装性\n\npublic成员定义类的接口\n\nprivate部分封装了类的实现细节\n\nclass和struct唯一的一点区别是默认访问权限不太一样\n\n\n\n\n友元类可以允许其他类或者函数访问它的非公有成员，方法是令其他类或者函数成为它的友元。只需增加一条以friend关键字开头的函数声明即可\n\n\n\n\n封装的益处：\n\n确保用户代码不会无意间破坏封装对象的状态\n被封装的类的具体实现细节可以随时改变而无需调整用户级别的代码\n\n友元的声明\n友元声明仅仅指定了访问的权限。如果我们希望类的用户能够调用某个友元函数，必须在友元声明之外再专门对函数进行一次声明。\n为了使友元对类的用户可见，通常把友元的声明与类本身放置在同一个头文件中。\n类的其他特性类型成员\n其实就是自定义某种类型在类中的别名\n\nclass Screen{public:\ttypedef std::string::size_type pos;    // 等价：using pos = std::string::size_typeprivate:    pos cursor = 0;    pos height = 0, width = 0;    std::string contents;};\n\n\n类型成员必须先定义后使用\n出现在类开始的地方\n\n类的成员的类内初始值class Screen{public:\ttypedef std::string::size_type pos;    // 等价：using pos = std::string::size_type    Screen() = default; // 必须的默认构造函数    Screen(pos, ht, wd, char c):height(ht),width(wd),    contents(ht*wd,c){}private:    pos cursor = 0; // 类内初始值，所以构造函数不用显式初始化    pos height = 0, width = 0;    std::string contents;};\n\nclass Window_mgr{    private:    std::vector&lt;Screen&gt; screens{Screen(24,80,' ')};}\n\n可变数据成员\n一个可变数据成员永远不会是const，即使它是const对象的成员\n因此，一个const成员函数可以改变一个可变成员的值\n\nclass Screen{    public:    void some_member() const;    private:    mutable size_t access_ctr;};void Screen::some_member() const{    ++access_ctr;}\n\n内联成员函数\n定义在类内部的成员函数是自动inline的\n也可以显式使用inline来声明成员函数\n\n从成员函数返回*thisinlineScreen &amp;Screen::move(pos r, pos c){    pos row = r*witdh;    cursor = row+c;    return *this;    // 以左值的形式返回}inlineScreen &amp;Screen::set(pos r, pos c, char ch){    contents[r*width+c] = ch;    return *this;    // 以左值的形式返回}inlineScreen &amp;Screen::set(char ch){    contents[cursor] = ch;    return *this;    // 以左值的形式返回}\n\n\nset重载了成员函数‘\n\n函数返回的是对象本身而非副本\n\n可以将一系列操作连接在一条表达式：\nmyScreen.move(4,0).set('#');\n\n一个const成员函数如果以引用的形式返回*this，那么它返回的类型将是常量引用。\n\n\n因此可以使用重载的方式，让编译器选择函数：\nScreen &amp;display(std::ostream &amp;os){    do_display(os);return *this;}const Screen &amp;display(std::ostream &amp;os) const{    do_display(os);return *this;}\n\n建议对公共代码使用私有功能函数：\nprivate:\tvoid do_display(std::ostream &amp;os) const{        os&lt;&lt;contents;    }\n\n\n避免使用重复代码\ndisplay可能变复杂\n只在do_display一处添加调试信息要简单些\n不会带来额外开销\n\n友元再探友元类\nclass Screen{    friend class Window_mgr;};class Window_mgr{    public:    using ScreenIndex = std::vector&lt;Screen&gt;::size_type;    void clear(ScreenIndex);    //后续省略};void Window_mgr::clear(ScreenIndex i){    Screen &amp;s = screens[i];    s.contens = string(s.height*s.width,' ');}\n\n友元成员函数\nclass Screen{    friend void Window_mgr::clear(ScreenIndex);};\n\n使用友元成员函数，限制比较多：\n\n\n\n\n\n友元声明影响的是访问权限，本身并非普通意义上的声明\n\n类的作用域名字查找\n\n\n构造函数再探构造函数初始值列表构造函数的初始值有时必不可少\n\nconst或引用\n类类型且没有默认构造函数\n\n正确方式：\nclass ConstRef{public:    constRef(int ii);private:    int i;    const int ci;    int &amp;ri;};ConstRef::ConstRef(int ii):i(ii),ci(ii),ri(i){}\n\n成员初始化的顺序\n\n构造函数初始值列表只说明用于初始化成员的值，而不限定初始化的具体执行顺序\n\n默认参数和构造函数\nclass Sales_data{    public:    Sales_data(std::string s=\"\"): bookNo(s){}}\n\n\n该构造函数实际上为我们的类提供了默认构造函数\n\n委托构造函数\nc++11新标准\n委托构造函数使用它所属类的其他构造函数执行它自己的初始化过程\n\n\n\n隐式类类型转换如果构造函数只接受一个实参，它实际上定义了转换为此类类型的隐式转换机制，如：\nstring null_book = \"9-999-99999-9\";item.combine(null_book);\n\n编译器会用string构造一个临时的Sales_data对象，然后传给combine。\n类类型转换并不总有效\n\n\n下面的显式转换也是可行的：\nitem.combine(static_cast&lt;Sales_data&gt;(cin));\n\n标准库中：\n\nstring构造函数，不是explicit的，接受单参数的(const char*)\n接受一个容量参数的vector构造函数是explicit的。\n\n聚合类聚合类：\n\n所以成员都是public\n没有任何构造函数\n没有类内初始值\n没有基类，也没有virtual函数\n\n\n不推荐使用\n\n字面值常量类\n\n类的静态成员\n有时类会需要它的一些成员与类本身直接相关\n\n\n一旦利率浮动,我们希望所有对象都能使用新值\n效率上,没必要每个对象都存储利率\n\n\n\n\n可以使用作用域运算符直接访问类的静态成员:\n\ndouble r = Account::rate();\n\n\n仍然可以通过类的对象,引用,指针来访问静态成员:\n\nAccount ac1;Account *ac2 = &amp;ac1;r = ac1.rate();r = ac2-&gt;rate();\n\n\n一般来说,我们不能在类的内部初始化静态成员, 而应该在类的外部定义和初始化\n\n为了确保对象只定义一次,最好的办法是把静态数据成员与其他函数的定义放在同一个文件中\n\n类内初始化需要满足:\n\n\n// 类内初始化static constexpr int period = 30;// 类外定义(好的实践)constexpr int Account::period;\n\n静态成员能适用于某些场景,而不同成员不行\n\n静态数据成员可以说不完全类型\n\nclass Bar{    private:    static Bar mem1;    Bar *mem2;    Bar mem3; // 有误,数据成员必须是完全类型}\n\n\n可以使用静态数据成员作为默认实参:\n\nclass Screen{public:    Screen&amp; clear(char = bkground);    private:    static const char bkground;}\n\n","categories":["Books","C++ primer","C++ 基础"],"tags":["C++"]},{"title":"coding笔记： 树状数组和线段树","url":"/2023/08/05/coding-solution/%E7%BA%BF%E6%AE%B5%E6%A0%91%E5%92%8C%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/","content":"树状数组和线段树\n\n树状数组 核心应用：动态快速地求前缀和 O(logn)\n\n单点修改：在某个位置上加上一个数（修改这个数）\n区间查询：求某一个前缀和\n区间修改：配合差分思想转换为已知问题\n单点修改：配合差分思想转换为已知问题\n\n思考：为什么不直接使用前缀和数组直接查表？\n\n不支持修改操作、或者说修改操作复杂度极高(O(n))\n在所有操作里，如果修改操作多，那么树状数组会很高效\n\n算法思路\n本质是一维数组。\n\n\n\n思考：如何计算x的二进制表示有多少个0？\n\nlowbit(x) = x &amp; -x = 2^k（二进制的最后一位1）\n\nc[x]存的是什么？\n\n存的是：(x-lowbit(x)，x]之和\n\n实现代码\n求前缀和\n\nint res = 0;for(int i=x; i&gt;0;i-=lowbit(x)) res+=c[i];return res;\n\n\n更新\n\nfor(int i=x; i&lt;=n; i+=lowbit(i)) c[i]+=v;\n\n当前结点x的父节点就是x+lowbit(x)\n线段树\n\n线段树操作\n对于维护总和的线段树来说，它有两个操作：\n\n单点修改 **O(logn)**：递归修改所有和x相关的结点，回溯时维护总和\n区间查询 **O(logn)**：不断往下递归，直到递归到目标区间完全包含它（区间或是叶节点）为止\n\n线段树存储：\n和heap是一种存储方式，假设有n个数，最多不超过4n个结点\n当前结点下标是x:\n\n父节点下标为 [x/2] x&gt;&gt;1\n左儿子下标为 2*x  x&lt;&lt;1\n右儿子下标为 2*x+1 x&lt;&lt;1 | 1\n\n核心函数：\n\npushup：用子结点信息更新当前结点信息（可写到其他函数内部）\nbuild：在一段区间上初始化线段树\nmodify：修改\nquery：查询\n\n","categories":["coding"],"tags":["树状数组","线段树"]},{"title":"coding笔记：递归实现指数型枚举","url":"/2023/08/05/coding-solution/%E9%80%92%E5%BD%92/","content":"92. 递归实现指数型枚举从 1∼n 这 n 个整数中随机选取任意多个，输出所有可能的选择方案。\n思路1—二进制表示既然这n个数每一个数既可以选也可以不选，我们就可以用二进制表示来表示每一位选（1）或是不选（0）。\n代码实现\nvoid solu_92_no_rec(){    int n;    cin&gt;&gt;n;    for(int i=0;i&lt;1&lt;&lt;n;i++){        for(int j=1;j&lt;=n;j++){            if(i&gt;&gt;(n-j)&amp;1) printf(\"%d \",j);        }        puts(\"\");    }}\n\n思路2—递归使用深度优先搜索，对每个位置选或是不选进行遍历，递归搜索树如下图：\n\n\n代码实现\nvector&lt;int&gt; vec;void dfs(int n,int l){    if(l==n){        for(auto i : vec){            printf(\"%d \",i);        }        puts(\"\");        return;    }    //select l;    vec.push_back(l+1);    dfs(n,l+1);    vec.pop_back();    //no select    dfs(n,l+1);}void solu_92_with_rec(){    int n;    cin&gt;&gt;n;    dfs(n,0);}\n","categories":["coding"],"tags":["递归"]},{"title":"coding笔记：贪心算法","url":"/2023/08/05/coding-solution/%E8%B4%AA%E5%BF%83/","content":"贪心算法\n证明困难，没有常用的套路\n\n对于区间问题：\n\n左端点排序\n右端点排序\n双关键字排序\n\n\n\n如上图，局部极值不一定是权重最优解，因此只有一个问题是单峰的，才可以用贪心算法来解\n区间选点算法思路\n将每个区间按右端点从小到大排序\n从前往后依次枚举每个区间：\n如果当前区间中已经包含选点，则直接pass\n否则，选择当前区间的右端点\n\n\n\n算法证明\nAns &lt;= Cnt\n\n整个算法流程保证了，选出Cnt个点的方案是合法方案，因此由上面的不等式\n\nAns &gt;= Cnt\n\n选出Cnt个点，实际上是找出了Cnt个不重叠区间，因此选点方案的最小数量至少为Cnt，即Ans&gt;=Cnt\n由上，即可证明Ans==Cnt\n最大不相交区间的数量算法思路做法和上一题完全一样\n算法证明\nAns是最大不相交区间的数量，Cnt是算法选择的点的数量（Cnt个不重叠区间）\n\n\nAns &gt;= Cnt\n\n选出Cnt个点的方案一定是合法方案，所以Ans&gt;=Cnt\n\nAns &lt;= Cnt\n\n反证法：假设Ans&gt;Cnt，意味着我们可以选出比Cnt更多个互不相交区间；由每一个区间至少包含一个我们选择出来的点，那么根据假设我们至少要选出来Ans个点，这与实际我们最少选出Cnt个点相矛盾，因此Ans &lt;= Cnt\n区间分组算法思路\n将所有区间按左端点从小到大排序\n从前往后处理每个区间\n判断能否将其放到某个现有的组中\n不能放入(不存在一个组可以放入)，则开新组，然后再将其放进去；\n可以放入：L[i] &gt; Max_r，将其放进去，并更新当前Max_r\n\n\n\n\n\n算法证明\nAns是相互补充的的区间的组的最小组数，cnt是算法的组数\n\n\nAns &lt;= Cnt\n\n按照算法得到的组数一定是一种合法的方案，而Ans是方案的最小值，因此Ans &lt;= Cnt\n\nAns &gt;= Cnt\n\n算法开新组的条件是该区间与每个组都有交集，因此Cnt其实是最少开的组的数量（不能更少，否则会有交集），因此Ans &gt;= Cnt\n区间覆盖问题算法思路\n将所有区间按照左端点从小到大排序\n从前往后依次枚举每个区间，在所有能覆盖开始点的区间中选择右端点最大的区间，若右端点&gt;end，算法退出\n若能选出，将start更新成右端点最大值\n若找不到满足对应条件的区间，输出-1\n\n\n\n霍夫曼树-合并果子算法思路叶节点到根结点一共有多长，对叶节点就要加多少遍。因此每次挑两个值最小的点相合并，他们深度一定最深，可以互为兄弟。\n算法证明\n深度最深：假设最小的两个点为a,f，那么b,f交换后一定收益为正\n\n\n\n\n可以互为兄弟：a,b,c,d顺序可以交换，不影响全局最优解\n\n合并剩下n-1个果子的最优解一定是合并n个果子的最优解吗？\n即f(n) = f(n-1)+a+b成立吗？\n因为合并果子一定可以先合并最小两个点作为最优解，所以对于所有方案都可以把（a+b）去掉不影响最值，因此原问题就可以变为n-1个点的huffman问题，所以合并剩下n-1个果子的最优解一定是合并n个果子的最优解\n\n\n排序不等式\n可能会爆int，所以用Long Long来做\n\n算法思路按照从小到大的顺序排队，总时间最小\n算法证明调整法\n若不是排好序的，那么一定存在ti&gt;ti+1,若我们将ti和ti+1交换位置，那么交换前比交换后多了ti-ti+1&gt;0，也就是说交换完后总时间就会降低。\n绝对值不等式算法思路按照从小到大排序，取中位数\n算法证明分组法\n\n只要x位于a,b之间，就可以取到最小值。分组后对每一个组都可以取到最小值，同时取即是总共的最小值，即取到正中间即可。\n推公式\n基于不等式来证明贪心问题\n\n算法思路按照wi+si从小到大的顺序排，最大的危险系数一定是最小的\n算法证明只要最优解不是严格从小到大递增的，我们一定可以找到第i个位置上的牛和第i+1位置上的牛他们满足，交换完这两个牛后，我们可以证明，这两个危险系数的最大值一定会严格变小\n","categories":["coding"],"tags":["贪心算法"]},{"title":"华为开发者峰会报告提纲","url":"/2023/08/05/jobs/%E5%8D%8E%E4%B8%BA%E6%8A%A5%E5%91%8A/","content":"华为开发者峰会报告提纲个人介绍（2-3页，1分钟左右）\n\n学校，专业背景\n\n获得奖项（与华为相关的提一下）\n\n参与过的的华为项目，智能基座课程，昇腾方向线上课程，昇腾微认证等（先列一张汇总表，之后会详细讲述）\n\n\n初次认识昇腾AI—学习”西交-华为“智能基座课程（3页，2分钟左右）\n\n在人工智能原理课中，学习昇腾AI的相关知识\n\n\n学习昇腾AI诞生的背景\nAI政策指引：AI核心软硬件成为国家重点战略布局\n硬核科技”受国外制约\n\n\n\n\n\n\n在课程中全面学习了华为昇腾全栈软硬件平台\nAI芯片体系架构: NPU\nAI算子开发语言: CANN\n人工智能编程框架：MindSpore\n\n\n为什么使用昇腾AI？逐渐流行：华为公司研发和力推的MindSpore在学界使用比例逐年增加\n\n\n\n深入了解昇腾AI—基于Atlas 200I DK A2开发板的智能交通应用（4页，3分钟左右）\n\n项目背景和目标\n自动驾驶面临着许多挑战；语义分割技术对自动驾驶的作用；探究如何在华为Atlas 200I DK A2开发板上部署一种高效的交通场景下的语义分割模型，以实现对交通场景的快速、准确的感知和理解。\n\n开发板及语义分割模型介绍\n\nom模型转换及脚本编写\n\n成果评估\n\n\n实际探索昇腾AI—基于Atlas 910服务器的Tensorflow&amp;Pytorch模型迁移（4页，4分钟左右）\n\n项目背景，交付要求\n在NPU芯片上训练开源模型（Twins和BSRN），对标原论文在英伟达GPU上的性能和精度\n\n模型迁移流程\n\n迁移中遇到的问题及解决方法\n\n性能优化及调优工具使用\n\n\n产业应用昇腾AI—基于昇腾算力及CANN的高级辅助驾驶（16页，10分钟左右，选取比赛PPT中的关键内容）\n\n命题分析\n\n\n\n\n指标要求\n为什么使用CANN\n行业背景\n研究基础1\n研究基础2\n整体解决方案\n核心技术1\n核心技术2\n方案效果\n华为验收测试\n华为专家评价\n指导老师\n专家顾问\n社会效益\n教育维度\n\n","categories":["技术分享"],"tags":["华为","报告"]},{"title":"西交智能基座报告讲稿","url":"/2023/08/05/jobs/%E5%8D%8E%E4%B8%BA%E6%8A%A5%E5%91%8A2%E8%AE%B2%E7%A8%BF/","content":"西交智能基座报告讲稿大家好，我是贺浩庭，很高兴能为大家做这次分享。今天我和邹润霖同学会为大家带来昇腾众智开发项目上的心得以及一些技术知识\n首先由我为大家讲第一个部分\n我介绍一下我自己，我专业是软件工程。获得过互联网+国赛银奖，特等学业奖学金，众智模型金质量奖等。在研究生期间，多次参与华为项目，从一开始的成员到后面的负责人，在项目中不断成长。\n我和CANN结缘之路，可以从初始的智能基座课程算起，再到昇腾开发板推理应用开发，再到昇腾众智项目，到最后积累了一定经验，参与互联网+CANN产业赛道，获得国赛银奖的好成绩。\n接下来我讲讲怎么去入门华为的AI应用开发项目，通过什么渠道或是方式去学习。首先是参与CANN训练营，每年CANN都会推出好几期新的训练营系列活动，参与课程并完成小作业可以有效提高我们对AI开发的动手能力。训练营内容是很丰富的，可以满足不同层级的开发者需求。\nCANN训练营提供了丰富了视频课程，这些课程会讲解完成项目开发的一般步骤，十分通俗易懂，比如准备工作中需要数据集上传OBS以及安装pycharm插件modelarts等。课程老师还会实际在编辑器中去演示操作步骤，适合初次入门的同学。\nCANN训练营还提供了课程作业供我们进行练习，实际体验整个项目的开发流程。它还提供了实际案例，比如基于Atlas 200DK的智能小车组装与实现，可以帮助我们快速入门。\n其次可以通过官方文档或者Sample案例，让自己快速了解昇腾各个功能和特性的使用方式，解决遇到的具体问题。比如，通过性能优化的相关文档，大部分模型性能优化的问题都可以解决；通过Sample案例，实际动手完成自己的应用开发。\n最后，如果自己还解决不了的，推荐求助昇腾社区，比如求助于仓库issue或者社区论坛FAQ。可以先尝试搜索issue看有没有相同问题（大概率你会遇到的问题之前也有人遇到过了），如果没有可以自己提交，但是需要注意如何去描述清楚问题，这样也有利于别人帮你去解决。我们要注意提出的Issue标题格式，并描述清楚是什么问题，是功能还是性能还是精度问题，设置训练任务的时候需要勾选Debugger选项，并且提供调试日志。\n【自由讲解范例ISSUE】\n因为有了之前在CANN上的知识和实践积累，我也有能力去参与到昇腾模型众智项目，这个众智项目主要是将开源模型迁移到昇腾平台，丰富昇腾Modelzoo社区。我们一共做过三期模型迁移项目，其中我参与的主要是前两期。\n众智项目主要是如下几个关键步骤，首先是复现论文精度，其次是NPU的功能打通，以及NPU性能和精度调优。在这几个步骤中，大家遇到的问题可能主要在代码修改和性能调优上。接下来我会分享我在项目中遇到的问题，以及我是如何去解决它们的，我还会分享一些模型调优的经验，希望会对大家有所帮助。\n我们一期项目的概况如表格所示，BSRN和SRDRM模型会相对困难一点。在我们完成项目的过程中，每周都会进行工作总结，及时反馈进度。我们的所有项目均在项目交付截至日期前顺利交付，并且一次性通过PR检查，并合入到开源仓库当中。最后我们提交了模型开发交付文档，模型代码，模型训练日志等交付材料。下面是我们的不同项目时期的交付件：\n在GPU复现阶段，我们需要准备数据集，训练代码，编写训练脚本，训练打屏日志，训练模型权重ckpt以及复现README文件，NPU代码打通阶段需要迁移后的代码，requirements.txt依赖文件，编写NPU训练脚本以及readme文件。PB转OM阶段需要我们提供PB固化代码，推理应用开发阶段需要我们提供推理应用代码。\n那么编写什么样的训练脚本，如何去编写它呢？我们需要在test目录下建立两个脚本，train_full_1p.sh进行完整的训练，得到的是训练的精度结果，而train_performance_1p只进行一个epoch的训练，目的是测试NPU的训练性能。\n编写训练脚本时，为了对日志文件进行处理，我们需要掌握linux 常用的shell命令。这里我简单列了一些常用的。\n【自由讲解shell命令】\n在一期中， 我做的第一个迁移任务是tensorflow模型迁移。这个模型有两个大难点。第一个是训练周期极长，一次训练大概要一周时间，很耽误任务进度，对调试影响也很大，因为得到训练指标数据真的很慢。我记得当时训练的时候还要等待代金券的审批，这个也很麻烦。第二个难点，因为它是图像超分辨模型，所以该模型支持动态shape，也就是说它支持不同大小图片同时作为输入。这个应该是算子的问题，而且训练时也没有任何报错，只是训练卡住了，我记得之前我们在这个问题上卡了很久，不知道出了什么问题。提了issue之后，华为工程师在算子上面修复了这个bug，我们才真正解决这个问题。\n我们的二期一共做了4个项目，分别将图像分类的Twins-PCPVT和ConvNext，实现语义分割的EfficientPS，以及姿态估计的centroids-reid网络迁移到了华为NPU上。如表格所示我们成功在交付日期前完成了所有的开发流程，且完成质量较高，右边是我们的开发成员以及分工情况。\n在二期中，我参与的是TwinsPCPVT的模型迁移，在这个项目的代码修改中，我们遇到了torch版本问题，以及第三方库合并问题。amp在1.6之后才内置于pytorch，所以只能用原生apex库进行代替；timm库一些接口默认使用的是cuda，而不是npu接口。所以还需要修改第三方库的源代码，并把它们的源码加入仓库。\n性能调优上，遇到了NPU上性能比GPU差的问题。我使用了如下几个调优方法：第一个是使用NPU版本的优化器FusedAdam代替原来的adam优化器。第二个是，如果你增大batchsize的话，一定要同比例地增加学习率，这里还需要注意多卡的因素。学习率对训练的影响比较大，是很重要的参数。第三个是使用NPU亲和函数代替原生函数。最后给大家讲一个小技巧，可以同时在pytorch和npu上同时使用profilling工具进行性能测试，它会可视化的显示耗时大的算子，一对比你就可以发现究竟是哪个算子导致了NPU上的性能下降。\n第三期模型迁移项目与前几期所不同的是，我们需要额外增加一个迁移步骤：AI框架迁移，把pytorch或是tensorflow的模型转换为mindspore下的模型。右图是pytorch与mindspore同一类型算子的对照API。三期模型的难点在于需要重构模型代码，将模型框架替换为mindspore框架，这个代码量还是比较大的。另外如果模型使用了第三方timm库，我们也需要对其源代码进行分析解构，使用MindsporeAPI进行重建。还有一个更难以解决的问题为如果原模型对应的某个API，在MindSpore没有对应的支持接口，我们需要使用目前MindSpore已有的原子算子接口来编写该新算子。比如tensorflow有一个embeddinglookup_sparse函数实现稀疏矩阵的embeddinglookup操作，mindspore没有相同功能的函数，我们就得把这个算子拆解成不同功能用有的方法重新写一下这个算子\n通过参与这些项目我也获得了很多奖项，比如昇腾众智开发者，昇腾众智金质量奖等。我还获得了2022年度昇腾社区优秀开发者的称号并在2023年昇腾开发者峰会发表主题演讲。我们还将CANN平台使用的经验和优势应用在了互联网+华为命题产业赛道当中，并取得了省赛金奖，国赛银奖的好成绩，接下来有请邹润霖同学介绍昇腾Atlas开发版的推理应用开发。\n","categories":["技术分享"],"tags":["华为","报告"]},{"title":"华为开发者峰会报告讲稿","url":"/2023/08/05/jobs/%E5%8D%8E%E4%B8%BA%E6%8A%A5%E5%91%8A%E8%AE%B2%E7%A8%BF/","content":"华为开发者峰会报告讲稿个人介绍（2-3页，1分钟左右）\n大家好，我是来自西安交通大学的贺浩庭，很高兴能为大家做这次分享。我将讲解我和CANN结缘的4个故事，从初始的智能基座课程，到通过华为开发板深入了解推理应用开发，再到昇腾众智项目中进行模型迁移，到最后积累了一定经验，使用CANN平台进行模型训练和推理，并参与互联网+产业赛道。接下来，我将对这4个方面一一进行讲解。首先我介绍一下我自己，我来自西安交通大学，专业是软件工程。获得过互联网+国赛银奖，特等学业奖学金，众智模型金质量奖等。在研究生期间，多次参与华为项目，从一开始的成员到后面的负责人，在项目中不断成长。\n首先，在课程学习方面，我多次参与了华为智能基座课程，比如人工智能原理，深度学习，以及昇腾方向线上课程，计算机视觉与机器学习，在这个过程中一方面夯实了自己在AI领域的基础知识，另一方面为我将来参与华为项目进行实践打下了坚实的基础。 其次是项目实践，我们完成了基于Atlas 200DK开发板的交通场景语义分割项目，以及基于Atlas 800服务器的Pytorch&amp;Tensorflow模型迁移项目，这里只是先提一下,之后会详细去讲。最后是参与互联网+产业赛道，我们取得了国赛银奖的好成绩，之后也会详细讲述。\n初次认识昇腾AI—学习”西交-华为“智能基座课程（3页，2分钟左右）\n\n在人工智能原理课中，学习昇腾AI的相关知识\n\n初次认识昇腾AI首先得从智能基座课程开始讲起，我们在课上学到，人工智能相关技术逐步成为“事关国家安全和发展全局的基础核心领域”。比如，4月份openai发布的gpt4成功地让人工智能走进了大众视野。基于chatgpt的autogpt仅仅在上线两周内，其star数便超过了已经发布4，5年的pytorch等仓库。 而昇腾CANN即是在这种大背景下蓬勃发展的。\n目前国内在算法应用层“枝繁叶茂”。目前数据集海量，应用场景也很丰富，算法顶会论文逐渐增多，部分算法模型处于世界前沿。但是计算系统层“根基薄弱”，也就是说底层“硬核科技”原创贡献少，如此一来核心系统和芯片易受国外制约，使得我国智能产业成为空中楼阁。在这种情况之下，华为从底层的芯片研发出发，再到计算架构层CANN，最后到AI框架Mindspore，推出了昇腾AI全栈软硬件平台。\n首先是CANN统一异构计算架构，它可以降低硬件适配难度，并通过软硬件协同优化，实现高性能算子，提升模型运行性能，释放底层芯片的算力。昇腾910芯片是聚焦AI特定领域的处理器，强调计算性能，而不是通用性。\n深入了解昇腾AI—基于Atlas 200 DK 开发板的智能交通应用（4页，3分钟左右）\n接下来，有了开发AI应用知识上的储备，我们通过一个小项目：基于Atlas 200 DK 开发板的智能交通应用来进行实践和深入了解。我简要讲一下这个项目。自动驾驶在近年来取得了丰硕的成果，并有望在不远的未来大规模商业化。然而，在现实应用中，自动驾驶仍然面临许多挑战，如路面标志、行人、车辆、障碍物等的识别和理解。语义分割技术可以帮助自动驾驶车辆实现对复杂场景的感知和理解，从而为车辆的自主行驶提供更加全面和精准的支持。\n因此，我们团队在华为Atlas 200 DK开发板上部署一种交通场景下的语义分割模型，并期望达到以下效果：在算力有限的移动设备上部署语义分割模型，并验证部署的语义分割模型的实用性与可行性。\n先简单介绍一下Atlas 200 DK 开发板。Atlas 200 DK 开发板广泛应用于智能安防、智能交通等领域，可以提供强大的AI算法支持，帮助企业快速实现AI技术落地。并且其硬件接口丰富，如以太网口，HDMI接口等。而且昇腾社区算法模型极其丰富，支持不同领域的SOTA模型；而且应用广泛，可以部署在摄像头、无人机和机器人等设备上。其上手也相对轻松，只需30分钟即可配好环境。接下来我讲讲怎么去入门AI应用开发，通过什么渠道或是方式去学习。\n首先是参与CANN训练营，每年CANN都会推出好几期新的训练营系列活动，参与课程并完成小作业可以有效提高我们对AI开发的动手能力。首先训练营内容是很丰富的，而且针对不同层级的开发者也有不同的内容。其次是参与昇腾众智计划，华为与多个高校在AI领域合作，我们可以参与适合的众智项目，进一步锻炼自己在调模型参数，模型debug，训练性能优化等方面的能力，一定程度上也有利于自己在科研或者未来工作中去优化自己的模型。如果在做项目的过程中，遇到了难以解决的问题，首先推荐去查阅官方文档，之前在modelzoo仓库的wiki页面有着模型训练迁移，性能优化的丰富文档，大部分问题都可以解决。推理应用开发也推荐看官网的指导手册，内容比较详细且有利于上手。最后，如果自己能力不足，查阅资料和搜索引擎也无法解决，推荐求助昇腾社区，项目中可以求助于仓库issue，可以先搜索issue看有没有人遇到过相同问题（大概率你会遇到的问题之前也有人遇到过了），或是去看社区论坛FAQ，没找到的话发一个求助帖，但是需要注意如何去提一个好问题，这样也有利于别人帮你去解决。最后，如果参与众智项目的话，一般会有项目接口人，积极与华为接口人沟通推进进度，而不是等待他们主动联系你。\n接下来回归正题，继续讲我们的项目。我们使用的模型是PIDNet，它是一种三分支网络架构。三个分支来分别解析细节、上下文和边界信息；并使用边界注意力机制来指导细节和上下文分支的融合。具体的细节如果有兴趣的话可以去看原论文。之后就是编写推理脚本了，如果你之前参与过训练营或者看过开发指导文档，这个推理脚本会很好写，这里就不多做赘述了。接下来是一个结果展示，证明在在算力有限的移动设备上部署语义分割模型是实用且可行的。\n实际探索昇腾AI—基于Atlas 800服务器的Tensorflow&amp;Pytorch模型迁移（4页，4分钟左右）\n因为有了之前在CANN上的知识和实践积累，我们也有能力去承接众智项目。我一共做过两期模型迁移项目，所以对这个项目还是了解比较深入的，接下来我会分享我在项目中遇到的问题，以及我是如何去解决它们的，我还会分享一些模型调优的经验，希望会对大家有所帮助。\n首先我简单介绍一下这个项目是在做什么。我们的核心任务是在华为NPU芯片上训练和推理开源模型，对标原论文在GPU上的性能和精度。指标有两个方面的要求，第一个是GPU复现的精度要达到原论文的99%以上。这个有时候就很难达到，我跑过很多代码，参数什么的都没改，但就是达不到原文的精度。这个确认不是训练问题并且实在没办法的话，可以把问题反映给华为接口人，因为不是我们训练的问题，而是原论文代码的问题，所以交由华为专家评审判定即可。第二个是NPU迁移，模型在NPU上的精度需要达到GPU的99%以上，才视为精度达标；性能上，在NPU8卡的性能也必须高于GPU8卡的性能。\n接下来我介绍一下整体的项目流程，大家可以宏观上了解这个项目究竟是在做什么。首先是GPU精度要达到原论文精度，并且如果原论文不支持混合精度和分布式训练的话，我们需要对源代码进行修改以支持它们。这个修改方法官网文档里有详细步骤。其次是NPU的功能打通，即模型能够在NPU上正常训练和推理。这里主要是修改原生pytorch的接口，使其支持NPU芯片。接下来如果训练性能出现了问题，会从以下几个方面考虑是哪里出了问题。比如说算子瓶颈，或是框架瓶颈亦或是编译瓶颈。一般来说主要是算子的问题。如果GPU精度正常，但是迁移到NPU之后，发现精度不达标，会从以下角度去考虑：比如说模型计算错误，loss计算错误等等。发现NPU在精度的bug其实很难，很考验一个人debug能力。\n我做的第一个迁移任务是tensorflow模型迁移。这个模型有两个大难点。第一个是训练周期极长，一次训练大概要一周时间，很耽误任务进度，对调试影响也很大，因为得到训练指标数据真的很慢。我记得当时训练的时候还要等待代金券的审批，这个也很麻烦。第二个难点，因为它是图像超分辨模型，所以该模型支持动态shape，也就是说它支持不同大小图片同时作为输入。这个应该是算子的问题，而且训练时也没有任何报错，只是训练卡住了，我记得之前我们在这个问题上卡了很久，不知道出了什么问题。之后算子上面修复了这个bug，我们才真正解决这个问题。\n我做的第二个迁移任务是pytorch模型迁移。在这个项目中因为一开始NPU只支持pytorch1.5，而这个原仓是pytorch1.8的，一些torch1.8的接口在在1.5是没有的。比如说，amp在1.6之后才内置于pytorch。所以只能用原生apex库代替。再比如说，原代码使用了timm库一些接口。但是这些接口默认使用的是cuda，而不是npu接口。所以还需要修改第三方库的源代码，还是比较麻烦的。之后我也有关注，发现NPU支持pytorch1.8之后，又需要将已迁移的代码升级到pytorch1.8，但是这个修改还是相对容易的。在这个项目中，我也遇到了性能方面的问题，接下来会介绍我使用过的一些性能调优的方法。第一个是使用NPU版本的优化器FusedAdam代替原来的adam优化器。然后是关键，如果你增大batchsize 的话，一定要同比例地增加学习率，这里还需要注意多卡的因素。学习率对训练的影响比较大，是很重要的参数。最后给大家讲一个小技巧，可以同时在 pytorch和npu上同时使用profilling工具进行性能测试，它会可视化的显示耗时大的算子，一对比你就可以发现究竟是哪个算子导致了NPU上的性能下降。\n通过参与这些项目也获得了很多奖项，比如昇腾众智开发者，昇腾众智金质量奖等。\n产业应用昇腾AI—基于昇腾算力及CANN的高级辅助驾驶（16页，10分钟左右，选取比赛PPT中的关键内容）\n因为之前我们在CANN技术栈上进行了多次项目开发，对于在CANN上模型的训练和推理我们团队也更加熟练，所以我们将在CANN上的经验和优势应用到互联网+产业赛道中。我们将课题组在智能交通领域科研成果在华为CANN架构上进行应用，并取得了不错的性能优势。接下来我介绍一下我们的比赛项目。\n首先我先讲一下项目背景。早在2019年华为就已经开始在智能车行业开展战略布局，其中，华为的ADS布局，全称为自动驾驶解决方案，就是针对智能车辅助驾驶方面的。华为目前在该领域进行了深入探索，但仍面临着许多卡脖子的技术难题。\n因此华为作为命题企业，希望我们能够利用昇腾人工智能软硬件技术，在自动驾驶领域攻克算法关键性难题，同时赋能昇腾平台，拓展华为社区生态。在研发过程中，我们团队基于CANN提出了针对自动驾驶的一种新的解决方案。我们在CANN计算架构之上，将昇腾强大的算力与我们创新设计的算法相结合。\n在自动驾驶领域，无人车的安全性非常依赖视觉识别算法对道路场景元素的精确感知和检测，只有准确且及时地检测车辆以及行人等元素，才能最大程度地避免事故的发生。而算法所搭载系统的实时性较差、检测精准度较低也是如今自动驾驶行业的痛点问题。因此华为在指标上对于算法计算速度和精确度有着极高的要求，例如对于车辆行为识别，我们需要保证推理速度（fps）大于85帧/秒，检测精度大于87.25%。\nCANN 使得我们能够基于昇腾平台快速构建自己的应用。CANN作为桥梁，能使得上层AI框架能够在底层NPU上高效运行。同时它的强大算力，使得我们的模型性能更加强大。\n我们团队所在的实验室积累了相当多的辅助驾驶方向的技术成果：首先，我们有来自中科院计算所等单位百万级的数据集作为算法的训练和测试数据集；其次，我们所在的实验室具有数百篇高水平计算机视觉论文及多项国家科技奖作为技术支持；另外，我们有智能交通领域的多项专利获得授权。\n在整体解决方案中，我们以车辆行为识别和轨迹预测作为我们的高级辅助驾驶的关键技术。 依托于华为的昇腾CANN计算架构，我们将设计的AI算法，应用到华为的ADS辅助驾驶系统中，把创新设计的算法与强大算力的CANN计算架构相结合。\n接下来我简要介绍一下我们的技术。我们使用多流3DCNN的网络进行车辆行为识别，如左图所示，我们的识别精度极高，高达99%，可用于工业界落地。我们其次使用结合StrongSORT进行车辆目标跟踪，得到车辆轨迹后，使用Traffic-STGCNN对其未来轨迹预测，预测未来轨迹也能确保安全性。通过这两个技术，我们能够构建范围更大，更安全的高级辅助驾驶系统。\n在3DCNN SELayer网络在中，我们对真实的道路图像进行处理，生成光流信息和边缘检测信息，将它们一起作为输入，送入到3DCNN SELayer网络中，通过加入三维感受野增强和特征融合模块，模型能够快速精确的得出各个车辆的行为类别。\n三维感受野增强采用多分支卷积结构，并使用空洞卷积也就是扩张卷积来增大感受野，在充分利用视频中的时空信息的基础上增强特征的判别能力和鲁棒性。\n因为我们有多个模态的输入，所以需要充分融合多模态特征，为此，我们提出了通道注意力特征融合模块，对通道信息进行充分融合，实现了跨通道交互，增加特征中重要通道的权值，抑制无用通道的权值，并且增加非线性特征，提高特征表达能力。\n由表格可以看出，我们的算法具有模型小，精度高，速度快、计算少的特点。我们的模型精度高达92.46%，而大小仅仅只有14.8Mb，推理速度极快，尤其将它与华为昇腾CANN相结合后，每秒能处理94.27张图像。\n该图是我们的可视化演示结果，可以看出我们识别和预测的精度是很高的。\n在华为给出的模型测试报告上：通过在华为Atlas800上进行测试，我们模型的训练性能提升12%，推理性能提升10%，远优于现有方法，满足了命题企业答题指标要求。我们的算法也获得了华为公司权威专家的高度认可。项目在昇腾算力及CANN平台的架构下进行开发，设计的模型在NPU上进行了训练和推理，能够有效降低预测和识别的系统时延，具有较高的技术难度，解决了当前辅助驾驶系统中存在的难点问题。\n团队成员在实践方面，10余名学生在参与产业赛道命题的过程中，完成华为众智项目，项目交付质量较高，华为官方授予所有团队成员昇腾众智金质量奖。在创新方面，2022年4月以来，团队在参与产业赛道命题过程中，共10余名本硕博学生，投稿“三类高质量”论文8篇、申请发明专利5项。\n我的分享到此结束，谢谢大家聆听\n","categories":["技术分享"],"tags":["华为","报告"]},{"title":"计网复习笔记","url":"/2023/08/05/jobs/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","content":"计算机网络从键入网址到网页显示，期间发生了什么？url 解析\n\n生成HTTP消息\n\n真实地址查询查询服务器域名对应的 IP 地址\n专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器\n域名解析工作流程：\n\n客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。\n本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。\n根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”\n本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”\n顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。\n本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。\n权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。\n本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。\n\n至此，我们完成了 DNS 的解析过程。\n\n\n指南好帮手 —— 协议栈DNS获取IP后，就可以把HTTP的传输工作交给操作系统中的协议栈\n\n\n应用程序调研socket库委托协议栈工作。协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。\n此外 IP 中还包括 ICMP 协议和 ARP 协议。\n\nICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。\nARP 用于根据 IP 地址查询相应的以太网 MAC 地址。\n\nIP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。\nTCP可靠传输TCP报文格式\n\n\n序号：解决乱序问题\n\n确认序列：解决丢包问题\n\n状态位：例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n\n窗口大小：为了进行流量控制，声明一个窗口，标识自己当前的处理能力\n\n\nTCP建立连接双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化如图：\n\n\n\n一开始双方状态均为close\n服务器先监听某个端口，处于listen状态\n客户端主动发起连接，发送SYN包，处于syn_sent态\n服务器收到SYN包后，发送SYN+ACK包，表明收到了数据包，处于syn_rcvd态\n客户端收到服务器的ACK包后，发送ACK包到服务器，处于established态（因为它一发一收成功了）\n服务器收到ACK的ACK包后，处于established态（因为它一发一收成功了）\n\n所以三次握手目的是保证双方都有发送和接收的能力。\nTCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。\nTCP分割数据如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据以MSS为单元，拆解成一块块的数据发送，而不是一次性发送所有数据。\n\n\n\nMTU：一个网络包的最大长度，以太网中一般为 1500 字节。\nMSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。\n\nIP远程定位IP报文格式\n\n假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？\n需要根据路由表规则，来判断哪一个网卡作为源地址 IP。\n在 Linux 操作系统，我们可以使用 route -n 命令查看当前系统的路由表。\n\n\n第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\n\n\nMAC两点传输MAC包头格式\n\n需要发送方和接收方的MAC地址，协议类型在TCP/IP通信里一般为：\n\n0800：IP\n0806：ARP\n\n发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。\nARP协议获取接收方MAC地址\n\n操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用。在发包时：\n\n先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。\n而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。\n\n在 Linux 系统中，我们可以使用 arp -a 命令来查看 ARP 缓存的内容。\n出口—网卡我们需要将数字信息转化为电信号，才能在网线上传输。负责这一操作的正是网卡，控制网卡还需要网卡驱动程序。网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列（FCS）。\n\n\n送别者—交换机交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。和网卡不同，交换机的端口不具有 MAC 地址\n将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n\n一个是设备的 MAC 地址，\n另一个是该设备连接在交换机的哪个端口上。\n\n\n\n地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。\n此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。\n以下两个属于广播地址：\n\nMAC 地址中的 FF:FF:FF:FF:FF:FF\nIP 地址中的 255.255.255.255\n\n处境大门—路由器这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。\n不过在具体的操作过程上，路由器和交换机是有区别的。\n\n因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；\n而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。\n\n路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。\n当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。\n路由器包接收\n\n进行错误校验\n如果没问题，检查MAC头部的接收方MAC地址，如果是发给自己的包就放到接受缓冲区，否则丢弃\n\n查询路由表确定输出端口\nMAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。\n查询路由表判断转发目标：\n\n\n路由器包发送\n接下来就会进入包的发送操作。\n我们需要根据路由表的网关列判断对方的地址。\n\n如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。\n如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。\n\n知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。\n抵达服务器扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。\nHTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。\n最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。\nLinux系统是如何收发包的？Linux接收网络包的过程当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。\n如何告诉操作系统这个网络包已到达？\n\n触发中断，每当网卡收到一个网络包后，就触发一个中断告诉操作系统\nLinux 内核在 2.6 版本中引入了 NAPI 机制。它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据。\n\n因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。\n硬件中断处理函数会做如下的事情：\n\n需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。\n接着，发起「软中断」，然后恢复刚才屏蔽的中断。\n\n至此，硬件中断处理函数的工作就已经完成。\n硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。\n软中断如何处理？\n内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。\nksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。\n网络协议栈做了哪些工作？\n\n首先，会先进入到网络接口层，进行包校验，若有误则丢弃\n\n到网络层后，取出IP包，根据目标IP地址判断是发到上层还是进行转发。确定发到本机后，从IP头中看上层协议类型是UDP还是TCP，然后去掉IP头，交给上层处理。\n\n到传输层后，取出TCP头或UDP头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。\n\n最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。\n\n\n\n\nLinux 发送网络包的流程首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。\n如果使用的是 TCP 传输协议发送数据，那么先拷贝一个新的 sk_buff 副本 ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。\n而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。\n接着，对 sk_buff 填充 TCP 头。这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。\n你可能会好奇，为什么全部数据包只用一个结构体来描述呢？\n协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。\n于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 data 的指针，比如：\n\n\n然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。\n网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。\n这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。\n当数据发送完成以后，其实工作并没有结束，因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。\n最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。\nHTTP 常见面试题HTTP基本概念是什么是超文本传输协议。使用计算机能够理解的语言确立了一种两台计算机之间交流通信（传输文字，图片，音频等）的规范，以及各种控制和错误处理方式。\n状态码\n\n\n3xx\n\n301：永久重定向\n302：暂时重定向\n\n301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。\n\n4xx\n\n400：请求报文错误\n403：服务器禁止访问资源\n404：请求的资源在服务器未找到\n\n\n5xx\n\n500：服务器通用错误\n501：客户端请求的功能还不支持\n502：通常是服务器作为网关或代理时返回的错误码\n503：服务器当前很忙，暂时无法访问\n\n\n\n常见字段\nHost：指定服务器域名\n\nContent-Length：表明本次返回的数据长度\n\n通过设置回车符、换行符作为HTTP header的边界\n通过Content-Length作为HTTP body的边界\n\n\nConnection：Keep-Alive用于客户端要求服务器使用【HTTP长连接】机制，以便其他请求复用\n\nContent-Type：本次数据的格式，Content-Type: text/html; Charset=utf-8\n\nContent-Encoding：说明数据的压缩方法（压缩格式），Content-Encoding: gzip\n\n\nGET与POSTGET与POST的区别\nGET：从服务器获取指定的资源\nPOST：根据请求报文对指定的资源做出处理\n\n安全和幂等\n安全：请求方法不会破坏服务器上的资源\n\n幂等：多次执行相同的操作，结果都是相同的\n\nGET方法是安全且幂等的，因此可以对GET请求的数据做缓存\n\nPOST方法是不安全且不幂等的，‘多次提交创建多个资源，且有可能会修改服务器上的资源’\n\nHTTP传输的内容都是明文的，要避免被窃取，可以使用HTTPS协议\n\n\nHTTP缓存计术强制缓存只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，如下图就是使用了强制缓存：\n\n\n如何实现？\n根据HTTP响应头部字段实现的，它们都用来表示资源在客户端缓存的有效期：\n\nCache-Control：相对时间\nExpires：绝对时间\n\n浏览器再次访问服务器中该资源时，会通过请求资源的时间与Cache-Control中设置的过期时间大小，来计算出该资源是否过期。服务器再次收到请求后，会再次更新Response头部的Cache-Control。\n协商缓存通过服务器告知客户端是否可以使用缓存的方式被称为协商缓存。返回的响应码是 304\n如何实现？\n第一种，基于请求头部中的If-Modified-Since与响应头部中的Last-Modified字段实现：\n\nLast-Modified：响应资源的最后修改时间\nIf-Modified-Since：当资源过期，发现响应头部有Last-Modified声明，则再次发起请求的时候带上Last-Modified时间，服务器收到请求后，发现有If-Modified-Since，则与被请求资源的最后修改时间进行比较，如果改过，则返回最新资源，HTTP 200 OK，否则返回HTTP 304。\n\n注意，协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。\n当使用 ETag 字段实现的协商缓存的过程：\n\n当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；\n\n当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：\n\n如果没有过期，则直接使用本地缓存；\n如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；\n\n\n服务器再次收到请求后，\n会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：\n\n如果值相等，则返回 304 Not Modified，不会返回资源；\n如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；\n\n\n如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。\n\n\nHTTP特性\n简单\n\n报文格式就是简单的header+body的格式，简单且易于理解\n\n灵活和易于扩展\n\nHTTP协议里的各类请求方法、URI、状态码、头字段等各个组成要求都没有固定死，允许开发者自定义和扩充\n其下层也可以随意变化：\n如https就是在HTTP与TCP之间增加了SSL安全传输层\nHTTP3.0改用了UDP协议\n\n应用广泛和跨平台\n\nHTTP/1.1的缺点？\n无状态双刃剑\n\n好处：\n服务器不会去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，可以有效减轻服务器的负担\n坏处：\n在完成有关联性的操作时会非常麻烦\n如何解决无状态的问题？\n使用cookie技术：在请求和响应报文中写入cookie信息来控制客户端的状态。\n\n\n\n\n２.　明文传输双刃剑\n通信使用明文，可能会被窃听\nHTTP的性能如何？\n长连接\n\n早期HTTP每发起一个请求都要新建一次TCP连接（三次握手），而且是串行请求，做了无谓的TCP连接和断开。因此，HTTP1.1提出了长连接的通信方式，也叫持久连接\n\n\n\n管道网络传输\n\n即在同一个TCP连接里，客户端可以发起多个请求，减少整体响应时间。\n\n\nHTTP1.1管道解决了请求的队头堵塞，但没有解决响应的队头堵塞。\n\n队头堵塞\n\n\n\nHTTP与HTTPS两者的区别\nHTTPS加入了SSL安全协议，使得报文可以加密传输\nHTTPS建立连接时，还需要SSL握手过程\nHTTP默认端口是80，HTTPS的默认端口是443\n需要向CA申请数字证书，来保证服务器的身份是可信的\n\nHTTPS解决了HTTP的哪些问题？HTTP存在：\n\n窃听风险\n篡改风险\n冒充风险\n\nHTTPS可以：\n\n信息加密：使用混和加密的方式来保密\n检验机制：使用摘要算法来实现完整性\n身份证书：将服务器公钥放入到数字证书中，解决了冒充的风险\n\n\n混合加密\n\nHTTPS采用对称加密和非对称加密结合的“混合加密”。\n\n在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。\n在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。\n\n采用「混合加密」的方式的原因：\n\n对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。\n非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。\n\n\n摘要算法+数字签名\n\n使用摘要算法计算出内容的哈希值（唯一）\n\n\n缺点：只能保证内容不会被篡改，但不能保证内容+哈希不会被中间人替换\n非对称加密算法：\n\n公钥加密，私钥解密：为了保证内容传输的安全，只有持有私钥的人才能解密出实际的内容\n私钥加密，公钥解密：为了保证消息不会被冒充，如果公钥可以解密，说明这个消息是持有私钥的人发的\n\n非对称加密的主要用途：通过「私钥加密，公钥解密」的方式，来确认消息的身份。数字签名算法用的就是这种方式，不过私钥加密的不是内容，而是内容的哈希值。\n私钥由服务器保管，然后服务器会向客户端颁发对应的公钥，如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。\n\n数字证书\n\n\n可以通过哈希算法来保证消息的完整性；\n可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；\n\n还缺少身份验证的环节，万一公钥是被伪造的呢（公钥可能被替换成坏人的公钥）？\n把公钥注册到数字证书认证机构CA，他们会用自己的私钥对公钥做一个数字签名，最终将【个人信息，公钥，数字签名】打包一个数字证书。服务端用自己的私钥签名后，还会把数字证书给客户端。客户端会通过CA判断是否可信。\nHTTPS是如何建立连接的？期间交互了什么？SSL/TLS协议基本流程:\n\n客户端向服务器索要并验证服务器的公钥\n双方协商产生会话密钥\n双方采用会话密钥进行加密通信\n\nTLS握手阶段涉及4次通信，若采用RSA密钥交换算法：\n\n\n\n客户端校验数字证书的流程是怎样的？\n\n\n\n为什么要使用证书链？\n这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。\nHTTPS中的应用数据是如何保证完整性的？TLS 在实现上分为握手协议和记录协议两层：\n\n握手协议：负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）\n记录协议：TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；\n\n\n\n\n分片\n压缩\n计算 MAC 值（消息验证码）\n加密\n\n","categories":["计算机网络"],"tags":["计网","笔记"]},{"title":"健身入门","url":"/2023/08/05/life-sharing/exersice/","content":"健身入门动作模式\n动作模式有哪些？\n\n\n\n胸的主要动作模式推胸\n\n夹胸\n\n背的主要动作模式划船\n\n下拉\n\n\n\n肱三头肌的动作模式臂屈伸\n肩关节伸\n划船可以练到\n\n肱二头肌的动作模式弯举\n\n肩前束的动作模式推举\n\n\n\n前平举\n\n肩中束的动作模式推举推举也有肩中束参与\n侧平举\n\n提拉\n\n肩后束的动作模式反向飞鸟、上背划船\n\n\n上背划船效果远大于下背\n\n股四头肌的动作模式膝关节伸\n\n股二头肌的动作模式膝关节屈\n\n髋关节伸\n\n膝关节屈和髋关节伸的比例\n\n臀肌的动作模式\n用硬拉练股二即可\n\n\n\n腹肌的动作模式卷腹、举腿\n\n\n\n\n\n总结\n\n训练计划三分化训练计划\n\n组间休息：胸背腿3min， 肩手2min\n四分化训练计划\n\n\n\n训练频率每周练5次\n\n\n训练时长\n部位：2-3个\n时长：1-1.5h\n组数：9+6+6\n不算热身+拉伸\n\n\n\n不同目的，不同配重\n\n\n重复做8次是合适的\n\n","categories":["健身"],"tags":["生活","健身"]},{"title":"闲散小记","url":"/2023/08/05/life-sharing/%E9%9A%8F%E8%AE%B001/","content":"闲散小记最近两周情绪一直处在一个内耗和低迷的状态，整个人感觉就像迷失了自己一般浑浑噩噩，因此算法上的学习和科研的进展甚至锻炼身体都有所荒废和懈怠。每每夜晚最是难熬，不知不觉通过游戏和动漫去麻痹自己的内心，经常熬到困累到拿不稳手机才睡。之前从没想到自己居然已经默许了这种将早上的时间浪费，直到中午才开始做事的颓废生活。\n直到在知乎上读到相同境遇的人的亲身经历，直到微信上看到连叔对小姑娘关于朋友问题的回信，我才发现自己很久都没有关注过自己了，内心上明明已经疲惫到觉得生活了无生趣，自己却没有注意到自己已然身处危险边缘。也许只需一步，就有可能跌落深渊，酿成难以挽回的遗憾。\n于是，我在内心里叩问自己：“为什么我要在感情上轻视自己？为什么我不敢去主导自己、去引领朋友？为什么要嫉妒、绑架、干涉别人？” 。结论就是我太弱小了，我没有“以我为主”，只有自己在身体和心理上强大起来，只有自己在工作和学习上强大起来，只有自己在维持一段感情的时候保持昂扬、积极、上升的态度，才能将主动权抓到自己手上，才能做到不后悔、不内耗，才能吸引到我想要的东西，包括友情和爱情。\n以连叔的最后一句话来勉励自己：“真正的朋友，是倾听者、安慰者、欣赏者、引领者。我们只有成为这样的人，才能成为别人真正的朋友。”\n","categories":["随记"],"tags":["生活","日记"]},{"title":"2023.4.26入舰苏醒日—目标锚定","url":"/2023/08/05/life-sharing/%E7%9B%AE%E6%A0%87balance/","content":"2023.4.26入舰苏醒日—目标锚定—follow your heartmotivation今天已经是2023年.4.26日，是我记忆苏醒登上舰的日子。我发现我还要好多目标没有实现，有着或多或少的杂事琐事牵绊住了自己的脚步，有些不必要的事情的确应该舍弃了，分清主次，轻装上阵，方能游刃有余，拔得头筹。\n任务列表\n蓝桥杯国赛，6月10日\nPA作业-实现全系统模拟器，6月前做完\nMIT6.S081和CSAPP学习，5+6月搞完\n论文进展，5月中旬写完初稿，6月初完善并投稿\n准备考托雅，预计7月份考，5+6月准备\n引体从0到1\n\n固化时间\n明确，只有以下事情对我是真正重要的，其他的杂事都是”次要的“\n\n\n锻炼\n每天1小时，7点~8点\n\n刷题（蓝桥杯，蓝桥结束后分时间给托雅）\n对我来说，机械式的做题让我很不爽，重复做自己会做的题只是在浪费时间，每天2小时+每日一题0.5小时\n下午2点~4半点\n晚上6点半~7点半\n\n课程学习（MIT6.S081和CSAPP）\n每天两个小时（今天看MIT，明天看CSAPP轮流）\n上午9 点~11点半\n\n科研（论文实验进度）\n下午4点半到5点半\n晚上7点半~9点（主做科研）\n\n项目（PA项目）\n下午4点半到5点半\n晚上7点半~9点（跑实验等待时做PA）\n\n\n几点反思\n是否不会太过严格，不人性化，是否我丧失了我个人的娱乐和生活？\n严格但是这些都是我想做的，首先如果我不去做，那我必定会后悔。如果我不去学习MIT课程，我怎么对得起leader对我的信任，如果我不去做PA项目，我又如何证明我自己的能力？我去参加算法竞赛，刷题也是为了证明自己的代码能力，至少自己努力过，不后悔就行。但也不单单是证明自己的代码能力过硬，我刷题是也是因为我喜欢做算法题。但是求职把它变成了应试这一点让我很反感，好像说它是我必须完成的任务一样，我一天必须要做多少题，这真的有意义吗？我宁愿在”质“，也不愿在“量”。我宁愿为一道好题花费一整个下午的时间，也不愿做多道烂题。即便面试，笔试中遇到自己见过的题又如何，我觉得这只是应试，没有一点实际意义。科研也是我必须去做的，一方面是为了毕业，一方面是为了去实习，满足导师的要求。\n\n游戏（love）更重要，还是工作（study）更重要呢？\n都重要，但是要明白现在此时此刻，你更偏向于什么，去做你最不后悔的事就行\n\n我为什么要这么努力，我是为了什么，是为了我自己吗，我能够说服我自己吗？\n必须是为了自己，不是为了自己，直接摆烂就行了，为了自己才要更努力\n\n\n","categories":["随记","目标"],"tags":["生活","平衡","计划"]},{"title":"闲散小记-续","url":"/2023/08/05/life-sharing/%E9%9A%8F%E8%AE%B002/","content":"复盘小记\n2022.8.17\n\n近两周真的感觉到了人生浮沉，一切都是不确定的，随机的。机会走的突然也来的突然。最好的朋友突然反悔和我 一起出去旅游，和比赛晋级下一阶段的备战这两件事，真的令人“身心俱疲”。不管是”央求”别人不要反悔，还是“鏖战”比赛，每天早出晚归，甚至通宵到天亮，我都尽力而为了，不求满意，只求不遗憾就行。\n因而，一切都结束的现在，我是极其平静的。终于回归日常的刷题，全部时间和精力由自己掌控的日子看起来是如此来之不易，料想之前我始终对此不甚真心，混吃懒作，属实不智。就记录到这里吧，能够写出这些，我已经很知足了。\n","categories":["随记"],"tags":["生活","日记"]},{"title":"论文阅读笔记：”Action Recognition by Dense Trajectories“","url":"/2023/08/05/paper-reading/paper_reading_001/","content":"Action Recognition by Dense Trajectories生僻术语\nKLT tracker\n\n用来抽取特征的一种方法，最早被提出是为了解决传统上的影像配准问题\n\nimage registration：影像配准\n\nSIFT：尺度不变特征转换\n\n\n用来侦测和描述影像中的局部性特征，它可以帮助辨识物体。基于物体上的一些局部外观的兴趣点而与影像的大小和旋转无关，对于光线，噪声的容忍度也很高\n\noptical flow field\n\n光流（optical flow）用来描述相对于观察者的运动所造成的观测目标，表面或边缘的运动。它通过检测图像像素点的强度随时间的变化进而推断出物体移动速度及方向的方法\n\nfeature\n\n特征是一块关于图像内容的信息，主要包括图像的特定区域是否包含特定的属性。特征也许是图像中明确的结构，如点，边或是物体，它也可能是对图像进行特征检测后的结果\n\n interest point\n\n图像中类点的特征，他有局部二维结构，可以被鲁棒地检测\n\n Gabor filter\n\n它是用来进行纹理分析的线性过滤器\n\nmedian filter：中值滤波器\n\n常用于去除图像或其他信号中的噪声\n\nbilinear interpolation：双线性插值\n\n双线性插值是一种基本的重采样技术\n\nHOG：方向梯度直方图\n\n用于目标检测的特征描述器。该技术是用来计算局部图像梯度的方向信息的统计值。局部目标的表象和形状（appearance and shape）能够被梯度或边缘的方向密度分布很好地描述\nBag of Features approach\n该论文使用了该方法在行为分类的场景下评估了创新的视频描述方法\n\n\nBag of Features框架是词包模型在图像识别领域的延申，2004年引入CV领域，逐渐形成了标准物体分类框架：\n\n底层特征提取\n特征编码\n特征汇聚\n使用SVM分类器进行分类\n\n\n搭建Bag-of_Features的步骤：\n\n特征提取（SIFT算子）\nK-means聚类\n量化特征，形成词袋\n统计每一类别的视觉单词出现频率，形成视觉单词直方图\n\n\n\n训练SVM分类器\n\n\n具体代码实践参考这里\n\n\n提取密集轨迹\n计算  ：\n\nM is the median fifiltering kernel,  is the rounded position of \n\n\n后续帧的点被连接起来形成轨迹，为了提取密集光流，文章使用了Farneback算法\n\n给定长度为L的轨迹，我们定义序列 来描述它的形状，其中位移向量为\n\n规范化之后，我们可以得到轨迹描述器：\n\n\n轨迹对齐的描述器\n计算局部描述器已成为视频表示的流行方法，本文在沿着轨迹的时空体（3D）中进行计算\n现存有很多行为识别的描述器\n\n\n\n","categories":["论文阅读","传统方法"],"tags":["传统方法","光流法"]},{"title":"论文阅读笔记：”Large-scale Video Classification with Convolutional Neural Networks“","url":"/2023/08/05/paper-reading/paper_reading_003/","content":"Large-scale Video Classification with Convolutional Neural Networks\n这一篇论文因其经典性，着重探索的各种模型的连接性，讨论如何更好地去获得时间信息，可以说是之后的C3D，Res3D，R(2+1)D的思想的先驱，有较大的参考价值，故阅读并写下笔记。\n\nIntroduction这篇文章的研究背景是利用CNN在大规模视频数据集上进行分类。此时的网络将不只能够接触到静态表观信息，还能够接触到复杂的时序变化信息。这篇文章研究了扩展CNN在时间域上的连接性的诸多方法，这些方法有效利用了局部时空信息。文章还提出了一种能够加速训练的多分辨率方法。\n数据集\n论文首先从实践的角度，判断当时没有合适的视频分类基准数据集。为了获取足够充分的数据来训练CNN，作者团队自己采集了名为Sports-1M的数据集。\n建模\n从建模的角度，作者以问题为导向，分析了在CNN中，什么样的时间连接模式在捕获视频中的局部运动信息是最佳的；而这些额外的运动信息是如何影响模型的预测的；它对预测效果的提升究竟有多大。作者尝试了在时间域中结合信息的不同方法。\n计算\n从计算的角度，因为训练CNN需要优化数百万参数，非常消耗时间，提高计算能力，对于大型网络结构较为重要。如上图所示，作者提出了双流法，将处理过程分为了两个结构相同的场景流和中心流。场景流学习低分辨率帧的特征，而中心流只学习图像中心的特征。使用这种方法大大提高了计算速度，同时对网络的性能几乎没有影响。\n核心亮点真知灼见：预测未来模型的发展是具有泛化性的Deep model on Large data\n上千万的参数量的大模型，以及大规模的标注数据集能够给出state-of-arts结果。为了模型的泛化能力，作者研究了CNN在大规模数据集上的表现，并通过迁移学习，看它在更小的数据集上的泛化效果如何\ntemporal connectivity pattern 时序连接模式\n\n\n\nsingle frame model\n\n如上图所示，最左边的single frame模型是baseline模型，而右边的三种不同时间融合方式的模型是它的扩展。baseline模型只提取了视频中的静态表观信息；这个对照主要是为了判断静态表观信息对分类的影响。其网络结构为：C(96, 11*,* 3)-N-P-C(256, 5*,* 1)-N-P-C(384, 3, 1)- C(384, 3*,* 1)-C(256, 3*,* 1)-P-FC(4096)-FC(4096)，\n\nlate fusion model\n\n第二个late fusion模型设置了两个平行的且共享参数的single-frame网络，这两个相隔15帧的流在第一个全连接层中进行汇聚；第一个全连接层可以计算全局运动特征。\n\nearly fusion model\n\nearly fusion在像素级别上就将整个时间窗口上的多帧信息进行融合，这时其第一个卷积层的过滤器的shape就变为了$11113*T$​​，实际上所做的就是3D卷积；论文说early fusion的连接可以允许网络精确地检测运动方向和速度。\n\nslow fusion model\n\nslow fusion结合了前两种方法，在整个网络中缓慢地融合时间信息，这样高层能同时获取较为同步的全局时空信息，整个表观特征的提取和时序信息的提取是同时进行的。这个方法参照了3D卷积网络2013年的文章，前三个卷积层都是3D卷积，后面两个为2D卷积\n多分辨率CNN\n为了改进运行时性能，作者改善了网络结构，但同时不影响其精度。\n\n\n如上图所示，为了试验不同的网络结构和不同的超参，作者提出了双流法，将处理过程分为了两个结构相同的场景流和中心流。这种双流方法改变了网络结构，但缩减了运行时间的同时又没有牺牲性能。场景流学习低分辨率帧的特征，而中心流只学习图像中心的特征。使用这种方法将帧分辨率从$178178降低为8989$，大大提高了计算速度。\n学习过程\n优化\n它使用的优化算法为 Downpour Stochastic Gradient Descent，可以参考查看这篇文章（Large scale distributed deep networks，NIPS 2012）\n\n数据增强和预处理\n首先，裁剪所有图片到中央区域，放缩图片到$200200，并在其中随机采样一个大小为170170$的区域，最终以50%的概率对图片进行水平随机翻转，并进行中心化\n\n\n实验结果对比实验\n\n这个实验令人惊异的是不同的架构对于精度的影响不大（抱有怀疑），但是slow fusion效果最好是有目共睹的\n运动信息对实验的影响\n\n\n有意思的是，比起singleframe，slowfusion对于类别的预测有部分很好，都也有部分比singleframe要弱，这些较弱的部分一般都有相机运动的存在。\n对于第一个卷积层filters的可视化\n\n\n可见，场景流主要学习的是颜色特征，而中心流主要学的是高频率的灰度细节特征。\n混淆矩阵的研究\n通过对混淆矩阵的研究发现，大部分分类错误都来自数据集的细粒度类别，模型对于细粒度的行为分类效果较差\n迁移学习\n\n\n只训练top层accuracy就很高了，说明学习到的特征具有普遍性。\n\n\n发现对于运动组的分类精度最高。\n","categories":["论文阅读","行为识别"],"tags":["行为分类","时间信息融合"]},{"title":"群体行为识别论文总结","url":"/2023/08/05/paper-reading/paper_presentation/","content":"2023.1.15汇报大纲\n基于关键实例的多层次时空推理transformer的群体行为识别方法\n\n研究背景实验创新点相关识别关键帧/关键角色\n\nDetecting events and key actors in multi-person videos\n结合空间注意力和时间注意力\n\n\n\n\nPosition-Aware Participation-Contributed Temporal Dynamic Model for Group Activity Recognition\n\n\n\nSocial Adaptive Module for Weakly-supervised Group Activity Recognition\n\n\n这个筛选的时候未用到注意力机制，主要实在密集关系图上做剪枝，做剪枝区别于前面的注意力机制，将所有非关键帧及非关键角色剔除。\n时空关系推理Empowering Relational Network by Self-Attention Augmented Conditional Random Fields for Group Activity Recognition\n\n\n\n\n\n\n\n\nHiGCIN: Hierarchical Graph-based Cross Inference Network for Group Activity Recognition\n\n\n\n\n其实，它的计算本质和上面提及的注意力很像，加上softmax后，该模块等价于transformer中的自注意力模块。与之前的注意力所区别的是\n\nCIN推理的特点是它只将视频中同一帧所有角色的特征，和同一角色所有帧的特征进行计算。\nCIN计算的是其他特征和当前特征的pair-wise关系推理，而前面计算的是个体特征与群体行为之间的注意力权重。\n\n\n\nSpatio-Temporal Dynamic Inference Network for Group Activity Recognition\n\n\n之前方法对个体之间的交互均在预定义的图上进行建模。这种方法可行，但有着很多缺陷：\n\n与给定主体交互的那些客体应该是主体特有的，或者说针对主体的，而不应该是预定义的。而一个预定义的图并不适合所有人的关系推理。\n之前预定义的图模型在一个全连接或是十字交叉的图上来对交互关系进行推理。它很容易导致过平滑(over-smoothing)，令特征难以区分。而且在长视频剪辑或是场景中有很多人的情况下，会导致极高的计算复杂度。\n\n\n动态关系 Dynamic Relation\n这里的动态指的是，关系矩阵仅仅依赖于初始化的交互场中的特征。所依赖的特征不是固定的，而是动态变化的。\n\n\n其中，，\n上面是计算第i个特征关系矩阵的表达式。\n\n\n上面的特征更新表达式从形式上与ARG的图卷积层是基本一致的，区别主要在于范围一个是K，另一个是T*N。\n动态漫游 Dynamic Walk\n论文的目的是通过DW模块来对复杂的时空依赖进行建模，它只使用了大小局限的交互场。首先，对于给定的第i个个体特征，我们要预测交互场范围内的时空动态漫步偏移量，其中 为线性投影矩阵，为所有交互场内堆叠起来的特征向量。得到漫步偏移量后，动态漫步的特征的计算公式如下：\n\n\n其中，为第i个交互场的第k个特征的坐标。\n结合DR和DW\n\n\n同过上式我们可以结合DR和DW来进行动态更新。\n多层次语义场景推理将整个场景按照粒度的不同进行划分，形成了不同尺度大小的场景元素。这些不同尺度元素存在着组合关系。\n\n\nGAR任务要解决的两个难题：\n\n对于整个复杂场景做复合式理解\n在所有场景元素上进行关系推理\n\n使用key-point模态的好处：\n\n对数据进行去隐私化，减少道德问题\nRGB输入对背景、光线亮度、以及纹理信息较为敏感，而key-point不会\n\n网络结构\n\n\nMultiscale Transformer Block\n多尺度transformer块可以层次式地对不同尺度的tokens进行关系推理。\n\n人体关键点（key point）: —第p个person第j个关键点的特征。人体关键点初始化包括：坐标嵌入，时间信息嵌入，关键点类型嵌入。\n人（person）：—对person关键点坐标在时间维度进行聚合，并作线性变换。\nP-to-P交互（interactions）：—人p和人q之间的交互初始化为，和的连接，并作线性变换。\n人群（person group）：—对场景内的人进行聚合（使用k-means等算法）\n剪辑（clip）：CLS是一个可学习的嵌入向量，它可以使得transformer可以从输入序列的所有tokens中总结分类相关的特征表示信息\n对象（object）：这里特指球关键点，因为它可以帮助我们更好地识别关键球员。\n\n\n\n\n\n由上图可知，multiscale transformer block在不同的尺度上有着差异化的输入，但是每个尺度的操作都是相同的。\n尺度一致的对比聚类\n我们强制同一clip的不同scale下的表示在聚类时所分配的标签是一致的，这其实是对特征空间的一种正则化处理。论文使用了交换预测（swapped prediction）机制来保证一致性。\n\n\n这种对比学习方法可以增强中间特征表示，从而提升总体效果。\n\n假设$v {n,s} \\in \\R^d表示第个剪辑的第个下的特征，然后通过将向量映射到个可训练的原型向量{c_1,…c_k}中，来计算q{n,s} \\in \\R^K。假设是是其中的两种尺度，并且我们希望从v_w预测q_s并从v_s预测q_w$，交换损失函数如下式：\n\n\n\n其中l函数计算匹配程度：\n\n\n总体的交换损失为：\n\n\n关键实例的多层次时空推理transformer的群体行为识别方法(key Instance Multiscale ST transformer)\n未来研究方向&amp;优化KIMSTT网络\n\n改进思路\n\n改进DIN模块，增加multiscale模块，使得可以对不同尺度范围的特征进行推理\n改进DIN模块，优化动态漫游 Dynamic Walk方法\n增加时空注意力模块，关注于与群体行为之间有较强的联系的个体特征\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：”Social LSTM：Human Trajectory Prediction in Crowded Spaces“","url":"/2023/08/05/paper-reading/paper_reading_005/","content":"论文阅读笔记—Social LSTM:Human Trajectory Prediction in Crowded Spaces（CVPR 2016）原理简单来讲，该论文通过邻域池化的思想来综合多个行人轨迹的的信息，提供给LSTM模型来生成下一个隐变量，这个隐变量包含了自身的历史轨迹信息，也包含了其邻域LSTM的历史信息。这个问题的目的是预测密集行人的轨迹，来防止与人发生碰撞，是序列生成问题的一种变体。作者使用了带有社交池化的LSTM模型，希望对复杂的行人社交常识（避让，转向等）进行建模，并通过该模型解释聚集行人场景下的运动行为。\n隐变量社交池化\n\n作者的思想很简单，通过共享周围邻域内的LSTM隐变量，使得模型具有捕获周围人运动信息的能力。在每一个时间步，LSTM单元从其领域LSTM单元接受池化隐状态信息，如下图所示，池化时，隐变量的空间信息可以在一定程度上保持。\n\n\n下面的等式(1)即社交池化的形式化表达，它是一个（$nnD$）形状的3D张量，n代表邻域的范围，D为隐状态的维度。\n\n\n位置估计论文里使用了t时刻的隐状态来预测t+1时刻人i轨迹位置的分布。作者假设其分布服从二元高斯分布，因其有5个待估计参数，可以利用线性层（权重矩阵shape为5*D）来估计，如等式4所示。我们可以通过该分布生成t+1时刻人i的轨迹位置。LSTM的参数可以使用似然函数损失作为目标函数来进行优化（即最小化负对数似然损失）。\n\n\n","categories":["论文阅读","轨迹预测"],"tags":["轨迹预测","LSTM"]},{"title":"论文阅读笔记：”Social GAN：Socially Acceptable Trajectories with Generative Adversarial Networks“","url":"/2023/08/05/paper-reading/paper_reading_004/","content":"Social GAN阅读笔记（cvpr 2018）方法问题定义论文的目标在于同时推理和预测在一个场景里的所有实体的未来行动轨迹。假设我们可以获得场景里人们的所有轨迹信息为，要同时预测所有人的未来轨迹信息为。行人i的输入轨迹为，t=1,…,，真实未来轨迹为，\nGAN论文模型包含三个关键组件：生成器G，池化模块PM，和判别器D。G是基于编解码框架的网络，论文使用了PM模块来连接编码器和解码器的隐状态。模块G提取输入Xi并输出预测轨迹。模块D输入整个包含和的序列，并把他们分类为真或假。SGAN的整体结构如下图所示：\n\nGENERATOR在模块G中，论文首先使用一个单层的多层感知机把每个行人的位置信息嵌入并得到了固定长度的向量，这些嵌入量之后用来作为编码器中的LSTM单元t时刻的输入。并遵从如下的迭代关系式：\n\n其中，是一个带有ReLu非线性的嵌入函数，Wee是嵌入权重，LSTM单元的权重被场景里的所有人所共享。编码器可以学习行人的状态并存储他们的历史运动。在论文的方法中，作者是通过PM模块来对人与人之间的交互建模。在时刻后，我们对所有场景里的人的隐状态信息进行池化。论文对decoder的隐变量状态进行了初始化：\n\n其中，是一个带有ReLu非线性的多层感知机，Wc是嵌入权重。在初始化解码器状态之后，我们可以根据以下步骤来获得预测轨迹：\n\nPooling Module\n对于行人1来说，其位置为(x1,y1)，将场景内其他人相对行人1的位置坐标（如）和隐状态传给多层感知机，之后使用最大池化来作为对称函数，池化的结果向量P1如右图所示。\n多模态输出论文提出了一种损失函数，它可以促进网络生成多样的样本。对于每个场景，我们生成了K个可能的预测输出，并选择其中最好的预测作为最终的预测。\n\n实现细节作者在GAN中使用了长短时记忆这一特殊的RNN来处理序列位置数据。编码器的隐状态维度为16，而解码器的隐状态维度为32。我们将输入坐标序列编码为了16维向量。作者使用Adam优化算法训练生成器和判别器200个epoch。其batch size大小为64，初始学习率为0.001。\n实验指标\n平均位移误差（ADE）：在所有预测时间点的L2距离\n最终位移误差（FDE）：在预测最终位置和真实最终位置间的距离\n\n基线\n线性：一个最小化最小二乘误差的线性回归器\nLSTM：一个没有pooling机制的简单LSTM\nS-LSTM：每个行人通过一个带隐状态的LSTM进行建模，该隐状态在LSTM的每个时间点使用social pooling layer进行池化\n\n消融实验论文对于不同的控制设定进行了消融实验。在测试时，论文从模型中采样N次并选择最好（L2距离小）的预测用来进行定量评估。\n评估方法论文使用了留一法来评估模型，即将数据集分为5个集合，每次在其中的4个数据集合上进行训练，在剩余的一个数据集合上进行测试，重复训练5次。论文观测8个时间点（总计3.2秒）的历史轨迹，并预测8和12个时间点的未来轨迹。\n定量分析\n指标精度\n\n\n因为线性模型只能够建模直线路径，所有其表现没有LSTM和S-LSTM好，因为他们可以建模更复杂的轨迹。但在实践中S-LSTM的性能并没有像论文中所说的那样超越LSTM。SGAN-1V-1表现没有LSTM好的原因在于模型的条件输出只是多种可能的未来轨迹的其中之一，也许与真实标签有较大差异，但当我们考虑多样本时，SGAN表现超越了baseline方法，这从一个侧面证明了该模型具有很好的多模态输出性质。\n\n性能速度\n\n\n\nSGAN-P的预测速度是S-LSTM块近16倍，LSTM更快但是不能避免碰撞和实现多模态输出预测。\n","categories":["论文阅读","轨迹预测"],"tags":["轨迹预测","RNN","GAN"]},{"title":"论文阅读笔记：“From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting(ICCV 2021)”","url":"/2023/08/05/paper-reading/paper_reading_006/","content":"Notes  of Reading “From Goals, Waypoints &amp; Paths To Long Term Human Trajectory Forecasting”(ICCV 2021)原理行人轨迹预测是一个内在的多模态问题，因为行人轨迹存在很多不确定性，论文将这种不确定性分解为认知不确定性（对于模型未知）和偶然不确定性（不可避免的随机性）。这篇文章利用了分解的思想，分别对认知不确定性（行人的目标）和偶然不确定性（路径）进行建模，从而能够预测更长时间且多样的轨迹。这篇文章极大的参考了U-net这个网络，并基于这个网络进行了一系列改进。\n模型网络Y-NET\n\nY-NET模型包含了3个子网络（Ue,Ug,Ut），并将整个随机性分解为两种模式。首先，对认知不确定性建模的模块A会预测多个目标（即行人轨迹的最终目的地坐标，共预测Ke个）；之后对随即不确定性建模的模块会根据从模块A得到的估计目标位置来预测多条路径（Ka个）。\n\n场景轨迹热图表示\n\n为了正确引入场景信息，在满足像素对齐的情况下，作者使用了场景轨迹热图表示的方法，即在和图片相同的空间内去表示轨迹信息。如图所示，RGB图像首先经过语义分割网络处理得到了语义分割图S（包含C个类别），在下方平行的路径中，作者将历史轨迹序列转化为了轨迹热图H，其空间大小和场景图像相同，通道数即为历史轨迹采样点数。作者将分割图和轨迹热图在通道维度进行连接，得到了轨迹场景热图张量$Hs(HW(C+np))$，并将其作为输入传递到编码网络Ue中。\n\n场景轨迹热图编码器（Ue）\n\n在编码器Ue中，它包含了M个block，在每个block后使用最大池化来进行降采样，最终空间紧凑的输出张量shape为($H_MW_MC_M$)。网络将该张量与中间M-1个block的输出张量合并起来作为输入传给目标位置解码器和轨迹解码器\n\n场景轨迹热图解码器（Ug）\n\n非参数化采样过程损失函数","categories":["论文阅读","轨迹预测"],"tags":["轨迹预测","Y-NET"]},{"title":"论文阅读笔记：“From Goals, Waypoints & Paths To Long Term Human Trajectory Forecasting(ICCV 2021)”","url":"/2023/08/05/paper-reading/paper_reading_007/","content":"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset(CVPR 2017)该论文提出了Kinetics这一更大的人类行为视频数据集，使用它进行预训练的模型更适合于迁移学习。该论文提出了一个新的模型I3D，并将该模型与之前提出的不同行为分类架构进行比较。\n模型网络I3D\n\nb图3D-convnet架构的缺陷是，无法有效利用ImageNet预训练模型，需要从头开始训练，并且由于参数量的庞大而较难以训练，因此网络较浅。c图双流法弥补了a图LSTM低层次运动信息的缺陷，而且更加容易训练。d图在双流法的基础上将空间和光流信息在最后进行融合，并将融合的信息送入3D-convnet进行分类。e图的I3D在d图的架构上进行了改进，用3D-convnet对之前的convnet进行了平滑扩展，并且可以充分利用ImageNet预训练参数。这里的想法是可以通过对原图片进行复制，并将其转换为每帧都相同的视频序列（boring-video）。但其实我们也不需要真的训练，这里需要满足一个条件我们就可以直接利用2D-convnet的参数：在视频上的响应或激活特征应与单张图片时作为输入时相同。所以我们只需对2D-filters沿时间维度进行复制，并将权重缩小n倍即可。还有一个问题也需要处理，就是如何进行时间维度感受野的设置，即我们如何设置时间维度的stride步长。它的设置应与采样帧率与图像维度有关，过大会会导致混淆不同物体的边缘，不利于学习良好的特征；过小也会不利于捕获场景中的动态信息。通过实验，作者认为在前两个maxpooling层不执行时间维度的池化会比较有效。下图是I3D主干网络的结构图：\n\n\n作者认为如果只使用RGB输入，模型只单纯地进行前馈计算，而因为光流算法涉及一些迭代优化，这可能是加入光流对模型性能有较大提升的原因。值得一提的是，作者并没有进行端到端的训练，而是分别训练两个不同输入的模型；并且训练时作者多个GPU进行同步训练。\n","categories":["论文阅读","行为识别"],"tags":["Kinetics","I3D"]},{"title":"论文阅读笔记：“Deep Temporal Linear Encoding Networks”","url":"/2023/08/05/paper-reading/paper_reading_009/","content":"Deep Temporal Linear Encoding Networks一. 论文思想这篇文章主要是针对如何对整个视频进行表示，即如何对视频中的片段进行聚合，提出了时间线性编码（TLE），它可以嵌入在CNN中作为一个层，从而允许端到端的训练。\n二. TLE　Layer\n\nTLE层主要分为两个部分，第一个是对视频的多个片段的特征图进行聚合的操作，第二个是将聚合表示转化为线性编码特征的编码操作，算法如下图所示：\n\n\n聚合方法可采用（逐元素）最大聚合，平均聚合和乘积聚合，编码方法可采用双线性模型和全连接池化。实验表明，双线性模型较第二种方法计算更加快速，参数量更少的同时效果更好，使用Tensor Sketch算法也可以通过将高维空间投影到低维空间而无需直接计算外积。作者在已有的典型模型的基础上只保留卷积，通过加入TLE层来进行实验。实验证明使用该层对模型效果均有较大提升。值得一提的是，作者还将环境场景信息纳入考虑，作为额外信息进行聚合，实验表明准确率有较大提升，该实验证明了TLE合并不同数据流的能力。\n\n","categories":["论文阅读","行为识别"],"tags":["时间线性编码","TLE Layer"]},{"title":"论文阅读笔记：“Notes on Long-Term Temporal Convolutions for Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_010/","content":"Notes on Long-Term Temporal Convolutions for Action Recognition一. 论文思想典型的人体动作经常持续数秒，只学习少数帧无法对动作在其持续时间范围内进行有效建模，将具有特定特征的视频分解为clips，并在视频层面将各个clips的信息加以聚合的方法可能不是最优的，因此该论文尝试通过长期时间卷积（LTC）来学习视频的有效表示。为了不让复杂度过高，使模型易于处理，作者在增加时间范围的同时降低了空间分辨率。\n二. 模型结构作者以C3D模型为基础，扩展该模型实验了不同输入时间分辨率（）和空间分辨率（${5858; 7171}$）的效果。作者认为如果在网络的高层保留更大的时间分辨率可以学习更为复杂的模式。该论文做了丰富的实验。\n\n\n如上图a,b所示，文章发现更大的空间分辨率在时间范围较小时对结果的提升较为明显，但是相当于空间分辨率，时间分辨率对结果的提升更明显，作者认为这可能是因为更多的参数需要大数据集进行训练，而训练数据的不足导致了过拟合。图c说明了时间分辨率对不同行为分类准确率的影响，小部分历时较小的行为（例如shotput）甚至会导致较差的效果。为了判断最优时间范围，作者统计了不同时间分辨率下的准确率最高的行为数量分布，如图d 所示，可见绝大部分的最优准确率均在100处获得。e图计算了平均准确率增益，进一步印证了在100时获得的增益最多。\n\n\n如上图，作者还研究了对不同时间分辨率的LTC网络进行组合（通过late fusion）所带来的增益。\n\n\n由图，在网络的越高层，越高的时间分辨率，同一个filter所对应的响应更加纯化（即同类的行为具有更高的聚合性）。\n","categories":["论文阅读","行为识别"],"tags":["Long-Term","长期时间卷积（LTC）"]},{"title":"论文阅读笔记：“MoViNets： Mobile Video Networks for Effificient Video Recognition”","url":"/2023/08/05/paper-reading/paper_reading_011/","content":"MoViNets: Mobile Video Networks for Effificient Video Recognition一. 论文思想传统视频行为识别需要巨大的计算量和存储需求，该论文所提出的模型极大地优化了计算和存储效率，movinet可以线上对流视频进行实时推理。该论文首先设计了一个视频网络搜索空间，应用NAS技术生成有效且多样的3D架构。其次论文引入了流缓冲技术，将内存从视频剪辑中解耦，从而允许3D网络仅需常数的内存足迹就可以嵌入任意长度的流视频序列进行训练和推理。该论文还使用了一种简单的组合方法来提升精度。值得注意的是，该模型未使用任何预训练技术，并且仅使用RGB输入。\n\n该论文在提高视频模型的效率做了进一步的研究。SlowFast networks， X3D等是这方面的代表。有些网络TSN等进一步探索了2D网络，这些网络在之后对片段特征图进行late fusion。TSM[1]使用了early fusion,它沿着时间坐标移动了一部分通道，在支持在线推理的同时提高了准确率。\n对于计算复杂的视频网络，寻找一个有效的架构是十分必要的， [2][3]探索了一些寻找架构的方法。在视频架构搜索方面，Tiny video networks[4]和AssembleNet[5]有较大贡献。\n深度组合常被用于提升CNN的性能，图像分类的近期研究表明[6]对小型的深度组合可能比单个大模型更加有效，作者将该发现扩展并应用于视频分类。\n在设计用于在线流视频推理的stream buffer的时候，作者受到了因果卷积[7]的启发。\n\n二. NAS作者通过NAS探索了如何融合时空操作来寻找最佳特征组合以权衡效率与精度。\n\n\n从图中可看出对于movinetA0在与mobilenetlarge+TSM达到相似准确率的情况下，浮点数运算减少了近75%。movinetA6达到了83.5%的精度，比X3D精度高了1.6%，浮点数操作减少了近60%。\n\n\n在2D 移动网络搜索的研究基础上，作者以TuNAS框架为起始，并对它略作修改使之适用于3D网络。Movinet搜索空间的基准是MobileNetV3，上图是对搜索空间的总体描述。对于网络中的每个block，NAS搜索了基准filter width，和每个块中的层数。作者将乘子{0.75，1，1.25}应用在特征图通道。作者设置了5个block，并在每个block的第一个层使用空间降采样。对于时间维度，每层的过滤器大小在如下的范围中选择：{1x3x3, 1x5x5, 1x7x7, 5x1x1,7x1x1, 3x3x3, 5x3x3} 。这些选择使得层关注并聚合不同的维度表示方法，在最适宜的方向扩展网络的感受野，并减少其他维度的计算量。每个层之后有$111卷积在c^{base}和c^{expand}$之间进行转换。文章使用了复合缩放启发式方法来进行搜索（随机搜索缩放系数）， EffificientNet使用了类似的方法。\n二. Stream Buffering原理：流缓冲通过缓存子剪辑边界处的特征图将时间依赖在连续非重叠子剪辑的进行传递。它在流缓冲中加入了无向因果操作如因果卷积，累计池化和带位置编码的因果SE操作，使得时间感受野只查看过去帧，允许我们在线上推理时递增地处理流视频。因果操作在kinetics数据集上仅仅损失了1%的精度。\n\n上图对比了流评估和多剪辑评估方法，左图的多剪辑评估也是一种有效减少内存的解决方法：模型在测试时对n个相互重叠的子剪辑进行平均预测，这种方法将内存消耗降低到。这种方式有两个缺陷：一是限制了时间感受野的（对每个子剪辑），并忽略了长时间范围的依赖，可能会影响精度；二是重复计算了重叠帧的激活，从而降低了计算效率。右图的Stream Buffering解决了上述两个缺陷，他应用了缓存的思想，对边界处的特征激活进行缓存，从而能够将时间感受野在子剪辑之间进行扩展，提高准确率。\n\n\n上面的公式将缓冲B与当前子剪辑xi沿时间维度进行拼接,并将得到的张量通过3D卷积进行处理，得到了特征图Fi。\n\n\n当处理下一个剪辑时，我们需要对buffer进行更新，公式如上图所示。作者在拼接后的张量中选择最新的b个帧来更新该buffer。因此，流缓冲技术的内存复杂度为。\n在流缓冲中，作者强制使用了因果关系，即任何特征不能从未来特征计算得出。它有很多好处，包括将子剪辑降低到单帧但不会影响激活和预测，从而使得3D网络能够对流视频进行在线推理。在因果卷积中加入CasualSE可以使得精度进一步提高。作者在实验中发现，将帧位置编码向量与CGAP（累积的全局平均池化）输出相加得到的输出来继续进行SE投影效果比不使用位置编码效果好。\n在训练时作者使用了循环训练策略来降低内存需求。作者不会对buffer进行反向传播，所以之前的子剪辑可以被释放掉，以空出内存。相反，它计算相邻clips之间的损失并累积计算的梯度（与batch梯度累积类似）。在线上推理时，我们经常将剪辑长度设为1来最大化内存效率，设置较小的剪辑长度同样降低了帧之间的延迟，使得模型能够输出单帧预测。\n三. 时序组装作者独立地训练了两个具有相同浮点运算数地stream movinets。它们的帧率均为先前的一半，但其中一个网络相对于另一个有一帧的偏移，作者在使用softmax之前先对它们的输出进行算数平均。该方法的计算量与训练一个大模型的计算量相同，但将两个小模型结合起来可以实现更高的精度。\n四. 不带流缓冲的movinet文章对7个不同计算复杂度的模型进行了实验，每个模型主要与X3D进行比对。\n\n\n从图中可以看出，movinet在达到state of arts的同时模型的效率也是最高的。\n\n\n\n\n从图中可以看出，带stream buffer的网络相较base网络仅有1%的下降但是随着输入帧数的增加器内存使用是常数的。\n\n\n有趣的是，在对ResNet3D使用stream buffer方法时，削减的内存并不显著，这可能是因为depthwise卷积和3D全卷积之间的差别。\n[1] Progressive neural architecture search. ECCV 2018\n[2] Progressive neural architecture search. ECCV 2018\n[3] Effificient neural architecture search via parameter sharing. 2018\n[4] Tiny video networks: Architecture search for effificient video models. 2020\n[5] Assemblenet: Searching for multi-stream neural connectivity in video architectures. 2019\n[6] When ensembling smaller models is more effificient than single large models. 2020\n[7] Massively parallel video networks. 2018\n","categories":["论文阅读","行为识别"],"tags":["MoViNets","NAS"]},{"title":"论文阅读笔记：“X3D：Expanding Architectures for Effificient Video Recognition”","url":"/2023/08/05/paper-reading/paper_reading_012/","content":"X3D: Expanding Architectures for Effificient Video Recognition一. 主要思想该模型基于“mobile-regime”系列模型MobileNet, 对原模型稍作修改，令乘加运算数少了近10倍，之后将模型从2D空间扩展到3D时空域\n\n为了探索计算高效的架构，MobileNet和ShuffleNet探索了channel-wise separable convolutions and expanded bottlenecks.\nMnasNet是通过采样近8000个模型来获得的（采用EfficientNet的grid search方法），作为对比，作者提出的方法每一个step仅需训练6个模型\n\n二. 扩展方法\n\n\nmobile-net 核心思想：channel-wise separable convolutions\n沿以下的轴进行扩展：历时，帧率，空间分辨率，网络宽度，瓶颈宽度及网络深度\n递进地增加计算量：每次只扩展一个轴，训练并验证结果架构，选择能够实现最佳复杂度，准确率权衡的扩展。重复该过程直到满足预期的复杂度预算\n该扩展方法可以被解释为坐标下降算法在超参数空间的应用\n\n\n\n三. 实验\n\n上图反映了top1准确率与模型容量之间的关系，作者将每一个step选择的维度都在曲线上进行了标注，从中我们可以得到一定的启示。\n\n\n上表展示了根据目标模型复杂度（FLOPs）来划分的6个不同大小的模型\n","categories":["论文阅读","行为识别"],"tags":["X3D","坐标上升算法"]},{"title":"论文阅读笔记：“Aggregated Residual Transformations for Deep Neural Networks”","url":"/2023/08/05/paper-reading/paper_reading_014/","content":"论文阅读笔记：“Aggregated Residual Transformations for Deep Neural Networks”\n我想读一些关于网络架构设计的文章，也许会有利于我搭建自己的network，虽然说他们只是2D的架构但是迁移到3D应该不是很困难\n\n核心亮点lego blocks\nResNeXt继承了VGG的思想，就是使用一种简单但是有效的策略来构建深度网络：像堆乐高积木一样，使用大小相同的building block来构建，这个block可以是多个层的组合，多个block具有相似的拓扑结构。这种思路不仅有利于代码实现，也可以减少需要调整的超参数。他还有一个“致命”的好处就是减少超参数对于特定数据集的过度适应。\nsplit-transform-merge\n“分离，变换，合并”，听起来很抽象，但实际上很易懂。一个最简单的neuron可以帮助我们更好地理解这个思想：\n\n\n对于一个向量x，我们对其使用神经元来处理，实际上就是将x在其特征维度分解为一个个标量（split），对于每一个变量乘以对应的权重（transform），最后将这些值进行求和（merge）。\n更加形式化地，可以将split-transform-merge表示为：\n\n\n可以为任意地函数，它会将x投影到低维度的embedding，再对其进行transform，C代表cardinality，也就是分组的组数。\ngroup convolutioon\n\n\n分组卷积是上述两个思想的自然延深和实际应用，因为每个block的拓扑结构均相同，因此通道的数量也可以作为参数来进行实验。如图c中，分组卷积实际上就是执行了32组的输入和输出channel均为4的卷积。\n亮点思考为什么分组卷积可以降低复杂度？\n\n\n从上图可以看出，左边block的复杂度近似等于右边的block，右边block也与图3的(c)block等价，因此感觉处理的通道数明明变多了，但实际上复杂度却近似相同。\n从计算的角度设输入的大小为（t,t)，那么左边block的运算量为：\n$tt25664+tt*(33642)64+tt64256=106496t^2$\n右边block的计算量为：\n$(tt2564+tt*(3342)4+tt4256)32 + tt25631=82688t^2$\n\n为了计算方便我省去了padding，因其对计算量影响不大。从计算可见右边block的计算量实际比左边要小（文中说的等价实际上是参数数量的等价，这个更好计算，这里不再赘述），这也证明了使用分组卷积可以大大降低计算量。\n\n从直观上进行理解的话是，虽然bottleneck更加wider，但是连接更加稀疏，因此需要计算和训练的参数也更少。\nchannel-wise conv &amp;&amp; group conv\nchanner-wise conv实际上分组卷积的特例，它将通道维度进行了split，令cardinality等于输入通道数\n模型架构\n\n关键结论新维度 cardinality\n基数（split的组数），可以作为设计深度架构的一个新的维度，必要时可以将其纳入考虑。\n","categories":["论文阅读","图像分类"],"tags":["ResNeXt","group convlution","architecture design"]},{"title":"论文阅读笔记：“Is Space-Time Attention All You Need for Video Understanding”","url":"/2023/08/05/paper-reading/paper_reading_013/","content":"Is Space-Time Attention All You Need for Video Understanding?一. 主要思想这篇文章所提出的模型仅使用了自注意力来实现视频分类。该模型将用于图像分类的ViT模型进行扩展，将空间从2D图像空间扩展为3D时空体。文章研究了不同的自注意力模式，提出了可分离式自注意力。\n\n之所以将NLP中的transform模型引入视频分类，是因为它们具有高层次的关联性：\n\n都是序列化的\n情景信息（上下文）对理解原子动作（词语）的语义十分重要\n\n\n当前的视频理解领域，大部分模型依旧采用2D或3D卷积作为核心操作，尽管有一些模型采用了自注意力机制，但也只是发现将其应用在卷积层之上精度会有一定回报。\n\n 作者认为只使用自注意力来搭建视频理解架构也是可行的：\n\n归纳偏好（局部连接和平移不变性）限制了CNN的表达能力\n卷积核的设计使得模型难以对感受野之外的依赖进行建模\nCNN的参数量大且训练较为困难\n\n\n二. 遇到的困难标准的transformer需要对每一对tokens进行相似度测量，因为一个视频中的patches数量很多，在这个情景下，其计算复杂度是很高的。为了解决这些问题，文章研究了不同的自注意力模式，其中可分离式自注意力效果最好。\n\n为了解决这个问题，其他论文采用了诸多方案降低复杂度：\n\n局部近邻（限制自注意力范围）\n全局自注意力（下采样的图像）\n稀疏键值采样\n分为时间自注意力和空间自注意力（本文采用的方法）\n\n\n三. TimeSformer模型线性嵌入\n首先论文将clip分解为patches，用x来表示每一个patch，公式1进行了线性嵌入得到嵌入向量z，其中E和e都是可以学习的参数，e代表对每个patch的时空位置进行编码的位置嵌入向量。\n\n\n查询键值计算\n模型包含了L个编码块，在每个块中，为每一个patch的表示（由上一个块编码得到）中计算查询/键/值向量。其中LN（）代表LayerNorm；a = 1,…,A，其中A为多头注意力的数量，其中每个注意力头的隐维度数量为Dh = D/A\n\n\n自注意力计算\n自注意力权重可以按照如下的公式进行计算：\n\n\nSM（）代表softmax激活函数，自注意力仅在p(空间维度)或t(时间维度)上进行计算所以计算量被显著地降低了。\n编码过程\n第l个块的patch编码z可以通过:\n\n先计算值向量的加权和，公式如下：\n\n\n\n\n将这些向量沿HEAD维度进行连接，再传入多层感知机即可得到最终编码向量（注，在每一个操作中还使用了残差连接）：\n\n\n\n","categories":["论文阅读","行为识别"],"tags":["坐标上升算法","TimeSformer"]},{"title":"论文阅读笔记：“MobileNets：Efficient Convolutional Neural Networks for Mobile Vision Applications”","url":"/2023/08/05/paper-reading/paper_reading_015/","content":"论文阅读笔记：MobileNets系列论文浅析：mobilenet v1\n参考原论文\n参考B站视频\nhint: 为了去寻找一个最优的网络架构，有哪些思考模式是可以借鉴的\n\n核心亮点depth-wise separable convolution\n\n\n深度可分离卷积是分解卷积的一种，如图它包含了DW卷积和PW卷积。DW卷积（depth-wise conv）也叫 channel-wise 卷积，实际上是分组卷积的特例，它处理长宽方向的信息。而PW卷积是卷积核大小为1的普通卷积，其目的是将depthwise convolution的输出进行结合，处理跨通道的信息。普通卷积在一步里同时完成了过滤（filter）和组合（求和combination）的操作，而深度可分离卷积将filter和combination分为了两步，每一步由一个单独的layer来负责。\n引入新超参：Width Multiplier&amp;&amp;Resolution Multiplier \n\n目的：让模型更小，更快\n引入Width Multiplier的计算量：\n\n\n\n\n再引入Resolution Multiplier的计算量：\n\n\n\n\n效果如下图所示：（计算量减少了近30倍）\n\n\n亮点思考为什么使用深度可分离卷积可以减少计算量？\n\n\n\n\n普通卷积\ndw卷积\npw卷积\n\n\n\n参数量\n$MD_KD_K*N$\n$D_KD_KM$\n\n\n\n计算量\n$D_KD_KMND_F*D_F$\n$D_KD_KMD_FD_F$\n$MD_FD_F*N$\n\n\n\n\n以卷积核大小为3为例，由上式可发现深度可分离卷积的计算量是普通卷积的至\n模型架构\n\n模型训练与大模型相比，该模型仅有28层，因此论文用了更少的数据增强与正则化方法（小模型不容易过拟合），且未用到side heads 或是 label smoothing。实验发现，在dw卷积上使用较小或是不使用l2正则会比较好，因为所含参数量较少。\n有意思的实验更浅的网络好还是更瘦的网路好？\n\n\n实验证明，参数量和计算量基本一致的情况下，更瘦的网络效果更好，高了近3个百分点。看系列第二篇笔记可以从理论上对这个结果进行解释。\ntrade-offs: 精度与计算量的平衡\n\n\n\n精度vs计算量：\n\n\n\n\n精度vs参数：\n\n\n\n可以根据实际应用需求来调整，究竟是需要精度还是需要速度。\n关键结论可以考虑深度可分离卷积，和Width Multiplier&amp;&amp;Resolution Multiplier超参来降低模型复杂度\n","categories":["论文阅读","图像分类"],"tags":["architecture design","MobileNet","depth-wise separable convolution","embedded vision application"]},{"title":"论文阅读笔记：“ AssembleNet++： Assembling Modality Representations via Attention Connections”","url":"/2023/08/05/paper-reading/paper_reading_017/","content":"AssembleNet++: Assembling Modality Representations via Attention Connections主要工作为了学习原始输入模态和语义输入模态之间的交互关系，作者提出了一族可以显示地学习表观信息，运动特征和对象特定信息之间相互作用的模型AssembleNet++。为了对这种不同模态信息的相互作用进行建模，作者搜索了块间的同辈注意力连接性，引入了创新性的peer-attention模块。\n网络结构该模型采用了继承自AssembleNet的多流，多block的架构设计模式。\n\n\n如图所示的连接图未加入注意力。可以看出输入block包括原始RGB，光流以及图中物体的信息多个模态。且图中的连接并非人为简单的设计，而是通过NAS方法搜索出来的，每个block都可以和其上层的多个block进行连接，也可以跳层连接，如图中最右侧的Object Input Block。每个Block又是R(2+1)D的residual block，包含1D的时间卷积，2D的空间卷积层还有一个1*1的conv层。\n核心亮点object information\n物体以及他们的位置可以提供丰富的语义信息来对视频中的行为进行有效理解，从搜索得到的网络结构也可看出，语义信息包含在了整个架构中，所以可以和其他模态以及从中得到的中间特征进行交互，而且每一个学习到的物体连接的权重都大于0.7，可见该输入block的有用性。\nweighted connections\n任和一个块的输入都可以由其下层的一个或多个块的输出进行加权和来得到：\n\n\n模型考虑了所有满足条件的connection(j,i)：只要block j 所在的层数小于i所在的层数。思想即通过设置权重来允许学习连接的大小。\npeer-attention（channel-wise attention）\n\n同辈注意力连接性\n\n\n\n对于每个连接，上面的公式可以计算大小为Ci的权重向量。它首先对张量x进行全局平均池化，之后通过一个全连接层映射为大小为Ci的向量。\n\n\n假设我们已经知道block k对connection(j,i)有影响，那么通过考虑来自块k的注意力，结合所有连接(j,i)，我们就可以得到块i的输入，如果xj == xk，那么这种注意力就等价于经典的SE注意力。\n one-shot differentiable architecture search\n\none of NAS approaches\n\n\n\n思想与weighted connections近似，通过设置每个peer block的weights，令weights是可学习的。通过训练，模型对每一个block会软选择（soft select）一个最好的peer block，这个peer会最大化识别的效果。从公式可以看出，x为所有peer block的加权和，公式的其他部分与前面的类似。\n实验结论物体信息的重要性\n\n\n从实验可以看出，物体连接数量越多，数据集的mAP指标成比例的升高。\npeer attention的有效性\n\n\n从图中可以看出，带有peer attention的mAP较无attention的网络提升了近6个百分点。\n对其他架构具有通用性\n","categories":["论文阅读","行为识别"],"tags":["NAS","peer attention"]},{"title":"论文阅读笔记：“MobileNetV3：Searching for MobileNetV3”","url":"/2023/08/05/paper-reading/paper_reading_018/","content":"论文阅读笔记：MobileNets系列论文浅析：mobilenet v3核心亮点SE注意力的集成位置\n为了让注意力可以在更大的特征表达上进行应用，所以该论文改变了SE模块的集成位置：\n\n\n网络搜索network search\n\nplatform-aware NAS\n\n对于大模型，文章的实验结果与[1]一致，因此作者直接使用了 MnasNet-A1作为初始模型，然后在其上对齐进行优化。但是对于小模型，原先的奖励设计并没有为小模型进行优化，作者发现对于小模型，在给定延迟的情况下，精确率的变化极为剧烈，因此调整了权重因子对其进行补偿。\n\nNetAdapt algorithm\n\n作者采用了NetAdapt[2]的技术并将其应用到了mobilenet架构搜索中。\n在每个步骤中：\n\n生成新的proposals的集合，每个proposal代表了一种架构的修改，它比前一步的延迟至少减少了\n对于每一个proposal，我们使用从前一步得到的预训练模型，并将其移植到我们的新架构，对于缺失的权重可以进行随机初始化。对每个proposal进行T步的调优可以得到对精度的粗略估计。\n根据指标metrics选择最好的proposal\n\n不断循环上述步骤直到达到目标延迟。\n新的nonlinearities: hard swish\n原先的swish的计算公式为：\n但是sigmoid函数在移动设备上的cost较为昂贵，因此论文类比它提出了新的非线性激活函数：\n下图为两个hard-soft函数的直观比较：\n\n\n网络结构\n\n\n相较于mobilev2，v3将第一    个conv层的卷积核数量减少为了16（原先为32）\n\n相较于mobilev2，v3对最后几层进行了如下的优化：\n\n\n\n\n网路优化roadmap\n\n\n\n\n训练细节\n优化器：RMSProp with 0.9 momentum\nbatch size： 4096\nlearning rate decay rate of 0.01 every 3 epochs.\ndropout of 0.8\nl2 weight decay 1e-5\nbatch-normalization layers with average decay of 0.99\n\n实验结果\n\n可以从精度-性能对比曲线中看出mobilenetv3优于之前提出的模型。\n\n\n具体的精度，计算量，参数量以及延迟的数据如上表所示。\n参考文献[1] Mnasnet: Platform-aware neural architecture search for mobile. CoRR 2018\n[2] Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV 2018.\n","categories":["论文阅读","图像分类"],"tags":["MobileNet"]},{"title":"论文阅读笔记：“MobileNetV2：Inverted Residuals and Linear Bottlenecks”","url":"/2023/08/05/paper-reading/paper_reading_016/","content":"论文阅读笔记：MobileNets系列论文浅析：mobilenet v2\n参考原论文\n参考B站视频\nhint: 为了去寻找一个最优的网络架构，有哪些思考模式是可以借鉴的。哪怕我无法提出一个通用的网路架构design的创新方法，学习已有的架构设计思路来改进已有模型也是可以的，所以为了改进模型而去学习这些改进的思路是很必要的。\n\n\n究竟有哪些架构优化方法呢？\n\n强化学习: [1]\n通用算法：[2]\n\n\n核心亮点manifold of interest\n\nmanifold: 流形的概念:\n\n\n流形学习的观点是认为，我们所能观察到的数据实际上是由一个低维流形映射到高维空间上的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上只需要比较低的维度就能唯一地表示。参考链接：https://en.wikipedia.org/wiki/Manifold\n\n\n举例1：实际上二维空间中的圆就是一个一维流形（维度冗余）\n举例2：三维空间中一个球面（只需要经纬两个维度即可描述）\n\n在深度学习领域，我们可以将激活张量视为多个容器组合而成的，每个容器包含了数量为的pixels向量，每个向量的维度为。这些激活张量的集合组成了流形特征（interest）。而且认为神经网络中的流形特征可以被嵌入到低维子空间中。正是这个概念，令如mobilenetv1（Width Multiplier），shufflenet等网络取得了不错的效果。\nLinear Bottlenecks\n\nintuition:\n如果我们感兴趣的流形经过relu变换后的信息不为零，那么这个变换对应的就是线性变换。\n有没有办法，能够让我们有relu的同时，尽量不丢失必要信息呢：在高维空间做relu可以尽量保留我们所需的低维度的信息。\n\n\n\ninverted residuals(倒残差)\n本文将残差的思想引入了mobileNet v2。传统的残差连接连的是具有较大channel数的两个层，而倒残差连接的是两个瓶颈层：\n\n\n可以看出，与传统残差连接相反，倒残差的整体形状是中间宽（增加非线性变换的表达能力），两头窄（更节省内存）。\n该块的实现架构如下表所示：\n\n\n计算量：(乘加运算数)$hwk*t(k+3^2+k^`)$\n网络结构\n\n\n\n[1] Neural architecture search with reinforcement learning. CoRR 2016\n[2]  Learning transferable architectures for scalable image recognition. CoRR 2017\n","categories":["论文阅读","图像分类"],"tags":["architecture design","MobileNet","Inverted Residuals","Linear Bottlenecks"]},{"title":"论文阅读笔记：“3D Convolutional Neural Networks for Human Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_019/","content":"3D Convolutional Neural Networks for Human Action Recognition（TPAMI 2013）\n读这篇文章的原因，是因为他是整个3D model的开山之作。虽然，它所提出的模型远没有达到”Deep Learning”的深度，一些模块的设计也有明显hand-craft—手工的影子，但不可否认的是，其创新性的3D卷积核的思想对后面的网络有较为深远的影响，同时这篇文章将传统方法中hardcoded的参数消除，令模型参数都是可以在data上训练得到，这种端到端的训练思想从这篇文章就可窥见一般。\n\n核心亮点3Dfilters\n3D卷积的数学形式化描述如下：\n\n\n3D卷积的输出特征图是一个体素，相比起3维的2D卷积，4维的3D卷积相对较难理解一些（这里的三维和四维指的是计算时的维度，加上了通道维度），图形化解释可见下图：\n\n\n如图为时间维度的stride为1的，kernel size为3的3D卷积。3Dfilter在整个4D张量的各个位置去进行卷积，得到的结果是一个3D张量，与2D卷积核类似，使用多个3Dfilters可以将多个3D张量组合为新的4D张量。\n分离式channel数据流+特征融合\n论文使用了预先hardwired的kernels对原始输入进行处理，生成了多通道的信息：分别为灰度，x方向梯度，y方向梯度，x方向光流，y方向光流。文章将该层称为hardwired层，用来编码我们对于特征的先验知识。之后论文在每个channel（指的灰度，梯度，光流等）上分别进行3D卷积和降采样(注：只有两个3D卷积，很浅)。之后文章使用全连接和卷积对得到的特征进行融合，全连接层（linear classifier）充当了分类器的作用。\n高层特征正则化\n\n\n\n\n受限于当时的硬件，可输入的帧数较少，所以编码高层运动信息显得尤为重要。作者通过对大量的帧计算运动特征（长期），并将其作为正则化模型的辅助输出。作者希望模型可以学习到一个类似于辅助输出的特征向量\n模型组合\n作者认为，构建多个不同架构的CNN模型，能够捕获潜在的互补的信息。作者为此提出了３个可选的CNN架构，，。\n模型架构\n\n模型的架构虽然简单，但是作为一个可以扩展的基础baseline，为后续研究的深入奠定了基础。\n","categories":["论文阅读","行为识别"],"tags":["3D model","3D filters"]},{"title":"论文阅读笔记：“Two-Stream Convolutional Networks for Action Recognition in Videos”","url":"/2023/08/05/paper-reading/paper_reading_020/","content":"Two-Stream Convolutional Networks for Action Recognition in Videos\n 之前虽然已经读过了一遍，但其中的经典思想依然是可以借鉴的，因此再细读一遍，希望能有新的理解\n\n这篇文章提出了一个新的双流架构（空间和时间），之后通过late fusion进行融合\n核心亮点two stream 双流架构\n空间流从静态视频帧中进行动作识别，而时间流从密集光流中学习。之所以将时间和空间分离，是为了有效利用imagenet进行预训练。从神经学的角度也可以得到一些解释：人脑视皮质(human visual cortex)包含两条通路，腹侧通路(ventral stream)执行目标识别，而背侧通路(dorsal stream)执行运动识别。\n\n\n光流convnet\n双流的主体在于光流convnet，其输入为堆叠的多个连续帧之间的光流位移场。如何去获取这个输入，文章提供了多种方法：\n\n光流 stacking\n\n轨迹 stacking\n上述两种光流可见下图，更能直观描述：\n\n\n左图将同一位置的x-y方向光流进行堆叠，而右图将沿着轨迹方向的所有位置的位移向量进行堆叠，公式如下：\n\n双向光流\n上述的两种光流位移场都是单向的，可以将其拓展为双向的，通过堆叠从t到t+L/2的前向光流和从t-L/2到t的反向光流可以得到输入体。\n\n去除平均光流\n为了对相机运动进行补偿，论文通过对密集光流计算全局运动部分（均值向量），并将其从位移场减去。\n\n\nMultitask Learning 多任务学习\n因为当时的视频数据集大小较小，所以作者考虑将多个视频数据集进行合并，但是因为有些类别是重复的。基于多任务学习的方法可以有效结合多个数据集。额外的任务（数据集）就像是正则化器一样，能够有效利用额外数据集。在这个场景中，双流架构修改为拥有两个softmax分类层，一个计算 HMDB-51 分类分数，另一个计算UCF-101 分数，每一个分类层都有自己的损失函数。总体训练损失为两个独立任务的损失之和，通过反向传播即可找到权重导数。\nfusion method 双流融合方法\n经典实验预训练的效果\n\n\n预训练带来的效果提升是巨大的，尽管数据集是图像数据集\n不同光流输入的效果\n\n\n有意思的是仅仅靠光流信息作为输入，他的效果就比spatial convnet效果好了，从一个侧面说明运动信息的重要性。还有个有意思的点，作者也实验了“slow fusion”网络，虽然比单帧效果好，但远没有光流效果好。但是这个实验侧面印证了多帧信息的重要性。\n额外数据集的效果\n\n可见，使用多任务学习的方法能够大幅提供hmdb-51数据集的精度。\n对双流网络的整体实验\n\n\n对于如何训练双流网络，作者提供了两种思路：在原网络的两个全连接层之后加一个全连接层，将两个网络的输出作以合并。或者融合两个网络的softmax分数（平均，或是线性softmax函数）。实验证明，svm作为融合方法是最佳的，且融合能大幅提高精度。\n对分类结果的分析\n\n混淆矩阵：\n\n各类的回归率：\n\n\n","categories":["论文阅读","行为识别"],"tags":["2D model","双流"]},{"title":"论文阅读笔记：“TSM：Temporal Shift Module for Effificient Video Understanding”","url":"/2023/08/05/paper-reading/paper_reading_021/","content":"TSM: Temporal Shift Module for Effificient Video Understanding\n对于实际部署来讲，硬件高效的视频理解方法十分重要。论文提出时也有一些方法，来tradeoff建模与计算量，但是论文提出，已知的方案牺牲了低级的时序建模以换取效率，所以一些重要特征的损失在所难免。\n\n核心亮点TSM模块\n\n\nTSM模块的额外计算在概念上是没有的，只有涉及数据移动的实际延迟，但该模块有很强大的时空建模能力\n\n时序局部平移策略：只平移一部分channels\n在何处使用TSM模块？在残差分支使用，不会对2D CNN的空间特征学习能力造成损害。\n\n\n\n为什么要平移？(卷积的替代)\n一维上讲，1D卷积可以分解为平移和乘加操作，形式化地可以表示为：\n\n\n因此，乘加操作就可以表示为：\n\n\n二维上沿空间维度平移，我对一维的思想做了延申：\n\n\n对于a12这个位置而言，平移和乘加操作的计算公式为：$a_{22}*w_{11}+a_{13}*w_{21}+a_{02}*w_{22}+a_{11}w_{12}+a_{12}{x}$，但是这个结果成十字形，与原先2D卷积相差较大。\n三维上沿时间维度进行平移，如下图所示：\n\n\n对于每一个插入TSM的模块，其时间感受野都增加了2，因此对其进行2D卷积时，就好像同时在时间维度进行filter size为3的卷积一样。\nTSM的好处不言而喻\n\n使用TSM模块可以把任意一个已有的2D网络模块变成伪3D模块，它能够同时持有空间和时间信息\n\n部署来讲是硬件高效且友好的，低延迟推理，低内存消耗，只需支持2D卷积操作即可\n\n支持在线推理，对于实时性要求高的应用很重要：\n\n\n对于前一帧的特征图，我们截取它的1/8并保存到内存中，在当前帧中用缓存的1/8的特征图替换当前帧特征图的对应部分。从图中我们可以发现，TSM是一种多层次的特征融合模块。\n\n\n实验结果基线对比\n\n\n从图中可以看出，对于时序关系相对重要的数据集，加入TSM模块之后的精度提升可达２位数的提升。\n泛用性证明\n\n\n对于不同的2D骨干网络，TSM模块的加入都能提升精度，即使对于NL R-50这种已具备时序建模能力的网络来说。\nstate-of-arts证明\n\n\n第一个区使用了late temporal fusion;第二个区域允许中级时序融合；第三个区域允许全层次的时序融合。\n精度-性能对比\n\n\n图中圆的面积代表参数量的大小，从图中可以看出TSM模型是精度高且效率高的。\n性能对比\n\n\n在线推理\n\n\n由图可知，TSM模块对于低延迟的实时推理十分有用。图二是仅观察一部分的帧后的预测精度，可以看出TSM模型提早预测的能力较强。\n","categories":["论文阅读","行为识别"],"tags":["2D model","TSM"]},{"title":"论文阅读笔记：“Learning Spatiotemporal Features with 3D Convolutional Networks”","url":"/2023/08/05/paper-reading/paper_reading_022/","content":"Learning Spatiotemporal Features with 3D Convolutional Networks\n这篇文章提出了C3D模型，成为了之后研究的基础性原型，值得注意的是作者使用了一系列可视化方法对C3D学习到的特征进行可视化，对于今后的模型的研究可能会有所裨益。\n\n核心思想特征的紧凑性：compact\n使用PCA将特征降低到低维度，通过线性SVM得到低维度特征在数据集上的分类精度：\n\n\n特征的泛用性：generic\n通过在其他数据集上进行可视化，使用了t-SNE方法，将得到的fc6特征投影到2D空间里：\n\n\n从图中可以看出，特征嵌入在其他数据集上的表现良好 \n模型结构","categories":["论文阅读","行为识别"],"tags":["3D model","C3D"]},{"title":"论文阅读笔记：“Convolutional Two-Stream Network Fusion for Video Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_024/","content":"Convolutional Two-Stream Network Fusion for Video Action Recognition\n这篇文章贵在思路清晰，整篇文章的问题引入及脉络在引言就已经很精彩了，很值得学习借鉴\n\n这篇文章引言其实就是再说，当前领域比起image领域并没有较大成就，原因可能在于数据集过于noisy或者是模型能力不足（提出了一些猜想），之后说之前提出的双流架构还有诸多问题，一是无法将表观的位置线索同时间线索相互匹配，并且无法对这些线索沿时间的变化进行表示（或者说时间感受野太小）。然后作者就在下文依次探索了如何在考虑位置的情况下去融合两个网络，在哪里融合这两个网络以及如何在时间维度进行融合。\n核心亮点空间融合 Spatial fusion 方法搜索\n\n加法融合\n\n最大值融合\n\n连接融合\n\n\n\n\n\n卷积融合\n双线性融合\n\n\n\n\n\n\n逐点乘积融合\n\n这些方法都很直观，对比在下文的实验部分有讲到\n网络结构\n\n这个网络结构的输入为T个帧，帧间隔为t，时间感受野从之前的L=20扩展为现在的T*L。 融合这些特征图的方法为3D conv 加 3D pooling，但是融合后并不截取光流这一路，因为保留它的效果更好：\n\n\n实验结论不同融合方法的比较\n\n\n从图中可以看出，简单的sum进行融合效果就已经很不错了，使用conv来融合两个网络效果更好。\n在哪个位置进行融合的比较\n\n\n从图中可以看出，越晚融合效果越好，并且不涉及较早layer的多层融合的效果最好：\n\n\n缺点是这种方法会近似增加一倍的参数量，有点得不偿失。\n不同时序融合方法的比较\n\n\n\n\n由表可得，3D卷积融合+ 3Dpooling效果最好。\n","categories":["论文阅读","行为识别"],"tags":["3D conv & pooling","fusion method"]},{"title":"论文阅读笔记：“Dynamic Image Networks for Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_023/","content":"Dynamic Image Networks for Action Recognition\n这篇文章先后发表在了CVPR和TPAMI上，DI可以尝试作为新的输入模态来提高精度\n\n核心思想动态图像\n\n它就是一个总结了表观和动态信息的标准RGB图像\n\n\n\n构建的思想为将视频表示为一个针对它的帧（）的排名函数\n从每一个单独的帧It中提取的特征向量表示为，用Vt表示直到时间t这些特征的一个时序均值，表示为，排名函数为每一个时间关联了一个分数，这个d就是需要学习的参数，它反映了视频中帧的一个排名。而学习d是一个凸优化问题：\n\n\n这个公式的本身意义很清楚：越往后的帧会被赋予更大的得分，公式中通过折页loss来表示，但要想在深度学习模型中使用，作者提出了一种近似方法。\n作者不像之前论文中对局部特征的fisher vector编码去进行一个排名池化，而是之前应用于像素。于是提取的特征向量表示即为图像中每一个pixel每一个RGB通道的堆叠后的一个大向量。学习得到的参数d*与普通的单帧具有相同数量的元素，并且可以被解释为一个标准RGB图像。动态图片实际上就是通过对整个视频中像素强度沿时间维度进行集成和重排序。\n动态特征图\n对动态图像的拓展，即我们可以对中间特征图进行rank pooling并得到动态特征图：\n\n\n近似排名池化 approximated rank pooling\n作者提出了的近似排名池化方法可以插入到CNN网络的中间层，并允许反向传播，提高了rank pooling的泛用性：\n\n\n文章还提出了一种线性计算权重系数的方式：，对比如下图所示：\n\n\n实验效果ResNeXt-50消融实验\n\n\n动态图像较视频序列均值图像等优越性\n\n\n近似排名池化与排名池化的对比\n\n\n动态图像是对静态图像的补充\n","categories":["论文阅读","行为识别"],"tags":["Dynamic Image","rank pooling"]},{"title":"论文阅读笔记：“A Hierarchical Deep Temporal Model for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_026/","content":"A Hierarchical Deep Temporal Model for Group Activity Recognition核心亮点层次模型\n\n\n如图，该模型逻辑上分为两个阶段，第一个阶段预测单人级别的行为，第二阶段收集第一阶段获得的行为隐变量，并希望对整个场景的行为进行建模，即组行为预测（这里默认同一个场景内的所有人为一组）。\n第一阶段预测单人行为识别，通过CNN提取基于图像的特征，将特征序列作为输入传给LSTM网络：\n\n\n其中ht为隐变量。第二个阶段，先对所有人的隐变量进行池化，再将全局信息送入LSTM网络学习组级别的动态信息，它的输出隐变量再输入softmax分类层得到分类结果：\n\n\n第一个公式代表连接空间特征和时序特征，第二个公式对同一帧的所有人进行max pooling。\n实验结果baseline消融实验\n\n图像分类模型：使用调优的model对单帧进行组行为识别\n组分类模型：对于单帧输入，使用model得到fc7特征，并对其进行池化后，送入softmax分类器来进行组行为识别\n调优组分类模型：对每一个人提取特征的model是经过调优了的，其他部分与组分类一致\n图像特征时序模型：第一个baseline的时序拓展\n组特征时序模型：第二个baseline的时序拓展\n不带第一个LSTM层的双阶段模型（忽略person-level时序模型）\n不带第二个LSTM层的双阶段模型（忽略group-level时序模型）\n\n\n\nstate-of-arts对比\n\n\n\n\n论文提出了一个新的volleyball数据集\n\n\n文章也说了，这个数据集是一个很有挑战性的数据集，因为能够决定组行为类别的个人行为类别，在数据集中较少出现。作者在这个数据集上进行实验：\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","LSTM","hierachical model"]},{"title":"论文阅读笔记：“Temporal Segment Networks： Towards Good Practices for Deep Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_025/","content":"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition（ECCV 2016）引言分析\n先从引言开始分析，分析文章的写作思路，说不定对写论文有所裨益，但这篇毕竟较早，所以主要是学习做研究的思路和核心方法。\n\n作者首先说明了如何去提取视频相关信息（表观和动态信息）并不简单，受：\n\n规模变化\n视角改变\n相机移动\n\n等因素影响。之后作者说明了现状：深度学习方法并不比传统方法好多少，并分析了卷积网络受阻的原因：\n\n缺乏对长时序建模的架构\n数据收集和标准较为困难，而卷积网络需要大量训练样本进行学习\n\n因此，文章针对上述问题提出了对应的解决方案：\n\n设计一个能够对长时序进行建模的有效且高效的视频级别的框架\n如何在训练样本受限的情况下让卷积网络进行学习\n\n作者认为，连续帧之间包含较多重复，因此密集时序采样是不必要的。因此作者采用了稀疏时序采样策略（所需的计算资源会相对较少），并设计了时序段网络（TSN）。对于数据量较少的问题，作者通过三种方式来解决：\n\n跨模态预训练 cross-modality pretraining\n正则化\n加强了的数据增强\n\n核心思想short snippets sequence 小片段\n从整个视频里稀疏采样的小片段，每个short snippets都会产生一个动作类别的预测。紧接着，段共识函数(求平均)将多个snippets的输出进行结合以得到一个关于类假设的共识。基于这个共识，预测函数(softmax)即可预测视频属于每一个行为类别的概率。\n新的输入模态\n\nRGB difference\n\n相邻两帧间的RGB difference可能与运动主导的区域相关。\n\nwarped optical flow fields(扭曲光流场)\n\n相机运动可能会对光流场造成影响\n跨模态预训练技术\n实际上是描述了怎么对于光流输入的temporal卷积网络的第一个卷积层进行初始化。\n防止过拟合\n\npartial Batch Norm，固定除了第一个BN层外的所有BN层。\ndropout，加入BN-inception的全局池化层之后。\ndata augmentation，包括随机裁剪，水平翻转，shape抖动，以及角裁剪。\n\n网络结构\n\n如图，该结构基于双流结构，本质上是2D模型。\n实验结果训练策略对于精度的影响\n\n\n不同输入模态对于精度的影响\n\n\n从图中可以看出，RGB difference有时不太稳定，所有模态数据在一起时反而会会降低精度。\n不同段共识函数对精度的影响\n\n\n不同深度网络架构对精度的影响\n\n\n对于长时序进行建模的重要性\n\n\n网络可视化\n\n论文使用了DeepDraw [42] toolbox来对网络效果进行可视化\n\n\n\n从图中可以看出，预训练对于捕获结构化视觉模式有一定帮助，同时对长时序进行建模也使得网络更关注运动的人而不是其他客体。\n","categories":["论文阅读","行为识别"],"tags":["2D model","Long time range modeling"]},{"title":"论文阅读笔记：“Real-world Anomaly Detection in Surveillance Videos”","url":"/2023/08/05/paper-reading/paper_reading_027/","content":"Real-world Anomaly Detection in Surveillance Videos\n这篇文章写得巨好，看完有种“原来是这样”的感觉，不愧是顶刊的文章。之所以看视频异常检测的文章，一方面是想深挖行为识别方向的具体应用，让研究方向变得更细一些。另一方面是群体行为检测和异常行为检测之间有着密切联系，希望能够触类旁通，将这两个任务结合起来。\n\n核心亮点多实例学习 Multiple Instance Learning（弱监督学习）\n这篇文章的写作手法真的很循序渐进，首先向我们介绍了标准的有监督分类任务的SVM优化函数：\n\n\n但是在有监督异常检测的情景下，分类器需要视频中每一个段的标注，但是对这种视频进行标注真的很浪费时间和人力。所以提出了MIL，它可以放宽对标注的要求，只需要对视频级别做标注即可，我们不需要知道异常行为的发生位置及时间点。因此我们可以将异常视频看作一个positive bag，视频的不同时序段组成了包中的个体实例。因为严格的正实例是未知的，所以我们可以选择scores最高的实例来对目标函数进行优化：\n\n\n介绍了什么是多实例学习之后，作者使用了ranking的思想，将深度模型与MIL相结合，提出了 Deep MIL Ranking Model，如下图所示：\n\n因为异常检测的模式检测可能性较小，因此作者将异常检测问题当作了回归问题，希望异常的视频片段比起正常片段具有较高的异常分数。使用一个排名损失函数(rank loss)可以鼓励异常行为片段具有更高的分数：，对段级别标注未知的情况下可以使用将其修正为：\n\n\n论文中只让正常和异常bag中包含的最大分数的实例进行排名，其实也很好理解。因此hing-loss的数学形式化表达如下：\n\n\n但是这种loss也有缺陷，它忽略了视频里的长范围的时序关系。首先，在异常视频中，异常往往只发生在一小段时间内，所以异常分数应当尽可能的稀疏，其次，视频中的段是连续的，因此异常分数在相邻段之间也应变化得较为平滑。对loss进行优化后，损失函数变为了：\n\n\n最终完整得目标函数即为：\n\n\n其中，W指的是模型权重。\n提出新数据集\n\n\n就算只是1900个视频，完成收集和标注也需要数人数月的努力。\n\n\n各个异常类的视频数如上图所示。\n\n\n数据集关于时间的分布如上图所示。\n实验结果与state of arts方法的对比\n\n\n\n\n实验证明，提出的方法在更低假阳率的情况下具有更高的真阳率。而且传统的行为识别方法Binary classifier不能直接拿来用于异常检测，因为异常行为的持续时间相比起整个视频而讲很短。\n对于提出方法的分析\n\n\n上图为随着训练迭代数的增加，异常得分的变化曲线，可见在未知段级别标注的情况下，网络依旧可以预测异常的发生时间。\n\n\n从错误预警率也可看出该方法超越了state of arts方法。\n扩展任务：异常行为识别\n\n\n\n\n作者在提出的数据集上使用C3D和TCNN进行了实验。可以看出实验结果很差，原因可能是数据集较长未裁剪，并且分辨率较低，还有较大的相机视角移动以及光照，背景噪音所产生的较大类内差异。\n","categories":["论文阅读","视频异常事件检测"],"tags":["MIL","Anomaly Detection"]},{"title":"论文阅读笔记：“Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks”","url":"/2023/08/05/paper-reading/paper_reading_029/","content":"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\n这篇文章其实挺简单的，思路和很多的顶会略有重合，注意比较他们之间的差异\n\n核心亮点P3D 块\n\n\n论文提出将3D卷积解耦为编码空间信息的2D空间卷积和编码时间信息的1D时间卷积。上图是作者设计的三种不同的P3D块，之后基于这三种P3D块，作者加入了bottleneck设计：\n\n\n这种设计可以有效减少计算复杂度。\n结构多样性\n论文提出的P3D Resnet混合了上面的三种P3D块：\n\n\n这种设计思路是由在深度网络种追求结构多样性的成果实践启发而来的。如图我们在P3D网络中对上面的三种结构循环使用，对比实验如下表所示：\n\n\n实验结果在Sports-1M上进行对比实验\n\n在三种不同的任务上验证P3D学习的视频特征\n\n\n未来可以加入光流输入来增强P3D的分类能力。\n学习到的特征的稳定性\n\n\n学习到的特征的区分能力\n","categories":["论文阅读","行为识别"],"tags":["3D model","p3d"]},{"title":"论文阅读笔记：“Non-local Neural Networks”","url":"/2023/08/05/paper-reading/paper_reading_030/","content":"Non-local Neural Networks引言分析这篇论文提出了非局部化操作(non-local)作为可以捕获长期依赖的基础搭建块。文章首先谈到了诸如卷积和循环神经网络的方法都只能对其近邻进行处理，有着计算复杂、难以调优、不能进行多点依赖建模(multi-hop dependency)，之后谈到了使用局部化操作的好处：能捕获长期依赖、高效、不会改变输入大小、即插即用。然后，作者将局部化操作应用于视频分类的任务中，一个单独的non-local块可以直接捕获时空依赖。为了说明非局部操作的泛用性，作者在目标检测和分割，姿态估计等任务上做了实验，都取得了不错的效果。\n核心亮点non-local 块\n理解non-local块的前提是理解非局部操作：\n\n\n简单来讲，它计算的是第i个位置与其他所有位置的关系，进行求和与归一化后的值。在我的理解看来，就像是两个位置的关系进行建模，而是这个关系的权重。\n论文简单的只考虑了g作为线性嵌入的情况。二元函数f的选择是论文讨论的重点：\n\n高斯: \n嵌入高斯: \n点积: \n连接: \n\n文章还说明了自注意力模块与嵌入高斯版的非线性操作的异同，他们的最终形式是一样的：。但是作者拓展得到时空非局部网络能够处理多样的输入，具有泛用性。下面简单推导了一下：\n\n\n值得注意的是y是yi的向量，而每一个yi又是划线式子的点积，因此若要转换成向量化操作也很容易(p.s. softmax函数里的式子是没有底数e的，手误)(我记得cs231n有讲softmax向量化操作)。\n之后搭建non-local块有意思的点在于如何将非局部化操作融入进去，作者将non-local块形式化地定义为：。实际上即使用了残差连接，它有诸多好处：\n\n能够让我们将新的non-local块插入任何预训练模型但不改变他的任何行为，只需将初始化为0即可。\n而是可以增强特征（+）, 同时防止梯度消失。\n\n具体的non-local块结构图如下所示：\n\n\n难以理解的点在上文均以阐述，这里需要注意的是论文使用$111的卷积来进行嵌入，他的另一个作用是可以将计算量减少一半。还可以使用子采样的技巧进一步降低复杂度：在\\phi,g$后加一个max_pooling层，可以令计算更加稀疏。\n网络结构2D baseline\n之所以以2D为baseline，是为了隔离时间建模因素对模型的影响，网络结构如下图所示：\n\n\n这个baseline只是简单地聚合了时间信息\nI3D\n我们每两个残差块inflate一次卷积核：从$kktk*k$\nNon-local network\n实验结果non-local块的f函数的选择\n\n\n由实验可以看出f函数的选择对精度的影响不大，为了方便作者选择了嵌入高斯。\n加入non-local块的位置选择\n\n\n如图，加入到3，4 stage都是合适的\n加入non-local块数的影响\n\n\n而且该实验也证明了精度的提升并不全部来自网络深度的增加\n时间-空间-时空维度的non-local操作对模型的影响\n\n\nnon-local与3D模型的对比\n\n\n上表展示了两种对时间建模的方式比较，可见 C2D+5 non-local块对于网络的精度提升最高，同时其计算量更少。\nnon-local与3D conv的互补性\n\n\n更长的输入对网络的影响\n\n\n与state-of-arts的对比\n\n\n从中可见，NL-I3D模型没有使用flow和audio信息，但是它的精度却超过了那些使用了的方法。\n","categories":["论文阅读","行为识别"],"tags":["NL块"]},{"title":"论文阅读笔记：“Hierarchical Relational Networks for Group Activity Recognition and Retrieval”","url":"/2023/08/05/paper-reading/paper_reading_028/","content":"Hierarchical Relational Networks for Group Activity Recognition and Retrieval(ECCV 2018)一句话概括这篇文章的要点在于对场景内的人的结构化关系进行建模，提出了层次式的关系网络，并在监督和非监督的应用中使用了这个模型。\n引言分析首先文章将来人类行为识别有多么多么难，人群行为识别是在什么情境下产生的，现在这个方向面临着什么什么挑战。为了解决了这个问题，作者提出了一个多么多么牛逼的模型。\n然后说，目前的人群行为识别基本都是两阶段模型，第一阶段首先得到每个人的特征表示，第二阶段就是将这些表示统统结合起来构建一个场景的最终特征表示，最后送入分类器进行分类。但是目前这些场景池化方法都不可避免地损失了重要信息：首先空间位置信息和关系信息被丢失，其次个人的特征(从某种程度上对人群行为而讲有巨大影响)也没有保持。因此，作者提出了层次式的关系网络，尝试对以上问题进行解决。\n核心亮点关系层 relational layer\n\n\n简而言之，对于每一个人，将其与和他相邻的所有结点（需要已知关系图结构）进行连接，并送入多层感知机进行处理，将处理得到的所有关系进行相加来聚合关系信息。关系层不仅可以编码关系信息，还可以压缩信息维度。下图清楚地解释了每一个人的处理过程：\n\n\n对relational autoencoder进行去噪\n若人检测器检测失败，相机移动，低相机分辨率等原因导致了某些人在场景中丢失了，论文提出了一种去噪方法，那就是在训练时丢掉K个特征向量中的某些个向量，实现即在输入层之后加一个dropout层即可。\n网络结构\n\n每一层相同颜色的特征向量为一个连通分量。如图所示，该网络结构堆叠了三个关系层，每层都将特征维度减少了一半，最后对最终的关系表示进行池化。每层每个人的特征计算形式化表示如下：\n\n\n应用于人群行为识别方法\n将每一帧的场景表示St送入LSTM层进行处理并将结果送入softmax层进行预测。但是池化的过程中，个人的信息被总体抹去了，所以LSTM的作用时间上是对于整个场景的时序进行建模。\n从这里也可以看出这个方法的一个缺陷，那就是只对关系而没有对个人的时序进行建模，而且对于关系的建模我觉得只是concate+mlp其实有点粗略。\n应用于行为检索方法\n对每一个检测框进行标注及其浪费时间，作为替代，我们可以利用使用无监督的autoencoder机制来学习场景中人的特征表示。可以通过比较这些基于关系和情景的表示，我们即可对某个人的行为进行检索，或是对整个场景进行检索。\n关系autoencoder模型如下图所示：\n\n\nrelational autoencoder模型首先使用了两个relation layer进行encode，接着使用了两个inverse relation layer进行decode。输入场景和重建后的场景特征的重建损失如下：\n\n\n注意，这个行为检索的方式不是检索具有总体行为的场景，而是检索具有相同行为场景结构的场景。论文使用了KNN最近邻算法来检索行为视频数据库。\n实验结果群体行为分类消融实验\n\n\n经过比较，推理关系表示对于精度的提升有一定作用，但是因为没有时序方面的信息，所以模型并没有state-of-arts的精度高。\n行为和场景检索消融实验\n指标：IoU(判断两个帧的类别分布是否匹配)\n\n\n\n\n上表说明，relational或是context信息对于情景检索十分重要。\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","LSTM","hierachical model"]},{"title":"论文阅读笔记：“Squeeze-and-Excitation Networks”","url":"/2023/08/05/paper-reading/paper_reading_032/","content":"Squeeze-and-Excitation Networks(2019)引言分析之前的行为识别研究主要是针对时空依赖，时空注意力进行建模（模块设计），去改进现有的一个网络架构。这篇文章从通道的角度研究了一种不同的网络设计方法。\n核心亮点SE-Block\n\n\nSE块可以显示地对通道之间的相互依赖进行建模，以得到一个更好的特征表达。这个模块做的实际上就是特征重标定，通过利用全局信息去选择性的增强有用信息并抑制无用信息。如图所示，该模块分为了两个操作：squeeze(挤压)和excitation（激活）。squeeze操作实际上就是沿着空间维度聚合特征图，得到一个沿着通道维度全局分布的特征响应。excitation是一个门控机制，以embeddings为输入，产生一个每个通道的权重集合。\nSqeeze：空间信息聚合\n\n\n这里的squeeze操作作者采用的是全局平均池化，来生成每个通道的统计数据。\nExcitation：自适应重标定\n\n\n论文采用了一种简单的门控机制来进行重标定，因为s是通道权重的集合，SE块也是固有地引入了基于输入的动态性，所以也可以看作基于全局通道的自注意力机制。\n将SE模块融入现有的模块中\n\n\n网络结构\n\n如图在每个残差块的尾端加入SE块\n实验结果加入SE模块的效果与网络深度的关系\n\n\n如表所示，resnet-152的 top-5 error高于SENet-101的top-5 error，证明了SENet的精度增长不仅仅是由深度带来的，而且深度越深，精度越高，证明使用SE块和增加深度是相互补充的。\n与现代架构进行集成的效果\n从上表和下表可以看出，将SE块融入主流backbone可以显著提高精度。\n\n\nSE块的泛用性不限于网络架构也不限于数据集\n\n\n可以看出，对于其他数据集，分类精度也有显著提高。\nSE的泛用性也不局限于图像分类任务\n作者在场景分类、目标检测任务上进行了实验，结果均有提升：\n\n\n与state-of-arts的对比\n\n\n消融实验1：缩减比率对于SE-ResNet50的影响\n\n\n消融实验2：squeeze操作符对精度的影响\n\n\n消融实验3：excitation操作符对精度的影响\n\n\n消融实验4：SE块的集成阶段对精度的影响\n\n\n消融实验5：SE块的集成的具体位置对精度的影响\n\n如上图，作者设计了不同SE模块插入位置的集成块，实验结果如下表：\n\n\n值得注意的是，mobilenetV3的创新点之一和table15所做的实验是重合的，但是这里只是简单说将SE模块可以放入残差块里，mobilenetV3做了充分的实验对其进行验证和补充。\n","categories":["论文阅读","图像分类"],"tags":["architecture design","SE块"]},{"title":"论文阅读笔记：“Attention Is All You Need”","url":"/2023/08/05/paper-reading/paper_reading_033/","content":"Attention Is All You Need(2017)\n阅读这篇文章的原因是之前读的两篇SE块和non-local块都使用到了自注意力机制，所以想通过这篇论文深入了解一些其中的原理，并与之前读的两篇进行比较和总结。\n\n核心亮点Scaled Dot-Product Attention 缩放点乘注意力 \n\n\n如图为注意力的流程模块图，形式化表达如下：\n\n\n从图和公式可以看出，Q与K首先做了一个矩阵乘法，如果说两个位置的距离越接近，所得到的点积结果也会越大，所以这个它其实计算的是每一个位置的embedding和其他所有位置的embedding的匹配程度，这个值越高说明这两个位置的嵌入越接近。然后经过softmax得到概率意义上的attention权重，再将这个W与V进行矩阵乘法。这个过程实际上是对每个特征维度上利用，某一位置对其他所有位置全局信息来对特征进行优化。\n与SE模块的联系\n这个思想与SE模块有着异曲同工之妙。SE模块是利用重标定的通道全局信息来对特征进行优化。上面的注意力形式正是利用全局信息的有效范例。\n与non-local块的联系\n从最终的主要形式上讲，non-local块和上面的attention机制就是同一个东西，只不过，non-local块对缩放点乘注意力进行了扩展，使之适用于任何大小，维数的输入。另外non-local块还增加了残差链接。\n多头注意力\n\n\n形式化描述如下：\n\n\n使用多头注意力可以是模型注意到不同表示子空间不同位置的信息。其中concat是沿特征维度进行的，concat之后与W进行的矩阵乘法实际上是对不同head的信息进行聚合aggregate\n网络结构\n\n注意，解码器有两个attention层，第一个是进行自注意力的计算，需要mask未来信息；第二个attention层利用input的输出对output的特征进行优化。\n","categories":["论文阅读","图像分类"],"tags":["architecture design","transformer","attention"]},{"url":"/2023/08/05/paper-reading/paper_reading_034/","content":"A simple neural network module for relational reasoning(2017)"},{"title":"论文阅读笔记：“A Closer Look at Spatiotemporal Convolutions for Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_031/","content":"A Closer Look at Spatiotemporal Convolutions for Action Recognition核心亮点时空卷积 new form spatio-temporal convolution\n\nmixed convolution\n\n3D卷积在网络的早些层，2D卷积在网络的后面的层\n\n(2+1)D 卷积块\n\n与P3D类似，这篇文章也是将3D卷积分解为一个2D空间卷积和一个1D时间卷积。这样做的潜在好处为：\n\n减少了参数量，更容易训练和优化\n激活函数增加了一倍，网络更容易表示复杂的函数\n\n与P3D的区别\nR(2+1)D只使用了单一类型的块，并且并不包含瓶颈设计，但是通过对（分解）维度的仔细选择（P3D只说了分解，但没说怎么对维度分解），它较P3D 的精度提高了9.1%，并且相较于152层的P3D，R(2+1)D只有34层。\n\n\nR(2+1)D卷积块\n它将个大小为$N_{i-1}tdd卷积核分解为M_i个大小为N_{i-1}1dd的卷积核核N_i个大小为M_it1*1的时间卷积核。因此M_i作为决定中间子空间（信号从空间卷积到时间卷积的投影）维度的超参。那么这个M_i$该如何选择呢？\n\n\n这样设计之后，参数数量是基本一致的，分解的过程如下图：\n\n\n实验结果对比多个不同的网络架构\n\n\n精度与模型复杂度的关系\n\n\n精度与输入帧数的关系\n\n\n既然明确了精度和输入帧数之间存在trade-off，我们应该如何对其进行权衡呢？\n\n\n论文发现，在较短输入进行训练，再在较长帧上进行finetune会比较好。\n\n使用64个gpu，真的说明目前的网络真的不好训练，并且还有值得优化的空间\n\n与state-of-arts的比较\n\n\n\n\n迁移学习\n\n\n","categories":["论文阅读","行为识别"],"tags":["3D model","r(2+1)d"]},{"title":"论文阅读笔记：“Learning Actor Relation Graphs for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_035/","content":"Learning Actor Relation Graphs for Group Activity Recognition(2019)引言总结分析组行为识别不仅需要描述场景中每个人地个体行为，还要推理出他们群体性地行为。所以对人与人之间的关联关系进行准确建模，并进行关系推理对于理解多人的群体行为是十分重要的。然而对这些人之间的关系进行建模是十分有挑战性的，因为我们只能够获取到个体行为标签和集体行为标签，对隐藏其下的相互作用信息没有足够的知识。论文提出可以通过其他方面：诸如表观相似性、相对位置来对人与人之间的关系进行推理。之后论文说目前提出的模型基本都是两阶段的模型，存在计算复杂度高，对于组行为的变化缺少灵活性等问题，针对这些问题论文提出了端到端的模型。与之前的模型不同，图的连接信息可以直接地从视频中学习得到。论文通过构建一个角色关系图ARG对人与人之间的关系进行建模。\n\n\n如上图，图中的每一个结点代表每一个人的特征，图中的边表示两人之间的关系。\n网络结构\n\n整体框架可以分为三步：首先，作者均匀地从视频中采样K帧，并从采样的帧中提取角色的多尺度特征图，应用RolAlign来提取每个角色bounding box的特征，将特征送入fc层以得到一个d维的表观特征向量。\n之后，利用这些原始特征，论文构建了角色关系图。为了能表达多样的关系信息，作者对同一角色特征集合构建了多幅ARG。\n最后，作者利用GCN来基于ARG进行关系推理，之后ARG会被融合起来以生成角色之间的关系表示，并通过分类器来分别识别个体和群体信息。\n\nps. 我一开始理解错了，其实N不是场景内人的数量，而是所有帧中bounding box的数量\n\n核心亮点构建ARG\n\n图的定义\n\n\n\nG中的每个位置其实表示的是j角色的特征对于i角色特征的重要性，上面的公式通过h函数来根据表观联系和位置关系计算边权\nh函数的具体形式如下：\n\n\n\n表观联系\n\n点积：\n\n\n\n\n嵌入点积：\n\n\n\n\n关系网络：\n\n\n位置关系\n\n距离掩膜：\n\n\n\n\n距离编码：\n\n\n\n时序建模\n\n稀疏时序采样\n数据集较小，容易过拟合\n\n\nlate fusion\n\n上面两种时序建模方式能够在尽可能少的花费下，尽量保持时序信息\n使用GCN进行关系推理\n\n\n其中，G就是前一步构建的ARG，W是权重矩阵，Z是输入，我们可以堆叠多个GCN层，为了效率论文中只使用了一层GCN。\n对多个图的推理结果进行融合\n\n\n论文其实就是简单的逐元素相加。当然我们也可以考虑concate，最大值融合，conv融合，逐点乘积融合等多种融合方案。\n损失函数\n\n\n该损失包含了个体行为分类损失和群体行为分类损失\n实验分析消融实验\n判断论文提出的框架的各个模块对最终的精度的影响\n\n不同表观联系函数\n\n\n不同位置联系函数\n\n\n不同数量ARG图\n\n\n不同ARG图融合方法\n\n\n不同时序建模方法\n\n\nstate of arts 对比\n\n可视化ARG图可视化\n\n\nt-SNE 可视化\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","ARG","GCN","relation reasoning"]},{"title":"论文阅读笔记：“Spatio-Temporal Dynamic Inference Network for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_036/","content":"Spatio-Temporal Dynamic Inference Network for Group Activity Recognition(iccv 2021)引言分析GAR激起了研究兴趣因其广泛的应用：安保/运动视频分析，社会场景理解等。目前提出的主要模块都包含了时空交互因素以得到行为特征。如何对主体的相互作用进行建模也得到了广泛的研究。主要包括RNN，注意力机制和GNN。目前GNN已成为GAR中经常采用的算法，它在构建的语义图上来传递信息。但是之前使用GNN的方法对个体之间的交互均在预定义的图上进行建模。这种方法可行，但有着很多缺陷：\n\n与给定主体交互的那些客体应该是主体特有的，或者说针对主体的，而不应该是预定义的。而一个预定义的图并不适合所有人的关系推理。\n之前预定义的图模型在一个全连接或是十字交叉的图上来对交互关系进行推理。它很容易导致过平滑(over-smoothing)，令特征难以区分。而且在长视频剪辑或是场景中有很多人的情况下，会导致极高的计算复杂度。\n\n\n\n如上图，a、b、c分别代表全连接图推理、十字交叉图推理和所提出的针对人的自适应的动态图推理。这种动态图推理对于每一个要更新的绿色结点来说，都是独特而唯一的。\n网络结构图\n\n上图是作者提出的框架：动态推理网络(DIN)。从逻辑上可以分为时空特征提取和推理模块两部分，第一部分得到的是个体特征的集合。论文提出的DR和DW模块动态地对每个特征预测一个特定的交互关系图。根据这些图我们可以对特定特征进行更新。\n核心亮点\n动态关系 Dynamic Relation\n这里的动态指的是，关系矩阵仅仅依赖于初始化的交互场中的特征。所依赖的特征不是固定的，而是动态变化的。\n\n\n上面是计算第i个特征关系矩阵的表达式。这个算法和ARG的差异很大。这个应该是可变形卷积，之后再读相关论文进行理解。\n\n\n上面的特征更新表达式从形式上与ARG的图卷积层是基本一致的，区别主要在于范围一个是K，另一个是T*N。\n动态漫游 Dynamic Walk\n论文的目的是通过DW模块来对复杂的时空依赖进行建模，它只使用了大小局限的交互场。首先，对于给定的第i个个体特征，我们要预测交互场范围内的时空动态漫步偏移量，其中 为线性投影矩阵，为所有交互场内堆叠起来的特征向量。得到漫步偏移量后，动态漫步的特征的计算公式如下：\n\n\n其中，为第i个交互场的第k个特征的坐标。\n结合DR和DW\n\n\n同过上式我们可以结合DR和DW来进行动态更新。\n实验结果消融实验\n\n\n论文进行消融实验来说明提出方法的有效性。MCA和MPCA分别代表，分类准确率和平均类准确率。\n代码阅读整体的训练代码包含了两个阶段。第一阶段微调一个backbone，使之可以适应Volleyball数据集；第二阶段是训练+动态推理。\n第一部分利用action loss和activity loss来学习模型。模型的架构图如下所示：\n\n\n参数数量，及所占内存如下：\n\n\n第二阶段动态推理的模型框架图如下所示：\n\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","relation reasoning","DIN","Dynamic relation"]},{"title":"论文阅读笔记：“Dual-AI： Dual-path Actor Interaction Learning for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_038/","content":"Dual-AI: Dual-path Actor Interaction Learning for Group Activity Recognition(cvpr 2022)\n\n引言分析通常对于联合的空间和时序信息信息进行优化比较困难，因此目前GAR的方法往往对时空注意力进行解耦。如图所示，这篇文章提出解耦的顺序对于不同的分类类别影响较大。基于这个发现，作者针对GAR提出了独特的双路角色交互框架，它可以有效地对两种互补的时空观点进行集成，从而能够学习视频中复杂的角色关联。此外作者提出了一个创新的损失函数：MAC-Loss（多尺度角色对比损失）。它可以提供一个简洁但有效的自监督信号，以增强两个通路之间的角色一致性。\n核心亮点Dual-AI框架\n\n\nDual-AI包含了时间空间交互通路(TS)和空间时间交互通路(ST)。其中的基本单元（spatial actor transformer &amp; temporal actor transformer）可以用来描述空间和时间联系。\n\nspatial actor transformer\n\n\n\n第一个式子加入了空间位置编码，以加入场景中角色的空间结构信息。第二个式子使用了多头自注意力机制(MHSA)来对场景中的角色位置信息的交互进行推理。第三个式子加入了前馈网络来进一步增加计算单元的学习能力。\n\ntemporal actor transformer\n\n与空间不同，时间trans的输入是，并且使用的是时间位置编码(TPE)\n有了这些基本单元，我们就可以用他们来构造角色演变的时空表示，构造方法如下：\n\n\nMAC-Loss\nMAC-Loss可以通过帧-帧、帧-视频、视频-视频三个级别的角色一致性来有效增强特征辨别能力。它可以将两个相对独立的通路之间的合作进行增强\n\n\n\n帧-帧角色对比损失\n\n对于一个通路上的帧表示，它应该与另一条通路上的帧表示相类似，但是与那条通路上的其他帧表示相区别。\n\n\n\n帧-视频角色对比损失\n\n对于一个通路上的帧表示，它应该与另一个通路上的对应角色的视频表示相一致，与那条通路上其他角色视频表示相区别\n\n\n\n视频-视频角色对比损失：\n最终的MAC-Loss为：\n\n\n\n\n训练目标：\n该框架可以端到端地对个体行为和组行为进行预测，通过结合交叉熵损失，最终的分类损失为：\n\n\n\n\n最终作者结合所有的损失来训练他们的Dual-AI框架：；推理时，对两个通路的预测进行加权平均即可。\n实验结果SOTA对比\n\nvolleyball数据集\n\n\n\n\ncollective数据集\n\n\n\n弱监督场景\n\n\n少样本场景\n\n\n消融实验\n\n双通路设置\n\n\n\n\nMAC-Loss\n\n\n\n\n场景信息\n\n\n\n可视化\n\n组特征可视化\n\n\n\n时空角色注意力可视化\n\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","transformer","MAC-Loss"]},{"title":"论文阅读笔记：“Detecting events and key actors in multi-person videos”","url":"/2023/08/05/paper-reading/paper_reading_039/","content":"Detecting events and key actors in multi-person videos(2016)\n这篇论文算是该领域开创性的一篇论文\n\n引言分析组行为识别问题，往往只涉及一些关键角色，他们主导或决定了整个行为事件。但是确定哪些角色对于该事件较为重要，这种标注首先很昂贵，并且往往设计不需要这种具体标注的模型。所以该论文提出了一个新的视角，即对关键角色行为识别的一个弱监督问题。该论文进一步在群体行为识别中应用了注意力机制\n核心亮点NCAA Basketball Dataset\n\n\n\n\n事件检测\n每个视频帧都可以表示为1024维的特征向量ft，对于帧中的每一个角色都可以计算2805维的特征向量。\n\n\n首先可以计算每帧的全局场景特征:\n\n\n然后使用单向LSTM来表示某事件在时刻t时的状态\n\n\n之后，我们就可以使用来预测类别标签。是关于类别k的权重向量。损失的计算表达式如下：\n\n\n其实就是针对所有帧的每个类别的损失求和，如果视频属于第k类，那么yk=1，否则为-1。\n注意力模型\n我们需要让模型关注每个时间步不同的特征子集。在这个情境下，有两个关键问题需要解决：\n\n使用目标跟踪算法来将不同帧的检测结果相连接，这样可以得到个体特征更好的表示\n角色注意力取决于事件的状态，随着事件的变化需要跟着变化。\n\n为了解决这些问题，作者提出了他们的模型（分为with tracking和tracking-free）\n\nAttention model with tracking\n\n首先使用KLT tracker得到角色跟踪结果，之后使用单独的BLSTM得到特定时间步下每个角色的隐状态表示：\n\n\n在每一个时间步里，我们希望选择最相关的角色。我们可以通过计算来实现：\n\n\n其中Nt为第t个帧所有检测的数量，我们得到的注意过的（attended）角色表示之后作为输入送入第二个式子的单向LSTM中进行处理。\n\nAttention model without tracking\n\n有时，移动过快或是有遮挡时，使用tracking-free的模型会有比较有利。在这个无跟踪的场景下，我们假设每一帧的检测独立于其他帧：\n\n\n与上面的不同的是，它直接使用了player检测特征。\n实验结果组行为分类\n\n\n事件检测\n\n\n对于注意力进行评估\n\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","LSTM","注意力"]},{"title":"论文阅读笔记：“GroupFormer： Group Activity Recognition with Clustered Spatial-Temporal Transformer”","url":"/2023/08/05/paper-reading/paper_reading_040/","content":"GroupFormer: Group Activity Recognition with Clustered Spatial-Temporal Transformer(ICCV 2021)\n\n引言分析论文首先说明利用个体关联来推理集体行为是很有挑战性的。有很多方法也在尝试去捕获这种关联信息。近期的很多方法都用到了注意力机制来对个体关联进行建模。但是上述方法也存在缺陷：\n\n无法对时空情景信息作为一个整体来进行建模。\n如上图所示，时间信息于空间信息是强关联的，因此需要将它们作为一个整体来进行考虑\n\n没有基于他们直接的关联关系进行分组\n不是所有的角色都对事件的类别起作用，存在一部分关键角色 ，他们的贡献更多。\n\n\n核心亮点\n\n组特征生成器GRG\n该模块是用来初始化组表示的。这个模块结合了场景特征和个体特征，其想法是通过visual tokens来总结视频中的信息，分别得到场景token和个体token，再将他们融合得到最终的组特征表示。\n聚簇时空transformer CSTT\n如图，STT包含了两个encoder并行化地生成时间和空间特征。之后两个decoders通过一种交叉的方式来对时间和空间特征进行解码。最后使用一个group解码器来增强组特征表示。\n\n编码器：\n\n我们使用encoders来嵌入时间和空间情景信息。公式如下：\n\n\n最终空间编码器得到的输出大小为，同理可得出时间编码器的输出。\n\n解码器\n\n个体解码器是用来将空间和时间情景信息整体地进行考虑。最终两个解码器的输出融合得到了增强的个体表示。\n组解码器利用增强的个体表示来强化组特征。在实际中，STT模块可以进行多次堆叠，以得到最佳的建模效果。\n\n聚簇注意力机制\n\nSTT使用了全连接的注意力机制，但是这样其实计算了很多冗余的联系。因此为了关注于比较关键的组联系。作者设计了聚簇注意力块，该模块可以对个体进行聚簇，并利用组内和组间联系，从而大大降低了计算量。具体来说，他们定义了C个质心向量（簇中心）。对于组间联系可以用簇中心向量来代表。\n实验结果SOTA\n\n\n单单是使用rgb输入，性能效果就比之前的大部分方法好了。\n消融实验\n\n时空关系建模的效果\n\n\n\n\n聚簇方法的效果\n\n\n\n\n\n\n堆叠的CSTT块数量的效果\n\n\n\n可视化\n\nt-SNE\n\n\n\n代码实验阅读获取光流\n配光流网络的环境，获取光流数据\n\n在官方提供的MPI-Sintel数据集上跑了下网络的推理：\n\n\n下图是对生成光流图的一个可视化：\n\n\n获取expriment dir\n\n\n# basedir: experiment dirconfig['basedir'] = os.getcwd() + '/experiments/' + Path(args.config).resolve().stem\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","transformer","CSTT","聚簇注意力机制"]},{"title":"论文阅读笔记：“Actor-Transformers for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_037/","content":"Actor-Transformers for Group Activity Recognition（cvpr2020）核心亮点静态+动态特征表示\n对于细化的行为类别，我们需要捕捉关节点的位置信息，以及他们的时序动态信息。因此作者使用了姿态估计模型HRNet来对关键关节点的位置进行预测，使用3D CNN来构建时空特征表示，这两个网络模型分别为静态分支和动态分支。对于动态分支，作者使用了RGB和光流这两种相互补充的输入。\n\n\n自注意力机制\n论文将transformer引入群体行为识别，从而无须进行显示的空间和时间建模。作者还研究了，将静态和动态角色相关的特征表示传入tranformer后，如何对得到的相互补充的特征进行有效融合。\n\n\n网络结构\n如上图，整个网络包含了3个阶段，第一个阶段是角色特征提取，经过特征提取网络以及embedding之后，得到的是每个角色的一维嵌入；在第二个阶段，使用transformer网络来对学习角色之间的关系，并选择性地提取对行为识别重要的信息；在最后一个阶段，作者分别在transformer之前和之后引入融合策略，来研究融合不同表示信息的有效性。\n实验结果融合策略\n\n\n由图，令transformer网络专注于静态或动态特征再融合会有比较高的精度。\nstate-of-arts\n\n\n比较有意思的是，对于volleyball数据集，Pose+光流的组合远高于其他与rgb的组合，而对于collective数据集结果证明RGB+光流远好于其他与Pose的组合\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","transformer","self attention","pose branch"]},{"title":"论文阅读笔记：“ Spatial Transformer Networks”","url":"/2023/08/05/paper-reading/paper_reading_042/","content":"Spatial Transformer Networks引言分析CNN不具备在网络的浅层或是中间层对于输入数据的空间不变性，论文提出了一种新的模块spatial transformer，该模块不仅会帮助我们选择图像中最相关的区域，同时还能将这些区域变换为经典的、预期的姿态来简化在后续层中的识别。如下图b所示，定位网络可以预测使用何种变换；c图是应用了变换后，transformer的输出。\n\n\n核心亮点空间变换网络 Spatial Transformer Network\n\n\nSpatial Transformer Network包含了三个组件：定位网络和参数化网格采样机制（网格生成器）和图像采样器。在CNN中加入该模块可以帮助最小化总体的网络花费函数。关于如何变换每个训练样本被压缩或缓存到了定位网络中的权重参数中。\n定位网络 localization network\n\n其输入是特征图U，输出是参数，其大小取决于变换的类型。例如仿射变换就是6维的。定位函数可以使用任何的形式，如全连接或是卷积，并且应当包含一个回归层来生成参数。\n参数化采样网格（网格生成器）\n、\n为了对输入特征图进行变形，每个输出像素都是由在输入特征图的特定位置应用一个采样kernel来计算的\n\n\n为输出特征图中正则网格的目标坐标。为输入特征图中对应的源坐标。\n可微分图像采样\n\n\n通过上式可以计算每个通道中每一位置的输出值。因为采样函数的不连续性，次梯度(sub-gradients)必须被使用。\n实验设计Distorted MNIST\n\n探索网络可以学习到的多种变换\n\n\n\n如图使用TPS变换+CNN+ST的效果最好\n街景房号识别\n\n\n细粒度识别\n\n由右图，不同的transformer识别不同的部位\n","categories":["论文阅读","图像分类"],"tags":["input transformer","localization network","grid generator"]},{"title":"论文阅读笔记：“Temporal Pyramid Network for Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_041/","content":"Temporal Pyramid Network for Action Recognition(2020)引言分析文章一开始就点明了时间节奏对识别行为的重要性，对于类间与类内的在时间节奏上的变化进行精确建模，可以对行为识别带来巨大的性能提升。之前尝试提取动作实例的动态视觉节奏的方法主要依赖于帧金字塔，即在金字塔的不同级别上用不同的采样帧率采样输入帧。但是这些方法的缺陷也很明显，即每个帧率的通路都需要一个单独的backbone来进行处理，从而计算复杂度极高。作者观察到，当网络的层次越深时，他们的时间感受野也会变大。因此，在同一个模型中不同深度的特征已经具有捕获快节奏和慢节奏运动的能力。作者由此提出了一个时间金字塔网络来在特征级别上聚合多样的视觉节奏信息。此外TPN还具有即插即用的能力\n核心亮点TPN框架\n\n\nTPN框架包含了两个重要部分：特征源以及特征聚合。作者使用空间语义调制和时间节奏调制来控制特征源的相对差异。使用多种信息流来进行特征聚合。\nTPN特征源\n对于M个层次化的特征，它们从底向上有着不断增加的时间感受野。可以用两种方法来从backbone网络中收集这些特征：\n\n单深度金字塔\n多深度金字塔\n\n\n\n空间语义调制\n调整各层特征的空间形状及感受野，使他们相互匹配。一个辅助的分类头也被加入了网络以获得更强的监督，总体的目标函数如下：\n\n时间速率调制\n在空间调制后，我们需要对第i层的特征进行因子为ai的降采样，以控制不同时间尺度特征的相对差异\n信息流聚合\n对于第i层的特征，我们可以采用以下三种基本操作来进行聚合：\n\n\n将B-U流和T-D流结合，我们可以得到两种额外的信息流：cascade流和parallel流。信息流聚合流程如下图：\n\n\n实验结果SOTA on Kinetics-400\n\n\n泛用性证明\n\n\n\n\n如何选择待处理的特征源？\n\n\n当我们选择相对浅层的特征源的时候，精度会略有下降。\n信息流聚合方法的重要性\n\n\n实验证明，top-bottom和bottom-top这两种信息流是相互补充的\n空间语义调制和时间速率调制的重要性\n\n\n输入帧数量的影响\n\n","categories":["论文阅读","行为识别"],"tags":["TPN","信息流聚合","时空调制"]},{"title":"论文阅读笔记：“VATT： Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text”","url":"/2023/08/05/paper-reading/paper_reading_043/","content":"VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text（nips 2021）核心亮点VATT整体框架\n\n\n上图是VATT的整体架构，作者将每个模态输入到一个标记化层，在该层中原始输入被投影为一个嵌入向量，并在之后送入transformer中。作者使用了两种设置进行对比：\n\n对于每种输入，其backbone都是分离的，权重不共享\n使用单一骨干网络，共享不同模态的权重\n\n网络提取模态特定的表示，并将它们映射到公共空间以通过对比损失相互比较\nDropToken\n因为transformer的计算复杂度是平方级别的，这个方法可以有效减少计算复杂度。我们得到标记序列后，随机采样其中的一部分，然后将采样后的序列送入transformer。对于可能包含冗余的数据，该方法可以大幅降低训练时间的同时保持很好的效果。\n标记化及位置编码\n作者将整个视频剪辑进行切分，每个patch的大小为。并在其上应用线性投影以得到d维向量表示。为了编码这些patches的位置，作者定义了如下可学习嵌入的特定维度的序列：\n\n\n对于音频和文字的处理同理。transformer的输入如下：\n\n\n为输入patches序列，为一种特殊的聚合标记的可学习嵌入，它即是整个输入序列的聚合表示。对于文字模型，作者移除了位置编码，并在多头注意力模块的第一层的注意力分数中加入了可学习的相对偏置，这个改变可以使得提出模型的权重能够直接迁移到最先进的语言模型T5上。\n公共空间投影\n给定视频-音频-文字三元组，作者定义了一个语义层次式公共空间映射，通过它我们可以利用余弦相似度来直接比较视频-音频对，视频-文字对。作者假设这些模态直接有不同级别的语义粒度，所有他定义了不同级别的投影：\n\n\n\n\n多模态对比学习\n作者使用噪声对比估计(NCE)来对视频-音频对进行对齐，使用多实例学习NCE来对齐视频-文字对。正样本为采样视频中同一个位置的对应的模态信息流，负样本为视频中不匹配位置的采样样本。损失函数如下式所示：\n\n\n其中N中包含了所有的负样本。式5中，P包含了5个离视频剪辑时间上最近的文字剪辑。用来调整将正样本与负样本相区分的严格程度。总体的目标函数如下：\n\n\n实验结果action recognition\n\n\n值得注意的是，如果从头开始训练（没有预训练），其精度会大幅下降\n可视化\n\n\n","categories":["论文阅读","行为识别"],"tags":["transformer","多模态","自监督"]},{"title":"论文阅读笔记：“HiGCIN： Hierarchical Graph-based Cross Inference Network for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_044/","content":"HiGCIN: Hierarchical Graph-based Cross Inference Network for Group Activity Recognition(TPAMI 2020)引言分析在组行为识别中，为了对组行为进行推理，我们需要获取包括身体区域，人，以及它们之间的联系的各种信息。个体行为与群里行为是强耦合的，而之前的一些方法使用了两阶段的pipeline，将个体行为与群里行为的推导相割裂，或者说传统方法忽略了人与人之前的潜在的时空依赖，只考虑了空间情景。同时，这些方法也没有考虑身体区域之间的时空依赖。\n\n\n因而论文提出了一个泛用的十字推理块（CIB）来利用隐藏在特征结点之间的时空依赖。基于CIB，作者提出了群体行为识别框架HIGCIN。设计了 推理身体区域之间依赖的BIM和人之间依赖的PIM。\n核心亮点网络整体架构\n\n\n如图所示，BIM模块考虑了固有的身体区域之间的时空联系，提取每个人的卷积特征。在这之后，使用PIM模块进一步探索人之间特征的时空依赖。最终每个帧的所有特征都被max-pooled到了单个向量。\n十字推理\n\n\n受到non-local网络的启发，时空共时依赖可以通过非局部推理得到，本文提出了一种新的推理方式十字推理，去掉了很多不必要的连接。\nCIB\n\n\n在时间t，第s个特征节点(图中的橘色向量)的空间表示为：\n\n\ns’为所有在空间域可能与其有交互的其他结点。r用来计算任意两个特征的空间依赖，g是线性变换。\n同理，时间表示为：\n\n\n二元函数r一般采用点积相似度：\n\n\n通过结合空间表示和时间表示，我们可以得到：\n\n\n它包含了时空共时依赖信息。之后作者用了残差连接来将设计的block包含进现有的深度架构中：\n\n\n该CIB模块可以被拓展至探索身体区域之间与人之间的联系。\nBIM\n作者认为人的结构信息个体行为的特征表示有一定帮助。首先使用CNN得到大小为的D个特征图。对于每个特征图的每个元素，我们将其看作一个身体区域。对于第k个人，其身体区域特征为。考虑身体区域之间的联系后，可得：\n\n\n通过平均池化，我们即可得到第k个人的特征。\n整个过程如下图所示：\n\n\nPIM\n同理，通过上一步得到B之后，可通过如下的公式计算人之间的联系：\n\n\n过程如下图所示：\n\n\n最终的loss函数定义如下：\n\n\nNY代表群体行为的类别数，lt是预测，带帽子的是真值。\n实验结果指标\n\nMCA：正确预测的百分比\n\nMPCA：每个类别的平均准确率\n\n混淆矩阵\n\n\n实验组对比\n\nb1：基线\nb2：使用BIM\nb3：使用PIM\nb4：同时使用BIM和PIM\n\n\n\nSOTA对比\n\n\n是否加入个体标签对实验的影响\n\n\n混淆矩阵\n\n\n可视化\n\n\n上面矩阵是根据r函数计算得到的。\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","CIB","时空共时依赖"]},{"title":"论文阅读笔记：“Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos”","url":"/2023/08/05/paper-reading/paper_reading_045/","content":"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos（eccv 2020）引言分析在一个真实场景中，它可能会包含多个人，每个个体可能属于一个社交群体中。文章专注于这样一个问题：“谁属于哪个社交群体，并且这个群体在做些什么？”。在此之前，有很多工作研究基于场景内的所有角色判断其群体行为，也有一些工作，基于场景内所有个体之间的联系进行分组推理。作者基于这两种工作，并进行了有效结合。这篇文章的主要贡献在于，提出了一种多任务解决方法，它可以同时解决分组，识别个体行为以及识别社交群体行为任务。\n核心亮点GAR框架\n\n\n该框架包含三个部分：\n\nI3D backbone\n文章用最后一层输出作为全局视频表示，使用中间层mixed-4f的输出来进行个体特征的提取\n\n自注意力模块\n使用非局部化操作，对个体特征图的空间域进行attention，以找到key-points。\n\n图注意力模块\nGAR框架核心模块。该模块采用图注意力网络，主要作用是进行节点间的关系信息编码。\n\n\n其训练是端到端的，目标函数为：\n\n\n社交行为识别\n社交行为的粒度介于个体行为与群体行为之间。文章对图注意力模块进行了简单修改，以适应新的任务。如下式，作者在目标函数中加入了边损失Lc。它可以让自注意力策略汇聚到个体之间的社交连接上。\n\n\n表示每个社交群体的分类损失。在推理的时候，作者基于GAT学习得到的注意力分数，利用图谱聚类算法来实现社会群体的划分。\n增强数据集CAD\n\n\n实验结果\n\n\n\nSOTA\n\n\n消融实验\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","CIB","时空共时依赖"]},{"title":"论文阅读笔记：“Deformable Convolutional Networks”","url":"/2023/08/05/paper-reading/paper_reading_046/","content":"Deformable Convolutional Networks引言分析cnn对于集合变换的建模主要来自，丰富的数据增强，大的模型容量以及一些简单的手工模块(max pooling)。CNN 不能对大的未知的变换进行建模。CNN模块的几何结构是固定的，卷积单元在固定的位置采样输入特征图。自适应感受野对视觉识别比较重要。论文提出了可变形卷积，能够大大增强CNN对集合变换的建模能力。\n\n\n核心亮点\n\n可变性卷积\n如上图所示，可变形卷积可允许采样网格的自由变换。偏移量是通过之前的特征图学习得到的。\n网格R：\n\n\n标准卷积：\n\n\n可变形卷积：\n\n\n因为经常为分数，因此可以使用双线性插值：\n\n\n其中G(q,p)为：\n\n\n只对少部分q来说，G(q,p)是非零的。\n可变形卷积的过程如下图所示：\n\n\n实验分析Deformable Convolution的效果\n\n\n卷积核感受野\n\n\n\n感受野大小与物体大小有关\n背景区域的识别需要较大的感受野\n\n与空洞卷积的比较\n\n\n模型运行时和复杂度\n","categories":["论文阅读","图像分类"],"tags":["architecture design","可变形卷积","自适应感受野"]},{"title":"论文阅读笔记：“Progressive Relation Learning for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_047/","content":"Progressive Relation Learning for Group Activity Recognition（cvpr2020）核心思想个体特征提取\n\n\n首先使用目标跟踪器得到人的边界框。之后对其使用卷积得到Person CNN，生成的空间视觉表示送入LSTM中得到个体的时间动态表示，使来作为人的时空特征表示。\n语义关系图建立\n\n\n定义无向图，u是全局的行为分数，V是图的结点，E是图中的边。\n\n场景信息聚合\n\n对于每个结点i，收集并聚合其所有邻居j的信息：\n\n\n\n结点信息更新\n\n对于每个结点i，使用刚刚得到的场景信息进行更新：\n\n\n\n边信息更新\n\n对于每条边，使用更新后的结点信息进行更新：\n\n\n\n计算全局行为分数\n\n\n\n因为在图中进行一次信息传播最多只能捕获成双的联系，为了编码高级别的交互，我们可以迭代m次进行图更新。\n渐进关系门控\n作者使用关系门控代理来探索一个自适应策略来选择与组行为相关的联系。决策过程可以用马尔可夫过程形式化表示。\n渐进特征蒸馏\n网络框架\n\n\n\n\n实验结果SOTA\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","relation graph","强化学习"]},{"title":"论文阅读笔记：“Progressive Relation Learning for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_048/","content":"Convolutional Relational Machine for Group Activity Recognition (CVPR 2019)引言分析该论文所采用的方法没有显示地检测或跟踪任何个体。它提出了模型CRM，并在该模型中引入了基于行为的中间表示activity map。它是一种提取个体之间空间联系的方法。 此外论文在训练时使用了多阶段的方法来逐步优化activity map，以学习到一个预测错误率更小的activity map。最终优化过的activity map和图像或视频特征进行结合，来进行组行为的预测。\n核心亮点\n\nActivity Map\n行为图实际上是2D域表示的集合（域可以理解为通道）。其2D域的个数是个体行为和组行为类别个数和。每个域实际上表示一个类别，其域表示的计算需要考虑图像中的bounding box。对于每个个体m，其个体行为为i，其组行为为g，我们会定义一个如下的2D高斯概率密度函数：\n\n\n通过该函数我们可以计算个体m的行为图的域i和域NI+g。一个双变量高斯图会在bounding box 上进行计算。最终所有的个体行为图会进行对齐，即对于每个域的同一个位置，我们取最大值来得到最终的activity map A。对于一个单独的输入来说，其组行为是确定的，即只有一个组行为类别的域非零，其他域均为0。\nRefinement\n\n\n采用如图的公式即可迭代地对activity map进行改进\nAggregation\n\n\n如上式，最终的组行为表示的计算公式即结合了特征图F和改进过的activity map。\nTraining Objectives\n\n\nLa实际上是预测行为图和真实行为图之间的欧几里得损失，Lg是群体行为的分类交叉熵损失。\n实验结果对比实验\n\n\nSOTA\n\n\n可视化\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition","CIB","时空共时依赖"]},{"title":"论文阅读笔记：“Social Adaptive Module for Weakly-supervised Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_049/","content":"Social Adaptive Module for Weakly-supervised Group Activity Recognition核心亮点SAM(Social Adaptive Module)\n对于弱监督GAR，SAM可以自适应地选择具有区分能力的边界框及关键帧。它利用了social 假设，即关键的实例（人或帧）总是高度关联的。\n\n\n\n整体任务建模：\n\n\n\n其中，V1-Vt为输入的帧序列，D(Vt)代表每个帧对应的N个proposal。\n\n空间建模函数 F(Vt;D(Vt);W)：\n\n首先，对每个帧Vt提取卷积特征图，其次利用RoIAlign来提取个体特征，最后将所有个体特征融合为一个单独的帧级别的向量。在这里，F函数需要在空间域里选择K个具有区分能力的个体特征。\n\n时间建模函数O()\n\n我们希望O可以选择K个有效的帧级别的特征表示。\n对于两个函数，我们可以进行抽象以得到一个统一的函数M，函数M的作用是学习向量，它是用来选择K个特征的\n\n\n\n密集关系图\n\n我们通过公式来计算第i个特征和第j个特征之间的关系。由此，我们可以得到关系矩阵R。\n\n剪枝操作\n\n首先，我们通过公式计算每个特征的关联度。它是将每个特征的出边和入边进行了求和。如果值越大，说明这个特征的重要性越高。因此，我们根据计算结果可以选择Top K个特征：\n\n\n\n稀疏关系图\n\n\n\n其中代表涉及选中特征的关系矩阵。从式中可以看出，我们对特征i到的K个特征进行了加权求和，文章称其为关系嵌入。\n实验部分\n消融实验\n\n\n\n\n对比实验\n\n可以与精度model进行比较\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“Hunting Group Clues with Transformers for Social Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_050/","content":"Hunting Group Clues with Transformers for Social Group Activity Recognition网络框架\n\nDeformable trans encoder\n使用修改过的特征图和位置编码P作为输入，一起送入堆叠的transformer encoder中， 可以得到优化的多尺度特征图。位置编码P辅助注意力模块识别特征在特征图的位置。\nDeformable trans decoder\n使用优化过的特征图和查询嵌入Q作为输入，一起送入堆叠的transformer decoder中，可以得到聚合的社群体特征图。查询嵌入Q被设计用来只能最多包含一个社会性群体。\nPrediction heads\n使用聚合后的特征图送入检测头中进行预测。对于个体，设置了Box头和action头来对个体的位置和行为进行预测；对于社会群体，设置了size头，point头以及activity头来分别预测群体的人数，群体的成员bounding box中心点，以及群体行为类别。\n损失函数Hungarian algorithm\n\n\n\n\nLoss function\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“COMPOSER：Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality”","url":"/2023/08/05/paper-reading/paper_reading_051/","content":"COMPOSER: Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality主要思想将整个场景按照粒度的不同进行划分，形成了不同尺度大小的场景元素。这些不同尺度元素存在着组合关系。\n\n\nGAR任务要解决的两个难题：\n\n对于整个复杂场景做复合式理解\n在所有场景元素上进行关系推理\n\n使用key-point模态的好处：\n\n对数据进行去隐私化，减少道德问题\nRGB输入对背景、光线亮度、以及纹理信息较为敏感，而key-point不会\n\n网络结构\n\nMultiscale Transformer Block\n多尺度transformer块可以层次式地对不同尺度的tokens进行关系推理。\n\n人体关键点（key point）: —第p个person第j个关键点的特征。人体关键点初始化包括：坐标嵌入，时间信息嵌入，关键点类型嵌入。\n人（person）：—对person关键点坐标在时间维度进行聚合，并作线性变换。\nP-to-P交互（interactions）：—人p和人q之间的交互初始化为，和的连接，并作线性变换。\n人群（person group）：—对场景内的人进行聚合（使用k-means等算法）\n剪辑（clip）：CLS是一个可学习的嵌入向量，它可以使得transformer可以从输入序列的所有tokens中总结分类相关的特征表示信息\n对象（object）：这里特指球关键点，因为它可以帮助我们更好地识别关键球员。\n\n\n\n\n\n由上图可知，multiscale transformer block在不同的尺度上有着差异化的输入，但是每个尺度的操作都是相同的。\n尺度一致的对比聚类\n我们强制同一clip的不同scale下的表示在聚类时所分配的标签是一致的，这其实是对特征空间的一种正则化处理。论文使用了交换预测（swapped prediction）机制来保证一致性。\n\n\n这种对比学习方法可以增强中间特征表示，从而提升总体效果。\n\n假设$v {n,s} \\in \\R^d表示第个剪辑的第个下的特征，然后通过将向量映射到个可训练的原型向量{c_1,…c_k}中，来计算q{n,s} \\in \\R^K。假设是是其中的两种尺度，并且我们希望从v_w预测q_s并从v_s预测q_w$，交换损失函数如下式：\n\n\n\n其中l函数计算匹配程度：\n\n\n总体的交换损失为：\n\n\n实验结果\n\n\n\n\n正则化多尺度表示\n多尺度表示可以表达更多的信息，和更有效的尺度一致性\n数据增强可以有效增加训练数据大小，注入有效噪声，使得泛化更容易\n辅助预测可以帮助学习中间表示\n多尺度transformer可以通过组合推理的方式从细粒度到粗粒度学习视频的高层信息表示\n参数共享和只使用单一的encoder效果都不好，使用反向的encoder效果会更差。\n\n\n\nGroupFormer中的CSTT模块有５个transformers并且还对图像场景进行了处理，所以计算昂贵。如果只使用RGB模态，composer的计算量为127M，因为它只需建模3个scales。\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“Spatiotemporal Multiplier Networks for Video Action Recognition”","url":"/2023/08/05/paper-reading/paper_reading_057/","content":"Spatiotemporal Multiplier Networks for Video Action Recognition主要思想\nto solve the combination of two streams:\n\nmultiplicative motion gating（乘法运动门控）\n\n\n如图2d，其公式为：\n\n\n在反向传播过程中，运动和表观流的输入被显示地牵涉，作为其梯度上的门控机制。它使得模型有能力去学习时空特征关联\n\n\n\n to solve long-term input\n\ninject temporal filters（注入时序过滤器）\n\n\n对应该变换的初始化，作者令其不会改变原始特征（即恒等映射），思想其实就是进行一个3D卷积，只在通道上和时序上进行了信息处理（不涉及空间维度信息变换）。\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“ActionVLAD：Learning spatio-temporal aggregation for action classification”","url":"/2023/08/05/paper-reading/paper_reading_056/","content":"ActionVLAD: Learning spatio-temporal aggregation for action classification\n代码：http://rohitgirdhar.github.io/ActionVLAD\n\n论文思想时空信息聚合\n\n将特征空间划分为K个区域，该区域可以表示为“action words”，也可以称其为锚点(achor points ck)\n公式：\n\n\n上面的公式对特征与锚点（typical actions）之前的差异在整个视频维度进行了求和。\nwhy use VLAD to pool?\n\n\n\n\nHOW to combine RGB and FLOW streams?\n\n\n\n\n\n\nIdeas?\ncan I add a attention to VLAD?\nwhere to add attention?\ncan I add non-local to VLAD?\n\nTodos\nrun the VLAD code\nlook at the core codes where the VLAD is implemented\ntry out the ideas that may work well\n\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“Position-Aware Participation-Contributed Temporal Dynamic Model for Group Activity Recognition”","url":"/2023/08/05/paper-reading/paper_reading_058/","content":"Position-Aware Participation-Contributed Temporal Dynamic Model for Group Activity Recognition主要思想Who are the key participants?\n作者认为关键参与者或者在整个过程中有稳定的运动，或者在某一时刻有显著的运动，如图所示：\n\n\n网络框架\n\nLong motion\n计算每个个体的平均运动强度 （MI）：\n\n\n\n\nFlash motion\n因为快速运动经常随着时间推移而改变，所以设置注意力权值，可以衡量每个个体快速运动的强度。\n\n动作变化最快的人，一定对整体的行为起着关键性作用吗？\n\n文章也说，不是所有快速运动都与群体行为或是其他人相联系，例如碰撞，摔倒等动作。所以某一个特定的快速运动的人往往在语义上与群体行为或是其他个体有着更强的联系。而对于这个联系的计算，作者引入了PIM模块。\nPIM模块\n\n同时考虑空间位置信息和特征相似度来对关系进行推理。\n\n\n\n\n\n\nRx是特征交互函数：判断两个特征之间的相似性\nRp是位置交互函数：基于位置信息衡量两个人之间交互的似然性\nK：场景中的所有人数\n\n\n\n\n\n\nd*是场景中距离最远的两人间的距离\n\nAGG-LSTM\n\n通过随时间变化的注意力，关注那些与群体行为关系密切的快速运动的人\n\n\n\n论文首先将场景中的个体分为不同组，对于volleyball数据集来说，组即是每只队伍。对于第g个组，开始id和结束id计算公式如下：\n\n\n划分为不同组之后，我们就可以捕获快速运动对于群体行为的关系。\n\n\n\n：全部人的行为的隐变量表示\n可以强调与组行为联系更紧密的个体行为，并抑制非重要个体行为\n\n\n\n每个组的特征即可表示为LSTM输出的最后一个特征向量，由公式也可看出，它聚合的是组内所有个体的信息。其实，每个组内也是有顺序的，这个顺序即是按Long Motion计算的MI递减顺序。最后，对所有组的特征进行拼接即可得到群体行为特征：\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“Empowering Relational Network by Self-Attention Augmented Conditional Random Fields for Group Activity Recognition（eccv 2020)”","url":"/2023/08/05/paper-reading/paper_reading_059/","content":"Empowering Relational Network by Self-Attention Augmented Conditional Random Fields for Group Activity Recognition（eccv 2020)核心思想网络结构\n\n整体的网络可以分为两个阶段，第一阶段为特征提取网络，第二阶段为关系推理网络。appearence信息是通过faster rcnn+I3D得到的。其中，先使用faster rcnn得到检测框信息（它是在用预训练的coco模型在volleyball数据集上进行微调得到的）再用I3D提取特征，在这个过程中需要用到检测框信息（I3D是在预训练的kinetics模型在volleyball数据集上进行微调得到的）。场景信息即直接用I3D处理得到的视频特征。\n创新模块temporal and spatial self-attention\n\n\n\n\n空间注意力，尝试将整个图划分为不同大小的子图，对于不同规模的子图，计算其特征，对于这些进行加权平均，权重是可学习的。\n\n\n mean-field inference algorithm\n\n\n简单地用图示来表示算法过程：\n\n\nbidirectional universal transformer encoder (UTE)\n\n\n\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“TokenLearner：What Can 8 Learned Tokens Do for Images and Videos?（NIPS 2021)”","url":"/2023/03/06/paper-reading/paper_reading_060/","content":"TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?（NIPS 2021）网络结构Framework for Video\n\n\nTokenLearner自适应地学习标记向量的集合，MHSA对时空关联进行建模，最后TokenFuser将它们结合起来，并重建为原始的输入tensor大小。\nTokenLearner\n\n\nTokenFuser\n\ntoken-wise linear layer: 在各个token间融合时空信息\n\n\ntoken特征的反向映射(映射回原先的tensor shape)\n\n\n\n\nEmbedding into ViT architecture\n\n\n实验kinetics400上的SOTA对比\n\n\ncharades数据集上的模型优化\n将TokenLearner嵌入X3D中，将3D卷积换成了一对2D卷积和1D卷积。1D卷积采用是TokenLearner进行替换。并把MHSA替换未来vector transformer。\n\n\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“Keeping Your Eye on the Ball”","url":"/2023/03/13/paper-reading/paper_reading_062/","content":"Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers（NIPS 2021）\nmain idea: pooling along motion trajectories would provide a more natural inductive bias for video data, allowing the network to be invariant to camera motion.\n\n\n\n首先预处理视频，生成ST个tokens，使用了cuboid嵌入来聚合不相交地时空块。之后在特征中加入了时间位置和空间位置编码，最后将可学习的分类token加入到整个序列中。\nvideo self-attentionjoint space-time attention\n\n\n\n计算量是平方级别的\n\ndivided space-time attention（time transformer）\n\n\n\n优点是计算量下降到或\n模型分析时间和空间是独立的（不能同时对时空信息进行推理）\n处理大量冗余信息，而且不灵活、不能充分利用有效tokens\n\ntrajectory attention\n\n\n\nbetter able to characterize the temporal information contained in videos\naggregates information along implicitly determined motion paths\naims to share information along the motion path of the ball\n\n\n\n\n应用在空间维度，且每个帧是独立的\n隐式地寻找每个时刻轨迹的位置（通过比较query, key）\n\ntrajectory aggregation\n\n\n\n\n\n应用在时间维度\n复杂度：\n\nApproximating attention\n基于原型的注意力近似：\n\n使用尽可能少的原型的同时重建尽可能准确的注意力操作\n作者从queries, keys中选择最正交的R个向量作为我们的原型\n\n\n\n\n\n因为最大复杂度为$RDN，而，均为常数，所以可以认为复杂度从O(N^2)降到了$$O(N)$\n实验\n\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“Coherence Constrained Graph LSTM for Group Activity Recognition”","url":"/2023/04/17/paper-reading/paper_reading_063/","content":"Coherence Constrained Graph LSTM for Group Activity Recognition  （TPAMI 2022）\n主要思想：寻找群体体行为中的相关行为\n\nSTCC和GCC约束\nSTCC：如果一个个体行为在时间域上相互关联，并且在空间域上与其他个体行为具有一致性，我们称该种行为为相关行为\nGCC：如果一个特定的行为与整体群体行为一致性更高，那么它对群体行为的贡献也越高\n\n\n\n网络框架\n\n核心模块spatial interactions among persons are dependent on the temporal motions of individuals  \nCCG-LSTM\n时空场景关联推理\n\n\n\n\n\n\n\n\n\ntemporal confidence gate \n\n\n\n\n\n如果相差越小，值越接近1\n加入这个temporal confidence gate后的新公式：\n\n\n\nspatial context confidence gate \n\n 捕获空间域的个体的“relative”运动\n\n\n\n\n\n\n\n\n如果相差越小，值越接近1\n加入这个spatial confidence gate后的新公式：\n\n\n\nAGG-LSTM\n全局场景关联推理\n\n\n\n","categories":["论文阅读","群体行为识别"],"tags":["Group Activity Recognition"]},{"title":"论文阅读笔记：“Masked Autoencoders As Spatiotemporal Learners”","url":"/2023/03/13/paper-reading/paper_reading_061/","content":"Masked Autoencoders As Spatiotemporal Learners框架\n\n\n从损坏的输入重建干净的信号\n\n发现\n最优mask比率和数据中的信息冗余度相关\n\n使用更高的mask比率可以更好地利用视频的时序关联信息\n\n\n采样方法\n\n自编码\n\n\ndecoder结构与encoder相比是不对称的，且只在预训练进行视频重建的时候使用。其复杂度远远小于encoder，因而就算处理的是全部的patches，它也不是性能瓶颈。\n\n实验性能优势\n\n\na masking ratio of 90% reduces the encoder time and memory complexity to *&lt;1/*10\n\n\n理论上， 7.7×  在计算量上的减少 vs. 编码全部tokens\n\n精度优势\n\n\n加入MAE能提升10个百分点以上，同时减少近1/5的训练时间\n\n消融实验\n\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“Real-world Anomaly Detection in Surveillance Videos”","url":"/2023/08/05/paper-reading/paper_reading_064/","content":"论文阅读笔记：“Real-world Anomaly Detection in Surveillance Videos”\n实际异常检测系统需要实时对那些偏离正常模式的行为发出警告，并识别发生异常的时间窗口。检测到异常行为之后，可以进一步用分类的方法来识别是哪种异常行为。\n难点是现实中的异常行为很多，很难去列出所有的异常事件。所以我们应该期望我们的算法不依赖于任何关于异常事件的先验知识。所以异常检测应该用尽量少的监督来完成。之前的方法用正常事件构建正常行为字典，异常行为没有办法通过正常行为字典来重建（机器学习中的稀疏编码）。但是现实中背景可能剧烈变化，导致不同背景下的正常行为可能被误认为异常行为（高假阳率）。\n正常情况下，把所有的正常模式考虑进去来定义正常行为是几乎不可能的。而且正常行为和异常行为之间的边界有时也比较模糊。在不同条件下，同一个行为在一个 场景下是正常的，在另一个场景下确是异常的。所以正常行为和异常行为数据集能帮助我们去更好地构建异常检测系统仍是有争议的。\n这篇论文创新性地把标注的范围上升到视频级别。也就是说只标注某个视频是否含有异常行为，但在哪里不需要标注。论文使用了多实例学习的方法，将正常和异常的监控视频视为包，并将每个视频的短片段/剪辑作为包中的实例。基于训练数据，可以自动学习异常排名模型，预测视频中异常片段的高异常分数。在测试过程中，一个未经修剪的长视频被分成多个片段并送入深度网络，该网络为每个视频片段分配异常分数，以便检测到异常。\n多实例学习损失\n\n\n\n我们把一个异常视频作为一个正标签包，这其中包含许多视频片段，至少有一个实例是异常的。可以通过每个包中的最大分数实例来优化目标函数\n多实例排名模型\n\n序号1时间上是尽可能平滑连续片段的分数，序号2是希望只有异常行为有较高分数，正常行为分数较低；主项是希望正样本和负样本尽可能地远离\n评价指标\n\n\n\n对于论文中的方法曲线下的面积是可以接受的\n","categories":["论文阅读","视频异常检测"],"tags":["video anomaly detection"]},{"title":"论文阅读笔记：“行为识别论文总结”","url":"/2023/08/05/paper-reading/paper_reading_conclusion_01/","content":"Paper Reading Reflections on Action Recognition3D Convolutional Neural Networks（TPAMI 2013）\n多通道输入（input），包括灰度，x方向梯度，y方向梯度，x方向光流，y方向光流信息\n\n模型组合（architechture）\n捕获潜在的相互补充的信息\n\n高层特征正则化（model）\n对每个类别预编码一个高层特征，期待学习到的特征与预编码特征尽可能地接近\n\n可视化(experiment)\n对于没有正确分类的视频序列进行分析：\n\n\n\n\nLarge-scale video classification(cvpr 2014)\n数据集(data)\n\n计算效率(architechture)双流法: scene stream and centre stream\n\n时空连接模式(model)对于时域信息，我们采用在网络的早期(early fusion)，后期(late fusion)，或是处理过程中(slow fusion)进行融合的效果\n\n数据分析(experiment)\n分类置信度bar图+对比\n\n\n\n  **类别分类精度对比排序**\n\n\n  **filters可视化**\n\n\n\nLearning Spatiotemporal Features（ICCV 2015）\n模型可视化（experiment）\n\n\n\n\n对学习到的特征进行分析（experiment）\n\n紧凑性\n\n区分能力(t-SNE)\n\n\n\n\n\n\n\n\nQuo Vadis, Action Recognition(cvpr 2017)\n数据集(data)：Kinetics\n\n2D 卷积膨胀(model)\n从视频中学习时空特征的同时，利用优秀的ImageNet网络架构及参数\n\n双流架构（model）\n双流算法采用的是 TV-L1 algorithm\n\n\n\n\n\n数据分析（experiment）\n不同架构对比\n\n\n\n\nPseudo-3D Residual Networks\nP3D Block: 3D卷积解耦（model）\n\n\n\n\nP3D Chain: 利用结构多样性（architecture）\n\n\n\n\n类别知识可视化（experiment）\n\n\n\nA Closer Look at Spatiotemporal Convolutions\n在解耦3D Filter方面对P3D做了优化（model）\n\n​    R(2+1)D卷积块\n​    它将个大小为$N_{i-1}tdd卷积核分解为M_i个大小为N_{i-1}1dd的卷积核核N_i个大小为M_it1*1的时间卷积核。因此M_i作为决定中间子空间（信号从空间卷积到时间卷积的投影）维度的超参。那么这个M_i$该如何选择呢？\n\n\n\nmixed convolution（architecture）\n\n​    3D卷积在网络的早些层，2D卷积在网络的后面的层\n\n精度与复杂度对比（experiment）\n\n\n\n\n精度与输入帧数的关系（experiement）\n\n\n\n​    Findings: 在较短帧上进行训练，在较长帧上进行finetuning，会达到比较好的效果。\n\n\nLong-Term Temporal Convolutions主要看它的实验部分：\n\n数据增强实验\n\n\n\n\n模型组合\n\n\n\n\n学习到的filters可视化\n\n\n\n\n\nNon-local Neural Networks\nNon-local Block — 捕获长期时空依赖（model）\n理解non-local块的前提是理解非局部操作：\n\n\n简单来讲，它计算的是第i个位置与其他所有位置的关系，进行求和与归一化后的值。在我的理解看来，就像是两个位置的关系进行建模，而是这个关系的权重。\n二元函数f的选择是论文讨论的重点：\n\n高斯: \n嵌入高斯: \n点积: \n连接: \n\n\n\n​      文章还说明了自注意力模块与嵌入高斯版的非线性操作的异同，他们的最终形式是一样的：。但是作者拓展得到时空非局部网络能够处理多样的输入，具有泛用性。\n​      作者将non-local块形式化地定义为：。实际上即使用了残差连接，它有诸多好处：\n\n能够让我们将新的non-local块插入任何预训练模型但不改变他的任何行为，只需将初始化为0即可。\n而是可以增强特征（+）, 同时防止梯度消失。\n\n\n\n\n加入non-local块的位置选择\n\n\n如图，加入到3，4 stage都是合适的\n\n加入non-local块数的影响\n\n\n而且该实验也证明了精度的提升并不全部来自网络深度的增加\n\n时间-空间-时空维度的non-local操作对模型的影响\n\n\n","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“行为识别论文总结-续”","url":"/2023/08/05/paper-reading/paper_reading_conclusion_02/","content":"Paper Reading Reflections on Group Action RecognitionWhat is GAR?\n\n\nA Hierarchical Deep Temporal Model for Group Activity Recognition(cvpr 2016)Detecting events and key actors in multi-person videos(cvpr 2016)Hierarchical Relational Networks for Group Activity Recognition and Retrieval(ECCV 2018)Learning Actor Relation Graphs for Group Activity Recognition(2019)Convolutional Relational Machine for Group Activity Recognition (CVPR 2019)HiGCIN: Hierarchical Graph-based Cross Inference Network for Group Activity Recognition(TPAMI 2020)Social Adaptive Module for Weakly-supervised Group Activity Recognition(eccv 2020)Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos（eccv 2020）Progressive Relation Learning for Group Activity Recognition（cvpr2020）Actor-Transformers for Group Activity Recognition（cvpr2020）GroupFormer: Group Activity Recognition with Clustered Spatial-Temporal Transformer(ICCV 2021)Spatio-Temporal Dynamic Inference Network for Group Activity Recognition(iccv 2021)Dual-AI: Dual-path Actor Interaction Learning for Group Activity Recognition(cvpr 2022)","categories":["论文阅读","行为识别"],"tags":["Activity Recognition"]},{"title":"论文阅读笔记：“MGFN：Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection”","url":"/2023/08/05/paper-reading/paper_reading_065/","content":"论文阅读笔记：“MGFN：Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection”网络框架\n\n核心亮点Feature Amplification Mechanism (FAM)\n\n对于第i个视频的第t个片段，FAM会计算一个特征范数，他是在特征维度进行归一化\n之后使用1d卷积调制范数信息来进行增强信息导出：\n\n\nMagnitude Contrastive Loss之前经典方案是二元交叉熵损失：\n论文提出了振幅对比损失：\n\n\np,q是正常clip的索引，u,v是异常clip的索引，Ma是异常视频top-k高的特征振幅。如果p，u是一对正常，异常视频clip\n\n\n总体loss计算公式：\n\n\n","categories":["论文阅读","视频异常检测"],"tags":["video anomaly detection"]},{"title":"行为识别survey","url":"/2023/08/05/paper-reading/paper_reading_overview/","content":"行为识别surveygithub论文代码\nECO: Efficient Convolutional Network for Online Video Understanding\n\nTSM: Temporal Shift Module for Efficient Video Understanding\n\nTemporal Action Detection with Structured Segment Networks\n\nOnline Real-time Multiple Spatiotemporal Action Localisation and Prediction\n\nNon-local Neural Networks for Video Classification\n\n\nsummary\nno single approach to all problems\n行为识别传统方法依赖于目标检测，姿态检测，密集轨迹或是结构化信息\n卷积神经网络可以提取每个帧的特征来获取视频级别的预测，它的缺点是不能有效地捕获运动信息\n结合光流方法可以捕获短期运动信息\n除了RGB和光流，其他形式的信息如音频，姿势，轨迹也应该加以利用\n王等人关注于带有外观特征的密集轨迹描述符\nchoutas等人编码了人体关节点的运动，得到的结果热图在时间上聚集\n我们可以使用双流法，通过融合运动和外观信息构建时空表示，对于短时视频它比较有效，但不适于获取长期的时间动态信息\n双流法包含了两个单独的子网络，一个用于原始图像，另一个用于堆叠的光流，通过融合两个流的softmax分数可以获取时空信息\nRNN，特别是LSTM，因其在长期时间建模的能力，在顺序任务上取得了令人瞩目的成就，所以一个可选的方案是采用LSTM来建模帧级别特征的动态信息\nDonahue等人设计了一个循环卷积架构，which cascaded a CNN with a recurrent model into a unified model。它可以在时间和空间维度学习视频级别的表示\nNg等人将时间特征池化架构与LSTM相结合\n王等人利用了深层3D卷积网络来处理salient-aware clips\nyuan等人合成了运动轨迹，光流，和视频分割并形成了空间-光流数据，之后使用双流法分别处理合成数据和RGB数据\n除了2D卷积网络，3D卷积网络被提出用来处理视频。但是这些方法通常有冗余参数，并且需要提前在大规模视频数据集上预训练\n并且，近期架构使用了注意力机制来获取视频中的显著部分，它可以克服LSTM中无法区分视频的不同部分的缺点\n\nno standard benchmark\nhigh spatial correlation among the videos makes the actual diversity in the training much lesser.\ngiven the similar theme (sports) across both the datasets, generalization of benchmarked architectures to other tasks remained a problem\nusing pre-trained 2D CNNs as a starting point for drastically better convergence\n\nactions recognition approaches overview\nLocal high-dimensional visual features that describe a region of the video are extracted either densely [3] or at a sparse set of interest points[4 , 5].(提取高维视觉特征)\nThe extracted features get combined into a fixed-sized video level description. One popular variant to the step is to bag of visual words (derived using hierarchical or k-means clustering) for encoding features at video-level.\nA classifier, like SVM or RF, is trained on bag of visual words for final prediction\n\nApproach 1: Single Stream Network\nThe learnt spatiotemporal features didn’t capture motion features\nThe dataset being less diverse, learning such detailed features was tough\n\nApproach 2: Two Stream Networks","categories":["论文阅读","综述"],"tags":["行为识别"]},{"title":"CS106L笔记：Multi-threading","url":"/2023/08/05/course-learning/CS-106L/Multi-Threading/","content":"Multi-threadingThread\nthreads are ways to parallelise  execution\n\n\nwhat’s the problem?\n\n\n\n\nDATA RACE!\n\nuse LOCK!\n\n\n\n\n\n\n\n\n\n\n//std::mutex mtx;void greet(int id){    //std::lock_guard&lt;std::mutex&gt; lg(mtx);    cout&lt;&lt;\"my name is \"&lt;&lt;id&lt;&lt;endl;}int main(){    cout&lt;&lt;\"Greetings from my threads...\"&lt;&lt;endl;    std::thread thread1(greet,id1);    std::thread thread2(greet,id2);    thread1.join();    thread2.join();    cout&lt;&lt;\"All greetings done!\"&lt;&lt;endl;    return 0;}\n\n\n\n\nData Racing is unpredictable!\n\n\nuse lock_guard to ensure the greeting is atomic:\n\nstd::mutex mtx;void greet(int id){    std::lock_guard&lt;std::mutex&gt; lg(mtx);    cout&lt;&lt;\"my name is \"&lt;&lt;id&lt;&lt;endl;}\n\n\nuse join to let the main wait the thread to finish\n\nthread1.join();thread2.join();\n\n\n\n\nthe results seems fine!\n\n//...work with vector if threadsvector&lt;std::thread&gt; threads;for(size_t i=0; i &lt; kNumThreads; ++i){    threads.push_back(std::thread(greet,i));}for(std::thread&amp; t: threads){    t.join();}//...\n\n","categories":["courses","c++"],"tags":["C++","CS106L"]},{"title":"CS106L笔记：OOP","url":"/2023/08/05/course-learning/CS-106L/OOP/","content":"Object Oriented Programming\n\nFundamentals.h vs .cpp\n\n.h defines public interface API\n.cpp handle all the dirty details\n\n\n\nwhy so may extensions?\n\nheader file: .h, .hh, .hpp\n\nsource file: .cc, .cpp, .cxx, .c++, .C\n\nDepends on the compiler\n\n\n\n\nConst\n\nWhy use CONST?There is no excuse for ignoring the safety mechanisms provided with a product, and there is particularly no excuse for programmers too lazy to write const-correct code.\n\nsame as Why don’t we use global variables?\n\n\n“Non-const variables can be read or modified by any part of the function“ &lt;**NOT SAFE!!!**&gt;\n\n\n\n\nif we don’t use const, we can’t spot the bug easily in the above code\n\n\n\n\nif we use const instead of the one above:\n\n\n\n\nwe could get errors from the compiler(compiler time error):\n\n\n\n\nBesides, const allows us to reason about whether a variable will be changed\n\n\n\nconst and Classes\n\n\ncan’t call non-const member function on const object:\n\n\n\nConst Iterators\nconst vector::iterator itr acts like int* const  itr\n\nto make an iterator read-only, define a new const_iterator\n\n\n\n\n\n\nOperatorsOperator Overloading\n\n\nWhen dealing with user-defined class:\n\n\n\n\n\n// membervector&lt;string&gt;&amp; vector&lt;string&gt;::operator+=(const string&amp; s){    push_back(element);    return *this;}vec += \"hello\";vec.operator+=(\"hello\");\n\n// const memberStringVector StringVector::operator+(const StringVector&amp; s) const{}// non-memberStringVector operator+(const StringVector&amp; s1, const StringVector&amp; s2){}\n\nSo, implement as Member of Non_Member?\n\n[], (), -&gt;, = must be implemented as member\n&lt;&lt;, implemented as non-member\n+,&lt; if binary op treats both operands equally, implement as non-member\n+= if binary op doesn’t treat both operands equally( change lhs)\n\n// non-member functionstd::ostream&amp; operator&lt;&lt;(std::ostream&amp; os, const Fraction&amp; F){    os &lt;&lt; f.num&lt;&lt; \"/\" &lt;&lt; f.denom;    }\n\nPOLA(Principle of Least Astonishment)\ndesign operators primarily to mimic conventional usage\n\n\nif operator is ambiguous ,  don’t overload that operator\n\nuse non-member functions for symmetric operators\n\n\n\n\n\nThe second one doesn’t work if overloaded as member function.\n\n\nalways provide all out of a set of related operators\n\n\n\n\ndon’t astonish others: if you implement &lt; , you should also implement &gt; etc.\n\n\nalways think about const vs non-const for member functions:\n\n\n\n\nFunctors (basically lambdas)\n\n\nAdvanced Multi-threading Support (C++20)\nawaiter operator co_await() const noexcept {    return awaiter{*this};}\n\nSpecial Member FunctionsStringVector vec7 = vec4;// copy constructorvec7 = vec2;// copy assignmentreturn vec7; // copy constructor\n\nwhen we don’t use default copy constructor? \n\n\nwhen we have ownership issues:\n\nownership issues: a member is a handle on a resource outside of the class\npointers\nmutexes\nfilestreams\n\nRule of Three\nif you explicitly define a copy constructor, copy assignment of destructor, you should define all three\n\nwhen we need to declare a destructor, we have to take care of the ownership issues, the issues happen to other two.\nMove Semantics\nemplace_back?\n\n\nbased on the philosophy: if you don’t need any copy, don’t do it\n\n\n\n\nfor larger objects\n\nAll things have its beginning\nWhat happens when running the following codes?\n\nStrVector readNames(size_t size){    StrVector names(size,\"Ito\");    return names;}int main(){    StrVector name1 = readNames(54321234);    StrVector name2;    name2 = readNames(54321234);}\n\n\nyou may find it surprising, lots of copy constructor and destructor!\n\n\n\n\nso any optimization?\n\ncopy elision, c++17, compiler make the copy only once in the caller function(main)\n\n\n\n\n\nstill have any further optimization ?\nYES!! The cool thing move can save us more time.\n\nin the following code:\nname2 = readNames(54321234);\n\n\nreadNames is a temporary value, and will become homeless and will be destroyed, why we need to copy it? There is no need!\nWe could move(steal) the resources instead!\n\nlvalue vs. rvalue\nlvalue: has a name, can find address\nrvalue: no name, temporary\n\nv1[1] = 4*i; // v1[1] is a reference to named value \"lvalue\"v1[2] = *ptr; // *ptr is a \"lvalue\" because it points to a named value\n\n  lvalue reference vs. rvalue reference\nauto&amp;&amp; v4 = v1+v2; // save the rvalue, or expands its life time!\n\n\nany changes to v4 will change (v1+v2) temporary object.\n\nauto&amp; ptr3 = &amp;val; // Wrong! can't bind lvalue reference to rvalueauto&amp;&amp; val2 = val; // Wrong! can't bind rvalue reference to lvalue\n\n\nbut we could bind const lvalue reference to rvalue\n\nconst auto&amp; ptr3 = ptr + 5; // correct! const save us a lot!\n\n\nwhy it works?\n\nbecause you are not changing it anyway, so it is fine.\nmove constructor and assignment\nwhy rvalue are key to move semantics?\n\n\nlvalue is NOT disposable, so you can copy from, but definitely cannot move from.\nrvalue is disposable, so you can move from\n\n// StringVector(StringVector&amp;&amp; other) noexcept;// StringVector&amp; operator=(StringVector&amp;&amp; rhs) noexcept;Axess&amp; operator=(Axess&amp;&amp; rhs){    students = std::move(rhs.students); // avoid copy!}\n\n\nrhs itself is actually lvalue, so we need to std::move\n\nswap\nThe first very primitive attempt:\n\ntemplate&lt;typename T&gt;void swap(T&amp; v1, T&amp; v2){    T temp = v1;    v1 = v2;    v2 = temp;}\n\n\nBad! make three copies, sadly.\n\n\nwith move, second attempt with the knowledge of rvalue reference:\n\ntemplate&lt;typename T&gt;void swap(T&amp; v1, T&amp; v2){    T temp = std::move(v1);    v1 = std::move(v2);    v2 = std::move(temp);}\n\n\nCool! We use no copy with move!\n\nRule of Five\nIf you declare one, you should declare all of them.(plus move constructor and move assignment)\n\nInheritanceNamespacesnamespace Lecture{    int count(const vector&lt;int&gt;&amp; v){        int ctr = 0;        for(auto i:v){            if(i==1)                ++ctr;        }        return ctr;    }    }cout&lt;&lt;Lecture::count(vec)&lt;&lt;endl;\n\nMotivationinterface\nclass Drink{\tvirtual void make() = 0;};\n\n\ncannot be instantiated\n\nAbstract Classes\n\ncannot be instantiated\n\nhas at least one pure virtual function\n\n\nNon-virtual Destructors\nclass Base{    ~Base(){}};class Derived: public Base{    ~Derived(){}}Base *b = new Derived();delete b; // Never calls the destructor for derived\n\n\n\nTempletes vs. Derived Classes\n\nWhen to use each?\nstatic vs. dynamic polymorphism\n\n\nTempletes: at complile time generate real codes\nDerived Classes: at run time\n\n\n\nRAII\nHow many code paths are there ?\n\n\n\n\n\n\nCan you guarantee there is no memory leek in the code?\n\n\n\n\nFor normal code paths, this code is fine.\nBut if there is an exception, we will never reach the delete e.\n\n\nHow to enforce exception safety?\n\n\n\nRAII: Resource Acquisition Is Initialization\n(Scope Based Memory Management) (Constructor Acquires, Destructor Releases)(Pointer to Implementation)\nWhat is RAII?\n\nall resources should be acquired in the constructor\nall resources should be released in the destructor\n\nan example: ifstream satisfies RAII\n\n\n\nyou should not call close\n\nanother example\n\n\nfix:\n\n\n\n\nbesides:\n\n\n\nIs automatic memory management a good or bad thing?\n\n\n\nUnique Pointer\nuniquely owns its resource and deletes it when the object is destroyed.\ncan’t be copied.\n\n\n\n\n\n\n\nShared pointer\nResources can be stored by any number of shared_ptrs.\nDelete when none of them point to it\n\n\n\n\n\n","categories":["courses","c++"],"tags":["C++","CS106L"]},{"title":"CS106L笔记：STL","url":"/2023/08/05/course-learning/CS-106L/STL/","content":"C++ Learning Roadmap\n\nSTLoverview of STL\n\nwhy use c++ for development?\ncommunity\ndeveloping or evolving\nopen source (unlike Java , which is owned by Oracle, so you can use c++ for business need.)\nsuper extensible (boost library like c++ STL plus plus)\n\nContainers Adaptors\nstack &amp; queue\n\nAdapt vector and deque containers to suit this particular need.\n\nwhy not just user a vector/deque?\n\nExpress ideas and intent directly in code. And compartmentalize messy constructs.\nAssociative Containers\nhave no idea of sequence \n\nData is accessed using the key instead of indexes.\n\nincludes:\n\nstd::map&lt;T1,T2&gt;：associate one key type of data with other value type of data\nstd::set\nstd::unordered_map&lt;T1,T2&gt;\nstd::unordered_set\n\n\nmap &amp; set are based on ordering property of keys(needs to be comparable)\n\nwhen to use map/set , when to use unordered ones?\n\n\nmap/set: iterate through a range of elements\nunordered: access individual elements by key\n\nHow do we iterate over associative containers?\n\nuse Iterators\nMultimaps\nMaps store unique keys\nsometimes we want the map to have the same key pointing different values\n\nmultimap&lt;int, int&gt; myMMap;myMMap.insert(make_pair(3,3));myMMap.insert({3,12});cout&lt;&lt;myMMap.count(3)&lt;&lt;endl; // prints 2\n\nIterators\nwhy iterator is powerful?\n\nmany scenarios require looking at elements, regardless of what type of container is storing those elements.\ngo through sequence in a standardized way( use the exact same code to perform a logical action, regardless of the data structure, independent of the container)\n\n\nphilosophy in Iterators\n\nlet us view a non-linear collection in a linear manner(iterate one by one without visiting twice)\n\n\n\nMap Iterators\nthe iterator of map&lt;string, int&gt; points to a std::pair\n\n\n\nauto time = std::make_pair(1,45);\n\nfind vs. count\n\ncount is just a call to the find. So find is faster\nIterator types\n\nthe one on the right is more powerful than the left one.\nTemplatesWhy use template functions(generic functions)?\nThey are such a powerful tool that could solve a bunch of similar problems.\n\nwhat if there are multiple potential templates functions?\n\n\n\n\nConcept Lifting\nQuestion the assumptions you place on the parameters whether they are really necessary?\nCan you solve a more general problems by relaxing the constraints?\n\n\nAn amazing example:\n\n\n\nImplicit interfaces\na template function defines an implicit interface that each template parameter must satisfy\n\nConcept\nA predicate, evaluate at compile time, that is a part of the interface\n\npredicate(谓语)predicate is a function which takes in some numbers of arguments and returns a boolean\n\nunary predicate: one argument\n\nbinary predicate: two arguments\n\n\nmore generic version of countOccurences:\ntemplate&lt;typename InputIterator, typename UniaryPredicate&gt;int countOccurences(InputIterator begin, InputIterator end, UniaryPredicate predicate){    int count = 0;    for(auto iter = begin; iter!=end; ++iter)        if(predicate(*iter)) ++count;    return count;}\n\n\nwhat if we want predicate to be more flexible? \n\npre c++11 solution:\nuse classses, of course,we have to override operators.\n\n\n\n\n\nc++11 solution:\nuse lambda, it’s an object but acts like a function, because it generate the class and create an instance of it.\nyou can use auto in parameters to templatize the lambda\n\n\nint main(){    int limit = getInteger(\"minimum for A?\");    vector&lt;int&gt; grades = readStudenGrades();    auto func = [limit](auto val){return val&gt;=limit;};    countOccurences(grades.begin(),grades.end(),func);}\n\n\nyou can also capture by reference, only capture the variables you need\n\nset&lt;string&gt; teas{\"black\",\"green\",\"oolong\"};string banned = \"boba\";auto likedByAvery = [&amp;teas, banned](auto type){    return teas.count(type) &amp;&amp; type!=banned;};\n\nAlgorithmsWhy use algorithms?\nAbstractions\nGeneric\nCorrect\nHeavily optimized\n\nstd::sortauto compareRating = [] (const Course&amp; c1, const Course&amp; c2){    return c1.rating &lt; c2.rating;};std::sort(courses.begin(),courses.end(),compareRating);std::copy(courses.begin(),courses.end(),std::ostream_iterator&lt;Course&gt;(std::cout),\"\\n\");\n\nstd::nth_elementauto m = v.begin() + v.size()/2;std::nth_element(v.begin(), m, v.end());std::cout &lt;&lt; \"\\nThe median is \" &lt;&lt; v[v.size()/2] &lt;&lt; '\\n';std::nth_element(v.begin(), v.begin()+1, v.end(), std::greater{});std::cout &lt;&lt; \"\\nThe second largest element is \" &lt;&lt; v[1] &lt;&lt; '\\n';std::cout &lt;&lt; \"The largest element is \" &lt;&lt; v[0] &lt;&lt; '\\n';printVec(v);\n\nstd::stable_partition\n\n\nreturn: Iterator to the first element of the second group\n\nauto isDep = [](auto element){    return element.name.size() &gt; 2 &amp;&amp; element.name.substr(0,2)==\"CS\";};std::stable_partition(courses.begin(), courses.end(),isDep);std::copy(courses.begin(),courses.end(),std::ostream_iterator&lt;Course&gt;(std::cout),\"\\n\");\n\nstd::copy_if#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;iterator&gt;#include &lt;numeric&gt;#include &lt;vector&gt; int main(){    std::vector&lt;int&gt; from_vector(10);    std::iota(from_vector.begin(), from_vector.end(), 0);     std::vector&lt;int&gt; to_vector;    std::copy(from_vector.begin(), from_vector.end(),              std::back_inserter(to_vector));// or, alternatively,//  std::vector&lt;int&gt; to_vector(from_vector.size());//  std::copy(from_vector.begin(), from_vector.end(), to_vector.begin());// either way is equivalent to//  std::vector&lt;int&gt; to_vector = from_vector;    std::cout &lt;&lt; \"to_vector contains: \";     std::copy(to_vector.begin(), to_vector.end(),              std::ostream_iterator&lt;int&gt;(std::cout, \" \"));    std::cout &lt;&lt; '\\n';     std::cout &lt;&lt; \"odd numbers in to_vector are: \";     std::copy_if(to_vector.begin(), to_vector.end(),                 std::ostream_iterator&lt;int&gt;(std::cout, \" \"),                 [](int x) { return x % 2 != 0; });    std::cout &lt;&lt; '\\n';     std::cout &lt;&lt; \"to_vector contains these multiples of 3: \";     to_vector.clear();    std::copy_if(from_vector.begin(), from_vector.end(),                 std::back_inserter(to_vector),                 [](int x) { return x % 3 == 0; });     for (int x : to_vector)        std::cout &lt;&lt; x &lt;&lt; ' ';    std::cout &lt;&lt; '\\n';}\n\n上面两例copy_if的最后一个参数使用了Iterator Adaptor\n\nback_inserter\nostream_iterator\n\nstd::remove_if\nremove can change the content, but does not change the size of the container(because it is not a member of std::vector)\n\n\n\n\nerase-remove idiom:\n\nv.erase(std::remove_if(v.begin(),v.end(),pred),v.end());\n\nstd::findWrapping Up The STLAbstraction in the STL\n\nstd::string str_tolower(std::string s) {    std::transform(s.begin(), s.end(), s.begin(),                 // static_cast&lt;int(*)(int)&gt;(std::tolower)         // wrong                // [](int c){ return std::tolower(c); }           // wrong                // [](char c){ return std::tolower(c); }          // wrong                   [](unsigned char c){ return std::tolower(c); } // correct                  );    return s;}\n\nfileToString: get the file into a string \nstring fileToString(ifstream&amp; file){    string ret=\"\";    string line;    while(std::getline(file,line)){        std::transform(line.begin(),line.end(), line.begin(),[](unsigned char c){return std::tolower(c);});        ret += (line + \" \");    }    return ret;}\n\ncountOccurrences: find the number of the word that appears in a text\n\nwhy can’t we use std::count()?\n\ncause, iterator in string actually points to a character, which can only count character\n\nuse std::search() instead\n\n Searches for the first occurrence of the sequence of elements [s_first, s_last) in the range [first, last)\nint countOccurrences(){    string toFind = \" \"+ word+\" \";    // &lt;regex&gt;    auto curr = text.begin();    auto end = text.end();    int count = 0;        while(curr!=end){        auto found = std::search(curr,end,toFind.begin(),toFind.end());        if(found == end) break;        ++count;        curr = found + word.size();    }    return count;}\n\nint dotProduct(const vector&lt;int&gt;&amp; vec1,const vector&lt;int&gt;&amp; vec2){    std::inner_product(vec1.begin(),vec1.end(),vec2.begin(),0);  }int mag(const vector&lt;int&gt;&amp; vec){    return std::sqrt(dotProduct(vec,vec));}\n\n","categories":["courses","c++"],"tags":["C++","CS106L"]},{"title":"CSAPP笔记：Bits, Bytes and Integer01","url":"/2023/08/05/course-learning/CMU-213/213_bits01/","content":"\ncourse website:here\n\nCSAPP笔记：Bits, BytesRepresenting information as bitsEverything is bits\n0/1\nencoding/interpreting sets of bits in various ways\ninstructions\nrepresent and manipulate numbers. sets and strings\n\n\nwhy use bits?\neasy to store\nreliably transmitted on noisy and inaccurate wires\n\n\n\n\n\nEncoding Byte Values\nBinary 00000000-11111111\nDecimal 0-255\nHexadecimal 00-FF\n\nExample Data Representations\n\nBit level manipulationBoolean algebra\n\nExample: Representing and manipulating Sets\nwidely used\n\n\n\n\nsymmetric difference is  对称差 in chinese:\n\n\n\nshift\n\nleft shift\nright shift\nlogical shift\narithmetic shift\n\n\nundefined behavior\nshift amount &lt; 0 or &gt;= word size\n\n\n\nIntegersRepresenting signed and unsignedEncoding IntsUnsigned\n\n\nSigned\n\nfor two’s complement, most significant bit indicated sign\n0 for nonnegative\n1 for negative \n\n\n\n\n\nNumeric RangesUnsigned\n0 ~\nTwo’s Complement(universal)\n~\nMinus 1\n1111…111\nvalues for W = 16\n\n\nvalues for different word sizes\n\n\n\n64bits TMax has 18  位\n\nConversion, CastingMapping between Signed &amp; Unsigned\n\n\nkeep bit representations and reinterpret\n\n\n\n\n\n\n\n\ncasting may cause some surprises , we need to be careful\n0 == 0U\n-1 &lt; 0\n-1 &gt; 0U\n2147483647U &lt; -2147483648\n\n\n\n\nwhat does this code return for TMin?\n\n\n\n\nit will return TMin(100…000)\n\n\nwhy UMax = 2TMax+1?\n\n\n\n\n What if i is declared unsigned?\n\n\n\n\ninfinite loop: 0-&gt;UMax\n\n\nanother example\n\n\n\n\n infinite loop\n\nExpanding, TruncatingSign Extension\n\nexample:\n\n\n\n\n\n\n\nthe above is a negative number\n\nTruncating\n\n\nit’ so funny here, the professor does the additions wrongly for two  times\n\n\n\n\nit wasn’t a very interesting example :)\n\n\n\n\npositive number may become negative number\nnegative number may become positive number\n\n","categories":["courses","CSAPP"],"tags":["CSAPP"]},{"title":"CSAPP笔记：Bits, Bytes and Integer02","url":"/2023/08/05/course-learning/CMU-213/213_bits02/","content":"CSAPP笔记：Bits, Bytes and Integer02IntegersAdditionUnsigned Addition\n\nw is the word size(bit)\n\n\n\n\n\n\n\nsubstract 2^w from the sum\n\nTwo’s Complement Addition\n\n\nnegative overflow\n\n\npositive overflow\n\n\n\n\nMultiplicationunsigned\n\nsigned\n\n\nDivide with Shift\nround down to zero\n\n\n\nNegative(~ + 1)\n\n\nWhen should use Unsigned?\n\n\nwhen performing modualr arithmetic\nusing bits to represent sets\n\nRepresentations in memory, pointers and stringsByte-Oriented Memory Organization\n\n\nAn address is like an index into that array\n\nsystem provides private address spaces to each “process”\n\n32 bit machines Limits addresses to 4GB\n\n\ngcc -m {32,64}\nWord-Oriented Memory Organizationgroup bytes to word\n\n\n\nassume the address of the word is the loweset address of byte in it\n\nExample Data Representation\n\n\nByte Ordering\nhow are the bytes within a word ordered in memory?\n\n\nBig Endian: internet, Sun\nleast significant byte has highest address\n\nlittle Endian: x86, Arm, IOS, Windows\nleast significant byte has lowest address\n\n\nan example\n\nVariable x has 4-byte value of 0x01234567\nAddress given by &amp;x is 0x100\n\n\nanother example \n\n15213\nbinary: 0011 1011 0110 1101\nhex:         3        B        6       D\n\n\n\na useful code to print Byte Representation of Data\ntypedef unsigned char * pointer;void show_bytes(pointer start, size_t len){    size_t i;    for(i = 0; i&lt;len; ++i)        printf(\"%p\\t0x%.2x\\n\",start+i, start[i]);}\n\n\n\nRepresenting strings\narray of characters\nASCII format\nnull-terminated\n\n\n\n  \n\nInteger C Puzzles\n\nx&lt;0 -&gt; ((x*2)&lt;0)\nFalse Tmin: “100000000” -&gt; “00000000”\n\nux &gt;= 0 \nTrue\n\nx&amp;7 == 7  -&gt; (x&lt;&lt;30) &lt;0\nTrue “1100…000”\n\nux &gt; -1\nnever true False\n\nx&gt;y -&gt; -x&lt;-y\nFalse Tmin: -Tmin is still Tmin\n\nx*x &gt;=0\nFalse\n\nx&gt;0 &amp;&amp; y&gt;0 -&gt; x+y &gt; 0\nFalse\n\nx &gt;=0 -&gt; -x&lt;=0\nTrue (Tmax)\n\nx &lt;=0 -&gt; -x&gt;=0\nFalse(Tmin)\n\n(x|-x)&gt;&gt;31 == -1\nFalse(0)\n\n\n","categories":["courses","CSAPP"],"tags":["CSAPP"]},{"title":"CS106L笔记：Template Metaprogramming","url":"/2023/08/05/course-learning/CS-106L/Template_Metaprogramming/","content":"Template MetaprogrammingMotivating example#include&lt;vector&gt;#include&lt;deque&gt;#include&lt;set&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;int main(){    vector&lt;string&gt; names{\"Anna\",\"Ethan\",\"Nikhil\",\"Avery\"};    auto anna_iter = find(name.begin(),name.end(),\"Anna\");    auto avery_iter = find(name.begin(),name.end(),\"Avery\");        return std::distance(anna_iter,avery_iter);}\n\n\nhow do you implement your own distance function?\n\ntemplate&lt;typename It&gt;size_t my_distance(It first, It last){\treturn last-first;}\n\n\nthe above code is O(1),  which is efficient.\nbut the above implementation only works for random access iterator\n\nanother optimization!\ntemplate&lt;typename It&gt;size_t my_distance(It first, It last){\tsize_t result = 0;    while(first!=last){        ++first;        ++result;    }    return result;}\n\n\nbut the second way is O(N), for any kind of iterators, which is unexpected\n\n\nHow does STL achieve this?\n\n\nYou have to extract type information from iterator of what it is.\nneed to determine if it is random access iterator\nrun the piece of code based on the type of iterator:\n\n\n\nComputations on TypesComparision of values vs. type computations : A Preview\n\n\n\n\n\n\n\n\n \n\n\n\n\n\nMeta-functionstemplate types\n\nuse them for template classes\n\n\n\ntemplate values\n\n\nmeta-function\nabstractly:\n\nIt is a function that operates on some types/values(“parameters”)\nand outputs some types/values(“return values”)\n\nconcretely:\n\nIt is a struct that has public member types/fields(output) which depend on what the template types/values(input) are instantiated with.\n\n\n\n\na simple example:\n\n\n\n\n\n//input type, output valuetemplate&lt;typename T, typename U&gt;struct is_same{    static const bool value = ????;};//input value, output valuetemplate&lt;int V, int W&gt;struct is_same{    static const bool value = (V==W);};\n\nTemplate DeductionTemplate Rules\n\nTemplate Specialization: you can have a “generic template”, as well as “specialized” templates for  particular types\n\nFully specialize:\n\n\nwhy specialization?: using a bit array to store booleans is much more efficient.\npartially specialize:\n\n\nSome examples using Template Deduction\nlet’s build up a collection of predicate meta-functions\n\n\n\nwhy does the second one return true?\n\nthe compiler tries to first match the specialized template\nthe second one got matched, so return true\n\n\n\n\nkind of interesting, you can figure out the type info, because of template deduction rules\n\n\n\n\nof course, same technique can be used to return a type\n\nActually it is a “hack”, because we  are using the compiler’s template matching rules to implement an if/else statement for types(we can’t directly compare them)\nLet finish our myDistance implement:using category = typename std::iterator_traits&lt;It&gt;::iterator_category;if (std::is_same&lt;category, std::random_access_iterator_tag&gt;::value){    return last - first;}else{    size_t result = 0;    while(first!=last){        ++first;        ++result;    }    return result;}\n\n\nneed to remove the offending code when the if statement knows that part won’t be run;\n\npre-C++17: std::enable_if\n\nC++17: if constexpr\n\n\nusing category = typename std::iterator_traits&lt;It&gt;::iterator_category;if constexpr (std::is_same&lt;category, std::random_access_iterator_tag&gt;::value){    return last - first;}//else ...\n\n\nwhat is constexpr?\n\nyou can calculate this expression at compile time.(stronger form of const)\n\nwhat is if constexpr?\n\ncalculate boolean at compile-time , Replace the entire if/else with the code that will be actually be run\n","categories":["courses","c++"],"tags":["C++","CS106L"]},{"title":"CSAPP笔记：Network Programming","url":"/2023/08/05/course-learning/CMU-213/213_network_programming/","content":"Network Programming\n\n\nnetwork behaves like files (in unix)\n\nAccessed via a mix of Unix file I/O and functions from sockets interface\n\n\n\n\n- \n","categories":["courses","CSAPP"],"tags":["CSAPP"]},{"title":"如何准备蓝桥杯？","url":"/2023/08/05/course-learning/lanqiao-preparation/lanqiao01/","content":"如何准备？\n过知识点（10个重要的），从历年题中抓10个最频繁出现的point\n例题的思路搞懂，再做一遍\n做习题题目\n\n重点\n\n刷题量\n调试\n\n套路\n一般ACM或者笔试题的时间限制是1秒或2秒。\n在这种情况下，C++代码中的操作次数控制在 为最佳。\n下面给出在不同数据范围下，代码的时间复杂度和算法该如何选择：\n\n , 指数级别, dfs+剪枝，状态压缩dp\n，floyd，dp，高斯消元n\n，，dp，二分，朴素版Dijkstra、朴素版Prim、Bellman-Ford\n，块状链表、分块、莫队\n =&gt; 各种sort，线段树、树状数组、set/map、heap、拓扑排序、dijkstra+heap、prim+heap、Kruskal、spfa、求凸包、求半平面交、二分、CDQ分治、整体二分、后缀数组、树链剖分、动态树\n, 以及常数较小的 算法 =&gt; 单调队列、 hash、双指针扫描、并查集，kmp、AC自动机，常数比较小的的做法：sort、树状数组、heap、dijkstra、spfa\n，双指针扫描、kmp、AC自动机、线性筛素数\n，判断质数\n，最大公约数，快速幂，数位DP\n，高精度加减乘除\n，k表示位数，高精度加减、FFT/NTT\n\n递归斐波那契数列\n1.2.3.5.8.13\n递推式：\nint fibo(int n){    if(n==1) return 1;    if(n==2) return 2;    return fibo(n-1)+fibo(n-2);}\n\n如何思考递归问题？\n所有递归都可以转化为一颗递归搜索树，例如对斐波那契数列而言：\n\n\n\n\n递推当前步的操作（状态）由上步的状态推出\n费解的开关\n25 盏灯排成一个 5×5 的方形。\n每一个灯都有一个开关，游戏者可以改变它的状态。\n每一步，游戏者可以改变某一个灯的状态。\n游戏者改变一个灯的状态会产生连锁反应：和这个灯上下左右相邻的灯也要相应地改变其状态。\n给定一些游戏的初始状态，编写程序判断游戏者是否可能在 6 步以内使所有的灯都变亮。\n\n思想首先，枚举第一行的所有可能操作（1：改变状态，0：不改变状态），当一行的所有操作确定之后，只有第二行才能改变第一行的状态。因此此时如果第一行的某个灯目前是暗的，第二行对应的灯必须要进行操作来使第一行的灯变亮。以此类推，前四行所有灯都变亮后（实际上每行的灯都进行了操作，所以不能再操作了），如果最后一行还有暗的就是无解。\n怎么存数据\n\n用int二维数组\nint sq[N][N];char in_str[N];//要做一个转换，多了一步for (int i = 0; i &lt; 5; i++) {            cin &gt;&gt; in_str;            for (int j = 0; in_str[j]; j++) {                sq[i][j] = in_str[j] - '0';            }}\n用char二维数组\nchar sq[N][N];// 无需转换for (int i = 0; i &lt; 5; i++)    cin&gt;&gt;sq[i];// 但在转变状态时需要注意sq[i][j] = sq[i][j]^1;\n\n飞行员兄弟\n这是一道和上题极像的题，但思路总体来说是枚举而非递推。首先同一个位置不能操作两次，对于每一个位置，有两种选择，要么操作，要么不操作。因此可以使用01串来表示操作的状态。对于4*4的网格，一共有2^16种可能的操作方案。暴力枚举，找最少操作数的方案即可。\nint board[4][4];int temp_board[4][4];char temp_str[5];typedef pair&lt;int,int&gt; pii;vector&lt;pii&gt; pairs,res;void solu_116(){    for(int i=0;i&lt;4;i++){        cin&gt;&gt;temp_str;        for(int j=0;j&lt;4;j++){            if(temp_str[j]=='-') board[i][j]=1;        }    }    int min_step = 17;    for(int i=0;i&lt;1&lt;&lt;16;i++) {        int step = 0;        pairs.clear();        memcpy(temp_board,board, sizeof board);        for (int j = 0; j &lt; 16; j++) {            if (i &gt;&gt; j &amp; 1) {                oper(j / 4, j % 4);                pairs.push_back({j / 4, j % 4});                step++;            }        }        bool can_sol = true;        for (int p = 0; p &lt; 4; p++)            for (int q = 0; q &lt; 4; q++)                if (!temp_board[p][q]) {                    can_sol = false;                    break;                }        if (can_sol) {            if (step &lt; min_step) {                min_step = step;                res.clear();                for (auto elem: pairs)                    res.push_back(elem);            }        }    }    cout&lt;&lt;min_step&lt;&lt;endl;    for (auto elem: res)        printf(\"%d %d\\n\", elem.first+1, elem.second+1);}\n\n二分\n确定一个区间（L，R），使得目标值一定在区间中\n找一个性质（判断条件），满足两点：\n性质具有二段性\n答案是二段性的分界点 \n\n\n分析中点M在该判断条件下是否成立，若成立，考虑答案在哪个区间；如果不成立，考虑答案在哪个区间。\n\n\n","categories":["courses"],"tags":["acwing","蓝桥杯"]},{"title":"代码解构-改","url":"/2023/05/18/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84-%E6%94%B9/","content":"Baseline代码解构-改数据读取与预处理数据准备\n 获得train_anns和test_anns 以及 train_frames 和 test_frames\n\n​        data{video}{clip} ={\n​        ‘file_name’: file_name,\n​        ‘group_activity’: activity,\n​        ‘actions’: actions,\n​        ‘bboxes’: bboxes,\n​         }\n\n获得边界框跟踪pkl\n获得训练集和验证集\n在Volleyballdataset初始化中，读取关键点数据\n\ndef volleyball_readpose(data_path):    f = open(data_path,'r')    f = f.readlines()    pose_ann= defaultdict(dict)    for ann in f:        values = ann.split(' ')        pickle_path = values[0]        with open(pickle_path,'rb') as f:            keypoints = pickle.load(f)        sid = int(values[1])        src_id = int(values[2])        pose_ann[sid][src_id] = keypoints    return pose_ann\n\n获取数据\n采用数据帧，volley_frames_sample\n\n载入样本序列，load_samples_sequence\n\n准备数据容器：\n​    images, boxes = [], []\n​    activities, actions = [], []\n​    poses = []\n\n对sample里的每一帧，需要首先打开该文件，并加入images中\n\n其次读取边界框跟踪数据，他是不能直接用的，需要进行一些处理：\n\n\nfor i, track in enumerate(self.tracks[(sid, src_fid)][fid]):                y1, x1, y2, x2 = track                # multiply output channel shape                w1, h1, w2, h2 = x1 * OW, y1 * OH, x2 * OW, y2 * OH                temp_boxes[i] = np.array([w1, h1, w2, h2])                temp_poses.append(keypoints[i])\n\n其他处理就比较简单\n模型处理模块\n初始化：\nbackbone使用resnet18\nroi_align\nglobal_head\nhead\npose_head\npose_head2\n\n\n首先使用backbone得到图像特征img_features\n如果特征是多尺度的，需要进行双线性插值\n再使用roi_align提取边界框特征boxes_features（B，T，N，NFB）\n使用global_head模块提取全局特征得到global_token\n使用joint_track 投影层初始化pose_features$(NJ, BT,d)$\n使用pose-selfatt模块计算pose特征(B,T,N,d)\n使用individual-init模块来初始化indi_features\n使用multi-level-inference模块来进行层次式推理来不断优化indi_features\n输入是 和\n先使用trans encoder计算优化过的jointfea 再将joints_fea投影到个体维度，并与boxes_feature相加\n再将加后的boxesfea使用transtrans encoder进行优化\n\n\n\n损失函数计算","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"CSAPP笔记：Overview","url":"/2023/08/05/course-learning/CMU-213/213_overview/","content":"CSAPP笔记：Overview\ncourse website:here\n\nProgram DataTopics\n\nBit operations, arithmetic, assembly language programs\n\nRepresentation of C control and data structures\n\nIncludes aspects of architecture and compilers \n\n\nAssignments\n\nL1 (datalab): Manipulating bits\n\nL2 (bomblab): Defusing a binary bomb\n\nL3 (attacklab): The basics of code injection attacks\n\n\nThe Memory HierachyTopics\n\nMemory technology, memory hierarchy, caches, disks, locality\n\nIncludes aspects of architecture and OS\n\n\nAssignments\n\nL4 (cachelab): Building a cache simulator and optimizing for locality.\nLearn how to exploit locality in your programs. \n\n\n\nExceptional Control FlowTopics\n\nHardware exceptions, processes, process control, Unix signals, nonlocal jumps\n\nIncludes aspects of compilers, OS, and architecture\n\n\nAssignments\n\nL5 (tshlab): Writing your own Unix shell. \nA first introduction to concurrency\n\n\n\nVirtual MemoryTopics\n\nVirtual memory, address translation, dynamic storage allocation\n\nIncludes aspects of architecture and OS\n\n\nAssignments\n\nL6 (malloclab): Writing your own malloc package\nGet a real feel for systems-level programming\n\n\n\nNetworking and ConcurrencyTopics\n\nHigh level and low-level I/O, network programming\n\nInternet services, Web servers\n\nconcurrency, concurrent server design, threads\n\nI/O multiplexing with select\n\nIncludes aspects of networking, OS, and architecture\n\n\nAssignments\n\nL7 (proxylab): Writing your own Web proxy\nLearn network programming and more about concurrency and synchronization. \n\n\n\n","categories":["courses","CSAPP"],"tags":["CSAPP"]},{"title":"实验记录04.15.2023","url":"/2023/04/15/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%954.15/","content":"实验记录04.15.2023实验：加入全局场景自注意力+AGGLSTM\n\n\n\n\n如图，最终效果还是不错的，最终的top1为92%。\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"实验记录04.06.2023","url":"/2023/04/06/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%954.6/","content":"实验记录04.06.2023实验一：改变融合方式\n觉得单纯的求和没有有效融合场景全局信息，因此缓存如下先cat再全连接层融合的方式\n\n\n实验结果没有直接相加好：\n\n\n实验二：把全局信息作为decoder的query\n\n\n实验三：把全局信息与自适应query相加作为新的query\n\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"实验记录05.09.2023","url":"/2023/05/09/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%955.09/","content":"实验总结05.09.2023joints分支实验一：调lr+预训练joints数据\n\n加入joints数据后发现效果一般，考虑是不是joints本身训练的问题，调整完学习率之后发现有效果：\n\n\n没想到改了学习率之后效果这么好，有点惊讶：\n\n\n修改代码，直接载入预训练好的pose分支模型：\n\n\n目前已经比baseline效果好了,现在的**结果已经达到了93%**，很接近SOTA方法（SOTA：93.6%），加入以下实验精度肯定会更高：\n实验二：对数据进行标准化实验三：增加坐标位置编码实验四：增加时间位置编码实验五：增加节点类型编码实验分支实验一：使用光流特征实验二：更换backbone（inceptionV3）实验三：使用tokenizer（已尝试，效果可以，可以合入主分支中）\n实验四：使用自适应的decoder代替maxpooling（已尝试，效果可以，可以合入主分支中）\n实验五：使用数据增强方法主分支实验一：加入全局场景自注意力（精度）（已尝试，效果可以，已合入主分支中）\n实验二：加入层次式的推理方法（精度）我们可以通过得到的pose特征，使用自注意力机制后，得到优化后的pose特征，将其组合成为人的特征，并与rgb的人特征进行concat，再使用注意力机制优化。\n\n\n实验三：加入交互推理模块（精度）\n先看看composer的推理模块\n对人与人之间的交互进行建模，利用提取的交互信息增强个体特征，这里考虑修改DIN模块\n\n实验四：Transformer优化（精度）目前代码其实没有用transformer，加入transformer也可，看精度是否提升\n实验五：减少计算复杂度（性能）使用tokenizer或是maskencoder，希望结合两者的优势，看代码好改不，不好改的话用tokenizer即可（先用这个）\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"代码解构","url":"/2023/05/18/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/","content":"Baseline代码解构数据读取及预处理\n我个人觉得这里的数据处理是比较精妙的，可以把同样的思想应用到RGB输入里\n\n数据准备：\n得到从群体类别到id的映射\n群体行为类别权重\n个体行为类别权重\n所有的个体行为类别标签\n所有群体行为标签\n所有个体行为标签\n所有的clip的关键点数据的文件路径\n所有的（video,clip）元组\n球轨迹\n边界框\n\n步骤：\n\nstore the dict {(video,clip) : group action id} in annotations_thisdatasetdir\nstore all the current split’s joint data paths in clip_joints_path\nget current split’s video, clip into clips\nget correspond group labels in annotations \nget correspond person labels in person_actions_all \ncount the number of clips\n\n数据增强：\n保存一个副本作为真实数据，每次用真实数据去增强数据集\n\n# 只有训练才需要进行增强# if horizontal flip augmentation and is training      if self.args.horizontal_flip_augment and self.split == 'train':          # 不需要增强的为0，需要的mask为1          self.horizontal_flip_mask = list(np.zeros(len(self.annotations))) + list(np.ones(true_data_size))          self.annotations += true_annotations          self.annotations_each_person += true_annotations_each_person          self.clip_joints_paths += true_clip_joints_paths          self.clips += true_clips          if self.args.ball_trajectory_use:              self.clip_ball_paths += true_clip_ball_paths\n\n\n设置随机数\n\nif self.args.horizontal_flip_augment and self.split == 'train':            # 这里因为flip所以群体标签需要调整        \tself.classidx_horizontal_flip_augment = {                0: 1,                1: 0,                2: 3,                3: 2,                4: 5,                5: 4,                6: 7,                7: 6            }            if self.args.horizontal_flip_augment_purturb:                self.horizontal_flip_augment_joint_randomness = dict()\n\n数据分析：\n我们需要对关键点数据进行统计分析。如果没有统计结果文件的话，我们需要得到以下信息：\n\njoint_xcoords = []joint_ycoords = []joint_dxcoords = []joint_dycoords = [] \n\n注意，这里统计分析的步骤需要包含增强数据\n对于每一个clip joint，我们先将它读到 joint_raw\n\n其次我们需要采样T帧：\n\nframes = sorted(joint_raw.keys())[self.args.frame_start_idx:self.args.frame_end_idx+1:self.args.frame_sampling]\n\n\n如果存在数据增强的话，如果需要有扰动，需要提前初始化\n\nif self.args.horizontal_flip_augment:                        if index &lt; len(self.horizontal_flip_mask):                            if self.horizontal_flip_mask[index]:                                if self.args.horizontal_flip_augment_purturb:                                    self.horizontal_flip_augment_joint_randomness[index] = defaultdict()                                    # ONLY CHANGE THE CHOSEN FRAMES JOINT INFO                                    joint_raw = self.horizontal_flip_augment_joint(                                        joint_raw, frames,                                         add_purturbation=True, randomness_set=False, index=index)                                else:                                    joint_raw = self.horizontal_flip_augment_joint(joint_raw, frames)                                                                    if self.args.ball_trajectory_use:                                    ball_trajectory_data = self.horizontal_flip_ball_trajectory(ball_trajectory_data)\n\n\n还有个比较特殊的dropout增强：这里仅需设置随机性即可\n\n# To compute statistics, no need to consider the random agent dropout augmentation,# but we can set the randomness here.          # if random agent dropout augmentation and is training                    if self.args.agent_dropout_augment:                        if index &lt; len(self.agent_dropout_mask):                            if self.agent_dropout_mask[index]:                                chosen_frame = random.choice(frames)                                chosen_person = random.choice(range(self.args.N))                                self.agent_dropout_augment_randomness[index] = (chosen_frame, chosen_person)\n\n\n因为姿态估计是存在错误的，所以需要对不合理的进行修改：\n\njoints_sanity_fix() # 函数\n\n\n之后就可以去更新上面的坐标了：\n\n# 更新joints list                    for tidx, frame in enumerate(frames):                        joint_xcoords.extend(joint_raw[frame][:,:,0].flatten().tolist())                        joint_ycoords.extend(joint_raw[frame][:,:,1].flatten().tolist())                        if tidx != 0:                            pre_frame = frames[tidx-1]                            joint_dxcoords.extend((joint_raw[frame][:,:,0]-joint_raw[pre_frame][:,:,0]).flatten().tolist())                            joint_dycoords.extend((joint_raw[frame][:,:,1]-joint_raw[pre_frame][:,:,1]).flatten().tolist())                        else:                            joint_dxcoords.extend((np.zeros((self.args.N, self.args.J))).flatten().tolist())                            joint_dycoords.extend((np.zeros((self.args.N, self.args.J))).flatten().tolist())\n\n\n有了上面这些，我们就可以去计算平均值和标准差了：\n\njoint_xcoords_mean, joint_xcoords_std = np.mean(joint_xcoords), np.std(joint_xcoords)               joint_ycoords_mean, joint_ycoords_std = np.mean(joint_ycoords), np.std(joint_ycoords)               joint_dxcoords_mean, joint_dxcoords_std = np.mean(joint_dxcoords), np.std(joint_dxcoords)               joint_dycoords_mean, joint_dycoords_std = np.mean(joint_dycoords), np.std(joint_dycoords)                self.stats = {                   'joint_xcoords_mean': joint_xcoords_mean, 'joint_xcoords_std': joint_xcoords_std,                   'joint_ycoords_mean': joint_ycoords_mean, 'joint_ycoords_std': joint_ycoords_std,                   'joint_dxcoords_mean': joint_dxcoords_mean, 'joint_dxcoords_std': joint_dxcoords_std,                   'joint_dycoords_mean': joint_dycoords_mean, 'joint_dycoords_std': joint_dycoords_std               }\n\n\n计算完成后需要保存统计数据：\n\n# 保存统计数据                with open(os.path.join('datasets', self.args.dataset_name, self.args.joints_folder_name, 'stats_train.pickle'), 'wb') as f:                    pickle.dump(self.stats, f)\n\n\n如果有扰动的话还需要保存下来：\n\nif self.args.horizontal_flip_augment and self.args.horizontal_flip_augment_purturb:                    with open(os.path.join('datasets', self.args.dataset_name, self.args.joints_folder_name,                                            'horizontal_flip_augment_joint_randomness.pickle'), 'wb') as f:                        pickle.dump(self.horizontal_flip_augment_joint_randomness, f)                        \n\n数据获取：\n得到person_labels:\n\nperson_labels = torch.LongTensor(person_labels[frames[0]].squeeze())  # person action remains to be the same across all frames # person_labels: (N, )\n\n\n使用数据增强：\n\n# if vertical move augmentation and is training        if self.args.vertical_move_augment and self.split == 'train':            if index &lt; len(self.vertical_mask):                if self.vertical_mask[index]:                    if self.args.ball_trajectory_use:                        if self.args.vertical_move_augment_purturb:                            joint_raw, ball_trajectory_data = self.vertical_move_augment_joint(                                joint_raw, frames, add_purturbation=True,                                 randomness_set=True, index=index,                                 ball_trajectory=ball_trajectory_data)                        else:                            joint_raw, ball_trajectory_data = self.vertical_move_augment_joint(                                joint_raw, frames, ball_trajectory=ball_trajectory_data)                     else:                        if self.args.vertical_move_augment_purturb:                            joint_raw = self.vertical_move_augment_joint(                                joint_raw, frames, add_purturbation=True,                                 randomness_set=True, index=index)                        else:                            joint_raw = self.vertical_move_augment_joint(joint_raw, frames)  \n\n\n并进行合法性检查\n\n\n\n\n获得4种类型的joint features并将它们进行连接：\n\njoint_feats = torch.cat((torch.Tensor(np.array(joint_feats_basic)),                              torch.Tensor(np.array(joint_feats_metrics)).permute(1,2,0,3),                              torch.Tensor(np.array(joint_feats_advanced)),                              torch.Tensor(np.array(joint_coords_all))), dim=-1)  \n\n\njoint_coords_all  目的是为了图像坐标嵌入\n\njoint_coords_all = []  # (N, J, T, 2)          for n in range(self.args.N):             joint_coords_n = []             for j in range(self.args.J):                 joint_coords_j = []                 for tidx, frame in enumerate(frames):                     joint_x, joint_y, joint_type = joint_raw[frame][n,j,:]                                          joint_x = min(joint_x, self.args.image_w-1)                     joint_y = min(joint_y, self.args.image_h-1)                     joint_x = max(0, joint_x)                     joint_y = max(0, joint_y)                     joint_coords = []                     joint_coords.append(joint_x)  # width axis                      joint_coords.append(joint_y)  # height axis                                              joint_coords_j.append(joint_coords)                 joint_coords_n.append(joint_coords_j)                joint_coords_all.append(joint_coords_n)\n\n\njoint_feats_basic 对关键点坐标进行标准化\n\njoint_feats_basic = []  # (N, J, T, d_0_v1)       for n in range(self.args.N):          joint_feats_n = []          for j in range(self.args.J):              joint_feats_j = []              for tidx, frame in enumerate(frames):                  joint_x, joint_y, joint_type = joint_raw[frame][n,j,:]                  joint_feat = []                  joint_feat.append((joint_x-self.stats['joint_xcoords_mean'])/self.stats['joint_xcoords_std'])                  joint_feat.append((joint_y-self.stats['joint_ycoords_mean'])/self.stats['joint_ycoords_std'])                  if tidx != 0:                      pre_frame = frames[tidx-1]                       pre_joint_x, pre_joint_y, pre_joint_type = joint_raw[pre_frame][n,j,:]                      joint_dx, joint_dy = joint_x - pre_joint_x, joint_y - pre_joint_y                   else:                      joint_dx, joint_dy = 0, 0                  joint_feat.append((joint_dx-self.stats['joint_dxcoords_mean'])/self.stats['joint_dxcoords_std'])                  joint_feat.append((joint_dy-self.stats['joint_dycoords_mean'])/self.stats['joint_dycoords_std'])                  joint_feats_j.append(joint_feat)              joint_feats_n.append(joint_feats_j)          joint_feats_basic.append(joint_feats_n)\n\n\njoint_feats_advanced 对关键点信息进归一化\n\njoint_feats_metrics\n\n接下来，如果当前正在训练，并且使用dropout增强的话：\n\n\n\t\t# if random agent dropout augmentation and is training                        if self.args.agent_dropout_augment and self.split == 'train':            if index &lt; len(self.agent_dropout_mask):                if self.agent_dropout_mask[index]:                    joint_feats = self.agent_dropout_augment_joint(                            joint_feats, frames, index=index, J=self.args.J)                    def agent_dropout_augment_joint(self, joint_feats, frames, index=0, J=17):        # joint_feats: (N, J, T, d)        chosen_frame = self.agent_dropout_augment_randomness[index][0]         chosen_person = self.agent_dropout_augment_randomness[index][1]         feature_dim = joint_feats.shape[3]        joint_feats[chosen_person, :, frames.index(chosen_frame), :] = torch.zeros(J, feature_dim)        return joint_feats\n\n\n最后，返回数据\n\nreturn joint_feats, label, video, clip, person_labels#, ball_feats\n\n模型处理模块\n获得所有需要的维度信息\n\nB = joint_feats_thisbatch.size(0)      N = joint_feats_thisbatch.size(1)      J = joint_feats_thisbatch.size(2)      T = joint_feats_thisbatch.size(3)            d = self.args.TNT_hidden_dim\n\n\n首先进行图像坐标位置编码\n\n# image coords positional encoding      image_coords = joint_feats_thisbatch[:,:,:,:,-2:].to(torch.int64).cuda() # B,N,J,T,2      coords_h = np.linspace(0, 1, self.args.image_h, endpoint=False)      coords_w = np.linspace(0, 1, self.args.image_w, endpoint=False)      xy_grid = np.stack(np.meshgrid(coords_w, coords_h), -1)      xy_grid = torch.tensor(xy_grid).unsqueeze(0).permute(0, 3, 1, 2).float().contiguous().to(device)      image_coords_learned =  self.image_embed_layer(xy_grid).squeeze(0).permute(1, 2, 0) # h,w,2*embed_dim,      image_coords_embeded = image_coords_learned[image_coords[:,:,:,:,1], image_coords[:,:,:,:,0]]      # (B, N, J, T, d_0)\n\n\n其次进行时间位置编码\n\n# time positional encoding      time_ids = torch.arange(1, T+1, device=device).repeat(B, N, J, 1)      time_seq = self.time_embed_layer(time_ids)       # (B, N, J, T, d_0)\n\n\n再进行关键点类型嵌入编码\n\n# joint classes embedding learning as tokens/nodes      joint_class_ids = joint_feats_thisbatch[:,:,:,:,-1]  # note that the last dim is the joint class id by default      joint_classes_embeded = self.joint_class_embed_layer(joint_class_ids.type(torch.LongTensor).cuda()) # (B, N, J, T, d_0)            x = joint_classes_embeded.transpose(2, 3).flatten(0, 1).flatten(0, 1)  # x: (B*N*T, J, d_0)      input = (x, self.adj.repeat(B*N*T, 1, 1).cuda())  # adj: # (B*N*T, J, J)      joint_classes_encode = self.joint_class_gcn_layers(input)[0] # output      joint_classes_encode = joint_classes_encode.view(B, N, T, J, -1).transpose(2, 3)  # (B, N, J, T, d_0)\n\n\n最后将这些进行拼接得到编码后的关键点信息\n\njoint_feats_composite_encoded = torch.cat(            [joint_feats_thisbatch, time_seq, image_coords_embeded, joint_classes_encode],             dim=-1) \n\n\n之后进行投影：注意，这里时间维度已经没有了\n\n# PROJECTIONS      # joint track projection      joint_track_feats_thisbatch_proj = self.joint_track_projection_layer(          joint_feats_composite_encoded.flatten(3, 4).flatten(0, 1).flatten(0, 1)  # (B*N*J, T*d_0)      ).view(B, N*J, -1)      # (B, N*J, d)            # person track projection      person_track_feats_thisbatch_proj = self.person_track_projection_layer(          joint_feats_for_person_thisbatch.flatten(0, 1).contiguous().view(B*N, -1)      ).view(B, N, -1)      # (B, N, d)\n\n\n这里还有两个track， interaction track &amp; group track，思想是类似的\n接下来将各个track输入到TNT网络中进行处理：\n\n\n\n\nTNT的主干是TNT_block:\n\n\n\n\n下面是我的流程图，整体处理还是比较好理解的：\n\n\n\n损失函数计算# outputs is a list of list# len(outputs) is the numbr of TNT layers# each inner list is [CLS_f, CLS_m, CLS_c, output_CLS, output_fine, output_middle, output_coarse, output_group]\n\n预测群体logits：pred_logits = []      for l in range(self.args.TNT_n_layers):                    fine_cls = outputs[l][0].transpose(0, 1).squeeze(1)  # (B, d)          middle_cls = outputs[l][1].transpose(0, 1).squeeze(1)  # (B, d)          coarse_cls = outputs[l][2].transpose(0, 1).squeeze(1)  # (B, d)          group_cls = outputs[l][3].transpose(0, 1).squeeze(1)  # (B, d)                    pred_logit_f = self.classifier(fine_cls)          pred_logit_m = self.classifier(middle_cls)          pred_logit_c = self.classifier(coarse_cls)          pred_logit_g = self.classifier(group_cls)                    pred_logits.append([pred_logit_f, pred_logit_m, pred_logit_c, pred_logit_g])\n\n计算scores：# fine_cls, middle_cls, coarse_cls, group_cls are from the last layer      fine_cls_normed = nn.functional.normalize(fine_cls, dim=1, p=2)      middle_cls_normed = nn.functional.normalize(middle_cls, dim=1, p=2)      coarse_cls_normed = nn.functional.normalize(coarse_cls, dim=1, p=2)      group_cls_normed = nn.functional.normalize(group_cls, dim=1, p=2)      scores_f = self.prototypes(fine_cls_normed)      scores_m = self.prototypes(middle_cls_normed)      scores_c = self.prototypes(coarse_cls_normed)      scores_g = self.prototypes(group_cls_normed)      scores = [scores_f, scores_m, scores_c, scores_g]\n\n预测个体logits：pred_logits_person = []      for l in range(self.args.TNT_n_layers):          person_feats = outputs[l][5].transpose(0, 1).flatten(0,1)  # (BxN, d)          pred_logit_person = self.person_classifier(person_feats)            pred_logits_person.append(pred_logit_person)\n\nloss计算：# model forward pass           pred_logits_thisbatch, pred_logits_person, scores = self.model(               joint_feats_thisbatch, ball_feats)\t\t   # measure accuracy and record loss            targets_thisbatch = targets_thisbatch.to(pred_logits_thisbatch[0][0].device)           person_labels = person_labels.flatten(0,1).to(pred_logits_thisbatch[0][0].device)                      loss_thisbatch, prec1, prec3, prec1_person, prec3_person = self.loss_acc_compute(               pred_logits_thisbatch, targets_thisbatch, pred_logits_person, person_labels)                       loss_thisbatch += contrastive_clustering_loss\n\n这部分loss计算挺难理解的，之后看看原文尝试去修改一下\n# learning the cluster assignment and computing the loss         scores_f = scores[0]         scores_m = scores[1]         scores_c = scores[2]         scores_g = scores[3]         # compute assignments         with torch.no_grad():              q_f = self.sinkhorn(scores_f, nmb_iters=self.args.sinkhorn_iterations)             q_m = self.sinkhorn(scores_m, nmb_iters=self.args.sinkhorn_iterations)             q_c = self.sinkhorn(scores_c, nmb_iters=self.args.sinkhorn_iterations)             q_g = self.sinkhorn(scores_g, nmb_iters=self.args.sinkhorn_iterations)         # swap prediction problem         p_f = scores_f / self.args.temperature         p_m = scores_m / self.args.temperature         p_c = scores_c / self.args.temperature         p_g = scores_g / self.args.temperature         contrastive_clustering_loss = self.args.loss_coe_constrastive_clustering * (             self.swap_prediction(p_f, p_m, q_f, q_m) +              self.swap_prediction(p_f, p_c, q_f, q_c) +             self.swap_prediction(p_f, p_g, q_f, q_g) +             self.swap_prediction(p_m, p_c, q_m, q_c) +             self.swap_prediction(p_m, p_g, q_m, q_g) +             self.swap_prediction(p_c, p_g, q_c, q_g)         ) / 6.0  # 6 pairs of views\n\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"实验记录04.22.2023","url":"/2023/04/22/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%954.22/","content":"实验记录04.22.2023实验一：处理joints数据\n生成注释文件，便于统一读取：\n\nfind /mnt/data1/data/volleyball/joints/*/*.pickle | sed -E 's/(\\/mnt\\/data1\\/data\\/volleyball\\/joints\\/([0-9]*)\\/([0-9]*).pickle)/\\1 \\2 \\3/' &gt; data/volleyball/joints/ann.txt\n\n\n\n\n读取注释文件：\n\n\n\n这种方式可以把数据统一读取到内存里，不需要get数据的时候从pickle文件里读，所以会训练会快一点\n实验二：修改网络结构\n对特征进行预处理，并加入pose_head模块：\n\n\n\n\n损失函数计算和指标计算：\n\n\n\n\n实验结果：\n\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"多车辆行为识别及预测","url":"/2023/08/05/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E6%96%B0%E6%96%B9%E5%90%91/","content":"高级辅助驾驶技术介绍—多车辆行为识别及预测P.S. 这是一个完全全新的方向，之前没有人在这个方面有过尝试，我们可以说是开创者\n\n比赛的核心技术: 车辆行为识别\n\n任务目标通过周围车辆的行为，预测当前第一视角车辆（车辆行车记录仪拍下的）的安全驾驶行为类型，包括：减速，加速，左拐，右拐4个类别。\n为什么要进行多车辆行为识别及预测？在复杂的交通场景中，车辆之间的行为在时空上是相互影响的。我们假设第一视角中的某台车的车辆行为（减速，加速，左拐，右拐）受其他车辆的历史运动的影响。那么我们需要对该行为特征在时空维度进行建模，并充分考虑车辆之间的相互影响。如何发掘并对这些关系进行推理，是多车辆行为识别及预测任务的难点。\n任务标注\n\n\n车辆bounding box\n4个关键点\n个体车辆行为类型（减速，加速，左拐，右拐）\n该场景下当前车辆的正确驾驶行为类型（减速，加速，左拐，右拐）\n\n任务框架\n\n任务核心技术多层次语义场景推理\nscale 1: 关键点（Keypoint）\nscale 2: 车辆（Car）\nscale 3: 同一车道线内的车辆（Interaction）\nscale 4: 全部车辆（Group）\n\n\n\n可变形时空推理（RADIN模块）\n\n在DIN模块的基础上，我们假设只有相关联的特征才会对我们当前的特征有贡献，所以可以定义一个gate来对特征进行门控：\n\n\n\n\n\n\n\n如果相差越小，值越接近1\n\n自注意力融合\n\n\n不同的特征的对于群体行为的贡献程度不同，可以利用自注意力机制对贡献程度进行建模\n\n","categories":["科研实验"],"tags":["idea","科研"]},{"title":"实验记录04.03.2023","url":"/2023/04/03/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%954.2/","content":"实验记录04.03.2023\n使用decoder作为maxpooling的替代：\n\n\n\n在训练过程中，query向量会自适应的学习群体特征（在不断变化），使用decoder对群体行为进行解码：\n\n\n目前baseline的MCA是91.55%，加入group trans之后的准确率提高了约0.5%\n\n在上面的实验基础上加入全局信息：\n\n即在img特征层面先使用tokenizer的思想进行分patches，得到L个patches，这里自适应地学习16个patches，这样可以大幅度减少后续encoder的计算量，再加入一个trans encoder，获得全局场景特征：\n\n\n\n\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"实验记录04.08.2023","url":"/2023/04/08/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%954.7/","content":"实验记录04.08.2023实验四：加入交叉transformer模块\n\n\n第一次跑效果很差，改过学习率后收敛了，但效果没有baseline好：\n\n\n\n实验五：加入transCls模块\n这个模块我是在transformer的基础上使用它的cls token来作为群体行为的特征。\n代码也改了挺多部分：\n\n\n目前正在训练：\n\n\n\n达到了91.5%，目前感觉效果还可以\n","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"实验记录05.17.2023","url":"/2023/05/17/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%955.17/","content":"实验总结05.17.2023pose分支实验一：加入posehead模块利用自注意力+LSTM得到权重优化后的姿态特征\n实验二：加入poseheadinfer模块","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"MIT课程笔记： Notes on Missing semester 01","url":"/2023/08/05/course-learning/MIT-Missing-Semester/note01-shell/","content":"Notes on Missing semesterlesson 1environment variables\nPATH\n\nshell搜索程序时，会去寻找PATH列表的所有路径下匹配的程序\n实用命令\nwhich\n\n显示所运行程序的所在路径\n\ncd -\n\n回到上次所在目录，非常好用！\n\nls ..\n\n显示上层的所有文件\n\nctrl - l\n\n清除屏幕，光标回到顶部\n\nxdg-open\n\n用合适的程序打开文件\n程序的交互\nlesson 2 Shell Tools and Scripting变量定义\nfoo=bar即可在shell中定义变量\n\n注：不能有空格，若有空格，我们其实是执行foo程序，其第一个参数为=，第二个参数为bar\n\n对于字符串来说，我们要注意空格，以及quote，因为通常情况下，空格会在shell中起到参数分割的作用：\n\n\n\n如上图，单引号的内容不会被替换，字面字符串\n预留的特殊变量一般情况下，命令会使用stdout返回输出，使用stderr返回错误，并返回一个程序代码（表示执行状态）。0代表正常执行，非0代表有错误发生\n\n$0：脚本名称\n\n$1~9：第一个到第九个参数\n\n$#：参数的数量\n\n$$：命令的pid\n\n$@：得到所有参数\n\n$?：得到前一条命令的错误代码\n\n正确执行：$?得到0\n\n错误执行：\n\n特殊的命令true or false:\n\n\n\n$_：得到前一条命令的最后一个参数\n\n!!：当某条命令没有permissions可以使用：\n\n\n\n\n程序输出到变量中\n\n使用$()包住命令\n\nfoo=$(pwd)echo $foo\n\n\n使用字符串替换\n\n例一：echo \"We are in $(pwd)\"\n例二：for file in $(ls)\n\n使用过程替换（好用！！）\n\n\n当命令期待从文件中获取输入时很方便\n\n&lt;(ls)可以将命令的输出存到临时文件中，并返回临时文件的句柄\n\n\n上图的命令可以打印本层和上层目录的所有文件\n逻辑运算\n或||：\n\n\n\n\n\n\n与&amp;&amp;：\n\n\n\n\n无条件执行；（连接多条命令）\n\n\n\n测试表达式（包含比较）test 程序可以评估表达式的真假，如果是真，返回0；否则返回1。\n\n-f file 如果file存在并且是一个常规文件，则返回True\n\n通配符wild cards\n\n简化表达式\n\n* 匹配任意多个字符\n?  匹配一个字符\n\n\n{}扩展列表\n只有一系列命令中有公共子串，我们就可以使用花括号来自动进行扩展。\n例一：创建4个文件\n\n\n上面的命令等价于：\n\n\n例二：将所有py和sh文件移到某个文件夹中\nmv *{.py,.sh} folder例三：将project1拷贝到新目录中，并在双方的test目录下建立文件\n\n第二个命令 一共有2*3=6个参数\n例四：与例三功能类似\n同理，可以进行如下操作：\n\n\n建立不同的文件,并比较foo文件夹和bar文件夹的差异：\n\n\n语法检查\nshellcheck file 有利于帮助我们找到语法错误，debug好用！\n控制流程顺序执行\n\n定义一个函数\n\n mcd(){\tmkdir -p \"$1\"\tcd \"$1\"}\n\n\nsource可以在shell中定义函数mcd，之后就可以使用mcd快速执行脚本\n\nif条件\n\n当在bash里使用判断时，使用if [[判断表达式]]\n\n循环语句\n\n循环的语法为：for name in “xxx”; do\n\nshell函数和脚本的区别\nshell函数只被加载一次,script每次执行时都会被加载；\n函数在当前的shell环境中被执行，而脚本在它们自己的进程里执行，也就是说，函数可以改变环境变量（改变当前目录），但是脚本不行；\n\n实用工具find usage\n第一步：–help\n第二步：man\n第三步：比起使用man获得详尽的文档，使用tldr获得常用命令的示例更加有用，例如tldr ffmpeg\n\nfind files\nprogrammers can’t avoid doing this\n\nfind\n查找当前目录下名称为src的目录：\nfind . -name src -type d\n查找当前目录下路径里有test的python文件：\nfind . -path '**/test/*.py' -type f\n 查找前一天以来修改的所有文件：\nfind . -mtime -1\n寻找作用大小为500k~10M的zip文件：\nfind . -size +500k -size -10M -name '*.tar.gz'\n将找到的每一个文件删除：\nfind . -name \"*.tmp\" -exec rm {} \\;\n找到所有PNG文件，并将它们转换为JPG：\nfind . -name \"*.png\" -exec convert {} {}.jpg \\;\nfind -iname 代表忽略大小写\nfd\n使用fd做为find的替代： simple, fast, and user-friendly\nfd \".*py\"\nlocate\n寻找文件的效率更高，locate使用了数据库，通过索引来进行高校查找\n有好就有坏：locate只使用文件名来查找\nfind content/code搜索当前文件夹下所有包含foobar的位置\ngrep -R foobar .\n-v 可以打印不满足匹配的所有行\n快速搜索scratch目录下所有python文件中，包含”import request“的位置，并显示其上下文，上下5行。\nrg \"import requests\" -t py -C 5  ~/scratch\n快速搜索所有不满足匹配的sh文件（包含隐藏文件）\nrg -u --files-without-match \"^#\\!\" -t sh\n--stats 额外打印关于搜索的所有信息\nfind command\n使用up/down方向键，缺点是不方便\n\n使用history\n\n\n展示所有历史命令，并找到convert相关命令：\nhistory 1| grep convert\n\n使用backward-searching\n\nctrl + R，重复键入可以在匹配结果中替换\n\nfzf：增加了交互功能\n\n\n过去子串搜索(前缀匹配)\ndirectory navigationtree, broot\n\n\nnnn\n\n\n示例#!/bin/bashecho \"Starting program at $(date)\" # Date will be substitutedecho \"Running program $0 with $# arguments with pid $$\"for file in \"$@\"; do    grep foobar \"$file\" &gt; /dev/null 2&gt; /dev/null    # When pattern is not found, grep has exit status 1    # We redirect STDOUT and STDERR to a null register since we do not care about them    if [[ $? -ne 0 ]]; then        echo \"File $file does not have any foobar, adding one\"        echo \"# foobar\" &gt;&gt; \"$file\"    fidone\n\n\n中间判断的含义为：$?是否不等于0\n当在bash里使用判断时，使用if [[判断表达式]]\n循环的语法为：for name in “xxx”; do\n\n作业练习\n不断运行同一个脚本，看他什么时候出错，题目要求如下：\n\n\n\n解答如下：\ncnt=0rm {std,err}*.logwhile ./bug.sh &gt;&gt; std_output.log 2&gt;&gt; err_output.log; do    cnt=$((cnt+1));donecat {std,err}*.logecho $cnt\n\n\n寻找某个目录下最近修改的文件（递归地），是否可以列出所有文件？\n\n列出所有文件命令：\nfind ../ -path \"../kgclue/**\" -type f | xargs ls -lt\n结果如下：\n\n\n列出最近修改的文件：\n`find ../ -path “../kgclue/**” -type f | xargs ls -lt 2&gt;/dev/null | head -n1\n","categories":["课程学习","shell"],"tags":["shell","tool"]},{"title":"第二章工作调研","url":"/2023/06/01/deep-learning/%E7%AC%AC%E4%BA%8C%E7%AB%A0/%E8%AE%BA%E6%96%87%E4%BF%AE%E6%94%B9/","content":"第二章工作调研","categories":["科研实验","行为识别"],"tags":["Activity Recognition","research"]},{"title":"MIT课程笔记： Notes on Missing semester 03","url":"/2023/08/05/course-learning/MIT-Missing-Semester/note03-data_wrangling/","content":"Data WranglingConception\nData Wrangling: Anything that goes from one piece of data to another representation of data.\n\nmassage data until you end up with exactly what you wanted\n\n\nPreparation to Data Wrangling\ndata to wrangle\nuseful tools to do with data\n\nUseful ToolsRegular Expressions\nCommon patterns for regular expressions:\n\n. : any single character\n* : zero or more of the preceding match\n+ : one or more of the preceding match\n[abc]: any one character of a,b and c\n(RX1|RX2) : either something that matches RX1 or RX2\n^ : the start of the line\n$ : the end of the line\n\nsomething need to be kept in mind : + and * are default greedy, it means that it will find the max match. In some implementations, we can suffix * or+ with a ? to make them non-greedy. But sed doesn’t support it. So we could switch to perl’s command-line mode to do this:\nperl -pe 's/.*?Disconnected from//'\n\nsed\n\na stream editor: you give short commands for how to modify the file.  The most common command is s: substitution.\n\ns command: s/REGEX/SUBSTITUTION, REGEX is the regular expression you want to search for.\n\nnote: we should pass -E to give them their special meaning\n\nget username out of the log file:\nuse what called capture group\n\n\ncat ssh.log| grep sshd| grep \"Disconnected from\"| sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \\[preauth\\])?$/\\2/'\n\n\nsed can do a lot of interesting things: injecting text, printing lines and selecting lines by index( check man sed for more info)\n\nsort\n\ncan be useful when the content has numerical attributes\nfor example, find the most common usernames, -n means sorting in numeric order.\n\ncat ssh.log| grep sshd| grep \"Disconnected from\"| sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \\[preauth\\])?$/\\2/'| sort | uniq -c| sort -nk1,1 | tail -n10\n\nawk &amp; paste\n\nif we want to extract only the usernames as a comma-separated list:\n\ncat ssh.log| grep sshd| grep \"Disconnected from\"| sed -E 's/.*Disconnected from (invalid |authenticating )?user (.*) [^ ]+ port [0-9]+( \\[preauth\\])?$/\\2/'| sort | uniq -c| sort -nk1,1 | tail -n10| awk '{print $2}' | paste -sd,\n\n\npaste -sd, means  combine lines (-s) by delimiter(-d) ,\n\nawk\n\nfurther link to learn more: here\n\nawk is a nice programming language that is good at processing text streams. \n\nif we want to compute the number of single-use username that start with c and end with e:\n\n| awk '$1 == 1 &amp;&amp; $2 ~ /^c[^ ]*e$/ {print $2}' | wc -l\n\n\nof course we can use another way to do the same thing:\n\nawk 'BEGIN {rows=0} $1 == 1 &amp;&amp; $2 ~ /^c[^ ]*e$/ {rows += $1} END {print rows}'\n\nData Analysisbc\na calculator that can read from stdin\nR\n专注于数据分析和画图的语言（it is not that difficult. Try to have fun!）\ngnuplot\n可以制作复杂的图表. demo: https://gnuplot.sourceforge.net/demo_5.4/\n","categories":["课程学习","Data Wrangling"],"tags":["数据处理","MIT课程"]},{"title":"CS61A笔记","url":"/2023/08/05/course-learning/CS-61A/note01/","content":"lecture 01 Course About\nmanaging complexity\n\ntool:  mastering abstraction\nabstraction is giving sth a name and talking about it without worrying about details\ntool: Programming paradigms: about how to organize programs\n\n\ntry a personal project if you have time\n\n\nlecture 02 Functions术语\n\ndomain: the set of all inputs\nrange: the set of all outputs\nbehavior: relationship between input and output\n\nexpression evaluate\n\nall expressions can use function call notation\nevaluate procedure\n\n\n\n\n上图称为表达式树。add(2,mul(4,6))称为操作数子表达式；其结果称为子表达式的值，同时它也是mul的第一个参数\n赋值是抽象（abstraction）的最简单的一种方法：把名字绑定到值上\n函数定义是抽象的一种更强大的手段：把名字绑定到表达式上\n\nEnvironment Diagrams\n\nenvironment 是 memory， 它可以跟踪名称和值之间的对应关系。\n所有的表达式都是在environment的情境下计算的。\nenvrionment是frames的序列\n它可以是全局frame，也可以是局部frame，后面跟着全局frame\n\n可视化解释器的执行过程：\n\n 函数是如何执行的？\n\nadd a local frame, forming a new environment\nbind the params to its arguments in that frame\nexecute the body of the function in that new environment\n\n名称的值是如何查找的?\n当前环境下，在最早的frame中找到的名称所对应的值。如在函数中，我们会先在local frame中查找名字，如果没找到，再去全局frame中查找。\nwhy does it work?\nfrom operator import muldef square(square):    return mul(square,square);\n\n函数sqaure在全局frame中，参数square在局部frame中，互不干扰。\nlecture 03 Controlprint &amp; None\n\nwhat happens when evalutate print(print(1),print(2))?\n\nanswer:\n12None None\n\n\nuse the expression tree: \n\n\n\nWhat is None?\n\nNone 表示没有任何东西被返回\n\nNone is not displayed by the interpreter as the value of an expression\n\n\n\n\n纯函数&amp;非纯函数\n\n纯函数：单纯地返回值\n非纯函数：有些side effects。例如 print，它返回None，但同时会输出值\n\n\n\nMultiple Environments in One Diagram\n\n\n\nAs you can see, there are three environments as the program executes.\n失去了环境，名称将不再有意义。名称在不同的环境中有着不同的含义\n\n\n\n\n\nlecture 04 High Order FunctionsA guide to design functions\n\nGive each function exactly one job\nDon’t repeat yourself. Implement a process just once\nDefine functions generally (share implementation)\n\nGeneralizing patterns with arguments\nGeneralizing Over Computational Processes\n\n\n\nall summing from 1 to 5\nhow to generalize?\n\n\n\n\nterm is a formal parameter which will be bound to a function\nso the summation is a high order function that take another function as an argument\n\nFunctions as return values\n\nfunction can be manipulated as values in programming\nhigh order function\ntake another function as an argument\nreturn a function\n\n\n\n","categories":["courses","python"],"tags":["CS61A","python"]},{"title":"xv6笔记：chapt1 Operating system interfaces","url":"/2023/08/05/course-learning/MIT6.S081/chapt1/","content":"xv6笔记：chapt1 Operating system interfacesxv6 - the operating systemxv6 takes the traditional form of a kernel, a special program that provides services to running programs. \nEach process has memory containing instructions, data, and a stack. the stack organizes the program’s procedure calls.\nWhen a process needs to invoke a kernel service, it invokes a system call, one of the calls in the operating system’s interface. The system call enters the kernel; the kernel performs the service and returns. Thus a process alternates between executing in user space and kernel space.  \nThe kernel uses the hardware protection mechanisms provided by a CPU: each process in the user space can access only its own memory\n\n\nWhen a user program invokes a system call, the hardware raises the privilege level and starts executing a pre-arranged function in the kernel.  \nxv6 provides a subset of system calls that Unix kernel traditionally offer:\n\n\nxv6’s servicesshell - no mystery about it\nshell is a user program, not part of the kernel. \nshell illustrates the power of system call interface\nxv6’s shell is a simple implementation of the essence of Unix Bourne shell. \nIt’s implementation can be found at(user/sh.c)\n\nProcesses and memorycreate the processint pid = fork();\nintfork1(void){  int pid;  pid = fork();  if(pid == -1) // &lt;0 error arise    panic(\"fork\");  return pid;}\n\nexit the processexit(0);\n\nexit system call let the calling process stop executing and to release resources (memory and open files)  \n\nwait the processwait(0);// doesn't care about the exit status of the a child , pass 0\n\nwait system call return PID of an exited (or killed) child  of current process, and copies the exit status of the child to the address passed to wait  \nIf the caller has no children, wait immediately returns -1.  \n\nexec new processcase EXEC:    ecmd = (struct execcmd*)cmd;    if(ecmd-&gt;argv[0] == 0)      exit(1);    exec(ecmd-&gt;argv[0], ecmd-&gt;argv);    fprintf(2, \"exec %s failed\\n\", ecmd-&gt;argv[0]);    break;\n\n\nThe exec system call replaces the calling process’s memory with a new memory image loaded from a file stored in the file system.  \n\nWhen exec succeeds, it does not return to the calling program  \n\nExec takes two arguments: the name of the file containing the executable and an array of string arguments.  \n\n\nI/O and File descriptorsFile descriptor\nWhat is file descriptor?\n\n\nA small integer representing a kernel managed object that a process may read from or write to.\n\n\nHow can we obtain file descriptor?\n\n\nBy opening a file, directory, device\nBy creating a pipe\nBy duplicating an existing descriptor\n\n\nWhat’s the benefit of the file descriptor interface?\n\n\nAbstracts away the difference between files, pipes, devices\nMaking them all look like streams of bytes\n\nFile descriptors and process// Ensure that three file descriptors are open.  while((fd = open(\"console\", O_RDWR)) &gt;= 0){    if(fd &gt;= 3){      close(fd);      break;    }  }\n\n\nshell ensures that it always has three file descriptors open   \n\nRead and Write to Filesexample : the essence of cat: copies data from its standard input to its standard output  \nchar buf[512];int n;for(;;){\tn = read(0,buf,sizeof buf);\tif(n==0)\t\tbreak;    if(n&lt;0){        fprintf(2,\"read error\\n\");        exit(1);    }    if(write(1,buf,n)!=n){        fprintf(2,\"write error\\n\");        exit(1);    }}\n\n**Abstraction: **\n\nCat doesn’t know whether it is reading from a file, console, or a pipe.  \nSimilarly cat doesn’t know whether it is printing to a console, a file, or whatever.  \n\nClose the file\nreleases a file descriptor  \n\nmaking it free for reuse by a future open, pipe, or dup system call (see below)  \n\nA newly allocated file descriptor is always the lowest-numbered unused descriptor of the current process\n\n\nIO redirectionchar *argv[2];argv[0] = \"cat\";argv[1] = 0;if(fork() == 0) {    close(0);    open(\"input.txt\", O_RDONLY);    exec(\"cat\", argv);}\n\n\nfork copies file descriptor table, but share underlying file offset\n\nif(fork() == 0) {    write(1, \"hello \", 6);    exit(0);} else {    wait(0);    write(1, \"world\\n\", 6);}\n\n\ndup duplicates the existing file descriptor, returning a new one refers to the same underlying object\n\nfd = dup(1);write(1, \"hello \", 6);write(fd, \"world\\n\", 6);\n\n\nwhat is the meaning of 2&gt;&amp;1?\n\n\nTells the shell to give command a file descriptor 2 that is a duplicate of descriptor 1.\n\nThe xv6 shell doesn’t support I/O redirection for the error file descriptor, but now you know how to implement it.  \n\n\nPipes\nwhat is pipe?\n\n\nA pipe is a small kernel buffer exposed to process as a pair of file descriptors, one for reading and one for writing\nWriting data to one end of the pipe makes that data available for reading from the other end of the pipe.   \nprovide a way for processes to communicate\n\nan example:\nint p[2];char *argv[2];argv[0] = \"wc\";argv[1] = 0;pipe(p);if(fork() == 0) {    close(0);    dup(p[0]);    close(p[0]);    close(p[1]);\texec(\"/bin/wc\", argv);} else {    close(p[0]);    write(p[1], \"hello world\\n\", 12);    close(p[1]);}\n\n\nif no data is available, a read on a pipe waits for either data to be written or for all file descriptors to be closed.\n\nIt’s  important for the child to close the write end of the pipe before executing wc above.\n\nif one of wc ’s file descriptors referred to the write end of the pipe, wc would never see end-of-file  \n\n\n\nHow does xv6 implement grep fork sh.c | wc -l ? \n\ncase PIPE:    pcmd = (struct pipecmd*)cmd;    if(pipe(p) &lt; 0)      panic(\"pipe\");    if(fork1() == 0){      close(1);      dup(p[1]);      close(p[0]);      close(p[1]);      runcmd(pcmd-&gt;left);    }    if(fork1() == 0){      close(0);      dup(p[0]);      close(p[0]);      close(p[1]);      runcmd(pcmd-&gt;right);    }    close(p[0]);    close(p[1]);\t//wait for both to finish    wait(0);    wait(0);    break;\n\n\nmay create a tree of processes, The leaves of the tree are commands and the interior nodes are processes that wait until the left child and right child complete.\n\nuse pipes is much more efficient over temporary files:\necho hello world &gt;/tmp/xyz; wc &lt;/tmp/xyz \n\n\nFile System\nThe following two code segments open the same file:\nchdir(\"/a\");chdir(\"b\");open(\"c\", O_RDONLY);open(\"/a/b/c\", O_RDONLY);\n\ncreate new files and directories\nmkdir creates a new directory\nopen with the O_CREATE flag creates a new data file\nmknod creates a new device file.  \n\nmkdir(\"/dir\");fd = open(\"/dir/file\", O_CREATE|O_WRONLY);close(fd);mknod(\"/console\", 1, 1);\n\n\nfile itself is code a inode, it has many names called links. \neach link consist of an entry in a directory\nthe entry contains a file name and a reference to an inode\nthe inode holds metadata about a file, including: \nits type(file, directory or device)\nlength\nlocation on  disk\nnumber of links\n\n\nfstatcan retrieves info from the inode that a file descriptor refers to:\n\n#define T_DIR 1 // Directory#define T_FILE 2 // File#define T_DEVICE 3 // Devicestruct stat {    int dev; // File system’s disk device    uint ino; // Inode number    short type; // Type of file    short nlink; // Number of links to file    uint64 size; // Size of file in bytes};\n\n\nlink system call : creates another file system name referring to the same inode  \n\nopen(\"a\", O_CREATE|O_WRONLY);link(\"a\", \"b\");\n\n\nunlink system all: removes a name from the file system  \n\nfd = open(\"/tmp/xyz\", O_CREATE|O_RDWR);unlink(\"/tmp/xyz\");// create a temporary inode with no name that will be cleaned up when the process closes fd or exits.\n\n","categories":["Books","Operating System","xv6"],"tags":["MIT6.S081","OS","xv6"]},{"title":"MIT课程笔记： Notes on Missing semester 02","url":"/2023/08/05/course-learning/MIT-Missing-Semester/note02-vim/","content":"vim一个有趣的idea\nprogramming vim through its interface\n\n\nvim接口(interfaces)自身就是一个编程语言\n\n我们可以组合多种按键以达到难以置信的effect\n\n一旦形成肌肉记忆，我们就能以思考的速度来编辑文件！\n\n\nvim模式\nnormal\ninsert\nreplace\nvisual\nplain\nline\nblock\n\n\ncommand-line\n\nvim基础navigation\n\nw move the cursor foward by one word\n\nb move the cursor backward by one word\n\ne move to the end of the word\n\n0 move to the begin of the line\n\n$ move to the end of the line\n\n^ move to the first non-empty word of the line\n\nctrl-D  scroll down\n\nctrl-U scroll up\n\nG move to the end of the buffer\n\ngg move to the begin of the buffer\n\nL move the cursor to the lowest line shown on the screen\n\nM move the cursor to the middle line shown on the screen\n\nH move the cursor to the highest line shown on the screen\n\nf+charactor find(and move the cursor on top of it) the first charactor of the line after the cursor\n\nF+charactor find (and move the cursor on top of it) the first charactor of the line before the cursor\n\nt/T works same but stop until it finds the charactor\n\n% jump between pairs like ([],{}, …)\n\n\nedition\n\no open a new line below the cursor\nO open a new line above the cursor\nd + movement key only delete\nc + movement key delete and change\n\nselect, copy &amp; paste\n\nv &amp; motion key select\n\nV &amp; motion key select lines\n\nctrl-V &amp; motion key select rectangle region of text\n\ny + motion key copy\n\n\ncounts\n\ndigit + command 表示重复做几次某条命令 \n\nmodifier\n\nd &amp; i &amp; [ delete things in []\n\nc &amp; i &amp; [ delete things in [] and change\n\nd &amp; a &amp; [ delete things in [] (include [])\n\n\nvim控制命令:help + key(命令)\n查看key或命令的用途(帮助文档)\n:qa\n退出全部打开的文件\nBuffers、Tabs、Windowsbuffers又叫打开的文件，在vim中打开的文件与windows没有一对一的对应关系。这样有好处，可以同时看同一个文件的两个不同位置的内容\nwindow\n\n打开一个Window :sp\n\ntab\n\n打开一个Tab :tabnew\n在tab间切换 gt\n\n","categories":["课程学习","vim"],"tags":["MIT课程","vim"]},{"title":"MIT课程笔记： Notes on Missing semester 04","url":"/2023/08/05/course-learning/MIT-Missing-Semester/note04/","content":"Command-line EnvironmentJob Control\nlots of SIGNALS to control jobs\n\n\n\n\nThe flowing commands show how to control jobs in terminal. KILL can be useful because it can send signals to the programs. bg can continue processes running on the background.\n\n\n\n\nwhy should we use nohup when closing the terminal? \n\n\n\n\nBecause by default the hangup will terminate the job. So what nohup do is pretty simple, it actually ignore the hangup signal. But the KILL signal can’t be ignored no matter what.\n\nTerminal MultiplexersCORE Concept in Tmuxstructure\nSessions\n\nWindows\nPanes\n\n\n\nwhat happens when we type tmux?\n\nIn our shell, we started a process called tmux, and tmux started a different process which is the shell we are currently in. \n\nThe key bindings the core to use tmux efficiently\n\nform: prefix＋key\n\nhow to split the current display into panes?\n\nctrl B + \": split horizontally\nctrl B + %: split vertically\nctrl B + arrow keys: navigate through different panes\n\nSo if you find panes are too small, how to deal with it?\n\nctrl B + z: zoom out &amp; zoom in\n\nWHAT ACTUALLY DOES TMUX DO ?\nGive you a more convenient visual layout, that you can quickly manipulate through.\nif we start a tmux session, it won’t be affected by the ssh connections（hangup signal）.\n\nDot Fileswhat does Dot files do?\nhow to configure your shell to do the things you want to do.\nmainly about how to do them quicker and in a more convenient way.\n\nRemote Machines","categories":["课程学习","命令行环境"],"tags":["MIT课程","命令行环境"]},{"title":"xv6笔记：chapt3 Page tables","url":"/2023/08/05/course-learning/MIT6.S081/chapt3/","content":"xv6笔记：chapt3 Page tables\nWhy using page tables?\n\nIsolate different process’s address spaces and to multiplex them onto a single physical memory\n\nAs a reminder\n\n\nRISC-V instructions manipulate virtual addresses.\nRAM is indexed with physical addresses\n\nPaging hardware\n\n\n\n\na page table gives the os control over virtual-to-physical address translations at the granularity of 4096 bytes, such a chunk is called a page\n\n页表在物理内存中以三级树的形式存储\n\n根页表是一个大小为4096-byte的页表，他有512个页表项\n每一级页表都保存这下一级页表的物理地址\n\n\n如果翻译地址时有任何页表项不存在的话，分页硬件会抛出一个页错误异常，由内核来解决\n\n通常情况下，大部分虚拟地址是没有映射的，这时候三级结构可以有效减少内存占用。\n\n但是这种方式潜在的缺陷是，CPU需要从内存读入三次PTEs来进行转译\n\n幸运的是，我们可以使用缓存页表的方式（TLB）来减少访存次数\n\n\nPTE状态bits\nPTE_V: 表示PTE是否存在，若未设置会抛出异常\n\nPTE_R：表示是否允许读取页\n\nPTE_W：表示是否允许写入页\n\nPTE_X：表示是否CPU会把页中的内容解释为命令，并执行\n\nPTE_U：表示是否允许用户模式下的命令访问页\n\n\n（定义在kernel/riscv.h）\nnotes:\n\n物理内存 == DRAM存储单元\n一个字节的物理内存拥有一个地址\n指令只使用虚拟地址,该地址由分页硬件翻译为物理地址\n虚拟内存不是实际的对象而是内核对物理内存提供的抽象\n\n内核地址空间\n每个进程，有一张页表描述了进程的用户地址空间。\n\n系统有一个单独的页表描述内核地址空间\n\n\n内核内存布局(kernel memory layout)\n\n\nkernel gets at RAM and memory mapped device registers using “direct mapping”\n\nDirect mapping simplifies kernel code that reads or writes physical memory  \n\nkernel virtual address that aren’t direct-mapped:\n\ntrampoline page\nkernel stack pages\n\n\n\n进程虚拟地址空间布局\n\n当一个进程向os申请用户内存的过程：\n\n使用kalloc分配物理页表\n把页表项加入进程页表中\n在加入的页表项中设置PTE_W, PTE_X, PTE_R, PTE_U, and PTE_V flags \n\n使用页表的好处：\n\n不同的页表把用户地址翻译到不同的物理内存的页，所以每个进程都有自己的用户内存。\n每个进程看到的内存是从0开始的连续虚拟地址，然而实际上进程的物理内存是非连续的\n因为内核将陷入页映射到了用户地址空间的顶部，所有物理内存的单个页出现在了所有地址空间中。\n\n\n\ncode: sbrk\nsbrk是增加或减少一个进程占用内存的系统调用，它的实现在growproc中。\ngrowproc会调用uvmalloc或是uvmdealloc来增加或减少一个进程占用的内存\n\ncode: exec\nexec 是创建用户区域地址空间的系统调用。它从一个文件中初始化用户地址空间。\n\n","categories":["Books","Operating System","xv6"],"tags":["MIT6.S081","OS","xv6"]},{"title":"并行软件设计—以“通过流水线管道pipes对质数进行并行筛选”为例","url":"/2023/08/05/course-learning/MIT6.S081/lab1/","content":"并行软件设计—以“质数并行筛选”为例并行编程\n为什么要并行编程？\n\n主进程可以在子进程执行的时候执行其他事务，提高时间效率。这个想法可以分为三个部分：\n\n过程（process）：在子进程执行的同时，推进自己的计算\n通信（communication）：从独立执行的子进程中获取result\n同步（synchronization）：等待子进程的结束\n\n一旦我们能分离出子进程（子任务），就可以使用RPC来远程运行\n\n进程本质上是一个函数，但是它有自己的内存空间，以及私有栈。我们能对函数做些什么呢？\n\n\n调用（call）\n调用并且独立执行（fork一个子进程，在子进程中执行）\n用目标函数替换当前的计算（进程被替换了，exec in Unix，shell执行命令执行的就是这种策略）\n函数A可以调用函数B，AB可以相互切换（协程，linux pipelines, 操作系统调度器都使用了这种策略）\n\n本篇博客主要关注于第二点：调用并且独立执行\n并行模型进程管理进程创建begin func(arg)\n\n\n创建一个进程，arg是传给新进程的参数（传递新进程信息最好的方式）\n父进程的下一条指令会和子进程的第一条指令并行执行\n\n进程终止\n从func返回\n调用显示的进程终止函数\n\n通信通道（Communication Channels）\n有点像pipelines，可以用pipe为例来思考\n\nc: channel of [int];c1: channel of [array of int];c2: channel of [channel of int];\n\n\n向通道发送一个数据： c1 &lt;- = val\n从通道接受一个数据：x= &lt;- c1\n\n同步原理\n如果发送方发送数据，但是没有接收方接受数据，发送方直到接收方接收之前会被阻塞\n\n如果接收方接受数据，但是没有发送方发送数据，接受方知道发送方发送之前会被阻塞\n\n其他同步模型还有很多：信号量，Condition variables ，spin lock , queued lock\n\n\nUnix实现pipelines\n它实现了上述提及的编程模型中的Communication Channels\n\n\n使用了buffering的概念\n发送进程会将其输出保存在buffer中\n当接收进程准备好读数据时，pipeline的下一个进程从buffer中读取数据\n当buffer被填满时，发送进程会被阻塞，直到接收进程将数据从buffer中移出\nLinux默认的buffer大小为65536字节（64KB)\n\n实例应用：primes (moderate)/(hard)动机（motivations）：\n为什么要做该实例?\n\n\n这个MIT偏hard难度的作业题要想独立解决真的不简单，它用到了递归的思想，同时也要注意进程的退出条件，以及文件描述符的正确使用（文件描述符数量有限）\n\n该实例是对Linux pipelines并行编程的比较好的实践，需要去仔细处理进程通信以及同步\n\n\n题目介绍：使用管道pipelines对小于35的质数进行筛选（可以并行筛选处理）\n算法框架：\n\n生成进程负责生成所有待筛选的数，之后的每个进程负责筛质数（这个筛的过程是并行的）。比如第一个子进程筛掉所有2的倍数，第二个并行的进程（子孙进程）筛掉所有3的倍数，以此类推。\n解决方法：\n对于这个问题的解决其实是一步步的，较为复杂的问题需要我们一点点去调试纠错\n\nversion 1\n这个版本的实现可以看出父进程并没有等待子孙进程的退出（即没有处理好同步）\n\n\nversion 2\n父进程等待子进程退出，但是子进程没有正确退出，即wait（）卡死了\n\n\nFinal version 3\n\n经过两个多小时的不懈努力终于解决\n\n处理好递归终止条件是解决这个题的关键：即我们需要处理好最后一个没有子孙进程的进程的正确退出\n这里使用函数（在函数中fork）来处理这个问题：\n\n一方面：利用了递归的思想，不需要编写重复代码\n另一方面：体现了进程的本质即函数的思想\n\n运行效果：\n\n\n代码如下：\n#include \"kernel/types.h\"#include \"kernel/stat.h\"#include \"user/user.h\"int prime_select(int p[]){  int n;  int newpid = fork();  if(newpid == -1){    fprintf(2, \"failed to fork\\n\");    exit(1);  }  if(newpid == 0){    int num;    close(p[1]);    // 对于子进程来说，它只需要从父进程读数据，所以可以关闭写端，因为是fork的，所以duplicate文件描述符，所以对父进程的p[1]并没有影响    n = read(p[0], &amp;num, sizeof num);    printf(\"prime %d\\n\",num);    int pri = num;    int np[2];    if(pipe(np)&lt;0){      fprintf(2, \"failed to construct a pipe\\n\");      exit(1);    }    int flag = 1;    for(;;){      n = read(p[0],&amp;num, sizeof num);      if(n==0){        // 这个是子进程退出的关键条件：父进程关闭了它管道的写端        break;      }      if(num%pri!=0){        if(flag){          // 第一个没筛过的是一定是质数，用该质数去筛所有它的倍数          // 递归创建子进程，子子进程...          prime_select(np);          flag = 0;        }        write(np[1],&amp;num,sizeof num);      }    }    close(np[1]);// 父进程不需要向子进程传递数据时，关闭写端    if(flag==0){      // 如果他有子孙进程，则等待，否则退出      wait(0);    }    exit(0);  }else{    close(p[0]);//子进程已经dup了文件描述符，父进程可以关闭掉这个读端（必须fork之后才能关闭）  \t\t\t\t//注意，父进程不能关闭写端，因为他当前不需要wait子进程，还需要写数据    return newpid;  }}intmain(int argc, char *argv[]){  int total = 35;  int p[2];  if(pipe(p)&lt;0){    fprintf(2, \"failed to construct a pipe\\n\");    exit(1);  }  for(int i=2;i&lt;=total;++i){    write(p[1],&amp;i, sizeof i);  }  //父进程已经生成了所有数，需要关闭它的写端  close(p[1]);  prime_select(p);  wait(0);  exit(0);}\n\n","categories":["courses","Operating System","Concurrent Programming"],"tags":["MIT6.S081","pipe","CSP"]},{"title":"MIT6.s081 lab3记录：页表","url":"/2023/08/05/course-learning/MIT6.S081/lab3/","content":"MIT6.s081 lab3记录：页表Print a page table\n\npage table 0x0000000087f6e000 ..0: pte 0x0000000021fda801 pa 0x0000000087f6a000 .. ..0: pte 0x0000000021fda401 pa 0x0000000087f69000 .. .. ..0: pte 0x0000000021fdac1f pa 0x0000000087f6b000 .. .. ..1: pte 0x0000000021fda00f pa 0x0000000087f68000 .. .. ..2: pte 0x0000000021fd9c1f pa 0x0000000087f67000 ..255: pte 0x0000000021fdb401 pa 0x0000000087f6d000 .. ..511: pte 0x0000000021fdb001 pa 0x0000000087f6c000 .. .. ..509: pte 0x0000000021fdd813 pa 0x0000000087f76000 .. .. ..510: pte 0x0000000021fddc07 pa 0x0000000087f77000 .. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000\n\n\nWhat does page 0 contain? \ncode and data\n\n\n What is in page 2?\n\n\n  user stack\n\nWhen running in user mode, could the process read/write the memory mapped by page 1?\npte: 0x0000000021fda00f\n\n\n\ncan’t read , write, and execute in user mode, this could be the guard page\n\nWhat does the third to last page contain?\nthe last page is the trapoline page, but the last two i am not sure, may be the heap and trapframe\n\n\n\n\nDetecting which pages have been accessed (hard)Task\nimplement pgaccess()：报告哪些页被访问了\n参数：\n第一个用户页的起始虚拟地址\n需要检查的页的数量\n用来存结果的用户缓存地址\n\n\n\n","categories":["courses","Operating System"],"tags":["MIT6.S081","pipe","CSP"]},{"title":"xv6笔记：chapt2 Operating system organization","url":"/2023/08/05/course-learning/MIT6.S081/chapt2/","content":"xv6笔记：chapt2 Operating system organizationRequirements for an OS\nsupport several activities at once\n\nmultiplexing: time-share the resources of the computer among these processes, every process has a chance to execute.\n\nisolation: if one process has a bug and malfunctions, it shouldn’t affect processes that don’t depend on the buggy process\n\ninteraction: for instance, pipelines\n\n\nFocusThis chapter focus on the mainstream designs centered around a monolithic kernel.(used by many operating systems like linux)\n\nxv6 runs on RISC-V microprocessor, RISC-V is a 64-bit CPU, and xv6 is written in “LP64”C.\n\n\nRISC-V reference: https://riscv.org/technical/specifications/\n\nThe Support HardwareXv6 is written for the support hardware simulated by qemu’s  “-machine virt” option  \nhardware includes:\n\nRAM\nROM containing boot code\nserial connection to the keyboard/screen\ndisk\n\nAbstracting physical resources\nwhy need strong isolation?\n\n\nthe applications may not be well behaved (we do not trust application to periodically give up the CPU)\nthe applications may have bugs\n\n\nHow to achieve strong isolation?\n\n\nforbid applications from directly accessing sensitive hardware resources\ninstead to abstract the resources into services\n\nExample 1for example, Unix applications interact with storage only through the file system’s open, read, write, close system calls, instead of reading and writing disk directly.\n\napplication will not pay attention to the details, they only need pathnames.\n\nExample 2\nthe details are transparent to the application\n\n\nthe applications don’t have to be aware of the time sharing\nUnix transparently switches hardware CPUs among processes\n\nExample 3\nUnix processes use exec to build up their memory image(instead of directly interacting with physical memory)\nlet the OSto decide where to place a process in memory\nOS may also store some of a process’ s data on disk if the memory is tight\n\nExample 4\nmany forms of interaction among Unix processes occur via file descriptors.\nfile descriptors abstract away many details (where data in a pipe is stored)\nfile descriptors simplify the interactions ( if one application in a pipeline fails, thekernel generates an end-of-file signal for the next process in the pipeline)\n\nUser mode, supervisor mode, and system callsThree modes in RISC-V\nmachine mode : \nfull privilege\nCPU starts in machine mode\nthis mode is intended for configuring a computer\n\n\nsupervisor mode: \nexecute privileged instructions :\nsuch as enabling and disabling interrupts\nreading and writing the register that holds the address of a page table\nthe software in supervisor mode can also execute privileged instructions and is said to be running in kernel space  \nThe software running in kernel space (or in supervisor mode) is called the kernel.  \nIt is important that the kernel control the entry point for transitions to supervisor mode;  (avoid the malicious application)\n\n\nuser mode\n\nKernel organizationmonolithic kernel\nthe entire operating system resides in the kernel ( linux )\n\nadvantages\n\nconvenient, OS designer doesn’t have to decide which part of OS doesn’t need full hardware privilege\neasier for different parts of the operating system to cooperate\nhigh performance to OS-intensive applications , because subsystems of the kernel can be tightly integrated  \n\ndisadvantages\n\ninterfaces between different parts of the operating system is complex\neasy for os developer to make a mistake\n\nmicrokernel\nkernel is simple (Minix, L4, QNX), used widely in ebedded settings\n\n\nminimize the amount of operating system code that runs\nexecute the bulk of the operating system in user mode \nThis organization allows kernel to be relatively simple\n\n\n\n\nin the above picture, file system runs as a user-level process\n\nOS services running as processes are called servers\n\napplication interacts with the server by an inter-process communication mechanism to send messages from one user-mode process to another\n\nthe kernel interface consists of a few low-level functions for starting applications, sending messages, accessing device hardware, etc  \n\n\nWhich one is better?\nIt depends\n\n\nfaster performance (mono)\nsmaller code size \nreliability of the kernel (micro)\nreliability of the complete operating system  \n\nCode: xv6 kernel organization\n\nIt is kind of simple surprisingly. With about 30 files, you can build a real world kernel!\nThe inter-module interfaces are defined in  defs.h  \nProcess overview\nIn Unix OS, the unit of isolation is process\n\nprocess abstraction can prevent one process from destroying or spying on another process’s memory, CPU, file descriptors, etc.   \n\nprocess abstraction also prevents a process from wrecking the kernel itself  \n\nprocess abstraction needs to be carefully designed and implemented so that no buggy or malicious applications may trick the kernel or hardware into doing something bad (for example, avoiding isolation)\n\n\nkey design ideas in abstracting process\nan address space to give a process the illusion of its own memory \na thread to give the process the illusion of its own CPU  \n\nIn xv6, a process consists of one address space and one thread, in the real world, a process may have more than one thread to take advantage of multiple CPUs  \nmechanism to implement process\nthe user/supervisor mode flag\n\naddress spaces\n\ntime-slicing of threads  \n\n\n\n How to enforce isolation?\n\n\nprovides the illusion to a program that it has its own private machine\n\nprovides a program with what appears to be a private memory system, or address space\n\nso other process cannot read or write\n\n\n\nHow to implement process in xv6?\n\nxv6 uses page tables(which are implemented by hardware ) to give each process its own address space.\nThe RISC-V page table translates (or “maps”) a virtual address (the address that an RISC-V instruction manipulates) to a physical address (an address that the CPU chip sends to main memory).\n\n\neach process has a separate page table that defines process’s address space. Process’s address space includes:\n\nuser memory starting at address 0\ninstructions\nglobal variables\nstack\nheap\nAt the top of the address space xv6 reserves a page for a trampoline and a page mapping the process’s trapframe.  \n\n\ntransition into kernel and back\n\nxv6 use these two pages to transition into the kernel and back:\n\nthe trampoline page contains the code to transition in and out of the kernel  \na page mapping the process’s trapframe  is necessary to save/restore the state of the user process  \n\n\nWhat limit the maximum size of a process’s address space?\n\n\npointers on the RISC-V are 64 bits wide  \nhardware only uses low 39 bits\nxv6 only uses 38 of those 39 bits  \nThus, the maximum address is 2^38 - 1 = 0x3fffffffff , which is MAXVA, (kernel/riscv.h)\n\nThe process state structure in xv6\nxv6 maintains many pieces of state for each process: struct proc (kernel/proc.h)\nthe most important pieces of kernel state:\npage table\nkernel stack\nrun state\n\n\nuse notation: p-&gt;xxx to refer to the elements of the proc structure\np-&gt;state indicates whether the process is allocated, ready to run, running, waiting for I/O, orexiting.  \np-&gt;pagetable holds the process’s page table, in the format that the RISC-V hardware expects.   \n\nThread and Process\neach process has a thread of execution which can be suspended and later resumed.\nmuch of the state of a thread is stored on the thread’s stacks. \neach process has two stacks:\nuser stack\nkernel stack(p-&gt;kstack): when the process enters the kernel, the kernel code executes on the process’s kernel stack\n\n\nThread alternates between actively using its user stack and its kernel stack\nThe kernel stack is separate and protected from user code, so that even if a process has wrecked its user stack, the kernel can execute.\n\nCode: starting xv6, the first process and system call\nHow the kernel starts and runs the first process?\n\n\ninitialize itself\nrun a boot loader (stored in read-only memory), the boot loader loads the xv6 kernel into memory\n\nThe loader loads the xv6 kernel into memory at physical address 0x80000000.  (because the address range 0x0:0x80000000 contains I/O devices  )\n\nin machine mode, the CPU executes xv6 starting  at _entry (kernel/entry.S)\n\n\n\nThe RISC-V starts with paging hardware disabled: virtual addresses map directly to physical addresses.  \nThe instructions at _entry set up a stack so that xv6 can run C code. \n\nXv6 declares space for an initial stack, stack0, in the file start.c. The code at _entry loads the stack pointer register sp with the address stack0+4096, the top of the stack, because the stack on RISC-V grows down. \n\n\nNow kernel has a stack. _entry calls into C code at start\n\n\nstart performs some configuration that is only allowed in machine mode, and then switches to supervisor mode\n\n\n\n\nBefore jumping into supervisor mode, it programs clock chip to generate timer interrupts.\nstart “returns”  to supervisor mode by calling mret. This causes the program counter to change to main  \nmain initializes several devices and subsystems\n\n\n\n\nmain then creates the first process by calling userinit\n\n\n\n\nIn the first process, it makes the first system call exec loads the number into register a7 and calls ecall to re-enter the kernel\n\n\n\n\nthe kernel use the number stored in a7 to call the desired system call\n\n\n\n\nthe system call table maps SYS_EXEC to sys_exec\nexec replaces the memory and registers of the current process with the new program\n\n\n\n\nIn this case, the new program will be the following, once the kernel has completed exec,  it returns to user space in the /init process. \nInit creates a new console device if needed, then open it as file descriptors 0,1,2. Then it starts a shell on  the console. The system is up.\n\n\n\nSecurity Model\nHow operating system deals with buggy or malicious code?\n\nTypical security assumptions and goalsfor user code\nfor kernel code\n\nKernel code is expected to be bug-free  \n\ncertainly to contain nothing malicious  \n\n\nReal life things are not so straightforward\nIt’s difficult to prevent clever user code from making a system unusable (or causing it to panic) by consuming kernel-protected resources – disk space, CPU time, process table slots, etc.  \n\nIt’s usually impossible to write bug-free code or design bug-free hardware;   \n\n\n","categories":["Books","Operating System","xv6"],"tags":["MIT6.S081","OS","xv6"]},{"title":"MIT6.S081笔记：lecture 1","url":"/2023/08/05/course-learning/MIT6.S081/lec1/","content":"MIT6.S081笔记：lecture 1\ncare about what is going on under the hook\nlike infrastructure\ncare about high performance\n\nCourse Goals\nOS design and implementation\nHands-on experience extending a small os\nHands-on experience writing systems software\n\nOS Purposes\nABSTRACTION of the hardware for convenience and portability\nMULTIPLEX the hardware among many applications\nISOLATION\nSHARING among cooperating applications\nSECURITY(PERMISSION)\nPERFORMANCE\nRANGE of USES\n\nOS ORGANIZATION\n\n\nuser app: vi, gcc, DB, &amp;c\nkernel services\nhardware\n\nwe care a lot about the interfaces and internal kernel structure\nWhat services does an O/S kernel typically provide?\nprocess\nmemory allocation\nfile contents\nfile names, directories\naccess control(securities)\nmany others: users, IPC, network, time, terminals\n\nWhat’s the kernel interface?\n“System calls”\nlike open()\nwrite()\nfork()\n\nWhy is O/S design+implementation hard and interesting?\nunforgiving environment: hard to debug\nmany design tensions:\nefficient vs abstract/portable/general-purpose\npowerful vs simple interfaces\nflexible vs secure\n\n\nfeatures interact: fd = open(); fork()\nuses are varied: laptops, smart-phones, cloud, virtual machine, embedded\nevolving hardware: NVRAM, multi-core, fast networks\n\nAPI for the Kernel\nfd = open(“out”,1)\nwrite(fd,”hellp\\n”,6)\npid = fork();\n\nsystem calls are special because they jump into the kernel\n\nWhy studying operating system both challenging and interresting?\n\n\nunforgiving\n\ntensions\n\nefficient - abstract interfaces\npowerful os services - simple interfaces\nflexible - secure\n\n\ninteract\n\n\nfd = open()pid = fork()\n\nClass structure\nOnline course information:https://pdos.csail.mit.edu/6.S081/ – schedule, assignments, labsPiazza – announcements, discussion, lab help\n\nLectures\n\nO/S ideas\ncase study of xv6, a small O/S, via code and xv6 book\nlab background\nO/S papers\nsubmit a question about each reading, before lecture.\n\n\nLabs:The point: hands-on experienceMostly one week each.Three kinds:  Systems programming (due next week…)  O/S primitives, e.g. thread switching.  O/S kernel extensions to xv6, e.g. network.Use piazza to ask/answer lab questions.Discussion is great, but please do not look at others’ solutions!\n\nGrading:70% labs, based on tests (the same tests you run).20% lab check-off meetings: we’ll ask you about randomly-selected labs.10% home-work and class/piazza discussion.No exams, no quizzes.Note that most of the grade is from labs. Start them early!\n\n\nIntroduction to UNIX system calls\nwhat happens when a program calls a system call like open()?\n\nlooks like a function call, but it’s actually a special instructionhardware saves some user registershardware increases privilege levelhardware jumps to a known “entry point” in the kernelnow running C code in the kernelkernel calls system call implementation  open() looks up name in file system  it might wait for the disk  it updates kernel data structures (cache, FD table)restore user registersreduce privilege leveljump back to calling point in the program, which resumeswe’ll see more detail later in the course\nfork.c\nthe shell create a new process for each time you type\n\n\nthe fork() system call create a new process\n\nthe kernel makes a copy of the calling process\n\ninstructions,\n\ndata,\n\nregisters,\n\nfile descriptors,\n\ncurrent directory\n\n“parent” and “child” processes\nonly difference: fork() returns a pid in parent, 0 in child\n\n\n\n\n\nHow can  we run program in that process?\n\nexec.c\nreplace calling process with an executable file\ndiscards instruction and data memory\nloads instructions and memory from the file\npreserves file descriptors\n\nforkexec.c\na common UNIX idiom\n\n\nfork() a child process\nexec() a command in the child\nparent wait()s for child to finish\n\nthe shell does fork/exec/wait for every command you type\nto run in the background – &amp; – the shell skips the wait()\n\nsome convention\n\n\nexit(status)-&gt;wait(&amp;status)\n0 = success, 1=command enountered an error\nnote: the fork() copies, but exec() discards the copied memory. this may seem wasteful, you’ll transparently eliminate the copy in the “copy-on-write” lab\n\nredirect.c\nredirect the output of a command\n\nwhat does the shell do for this?\n$ echo hello &gt; out\n\n\nfork\nchange FD 1 in child\nexec echo\n\nnote: open() always chooses lowest unused FD; 1 due to close(1).\nfork, FDs, and exec interact nicely to implement I/O redirection\nonly sh has to know about I/O redirection, not each program\npipe1.c\ncommunicate through a pipe\n\nhow does the shell implement?\n\nan FD can refer to a “pipe”, as well as a file\nthe pipe() system call creates two FDs\nread from the first FD\nwrite to the second FD\n\n\nthe kernel maintains a buffer for each pipe[u/k diagram]\nwrite() appends to the buffer\nread() waits until there is data\n\n\n\npipe2.c\ncommunicate between processes\n\npipes combine well with fork() to implement ls | grep x\n\nshell creates a pipe\nthen fork twice\nthen connects ls ‘s FD 1 to pipe’s write FD\nconnects grep’s FD 0 to the pipe\n\nAsking about design decisions\nwhy these I/O and process abstractions? why not something else?\n\nwhy provide a file system? why not let programs use the disk their own way?\n\nwhy FDs? why not pass a filename to write()?\n\nWhy are files streams of bytes, not disk blocks or formatted records?\n\nwhy not combine fork and exec?\n\nseparate fork-then-exec give child a chance to change FDs before exec\n\n\n\nSummary\nWe’ve looked at UNIX’s I/O, file system, and process abstractions.\nThe interfaces are simple – just integers and I/O buffers.\nThe abstractions combine well, e.g. for I/O redirection.\n\n","categories":["courses","Operating System"],"tags":["MIT6.S081","OS"]},{"title":"MIT6.s081 lab2记录：编写系统调用","url":"/2023/08/05/course-learning/MIT6.S081/lab2/","content":"MIT6.s081 lab2记录：编写系统调用独立完成整个lab2的作业，评分如下：\n","categories":["courses","Operating System"],"tags":["MIT6.S081","pipe","CSP"]},{"title":"MIT6.S081笔记：lecture 4","url":"/2023/08/05/course-learning/MIT6.S081/lec4/","content":"MIT6.S081笔记：lecture 4 Page TablesIsolation\nwhy use virtual memory?\n\n\n\nmake bad code doesn’t affect the os\nwant sth really seperates these memories from different programs\n\n\n\nHow to give isolation?Address Spaces\n\ngive applications including the kernel its own address space\n\n\n\n\nHow to multiplex all these different address spaces on a single physical memory?\nPAGE TABLES (HW: memory management unit)\n\n\nBlueprint\n\n\n\nevery app has its own map which basically defines its address space\n\nPAGE TABLE\nnot per address, per page! each page is 4kB\n\n\n\n\nin xv6, virtual memory is less than physical memory space\nand it’s inefficient to store all entries(2^27)\n\nRISC-V PAGE TABLE\nUse cache(TLB) to avoid 3 times of memory translations\nWhen switching page table,  also need to flush the TLB\n\nKernel memory address space layout\n\n\nevery process has a corresponding kernel stack\n\n","categories":["courses","Operating System"],"tags":["MIT6.S081","OS"]},{"title":"MIT6.S081笔记：lecture 2 introduce to C","url":"/2023/08/05/course-learning/MIT6.S081/lec2/","content":"MIT6.S081笔记：lecture 2 introduce to CMaterials learningWhat is different about C? (vs. Python)\nC是一个高级汇编语言\n\n其代码直接对应于机器指令\npython dict相反，会使用很多隐藏于之下的code\n\n\nC是编译而不是解释的\n\n可以直接在解释器上执行，非常快\n\n\nC是静态类型的\n\npython中，在变量中，类型与变量值相关联：\n每个值存于一个内存区域中，这个区域包含了这个值的类型相关信息\n\nC中，类型与变量相关联，并解释为字节值：\n值并不包含任何类型信息，所有信息均存于变量\n\n类型错误在编译时被捕获\n\n\n\nC使用手动内存管理，没有垃圾收集机制\n\n显示的“malloc”和“free”，直接访问内存\n更快，也更容易出现错误\n\n\nC中的Intergers和floats有特定的但不明确的边界\n\n不同的类型在不同的平台有着不同的涵义（同为int可能机器不一样，所表示的范围也就不一样）\n\n\n\n\n大端和小端\n怎样在内存中表示：number like 0x12345678 (= 305419896) ？\n\n\n\n\nRISC-V platform is little-endian  \n\nC中的内存类型\n堆内存\n动态内存，需要显示分配（未初始化过的）\n\n静态内存\n\n在任何函数之外定义的变量，以及通过static声明的变量\n只有单个的拷贝，被存储在了一个预先定义且不会改变的内存地址\n初始化为0\n\n\n栈内存\n\n函数中的局部变量\n未初始化\n\n\n\nKey topic in C ：内存安全\nuse after free\ndouble free\nuninitialize memory\nbuffer overflow\nmemory leak\ntype confusion\n\nKey topic in C：指针\n\n\n指针本质上是int，它表示的是变量所在的内存地址\n\n\n\n\n不同类型的指针如上图\n指针的大小\n与特定平台相关\nRISC-V使用64bit指针（与long大小相同）\nThis means, in 6.S081, we can cast a pointer to a long, but not to an int.  \n\n\n\nC中的数组\n固定大小\n\n\n\n\n在内存中连续存储：\n\n\n\n定义 v.s. 声明\nC中的声明是必须的，C需要其类以及类型签名\n\nIf it hasn’t seen a declaration yet, it won’t know the correct types to use.  \n\n\n定义在代码中只能出现一次\n\n通常情况下，会把声明放在单独的头文件里\n\n\n定义静态函数和变量\n如果一个函数在两个文件中出现，他们会发生冲突。\n为了避免冲突，可以使用static关键字\n\nstatic void function_2(int xyz);static void function_2(int xyz) {\tprintf(“%d\\n”, xyz);}\n\n\n上面的函数只可以在当前定义的文件中使用\n也可以在局部变量上声明static关键字：\n\nint add_cumulative_numbers(int increase) {    static int total_sum = 0;    total_sum += increase;    return total_sum;}\n\n\n在调用的初次会被初始化为0，并且会保存其值\n\n作为函数指针：\n\n\nstatic void my_function_1(int);static void my_function_2(int);void pointer_example(int variant) {    void (*local)(int);    if (variant == 1) {    \tlocal = my_function_1;    } else {    \tlocal = my_function_2;    }    local(100); // call function via variable}\n\nC中的字符串\n尾字符为'\\0' = (0x00)。注意，其值为0\n计算字符串的长度：\n\nint strlen(const char *str) {    int i;    //可通过判定是否为终结字符来判断是否结束    for (i = 0; str[i] != 0; i++) {}    return i;}\n\n类型定义\n类型别名：\n\n// from kernel/types.h:typedef unsigned char uint8;typedef unsigned short uint16;typedef unsigned int uint32;typedef unsigned long uint64;\n\n\n方便使用+更加清楚\n跨平台：If we ever port xv6 to another platform where the sizes don’t match up like this, we can just change the one file that defines these typedefs, and the rest of the code will update to match!  \n\n头文件和源文件\n头文件包含用来共享的声明\n源文件包含不同代码的定义，如：\n\n// kernel/spinlock.h: declarations describing the spinlock interface// kernel/spinlock.c: actual definitions of spinlock code\n\nC预处理器\n常见预处理指令：\n\n#include “spinlock.h” // -&gt; Incorporate the contents of spinlock.h here#define NPROC 64 // -&gt; Replace all instances of ‘NPROC’ with ‘64’#define TWICE(x) ((x)*2)//-&gt; Replace all instance of ‘TWICE(x)’ with ‘((x) * 2)’ … for any expression ‘x\n\n#ifdef DEBUG // only if DEBUG was defined by #define\tprintf(“some debug message: %d”, my_value);#else\t// do something else instead of printing#endif\n\n#ifndef VAR // if VAR wasn’t defined by #define#if EXPR // if EXPR evaluates to true\n\nInclude Guard// at the start of the something.h file#ifndef SOMETHING_H#define SOMETHING_H// ... the normal contents go here ...#endif /* SOMETHING_H */\n\n常见内存函数\nmalloc(n):  返回分配内存的首地址\nfree(ptr)\nmemset(ptr,v,n)：set every byte from ptr[0] to ptr[n-1] to v\nmemmove(dst, src, n): copies src[0]…src[n-1] to dst[0]…dst[n-1]  \nmemcpy(dst, src, n):  (Discouraged! Prefer memmove.)  \n\n常见字符串操作函数\nstrlen(str)\nstrcmp(a,b)\nstrcpy(dst, src)\n\n一定要记住NULL终结符\nUnionsunion my_union {    float x;    int y;}\n\n\nonly safely use a single field of a union at a time  \nYou won’t need these much.   \n\nC位操作unsigned int my_int;// Set the Nth bit of an integer:my_int |= 1 &lt;&lt; N;// Clear the Nth bit of an integermy_int &amp;= ~(1 &lt;&lt; N);// Check if any bits in MASK are setif (my_int &amp; MASK) { /* ... */ }// Check if all bits in MASK are setif ((my_int &amp; MASK) == MASK) { /* ... */ }// Check if integer is a power of twoif (my_int &amp;&amp; !(my_int &amp; (my_int - 1))) { /* ... */ }\n\nFinally: a pointer challengeSource: The Ksplice Pointer Challenge - Oracle Linux Blogint main() {    int x[5]; // x is at 0x7fffdfbf7f00    printf(\"%p\\n\", x); // -&gt; 0x7fffdfbf7f00    printf(\"%p\\n\", x+1); // -&gt; 0x7fffdfbf7f04    printf(\"%p\\n\", &amp;x); // -&gt; 0x7fffdfbf7f00    printf(\"%p\\n\", &amp;x+1); // -&gt; 0x7fffdfbf7f14    return 0;}\n\nExercise testing","categories":["courses","Operating System"],"tags":["MIT6.S081","OS"]},{"title":"国产开源OS调研浅析：龙蜥，鸿蒙和欧拉","url":"/2023/08/05/course-learning/MIT6.S081/research1/","content":"国产开源OS调研浅析：龙蜥，鸿蒙和欧拉\n在调研过程中依据开源操作系统的用户数量以及生态的丰富和完善性，选用了龙蜥，鸿蒙和欧拉作为调研目标\n\n龙蜥（open Anolis）支持多架构的安全高性能操作系统系统框架\nAnolisOS-8.8\n\n\nL0层软件（内核层）：\n内核版本 ANCK-5.10\n\n\nL1层软件（核心层）：\nopenssl 1.1.1 支持国密\n\n\nL2层软件（系统层）：\n系统工具更新（crash ，bison ）\n系统库更新（glib2 ，libtirpc ，rdma-core，Intel QAT，Intel SPR 特性）\n\n\nL3层软件（应用层）：\n新增软件包 ancert\n新增软件包 ssar\n新增软件包 sysom\n新增软件包 sysak\n\n\n\n龙蜥社区\n开源影响力：有超过 280 家合作伙伴参与共建开源社区，整体装机量达500多万，100余款企业产品完成与龙蜥操作系统的适配。\n运作模式：已成立 50+ 个 SIG 工作组，围绕芯片、内核、编译器、安全、虚拟化及云原生等操作系统核心领域进行技术创新\n\n技术特性\n\n\nCentOS 迁移\n经典产品特性迁移\n\n云原生场景\nPaaS，CaaS 场景下的相关组件和特性\n\n一云多芯\n对多处理器芯片及多芯片平台相关的指令集，芯片的支持\n\n运维与性能\n降本增效相关的特性，包括系统诊断、跟踪、监控，性能优化\n\n软硬件协同\nRASD，各种硬件 offload，bypass 内核等以释放硬件能力为目标的技术特性\n\n安全可信\n包括但不限于提升系统安全可信，数据安全可信的相关产品特性\n\n编程语言\n编译器相关的运行时和工具和特性\n\n社区基础设施\n用于支撑操作系统产品的开发协同，研发流程，效能提升，版本质量相关的平台和工具。\n\n\n鸿蒙（open Harmony）面向全场景智能终端设备的操作系统平台系统框架\n\n\n系统功能按照“系统 &gt; 子系统 &gt; 组件”逐级展开\n\n采用分层设计：\n\n内核层：\n\n内核子系统：采用多内核（Linux内核或者LiteOS）设计，支持选用适合的OS内核。内核抽象层通过屏蔽多内核差异，对上层提供基础的内核能力：进程/线程管理、内存管理、文件系统、网络管理和外设管理等\n驱动子系统：驱动框架（HDF）提供统一外设访问能力和驱动开发、管理框架\n\n\n系统服务层\nOpenHarmony的核心能力集合，通过框架层对应用程序提供服务。\n\n系统基本能力子系统集：为分布式应用在多设备上的运行、调度、迁移等操作提供了基础能力。由分布式软总线、分布式数据管理、分布式任务调度、公共基础库、多模输入、图形、安全、AI等子系统组成。\n基础软件服务子系统集：提供公共的、通用的软件服务，由事件通知、电话、多媒体、DFX（Design For X） 等子系统组成。\n增强软件服务子系统集：提供针对不同设备的、差异化的能力增强型软件服务。由智慧屏专有业务、穿戴专有业务、IoT专有业务等子系统组成。\n\n\n框架层\n框架层为应用开发提供了C/C++/JS等多语言的用户程序框架和Ability框架，适用于JS语言的ArkUI框架，以及各种软硬件服务对外开放的多语言框架API。根据系统的组件化裁剪程度，设备支持的API也会有所不同。\n\n应用层\n应用层包括系统应用和第三方非系统应用。应用由一个或多个FA（Feature Ability）或PA（Particle Ability）组成。其中，FA有UI界面，提供与用户交互的能力；而PA无UI界面，提供后台运行任务的能力以及统一的数据访问抽象。基于FA/PA开发的应用，能够实现特定的业务功能，支持跨设备调度与分发，为用户提供一致、高效的应用体验。\n\n\n\n\n系统类型\n轻量系统\n面向Arm Cortex-M、RISC-V 32位的设备，硬件资源极其有限。支撑的产品如智能家居领域的连接类模组、传感器设备、穿戴类设备等。\n\n小型系统\n面向应用处理器例如Arm Cortex-A的设备，支持的设备最小内存为1Mi。可支撑的产品如智能家居领域的IP Camera、电子猫眼、路由器以及智慧出行域的行车记录仪等。\n\n标准系统\n面向应用处理器例如Arm Cortex-A的设备，支持的设备最小内存为128MiB。可支撑的产品如高端的冰箱显示屏。\n\n\n欧拉（open Euler）面向数字基础设施的操作系统\n\n\n支持服务器、云计算、边缘计算、嵌入式等应用场景\n\n每两年推出一个 LTS 版本\n\n将社区验证成熟的特性逐步回合到发行版中\n\n已支持 x86、ARM、SW64、RISC-V、LoongArch 多处理器架构\n\n新增发布面向边缘计算的版本 openEuler Edge、面向嵌入式的版本 openEuler Embedded\n\n\n系统框架\n统一基于 Linux Kernel 5.10 构建\n文件系统：采用软更新、目录双视图\n内存分级扩展：支持用户态swap\n创新 CPU 调度算法\n创新业务优先级 OOM 内存回收算法\n\n平台框架\n\n硬件支持\n\n总结欧拉操作系统适用场景比较广泛：包括大数据，云计算，人工智能等。鸿蒙更加偏向智能终端设备如穿戴类设备，传感器设备，冰箱显示屏等。龙蜥操作系统兼容CentOS生态，支持多计算架构，提供稳定、高性能、安全、可靠的操作系统支持。\n","categories":["Operating System","OS调研"],"tags":["OS","Anolis","Harmony","openEuler"]},{"title":"MIT6.S081笔记：lecture 3","url":"/2023/08/05/course-learning/MIT6.S081/lec3/","content":"MIT6.S081笔记：lecture 3OS designOS organization\n\nStrawman design: NO OS\nApplication interact directly with the OS:\n\nOS acts as a library:\n\nwhich is not a good design, because it doesn’t have enforced multiplexing and strong memory isolation\n\n\nUnix interface\nabstract the hardware resources to provide strong isolation\nprocesses: instead CPU: fork()\nOS transparently allocates cores\nenforce that processes give them up\n\n\nmemory: instead physical memory: exec(), brk()\nEach process has its own memory\nOS decides where to place app in memory\nOS enforces isolation between apps\nOS stores image in file system (loaded with exec)\n\n\nfiles: instead disk block: open(), read(), write()\nOS provides convenient names\nOS allows files to be shared by apps and users\n\n\nPipes: instead shared physical memory: pipe()\nOS buffers data\nOS stops sender if it transmits too fast\n\n\n\nOS should be defensive\napp can not crash the operating system\napp can not break out of its isolation\nit means Strong  Isolation between apps and OS\nhardware support\nuser/kernel mode\nvirtual memory\n\n\n\n\n\nUser/Kernel mode\nkernel mode: privileged instructions\nchanging back to user mode\nprogramming a timer chip\ncontrolling the virtual memory\n\n\nuser mode: unprivileged instructions\n\nCPU provide virtual memorypage table\nmap virtual addr to physical addr\n\ndefines what physical memory an app  can access\n\nprocess has its own page table\n\n\nSystem calls\napps need to communicate with kernel\nsolutions add instruction to change mode in controlled way:\necall\nenter kernel at pre-agreed instruction address\n\n\n\n\n\nEntering the kernelecall\nfork();\necall sys_fork -&gt; syscall\n\n\nwrite()\necall sys_write -&gt; syscall\n\n\n\nTrusted computing base\nkernel must have no bugs\n\nkernel must treat process as malicious\n\nsecurity mindset\n\n\nMonolithic kernels\nkernel is one big program with everything\nKernel interface == system call interface\nPros:\ngood performance\neasy for subsystems to cooperate\n\n\ncons:\nInteractions are complex\nNo isolation within\n\n\n\nMicrokernels\nRuns OS services as ordinary user programs\nkernel implements minimal mechanism to run services in user space\nIPC\nprocess with memory\n\n\nKernel interface != system call interface\nPro:\nmore isolation\neasy to  debug\n\n\nCon:\nHard  to get good performance\ncomplexity\n\n\n\n","categories":["courses","Operating System"],"tags":["MIT6.S081","OS"]},{"title":"MIT6.S081 tips：常用工具","url":"/2023/08/05/course-learning/MIT6.S081/tools_learning/","content":"MIT6.S081 tips：常用工具\n工欲善其事，必先利其器\n\nC pointersprepsint a[4];int *b = malloc(16);int *c;int i;\n\nQ1printf(\"1: a = %p, b = %p, c = %p\\n\", a, b, c);\n\nanswer:\n\n1: a = 0x7ffdd2edd3f0, b = 0x56411ea742a0, c = 0x7ffdd2edd889\n\nQ2c = a;for (i = 0; i &lt; 4; i++)    a[i] = 100 + i;c[0] = 200;printf(\"2: a[0] = %d, a[1] = %d, a[2] = %d, a[3] = %d\\n\",\t   a[0], a[1], a[2], a[3]);\n\nanswer:\n\n2: a[0] = 200, a[1] = 101, a[2] = 102, a[3] = 103\n\nQ3c[1] = 300;*(c + 2) = 301;3[c] = 302;printf(\"3: a[0] = %d, a[1] = %d, a[2] = %d, a[3] = %d\\n\",\t   a[0], a[1], a[2], a[3]);\n\nanswer:\n\n3: a[0] = 200, a[1] = 300, a[2] = 301, a[3] = 302\n\nQ4c = c + 1;*c = 400;printf(\"4: a[0] = %d, a[1] = %d, a[2] = %d, a[3] = %d\\n\",\t   a[0], a[1], a[2], a[3]);\n\nanswer:\n\n4: a[0] = 200, a[1] = 400, a[2] = 301, a[3] = 302\n\nQ5c = (int *) ((char *) c + 1);*c = 500;printf(\"5: a[0] = %d, a[1] = %d, a[2] = %d, a[3] = %d\\n\",\t   a[0], a[1], a[2], a[3]);\n\nanswer:\n\n5: a[0] = 200, a[1] = 400, a[2] = 500, a[3] = 302\nwrong! this answer is much more difficult\n\n5: a[0] = 200, a[1] = 128144, a[2] = 256, a[3] = 302\n\n\n\nwhy a[1] = 128144, a[2] = 256?  这个题对于不懂大小端以及指针的人来说挺难的\n\n\n\n 如上图，其实是以大端的方式存储的（方便查看内容），但是其实在该计算机中实际以小端存储：\n（以a[0]-a[2]为例）c8000000 90010000 2d010000…\nc实际上是：\n\n\n也就是修改*c，会修改加粗部分的内容c8000000 90010000 2d010000…（整体向后偏移1字节，因为char大小为1字节），修改后为：c8000000 90f4010000 00010000…，转换为大端表示如下图所示：\n\n\nQ6b = (int *) a + 1; // a+4c = (int *) ((char *) a + 1); // a+1printf(\"6: a = %p, b = %p, c = %p\\n\", a, b, c);\n\nanswer:\n\n6: a = 0x7fffac3d88e0, b = 0x7fffac3d88e4, c = 0x7fffac3d88e1\n\ngit从有向无环图去理解git的原理： 一个git 仓库永远仅仅只是一个DAG和它的便利贴（branch 可以移动，tag则不行）\nStoragegit 对象存储 仅仅只是 对象的有向无环图， 它们通过SHA-1哈希来压缩和识别\nblob\n\n最简单的对象，字节的集合。通常是一个文件，但也可以是一个符号链接或是其他任何东西。\n\ntree\n\n目录由tree进行表示。他们指向的是file blobs 或 是其他的trees（子目录）\n\ncommit\n\n一个commit指向一个代表提交时刻文件状态的tree，它还可以指向0~n个其他的父commits，如果父commits多于一个意味着该commit是merge，没有父commit意味着是初始提交。\n\nrefs\nreferences, heads or branches\n\n\n\nrefs就像一个节点的便利贴一样，或是书签，表示“我在该节点工作”\ngit commit 在有向无环图中加入一个新的节点，并将当前分支的便利贴移动到最新的节点\nHEAD ref比较特殊，因为它实际上指向另一个ref（指向当前正在活跃的branch）\n\nremote refs\n\n远程ref在不同的namespace下，并由远程服务器控制，git fetch可以更新它们\n\ntag\n\ntag既是有向图中的节点，又是一个便利贴，它指向一次提交（不会移动的便利贴）\n\nHistory\n how to manage history?\n\nsimplest repo\nfetch one from remote\ngit merge remote\ngit commit and git fetch later\ngit merge remote\n\nwasn’t fast-forward\na new commit node was create(e)\n\na few commits on both branches and another merge\n\nDAG records exactly what the history of actions taken was\n\nrebase\n\nyour commit is replaced by another commit with a different parent, and your branch is moved there.\nthe d is still here, not removed:\n\n\nrebase multiple commits\nscript为什么用script？script是用来记录一个terminal session中发生的所有事情的\nsession的所有都可以被回放（replay），但需要timing log file的支持，详见scriptreplay\n\n\n当print语句很多时，我们想要搜索我们关注的部分，可以把所有的console输出到一个文件中方便我们查找，别忘了记录完要exit哦\n用法：script [options] [file]\n选项：\n-a：追加输出到文件\n-c：运行命令\n-f：每次写之后刷新输出\n-T: 记录时间信息到文件中\n-I：记录输入到文件\n-O：记录输出到文件\n\n退出：exit展示：\n\naddr2line当内核出现错误，它会打出一个错误信息，里面包含程序计数器的值。可以使用addr2line将程序指令地址转换为所对应的函数名、以及函数所在的源文件名和行号。\n例如，我们写一个错误程序：\n#include&lt;iostream&gt;int divide(int a, int b){    return a/b;}int main(){    int  a = 3, b = 0;    int div = divide(a,b);    std::cout&lt;&lt;div&lt;&lt;std::endl;    return 0;}\n\n\n\n查看系统日志的错误信息发现，就是出错时所执行的位置。使用addr2line将程序指令地址进行转换，但是出现了显示？？:的问题\n我试了好久，原来是每次程序运行时其VA（虚拟地址都是不同的），所以需要指定其偏移而不是绝对地址。那么是关于哪一个section的偏移呢？我试验了使用text是有问题的，即得不到正确的错误代码所在的行号：\n\n\n实际上错误代码所在行号为5，而不是18；\n为此，我查阅了资料，发现**/proc/id/maps** 对于正确使用addr2line很有帮助。\n\nuse  /proc/id/maps to view the virtual address space of a particular process.\n\nSegment Types\nCode segments \nData segments\nStack segments\nShared libraries segments\n\nSegment Permissions\nread-only (r) means that the segment is readable, hence all segments usually have that mode\nread-write (w) means that the segment is readable and writeable to allow for data modification\nexecute (x) means that the segment contains executable code\nprivate (p), which means that the segment is private, thus only visible from that process\nshared (s), which means that multiple (at least 2) processes share that segment\n\nUnderstanding Output&lt;address start&gt;-&lt;address end&gt;  &lt;mode&gt;  &lt;offset&gt;   &lt;major id:minor id&gt;   &lt;inode id&gt;   &lt;file path&gt; 559b8c418000-559b8c41a000      r--p    00000000          08:30               1708     /usr/bin/cat\n\n\naddress start – address end is the start and end address of that mapping. Note that the whole output is sorted based on those addresses, from low to high.\nmode (permissions) specifies which actions are available on this mapping and if it’s private or shared.\noffset is the start offset in bytes within the file that is mapped. This only makes sense for file mappings. For instance, stack or heap mappings are examples of mappings that aren’t files, and in those cases, the offset is 0. In the above example, the mapping is of the /usr/bin/cat file, and the offset is 0.\nmajor:minor ids represent the device that the mapped file lives in the form of a major and minor id. In the above example, 08:30 represents the major and minor id of the hard drive that has the root filesystem. For non-file mappings, this column shows 00:00*.*\ninode id of the mapped file (again, that’s only valid for file mappings). Inodes are data structures that contain the core filesystem-related metadata. When it comes to non-file mappings, this field is set to 0. In our example, this id is 1708.\nThe file path of the file for that mapping. In the event that this is not a file mapping, that field is empty.\n\nUsed in Codechar buff[64] = {0x00};sprintf(buff, \"cat /proc/%d/maps\", getpid());system((const char*) buff);\n\nobjdump还有一个工具对使用addr2line也很用帮助: objdump\n用法： objdump -d a.out\n\n\n\n\n然后，可以发现 0x11fb终于显示出来正确的错误行数：\n\n\n由此我们可以发现，VA对我们使用addr2line找bug作用极小，因为程序是动态加载的，VA是不断变化的，只有偏移是不变的。\n\n\n所以，只有找到偏移才对我们使用addr2line有用。由sprintf(buff, \"cat /proc/%d/maps\", getpid());打印出：\n\n\n我们可以看出text段是在（560224121000-560224122000）,它的offset是1000，所以可以找到偏移地址为11fb。最后使用addr2line可以显示出正确行数：\n\n\nGDBstart QEMU  with GDB\n\nmake qemu[-nox]-gdb, then start GDB in a second shell  \n\nBreakpointsbreak &lt;location&gt;\nlocation can be address, or names(mon backtrace , monitor.c:71  )\nWatchpointswatch &lt;expression&gt;\nstop execution whenever the expression’s value change\nwatch -l &lt;address&gt;\nwill stop execution whenever the contents of the specified memory address change  \np.s. what ‘s the difference between ‘wa var and wa -l &amp;var  ?\nrwatch [-l] &lt;expression&gt; \nwill stop execution whenever the value of the expression is read  \nExaminingx/x for hexadecimal, x/i for assembly  \nx prints the raw contents of memory in whatever format you specify  \nprint\nevaluates a C expression and prints the result  \ninfo registers  \nprints the value of every register  \ninfo frame  \nprints the current stack frame  \nlist &lt;location&gt;  \nprints the source code of the function at the specified location\nbacktrace  \n","categories":["courses","Operating System"],"tags":["MIT6.S081","OS","tools"]},{"title":"论文实验","url":"/2023/05/30/deep-learning/%E7%AC%AC%E4%B8%80%E7%AB%A0/%E8%AE%BA%E6%96%87%E4%BF%AE%E6%94%B9/","content":"论文实验加入“encoder-decoder”全局模块（MSE）推理模块重新设计","categories":["科研实验","群体行为识别"],"tags":["Group Activity Recognition","Experiment"]},{"title":"安装和使用龙蜥操作系统","url":"/2023/08/05/projects/anolis/pa1/","content":"下载、安装和使用龙蜥操作系统\n","categories":["os","anolis"],"tags":["os","anolis"]},{"title":"MIT6.S081笔记：lecture 5","url":"/2023/08/05/course-learning/MIT6.S081/lec5/","content":"MIT6.S081笔记：lecture 5 calling conventions and stackCalling convenstionsRISC-V Register File\n\nInteger Instructions\nlb t0, 8(sp)\nloads from memory address (sp+8) into register t0\nlb = load byte, lh = load halfword, lw = load word, ld = load doubleword\n\nadd a0, t0, t1\nadds value of t0 to the value of t1 and stores the sum into a0\n\naddi a0, t0, -10\nadds value of t0 to the value -10 and stores the sum into a0\n\nmul a0, t0, t1\nmultiplies the value of t0 to the value of t1 and stores the product int a0\n\n\nPseudo Instructions\ntranslate to real instructions by assembler\n\n\n\nBranching Instructions\n a way to jump to different parts of your code\nBranching refers to the “conditional jump” instructions, such as beq, bne, bgt, bge, blt, ble for branch-if equals, not equals, greater than, greater than or equals, less than, and less than or equals, respectively.\n\n# t0 = 0li      t0, 0li      t2, 10loop_head:bge     t0, t2, loop_end# Repeated code goes hereaddi    t0, t0, 1j\t\tloop_headloop_end:\n\n\n\nStackStack frame\n\n\nstack frame is generated by function calls\n\nstart from high addresses and grow downwards to low addresses\n\nthe return address and to prev frame pointer are at a predictable position\n\nsp - bottom of the stack\n\nfp - top of the current frame\n\n\nUse backtrace to debug","categories":["courses","Operating System"],"tags":["MIT6.S081","OS"]},{"url":"/2023/08/05/unix-program/apue_notes/chapt1_unix%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","content":"chapter 1 unix基础知识1.1 引言从程序员的角度，快速浏览UNIX。\n1.2 UNIX体系结构操作系统狭义上指的就是内核，内核的接口称为系统调用，公用函数库建立在系统调用之上。应用程序既可以使用公用函数库，也可以使用系统调用。shell是一个特殊的应用程序，为运行其他应用提供接口。\n广义上讲，操作系统包含内核和一些其他软件。实际上Linux是GNU操作系统的内核，但大家普遍上称其为操作系统\n1.3 登录可在/etc/passwd文件中查看登录名，目前系统已经加密口令移到了另一个文件中\n1.4 文件和目录\n目录：一个包含目录项的文件。逻辑上认为每个目录项都包含一个文件名和文件属性信息。stat命令可以查看文件属性。目录项的逻辑视图与实际在磁盘上的存储是不同的。\n\n\n\n\n\n\n创建新目录时，会自动创建两个文件名：. 和 ..\n列出一个目录所有文件的名字\n\n1.5 输入和输出\n文件描述符：小的非负整数，内核用以标识特定进程正在访问的文件。当打开或是创建一个新文件时，内核都返回一个文件描述符，在读写的时候可以使用它\n标准输入，标准输出和标准错误：每当运行一个新程序时，shell都会默认为其打开3个文件描述符，即标准输入，标准输出和标准错误，若不做特殊处理，这三个文件描述符都链接向终端。\n不带缓冲的IO：\nread：返回读取的字节数。到达文件尾端时，返回0；出错时，返回-1\nwrite：返回写入的字节数#include \"apue.h\"#define    BUFFSIZE   4096intmain(void){   int       n;   char   buf[BUFFSIZE];   while ((n = read(STDIN_FILENO, buf, BUFFSIZE)) &gt; 0)      if (write(STDOUT_FILENO, buf, n) != n)         err_sys(\"write error\");   if (n &lt; 0)      err_sys(\"read error\");   exit(0);}\n\n\n标准IO的优势：\n无需担心选取最佳的缓冲区大小\n简化了对输入的处理：如fgets函数可以读入一个完整的行，而read要指定字节数\n\n\n\n#include \"apue.h\"intmain(void){   int       c;   while ((c = getc(stdin)) != EOF)      if (putc(c, stdout) == EOF)         err_sys(\"output error\");   if (ferror(stdin))      err_sys(\"input error\");   exit(0);}\n\nstdin和stdout也在头文件&lt;stdio.h&gt;中定义，分别代表标准输入和标准输出。\n\n\n\n文件结束符通常是ctrl-D\n\n1.6 程序和进程\n打印进程ID\n\ngetpid()函数可以得到进程ID，数据类型为pid_t，标准会保证它可以存储在长整型当中。\n#include \"apue.h\"intmain(void){   printf(\"hello world from process ID %ld\\n\", (long)getpid());   exit(0);}\n\n\n进程控制\nfgets\nfgets从标准输入一次读取一行，当键入文件结束符作为行的第一个字符时，fgets返回null指针，进程终止\nfgets返回的每一行都以换行符结尾，后接一个null字节。需要将换行符替换为null，因为execlp要求的参数是以null结束的\n\n\nfork\n用fork可以创建一个新进程，fork对于父进程返回子进程的pid，而对于子进程则返回0；\n因为fork创建一个新进程，所以它被调用一次（在父进程），但返回了两次（在父进程和子进程）\n\n\nexeclp\nexeclp用以执行从标准输入读入的命令，实际上是用新的程序文件代替了子进程原先执行的程序文件\nfork和exec两者的组合就是产生(spawn)一个新进程\n子进程调用execlp执行新程序文件，而父进程希望等待子进程终止，这就是通过调用waitpid实现的。\n\n\nwaitpid\n需要指定要等待进程的pid，返回子进程的终止状态(status变量)\n\n\n\n\n\n#include \"apue.h\"#include &lt;sys/wait.h&gt;intmain(void){   char   buf[MAXLINE];  /* from apue.h */   pid_t  pid;   int       status;   printf(\"%% \"); /* print prompt (printf requires %% to print %) */   while (fgets(buf, MAXLINE, stdin) != NULL) {      if (buf[strlen(buf) - 1] == '\\n')         buf[strlen(buf) - 1] = 0; /* replace newline with null */      if ((pid = fork()) &lt; 0) {         err_sys(\"fork error\");      } else if (pid == 0) {    /* child */         execlp(buf, buf, (char *)0);         err_ret(\"couldn't execute: %s\", buf);         exit(127);      }      /* parent */      if ((pid = waitpid(pid, &amp;status, 0)) &lt; 0)         err_sys(\"waitpid error\");      printf(\"%% \");   }   exit(0);}\n\n该命令的主要缺陷是不能向所执行的命令传递参数，如下图，需要进一步通过某种约定对行进行解析。\n\n\n\n线程与线程ID\n使用线程的好处\n有多个控制线程分别作用于问题的不同部分，解决起来就会容易得多\n多个线程可以充分利用多处理器系统的并行能力\n\n\n一个进程内的所有线程共享同一地址空间、文件描述符、栈以及进程相关的属性，所以访问共享数据时需要采取同步措施以避免不一致性\n线程也通过ID标识，但它只对它所属的进程有作用\n\n\n\n1.7 出错处理\n系统函数出错时通常会返回一个负值\nLinux出错常量在errno中定义\nC标准定义了两个函数，用于打印出错消息\nstrerror：将errno映射为一个出错消息字符串\nperror：基于errno在标准错误上产生一条出错消息\n\n\n出错恢复：\n致命性错误\n非致命性错误\n延迟一段时间，重试等方法\n\n\n\n\n\n1.8 用户标识\n用户ID：\n\n用户ID是系统用来标识不同用户的，每个用户有唯一的ID，内核通过使用用户ID来检验该用户是否有执行某些操作的权限\nID为0的用户为超级用户(root)\n\n\n组ID：\n\n被用于将若干用户集合到项目或部门中去，该机制允许同组的各个成员之间共享资源\n组文件将组名映射为组ID，通常是/etc/group\n\n\n存储用户ID和组ID仅需4字节\n\n打印用户id和组id\n\ngetuid()：用户id\ngetgid()：组id\n\n\n\n#include \"apue.h\"intmain(void){   printf(\"uid = %d, gid = %d\\n\", getuid(), getgid());   exit(0);}\n\n\n\n1.9 信号\n用户通知进程发生了某种状况，如若发生了除0错误，会将名为SIGFPE的信号发送给该进程。\n\n\n进程有以下处理信号的方式\n忽略信号\n按系统默认方式处理\n提供一个函数，信号发生时调用该函数\n\n\n终端键盘上产生信号的两种方法：\n中断键：ctrl-c\n退出键：ctrl-\\\n\n\n\n"},{"title":"PA1项目心得记录","url":"/2023/08/05/projects/general%20notes/pa1/","content":"PA1 notesSome preparations\nHow to get all things done remotely?\n\nBecause I have my linux server in my bedroom, which is far away for me to run graphic UI applications in my work place. (Obviously, commands through shell are fine).\nSo I STFW and found that mobaXterm actually support x11 forwarding, which can show the GNOME desktop. I made some configuration to realize it:\n\nchange the remote environment to Gnome desktop:\n\n\n\n\nEdit /etc/ssh/ssh_config to have the following settings\n\nForwardAgent yes\n\nForwardX11 yes\n\nForwardX11Trusted yes\n\n\n\nEdit /etc/ssh/sshd_config to have the following setting\n\nX11Forwarding yes\n\n\nset xdmcp on gdm3\n\nvim /etc/gdm3/custom.conf\n\n\n\n\n\napt install gnome-tweaks\n\nreboot. (all things done!)\n\n\n\n\n\nmulti thread compiling v.s. single thread compiling\n\nsingle thread:\n\n\n16 threads:\n\n\n\nif we don’t change any file, object files should be the same, so there is no need compiling again!\n\nBy using ccache the compiler time is longer, which is confusing\n\n\n\n\n\nHow does can Super Mario runs on the linux machine?\n\n\n\n\nfor super mario, it can’t figure out it runs on the real Red White devices or runs on the simulated “Red White devices”\n\nNEMU\nWhat is NEMU?\n\n\nNEMU is a simulated computer system. Physical computer’s essential functions is implemented by programs in NEMU.\n\n在NEMU中, 每一个硬件部件都由一个程序相关的数据对象来模拟, 例如变量, 数组, 结构体等;\n\n对这些硬件部件的操作则通过对相应数据对象的操作来模拟\n\n\nISA\nFirstly… you need to choose ISA\n\nISA is instruction set architecture, also called computer architecture, is an abstraction model of computer\nA device that execute instructions described by that ISA such as a CPU, is called an implementation.\nISA defines supported instructions, data types, registers, the hardware supporting for managing main memory, fundamental features(such as memory consistency, addressing modes, virtual memory), and the input/output model\n因此, ISA的本质就是类似这样的规范. 所以ISA的存在形式既不是硬件电路, 也不是软件代码, 而是一本规范手册.\n和螺钉螺母的生产过程类似, 计算机硬件是按照ISA规范手册构造出来的, 而程序也是按照ISA规范手册编写(或生成)出来的\nGoals至于ISA规范里面都有哪些内容, 我们应该如何构造一个符合规范的计算机, 程序应该如何遵守这些规范来在计算机上运行 is our goal.\nChapter of Creating the World\nstorage(存储器): we need some place to store our program\n\nCPU: we need someone to calculate(compute) CPU是负责处理数据的核心电路单元\n 同时天下也没有免费的午餐, 存储器的大容量也是需要付出相应的代价的, 那就是速度慢, 这是先驱也无法违背的材料特性规律\n\n如果每完成一次累加都需要把它写回存储器, 然后又把它从存储器中读出来继续加, 这样就太不方便了.先驱为CPU创造了寄存器, 可以让CPU把正在处理中的数据暂时存放在其中.\n\n\n\n\n如果没有寄存器, 计算机还可以工作吗?\n\n\nto let the CPU become the most loyal servant, pioneer designs “instructions“, to tell CPU to do what kind of operation to data\n\n能否让程序来自动控制计算机的执行?\n\n\n先驱和CPU作了一个简单的约定: 当执行完一条指令之后, 就继续执行下一条指令. \n\n但CPU怎么知道现在执行到哪一条指令呢? 为此, 先驱为CPU创造了一个特殊的计数器, 叫”程序计数器”\n\n\n从此以后, 计算机就只需要做一件事情:\nwhile (1) {  从PC指示的存储器位置取出指令;  执行指令;  更新PC;}\n\n一个足够简单的计算机:  我们只要将一段指令序列放置在存储器中, 然后让PC指向第一条指令, 计算机就会自动执行这一段指令序列, 永不停止\n一个最简单的真实计算机需要满足哪些条件:\n\n结构上, TRM有存储器, 有PC, 有寄存器, 有加法器\n工作方式上, TRM不断地重复以下过程: 从PC指示的存储器位置取出指令, 执行指令, 然后更新PC\n\n\n计算机是个状态机\n\n既然计算机是一个数组逻辑电路, 那么我们可以把计算机划分成两部分, 一部分由所有时序逻辑部件(存储器, 计数器, 寄存器)构成, 另一部分则是剩余的组合逻辑部件(如加法器等). 这样以后, 我们就可以从状态机模型的视角来理解计算机的工作过程了: 在每个时钟周期到来的时候, 计算机根据当前时序逻辑部件的状态, 在组合逻辑部件的作用下, 计算出并转移到下一时钟周期的新状态.\n\n程序是一个状态机\n\n程序是指令的集合。那么指令在状态机的模型里面是什么呢？\n所以在状态机模型里面, 指令可以看成是计算机进行一次状态转移的输入激励.\n假设某个计算机有4个8位的寄存器, 一个4位PC, 以及一段16字节的内存(也就是存储器)\n那么这个计算机可以表示比特总数为：\n4*8 + 4 + 16*8 = 164\n\n因此这个计算机总共可以有种不同的状态\n假设这个在这个计算机中, 所有指令的行为都是确定的, 那么给定N个状态中的任意一个, 其转移之后的新状态也是唯一确定的.\n\n\n\n通过状态机的视角来解释**”程序在计算机上运行”的本质**\n\n给定一个程序, 把它放到计算机的内存中, 就相当于在状态数量为N的状态转移图中指定了一个初始状态, 程序运行的过程就是从这个初始状态开始, 每执行完一条指令, 就会进行一次确定的状态转移. 也就是说, 程序也可以看成一个状态机! 这个状态机是上文提到的大状态机(状态数量为N)的子集.\n例如：1+2+…+100\n// PC: instruction    | // label: statement0: mov  r1, 0         |  pc0: r1 = 0;1: mov  r2, 0         |  pc1: r2 = 0;2: addi r2, r2, 1     |  pc2: r2 = r2 + 1;3: add  r1, r1, r2    |  pc3: r1 = r1 + r2;4: blt  r2, 100, 2    |  pc4: if (r2 &lt; 100) goto pc2;   // branch if less than5: jmp 5              |  pc5: goto pc5;\n\n的状态机转换为：\n(0,x,x) -&gt; (1,0,x)-&gt;(2,0,0)-&gt;(3,0,1)-&gt;(4,1,1)-&gt;(2,1,1)-&gt;(3,1,2)-&gt;(4,3,2)-&gt;….-&gt;(2,4851,98)-&gt;(3,4851,99)-&gt;(4,4950,99)-&gt;(2,4950,99)-&gt;(3,4950,100)-&gt;(4,5050,100)-&gt;(5,5050,100)-&gt;….\n\n以代码(或指令序列)为表现形式的静态视角\n描述精简\n分支, 循环和函数调用的组合使得我们可以通过少量代码实现出很复杂的功能. \n但这也可能会使得我们对程序行为的理解造成困难\n\n\n以状态机的状态转移为运行效果的动态视角\n直接刻画了”程序在计算机上运行”的本质\n但对于程序的局部行为, 尤其是从静态视角来看难以理解的行为, 状态机视角可以让我们清楚地了解相应的细节.\n\n\n\n 因为在PA中你需要不断地和代码打交道. 如果你不能从微观视角理解某些关键代码的行为, 你也无法从宏观视角完全弄清楚程序究竟是如何运行的.\nRTFSC在NEMU中模拟的计算机称为”客户(guest)计算机“, 在NEMU中运行的程序称为”客户程序“.\n框架代码初探ics2022├── abstract-machine   # 抽象计算机├── am-kernels         # 基于抽象计算机开发的应用程序├── fceux-am           # 红白机模拟器├── init.sh            # 初始化脚本├── Makefile           # 用于工程打包提交├── nemu               # NEMU└── README.md\n\nNEMU的四个主要模块\nmonitor\nCPU\nmemory\ndevice\n\nMonitor模块\n\n监控客户计算机的运行状态而引入的\n\n\n负责与GNU/Linux进行交互（读入客户程序）\n有调试器的功能\n\n如果没有monitor，对NEMU的调试将极为困难\nNEMU源文件组织nemu├── configs                    # 预先提供的一些配置文件├── include                    # 存放全局使用的头文件│   ├── common.h               # 公用的头文件│   ├── config                 # 配置系统生成的头文件, 用于维护配置选项更新的时间戳│   ├── cpu│   │   ├── cpu.h│   │   ├── decode.h           # 译码相关│   │   ├── difftest.h│   │   └── ifetch.h           # 取指相关│   ├── debug.h                # 一些方便调试用的宏│   ├── device                 # 设备相关│   ├── difftest-def.h│   ├── generated│   │   └── autoconf.h         # 配置系统生成的头文件, 用于根据配置信息定义相关的宏│   ├── isa.h                  # ISA相关│   ├── macro.h                # 一些方便的宏定义│   ├── memory                 # 访问内存相关│   └── utils.h├── Kconfig                    # 配置信息管理的规则├── Makefile                   # Makefile构建脚本├── README.md├── resource                   # 一些辅助资源├── scripts                    # Makefile构建脚本│   ├── build.mk│   ├── config.mk│   ├── git.mk                 # git版本控制相关│   └── native.mk├── src                        # 源文件│   ├── cpu│   │   └── cpu-exec.c         # 指令执行的主循环│   ├── device                 # 设备相关│   ├── engine│   │   └── interpreter        # 解释器的实现│   ├── filelist.mk│   ├── isa                    # ISA相关的实现│   │   ├── mips32│   │   ├── riscv32│   │   ├── riscv64│   │   └── x86│   ├── memory                 # 内存访问的实现│   ├── monitor│   │   ├── monitor.c│   │   └── sdb                # 简易调试器│   │       ├── expr.c         # 表达式求值的实现│   │       ├── sdb.c          # 简易调试器的命令处理│   │       └── watchpoint.c   # 监视点的实现│   ├── nemu-main.c            # 你知道的...│   └── utils                  # 一些公共的功能│       ├── log.c              # 日志文件相关│       ├── rand.c│       ├── state.c│       └── timer.c└── tools                      # 一些工具    ├── fixdep                 # 依赖修复, 配合配置系统进行使用    ├── gen-expr    ├── kconfig                # 配置系统    ├── kvm-diff    ├── qemu-diff    └── spike-diff\n\n\n为了支持不同的ISA, 框架代码把NEMU分成两部分: ISA无关的基本框架和ISA相关的具体实现。NEMU把ISA相关的代码专门放在nemu/src/isa/目录下, 并通过nemu/include/isa.h提供ISA相关API的声明. 这样以后, nemu/src/isa/之外的其它代码就展示了NEMU的基本框架. \n\n体现抽象的思想: 框架代码将ISA之间的差异抽象成API, 基本框架会调用这些API, 从而无需关心ISA的具体细节. 如果你将来打算选择一个不同的ISA来进行二周目的攻略, 你就能明显体会到抽象的好处了: 基本框架的代码完全不用修改!\n\nNEMU ISA相关说明文档：这里\n\n\n配置系统和项目构建配置系统kconfig\n为什么要使用配置系统？\n\n可配置选项的数量可能会非常多, 而且配置选项之间可能会存在关联。比如打开配置选项A之后, 配置选项B就必须是某个值. 直接让开发者去管理这些配置选项是很容易出错的, 比如修改选项A之后, 可能会忘记修改和选项A有关联的选项B. 配置系统的出现则是为了解决这个问题.\nNEMU中的配置系统位于nemu/tools/kconfig\nkconfig定义了一套简单的语言, 开发者可以使用这套语言来编写”配置描述文件”.\n 在”配置描述文件”中, 开发者可以描述:\n\n配置选项的属性, 包括类型, 默认值等\n不同配置选项之间的关系\n配置选项的层次关系\n\n当你键入make menuconfig的时候, 背后其实发生了如下事件:\n\n检查nemu/tools/kconfig/build/mconf程序是否存在, 若不存在, 则编译并生成mconf\n\n检查nemu/tools/kconfig/build/conf程序是否存在, 若不存在, 则编译并生成conf\n\n运行命令mconf nemu/Kconfig, 此时mconf将会解析nemu/Kconfig中的描述, 以菜单树的形式展示各种配置选项, 供开发者进行选择\n\n退出菜单时, mconf会把开发者选择的结果记录到nemu/.config文件中\n\n运行命令conf --syncconfig nemu/Kconfig, 此时conf将会解析nemu/Kconfig中的描述, 并读取选择结果nemu/.config, 结合两者来生成如下文件:\n\n可以被包含到C代码中的宏定义(nemu/include/generated/autoconf.h)\n可以被包含到Makefile中的变量定义(nemu/include/config/auto.conf)\n可以被包含到Makefile中的, 和”配置描述文件”相关的依赖规则(nemu/include/config/auto.conf.cmd), 为了阅读代码, 我们可以不必关心它\n通过时间戳来维护配置选项变化的目录树nemu/include/config/, 它会配合另一个工具nemu/tools/fixdep来使用, 用于在更新配置选项后节省不必要的文件编译, 为了阅读代码, 我们可以不必关心它。\n\n\n\n所以, 目前我们只需要关心配置系统生成的如下文件:\n\nnemu/include/generated/autoconf.h, 阅读C代码时使用\nnemu/include/config/auto.conf, 阅读Makefile时使用\n\n项目构建和Makefile与配置系统进行关联\n通过包含nemu/include/config/auto.conf, 与kconfig生成的变量进行关联. 因此在通过menuconfig更新配置选项后, Makefile的行为可能也会有所变化.\n文件列表\n通过filelist决定最终参与编译的源文件，它们会根据menuconfig的配置对如下4个变量进行维护:\n\nSRCS-y - 参与编译的源文件的候选集合\nSRCS-BLACKLIST-y - 不参与编译的源文件的黑名单集合\nDIRS-y - 参与编译的目录集合, 该目录下的所有文件都会被加入到SRCS-y中\nDIRS-BLACKLIST-y - 不参与编译的目录集合, 该目录下的所有文件都会被加入到SRCS-BLACKLIST-y中\n\nMakefile会包含项目中的所有filelist.mk文件, 对上述4个变量的追加定义进行汇总, 最终会过滤出在SRCS-y中但不在SRCS-BLACKLIST-y中的源文件, 来作为最终参与编译的源文件的集合.\n# Include all filelist.mk to merge file listsFILELIST_MK = $(shell find ./src -name \"filelist.mk\")include $(FILELIST_MK)# Filter out directories and files in blacklist to obtain the final set of source filesDIRS-BLACKLIST-y += $(DIRS-BLACKLIST)SRCS-BLACKLIST-y += $(SRCS-BLACKLIST) $(shell find $(DIRS-BLACKLIST-y) -name \"*.c\")SRCS-y += $(shell find $(DIRS-y) -name \"*.c\")SRCS = $(filter-out $(SRCS-BLACKLIST-y),$(SRCS-y))\n\n\n\n上述4个变量还可以与menuconfig的配置结果中的布尔选项进行关联, 例如DIRS-BLACKLIST-$(CONFIG_TARGET_AM) += src/monitor/sdb, 当我们在menuconfig中选择了TARGET_AM相关的布尔选项时, kconfig最终会在nemu/include/config/auto.conf中生成形如CONFIG_TARGET_AM=y的代码, 对变量进行展开后将会得到DIRS-BLACKLIST-y += src/monitor/sdb; 当我们在menuconfig中未选择TARGET_AM相关的布尔选项时, kconfig将会生成形如CONFIG_TARGET_AM=n的代码, 或者未对CONFIG_TARGET_AM进行定义, 此时将会得到DIRS-BLACKLIST-n += src/monitor/sdb, 或者DIRS-BLACKLIST- += src/monitor/sdb, 这两种情况都不会影响DIRS-BLACKLIST-y的值, 从而实现了如下效果:\n在menuconfig中选中TARGET_AM时, nemu/src/monitor/sdb目录下的所有文件都不会参与编译.\n\n编译和链接\nMakefile的编译规则在nemu/scripts/build.mk中定义:\n# Compilation patterns$(OBJ_DIR)/%.o: %.c\t@echo + CC $&lt;\t@mkdir -p $(dir $@)\t@$(CC) $(CFLAGS) -c -o $@ $&lt;\t$(call call_fixdep, $(@:.o=.d), $@)$(OBJ_DIR)/%.o: %.cc\t@echo + CXX $&lt;\t@mkdir -p $(dir $@)\t@$(CXX) $(CFLAGS) $(CXXFLAGS) -c -o $@ $&lt;\t$(call call_fixdep, $(@:.o=.d), $@)\n\n\nMakefile 中的 ^, ? 符號\n\n$@  表示目標文件$^  表示所有的依賴文件$&lt;  表示第一個依賴文件$?  表示比目標還要新的依賴文件列表\n\n\ncall_fixdep 调用用于生成更合理的依赖关系\n\n链接命令：\n$(BINARY): $(OBJS) $(ARCHIVES)\t@echo + LD $@\t@$(LD) -o $@ $(OBJS) $(LDFLAGS) $(ARCHIVES) $(LIBS)\n\n准备第一个客户程序\nNEMU is a process that execute guest process\n\nWe need to read guest process into our computer, monitor is responsible for this part.\nWhen NEMU is starting, it will first call init_monitor() to do some initialization work.(在nemu/src/monitor/monitor.c中定义) \n\nkconfig generates 宏\n\nkconfig will define some CONFIG_xxx in ‘nemu/include/generated/autoconf.h’ according to the configuration we made in kconfig.\nwe can also test these defines using conditional compiling. For example, if CONFIG_DEVICE is not defined, device related code will not be compiled.\nTo write more compact code, we define a lot of test in nemu/inlcude/generated/autoconf.h:IFDEF(CONFIG_DEVICE, init_device()); 而MUXDEF(CONFIG_TRACE, \"ON\", \"OFF\")则表示, 如果定义了CONFIG_TRACE, 则预处理结果为\"ON\"(\"OFF\"在预处理后会消失), 否则预处理结果为\"OFF\".\nvoid init_monitor(int argc, char *argv[]) {  /* Perform some global initialization. */  /* Parse arguments. */  parse_args(argc, argv);  /* Set random seed. */  init_rand();j  /* Open the log file. */  init_log(log_file);  /* Initialize memory. */  init_mem();  /* Initialize devices. */  IFDEF(CONFIG_DEVICE, init_device());  /* Perform ISA dependent initialization. */  init_isa();  /* Load the image to memory. This will overwrite the built-in image. */  long img_size = load_img();  /* Initialize differential testing. */  init_difftest(diff_so_file, img_size, difftest_port);  /* Initialize the simple debugger. */  init_sdb();  IFDEF(CONFIG_ITRACE, init_disasm(    MUXDEF(CONFIG_ISA_x86,     \"i686\",    MUXDEF(CONFIG_ISA_mips32,  \"mipsel\",    MUXDEF(CONFIG_ISA_riscv32, \"riscv32\",    MUXDEF(CONFIG_ISA_riscv64, \"riscv64\", \"bad\")))) \"-pc-linux-gnu\"  ));  /* Display welcome message. */  welcome();}\n\n\nWe can see that in the init_monitor(), all lines are  functions. And in parse_args():\n\nstatic int parse_args(int argc, char *argv[]) {  const struct option table[] = {    {\"batch\"    , no_argument      , NULL, 'b'},    {\"log\"      , required_argument, NULL, 'l'},    {\"diff\"     , required_argument, NULL, 'd'},    {\"port\"     , required_argument, NULL, 'p'},    {\"help\"     , no_argument      , NULL, 'h'},    {0          , 0                , NULL,  0 },  };  int o;  while ( (o = getopt_long(argc, argv, \"-bhl:d:p:\", table, NULL)) != -1) {    switch (o) {      case 'b': sdb_set_batch_mode(); break;      case 'p': sscanf(optarg, \"%d\", &amp;difftest_port); break;      case 'l': log_file = optarg; break;      case 'd': diff_so_file = optarg; break;      case 1: img_file = optarg; return 0;      default:        printf(\"Usage: %s [OPTION...] IMAGE [args]\\n\\n\", argv[0]);        printf(\"\\t-b,--batch              run with batch mode\\n\");        printf(\"\\t-l,--log=FILE           output log to FILE\\n\");        printf(\"\\t-d,--diff=REF_SO        run DiffTest with reference REF_SO\\n\");        printf(\"\\t-p,--port=PORT          run DiffTest with port PORT\\n\");        printf(\"\\n\");        exit(0);    }  }  return 0;}\n\n\nsome notes about getopt_long()\n\n\ngetopt_long() works like getopt() except that it also accept long options :”–”.\n\nlongopts is a pointer to the first element of an array of struct option:\n\n\nstruct option{    cosnt char *name; // name    int has_arg;// 0: no_argument; 1: required_argument; 2: optional_argument    int *flag;// NULL: getopt_long() return val; otherwise: getopt_long() return 0, flag points to a variable set to val if the option is found.    int val; // the value to return}\n\nThe last element of the array has to be filled with zeros\n接下来monitor会调用init_isa()函数(在nemu/src/isa/$ISA/init.c中定义), 来进行一些ISA相关的初始化工作.\ninit_isa()函数的第一项工作：读入客户程序到内存里\n客户程序是什么？：程序本身是ISA相关的，因此内置程序放在nemu/src/isa/$ISA/init.c中。\n内存是什么？：一段连续的地址空间，按字节编址（一个内存位置存放一个字节的数据）。 在C语言中我们就很自然地使用一个uint8_t类型的数组来对内存进行模拟。NEMU默认为客户计算机提供128MB的物理内存(见nemu/src/memory/paddr.c中定义的pmem)\n需要将客户程序读入到内存的什么位置？\n\n约定. 具体地, 我们让monitor直接把客户程序读入到一个固定的内存位置RESET_VECTOR。其值在nemu/include/memory/paddr.h中定义.\n\nBIOS和计算机启动\n\n在真实的计算机系统中, 计算机启动后首先会把控制权交给BIOS, BIOS经过一系列初始化工作之后, 再从磁盘中将有意义的程序读入内存中执行.对这个过程的模拟需要了解很多超出本课程范围的细节, 我们在PA中做了简化: 采取约定的方式让CPU直接从约定的内存位置开始执行.\n\n初探操作系统启动\n\n如何得知操作系统在启动时，做了什么？\n\n在linux中，sudo dmesg可以输出操作系统的启动日志\n\ninit_isa()函数的第二项工作：是初始化寄存器 在C语言中我们就很自然地使用相应的结构体来描述CPU的寄存器结构. \n不同ISA的寄存器结构也各不相同, 为此我们把寄存器结构体CPU_state的定义放在nemu/src/isa/$ISA/include/isa-def.h中, 并在nemu/src/cpu/cpu-exec.c中定义一个全局变量cpu.\n初始化寄存器的一个重要工作就是设置cpu.pc的初值, 我们需要将它设置成刚才加载客户程序的内存位置, 这样就可以让CPU从我们约定的内存位置开始执行客户程序了\n物理内存的起始地址\nx86的物理内存是从0开始编址的\n例如mips32和riscv32的物理地址均从0x80000000开始。因此对于上面的两个，其CONFIG_MBASE，将会被定义为：0x80000000，将来CPU访问内存时，我们会将要访问的内存地址映射到**pmem中的相应偏移位置**，这是通过nemu/src/memory/paddr.c中的guest_to_host()函数实现的.\nMonitor读入客户程序并对寄存器进行初始化后, 这时内存的布局如下:\npmem:CONFIG_MBASE      RESET_VECTOR      |                 |      v                 v      -----------------------------------------------      |                 |                  |      |                 |    guest prog    |      |                 |                  |      -----------------------------------------------                        ^                        |                       pc\n\n运行第一个客户程序main()函数包含了monitor的初始化，并且会继续调用engine_start函数。代码会进入简易调试器的主循环。\n键入c后，执行主循环cpu_exec， 它又会调用execute()。后者模拟了CPU的工作方式。它又会执行exec_once()：让CPU执行当前PC指向的一条指令，然后更新PC。\n不同的ISA有着不同的指令格式和含义, 因此执行指令的代码自然是ISA相关的. 这部分代码位于nemu/src/isa/$ISA/inst.c. 关于指令执行的详细说明需要涉及很多细节, 目前你无需关心, 我们将会在PA2中进行说明.\n何时退出指令的循环？\n\n达到要求的循环次数.\n\n客户程序执行了nemu_trap指令. 这是一条虚构的特殊指令, 它是为了在NEMU中让客户程序指示执行的结束而加入的, NEMU在ISA手册中选择了一些用于调试的指令, 并将nemu_trap的特殊含义赋予它们.\n\n 例如在riscv32的手册中, NEMU选择了ebreak指令来充当nemu_trap. 为了表示客户程序是否成功结束, nemu_trap指令还会接收一个表示结束状态的参数. 当客户程序执行了这条指令之后, NEMU将会根据这个结束状态参数来设置NEMU的结束状态, 并根据不同的状态输出不同的结束信息, 主要包括\n\nHIT GOOD TRAP - 客户程序正确地结束执行\n\nHIT BAD TRAP - 客户程序错误地结束执行\n\nABORT - 客户程序意外终止, 并未结束执行\n\n\n\n\n\n怎么读代码？\n\n有没有工具能够帮你模拟这个巨大的状态机呢? 这时我们在PA0里面提到的一个工具就派上用场了, 它就是GDB. 在GDB中, 我们可以通过单步执行的方式让程序一次执行一条指令, 相当于让状态机一次只前进一步, 这样我们就可以观察程序任意时刻的状态了! 而且状态机前进的轨迹就是程序执行的真实顺序, 于是你就可以一边运行程序一边理解程序的行为了. 这对于一些指针相关的代码有着不错的效果, 尤其是函数指针, 因为你从静态代码上很可能看不出来程序运行的时候这个指针会指向哪个函数.\nGDB还自带一个叫TUI的简单界面. 在一个高度较高的窗口中运行GDB后, 输入layout split就可以切换到TUI, 这样你就可以同时从源代码和指令的角度来观察程序的行为了. 不过为了看到源代码, 你还需要在编译NEMU时添加GDB调试信息, 具体操作见下面的提示框. 如果你想了解TUI的更多内容, STFW.\n为了帮助你更高效地RTFSC, 你最好通过RTFM和STFW多认识GDB的一些命令和操作, 比如:\n\n单步执行进入你感兴趣的函数\n单步执行跳过你不感兴趣的函数(例如库函数)\n运行到函数末尾\n打印变量或寄存器的值\n扫描内存\n查看调用栈\n设置断点\n设置监视点\n\n 为NEMU编译时添加GDB调试信息\nmenuconfig已经为大家准备好相应选项了, 你只需要打开它:\nBuild Options  [*] Enable debug information\n\n然后清除编译结果并重新编译即可. 尝试阅读相关代码, 理解开启上述menuconfig选项后会导致编译NEMU时的选项产生什么变化.\n\n\n\nggdb3指的是debug的level为3级，会输出一些额外的信息\nOg指的是优化debug体验，会减少一些优化级别，以加快编译\n\n基础设施: 简易调试器","categories":["ics2022","pa作业"],"tags":["PA","ics2022"]},{"title":"scrum软件过程基础浅析","url":"/2023/08/05/projects/general%20notes/scrum/","content":"scrum软件过程基础浅析\n就软件过程框架本身而言，scrum比较好理解，是一种迭代、循序渐进的开发方法，也明白这个框架充分重视了人作为开发主体的重要作用，即不是以文档驱动，而是故事点（代码任务或者说可演示的功能）驱动开发。但就实际而言，这个框架可能不太适合中国软件开发的“行情”，实际效果有待验证。\n\nscrum简介Scrum是一个轻量级的敏捷开发框架，是一个增量的、迭代的开发过程。其核心准则就是自我管理和迭代开发，可以最大化生产率。\nScrum特点\n\n持续的设计、开发、集成和测试\n跨职能的团队成员\nSprint期间不允许需求变更\n时间盒技术：迭代周期的期限是固定的，不延长迭代的时间\n严格定义的开发节奏\n\nScrum好处\nScrum能让每个参与者都对自己所做的工作以及自己做出的贡献感到骄傲，并让他们发挥到最佳水平。\nScrum与XP的关系\nScrum注重的是管理和组织实践，而XP关注的是实际的编程实践，两者相互兼容且相互补充，如结对编程、测试驱动开发、持续集成等XP的最佳实践仍然可以在Scrum中使用。\nscrum目标通过高透明性、检验和适应性来管理复杂性、不可预测性和变化。\nscrum框架\np.s. 354很好记\n\n\n\nscrum的3个角色scrum master\n做为团队和外部的接口，解决团队开发中的障碍,保证各个角色及职责的良好协作，保证开发过程按计划进行，组织会议，并更新燃尽图\nproduct owner\n负责提出和维护产品Backlog\nscrum team\nSCRUM团队负责在每个Sprint中将产品Backlog中的条目转化成为潜在可交付的功能增量。自组织，跨职能，一般5-9个人\nscrum的5个仪式发布计划会议\n\n只是确立大致交付日期和成本，之后每次迭代开始前均需要依据项目进展情况重新进行调整\n\n\n确立项目整体发布目标和预期结果\n\n确定产品Backlog条目、重大风险和发布所包含的全部特性和功能\n\n敏捷工作量估算：规模计量单位使用故事点，是一个相对值（区别于传统的人天估算）\n\n计算团队速度：一个迭代中团队完成的故事点总数\n计算迭代周期数：所有故事总的故事点数/团队速度\n计算项目成本：每个迭代的成本 * 迭代周期数\n\n\n根据工作量估算确立大致交付日期和费用\n\n\nSprint计划会议\n\n确定做什么\n介绍最高优先级的产品Backlog条目；选择产品Backlog条目，确定Sprint目标\n\n选多少：Sprint计划完成故事点数 = 团队速度 * 120%（120原则）\n选什么：新用户故事占70%，bugs和技术债务占30%（70/30原则）\n\n\n确定怎么做\n团队成员将产品Backlog分解为多个1天以内可以完成的任务，细分的任务构成Sprint Backlog\n\n\n每日站会\n\n这个图看起来挺有意思的，精准展现了每日站会，所以贴上。从中也可以看出，敏捷团队的规模只是5-6人左右（还有程序员真的是聪明绝顶（bushi）），中间红衣服的人最有可能是scrum master，纯属猜测。\n\n\n\n由scrum master主持，每个开发成员会被问三个问题：\n\n昨天做了什么？\n今天打算做什么？\n工作中遇到了哪些问题？\n\n前两个问题的目的是维护任务状态，哪些已完成，哪些未完成。但注意，每日站会不是进度汇报，而是Scrum成员互相的承诺；不是系统设计讨论，遇到的问题应会后解决；会议还应注意时间和效率（10-15分钟），确保 “鸡” 的角色不允许在会议上发言过长。\n\n“鸡的角色”，描述得有点形象，有可能暗示只说不做，不了解任务实现难度，滔滔不绝的人。下面的图emmm很直观\n\n\n\nSprint评审会议\n\n团队按Sprint Backlog中的条目，为产品负责人或是用户逐个地介绍结果、演示新功能。演示不是验收，目的是收集反馈\n如果产品负责人或客户想改变功能或对功能有新的想法，则添加新条目到产品Backlog中\n将还没能解决的问题加入到问题Backlog列表\n\nSprint回顾会议\n\n通过总结以往的实践经验来提高团队生产力\n\n\n以头脑风暴的方式Review Sprint过程和结果，发现和列举存在的问题\n\n参会人员投票决定需要在下个Sprint中解决的1-3个问题， 探讨解决方案，确定实践方式\n\n回顾是团队的定期自我审视（p.s. 审视这个词很妙）\n\n\nscrum的4个工件产品 Backlog\nSprintBacklog\nSprint 燃尽图\n发布燃尽图\nscrum工作流总结\n\n\n前期\n产品负责人整理业务需求，形成Product Backlog库\n\n执行\n\n以Sprint为单位迭代式地完成Sprint Backlog\n每个Sprint以Sprint Planning开始，通过每日例会跟踪进度和issue\nSprint结束时进行评审，交付可运行的产品\n\n\n后期\n\n每个Sprint完成后，通过Sprint回顾发现问题和改进点\n制定下个Sprint要引入的新的实践\n\n\n\n","categories":["软件过程"],"tags":["scrum","敏捷"]},{"url":"/2023/08/05/projects/basketball%20project/%E6%95%B0%E6%8D%AE%E9%9B%86%E8%A6%81%E6%B1%82/","content":"数据集要求球员跟踪算法\n数据集参考Market-1501\n\n\n\n\n需要1501个个体（ID）：训练集750，测试集751\n指标map\n\n\n\n总计标注32668 个bboxes\n总计有6个摄像头对各个个体进行拍摄，需要保证每个标注个体至少被两个摄像头捕获（为了跨摄像机搜索）\n需要提供2798张干扰图片：对准确率有负面影响的图片\n需要提供3819张垃圾图片：对准确率没有影响的图片\nquery图片：3368张\n\n具体参考链接：\n\n参考1\n参考2\n\n数据集格式参考：\n\n\n行为识别\n参考Kinetics 数据集\n\n\n\n\n总计标注13个类别\n每个类别标注400个剪辑片段，训练集：250，验证集：150，测试集：100\n每个剪辑片段60张图片\n\n数据集参考链接：\n\n参考1\n\n"},{"title":"linux笔记： Makefile基础","url":"/2023/08/05/unix-program/linux_foundations_notes/Makefile%E5%9F%BA%E7%A1%80/","content":"Makefile基础思想\n成百上千个源文件，按照类型，功能，模块分别放到若干个目录中，Makefile文件定义了一系列的规则来指定哪些文件需要先编译，哪些文件需要后编译\n自动化编译，一旦写好就可以整个工程完全自动编译\n\n使用规则\n规则：\n\n目标 …：依赖 …\ntab    命令\n​        …\n\n目标：最终要生成的文件\n\n依赖：生成目标所需要的文件或是目标\n\n命令：通过执行命令对依赖操作生成目标（需添加tab缩进）\n\n\n\n可以有多个规则，一般来说其他规则都是为了第一个规则服务的\n\n命令在执行之前，会先检查依赖：\n\n若依赖存在，直接执行命令；\n若不存在，看之后的规则能否生成当前规则所需的依赖，若能即正常执行；若不能则报错\n\n\n检测更新，在执行规则中的命令时，会比较目标和依赖文件的时间，不做不必要的工作\n\n若依赖的时间比目标的时间晚，则会重新生成目录；\n否则不需要更新，即对应规则中的命令不执行；\n\n\n\n\n\n\n一般来说，写的越详细，效率越高（检测更新）：\n\n\n\n\n但是上面的写得特别繁琐，可以用变量改进\n\n变量：\n\n自定义变量\n预定义变量\nCC：C编译器的名称\n$@：目标的完整名称\n$&lt;：所有的依赖文件名称\n$^：第一个依赖文件名称\n\n\n获取变量值：$(变量名)\n\n\n模式匹配：\n\n\n\n\n\n函数：\n\n$(wildcard PATTERN…)\n功能：获取指定目录下指定类型的文件列表\n实例：$(wildcard *.c ./sub/*.c)\n\n$(patsubst  , ,)\n功能：进行字符串替换\n实例：$(patsubstr %.c ,%.o, x.c bar.c)\n\n\n\nclean规则：\n\nmake clean\n伪目标：.PHONY:clean 不真实地生成clean目标文件因此一定会执行\n\n\n\n","categories":["linux"],"tags":["makefile"]},{"title":"linux笔记：静态库和动态库浅析","url":"/2023/08/05/unix-program/linux_foundations_notes/Linux%E9%9D%99%E6%80%81%E5%BA%93%E5%92%8C%E5%8A%A8%E6%80%81%E5%BA%93/","content":"linux静态库和动态库静态库和动态库的工作原理\n静态库：进行链接时，会把静态库中的代码打包到可执行文件中\n动态库：进行链接时，不会把动态库中的代码打包到可执行文件中\n\n它们的区别在于链接阶段如何处理: 静态链接方式和动态链接方式\n静态库与动态库的优缺点\n\n\n链接方式\n优点\n缺点\n\n\n\n静态库\n加载速度快,无需提供静态库,移植方便\n占多份内存,消耗系统资源,浪费内存,更新发布部署麻烦\n\n\n动态库\n进程间资源共享,更新,部署,发布简单\n加载慢,需要提供动态库\n\n\n静态库的制作和使用\n当前的目录结构如下：\n\n首先到源代码目录进行编译和汇编得到目标文件，但不进行连接：\n\n\ngcc -c *.c -I ../include/\n\n制作静态库libxxx.a:\n\nar rcs libcalc.a *.o并移到lib目录下\n注意：需提供静态库.a文件以及头文件，才可以成功对main.c进行编译\n\n 编译测试文件main.c，需指定包含头文件的路径、静态库的目录和静态库的名称\n\ngcc main.c -o app -I ./include/ -L ./lib/ -l calc\n\n运行测试文件./app ，结果如图：\n\n\n\ngcc编译选项总结\n\n\ngcc编译选项\n说明\n\n\n\n-E\n预处理指定的源文件，不进行编译\n\n\n-S\n编译指定的源文件，但是不进行汇编\n\n\n-c\n编译、汇编指定的源文件，但是不进行链接\n\n\n[file2] -o [file1]\n将文件 file2 编译成可执行文件 file1\n\n\n-I directory\n指定 include 包含文件的搜索目录\n\n\n-g\n在编译的时候，生成调试信息，该程序可以被调试器调试\n\n\n-D\n在程序编译的时候，指定一个宏\n\n\n-Wall\n生成所有警告信息\n\n\n-On\nn的取值范围：0~3。编译器的优化选项的4个级别\n\n\n-l\n在程序编译的时候，指定使用的库\n\n\n-L\n指定编译的时候，搜索的库的路径\n\n\n-fPIC/fpic\n生成与位置无关的代码\n\n\n-shared\n生成共享目标文件，通常用在建立共享库时\n\n\n动态库的制作和使用\n命名：\n\nLinux：libxxx.so\nwindows：libxxx.dll\n\n\n动态库制作：\n\n得到和位置无关的代码 -fpic\n得到动态库：gcc -shared a.o b.o -o libcalc.so\n\n\n 编译测试文件main.c：\n\n\ngcc main.c -o app -I ./include/ -L ./lib/ -l calc\n\n运行测试文件./app ，结果如图：\n\n动态库的搜索路径定位共享库（动态库）文件时，需要知道其绝对路径，此时就需要系统的动态载入器来获取该路径，并将其载入内存，它是通过ld-linux.so来完成的。搜索顺序如下：\n\n环境变量LD_LIBRARY_PATH\n\n\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:动态库所在目录；(当前会话有效)\nvim ~/.bashrc 把上面的代码拷贝到最后一行；（用户级别）\nvim /etc/profile 同理（系统级别）\n\n\n/etc/ld.so.cache\n\n需要修改/etc/ld.so.conf文件, 并运行ldconfig进行更新\n\n/lib\n\n/usr/lib\n第三种和第四种不建议，推荐前两种配置\n\n\n","categories":["linux"],"tags":["静态库和动态库","linux"]},{"title":"vhr项目：学习记录1","url":"/2023/08/05/projects/java%20project/%E4%BA%BA%E4%BA%8B%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/","content":"动态处理角色与资源的关系用户类\n实现UserDetails接口（org.springframework.security中）\n账户的锁定、密码的过期等等等接口均返回True，只处理了是否禁用账户的isEnabled()方法\nCollection&lt;? extends GrantedAuthority&gt;解释：？类型实现了Collection接口，且一定是GrantedAuthority的子类\n\nJava泛型即“参数化类型（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）\nSpringBoot web资源控制器\nHTTP请求由控制器所处理，处理对/greeting下的路由的GET请求，它返回Greeting类的新实例\n注解RestController表明该类是一个Restful控制器类\n\n","categories":["java项目"],"tags":["java web","springboot"]},{"title":"AI-EARTH学习记录","url":"/2023/08/05/projects/nlp%20project/ai-earth_with_pytorch/","content":"数据挖掘-AI-Earth项目背景\n2021 “AI Earth”人工智能创新挑战赛:链接\n\n发生在热带太平洋上的厄尔尼诺-南方涛动(ENSO)现象是地球上最强、最显著的年际气候信号。准确预测ENSO，是提高东亚和全球气候预测水平和防灾减灾的关键。\n任务基于历史气候观测和模式模拟数据，利用T时刻过去12个月(包含T时刻)的时空序列（气象因子），构建预测ENSO的深度学习模型，预测未来1-24个月的Nino3.4指数\n模型STTransformer训练学习率衰减策略\n\n训练初期学习率大一些，使得网络收敛迅速，在训练后期学习率小一些，可学习该post了解更多\n\nSTTransformer采用了Noamopt优化策略，详细可参考Annotated Transformer, Harvard NLP Group, ArdalanM/annotated-transformer，衰减公式如下所示：\n\n训练器\n包含变量：\n\n配置 config\n设备  device\n网络结构 network\n优化器 opt\n\n\noptim作用：基于梯度更新当前的参数，具体地，其step()方法可以更新所有参数（要在梯度计算出来之后调用，例：loss.backward()）\n\n注意，将model放入gpu在构建优化器之前\n\n权重 weight\n\n我们可以由下图得知，不同的月份有不同的权重，self.weight实际上是公式1.2中的，a实际上是accskill权重，预报提取时间越长，accskill权重越高\n\n\nself.weight = torch.from_numpy(np.array([1.5]*4 + [2]*7 + [3]*7 + [4]*6) * np.log(np.arange(24)+1)).to(configs.device)\n\n包含函数：\n\n得分函数score\n\n\n\n\n\n\n# 中心化pred = y_pred - y_pred.mean(dim=0, keepdim=True)  # (N, 24)true = y_true - y_true.mean(dim=0, keepdim=True)  # (N, 24)# 协方差矩阵判断相关性，值越大相关性越高cor = (pred * true).sum(dim=0) / (torch.sqrt(torch.sum(pred**2, dim=0) * torch.sum(true**2, dim=0)) + 1e-6)acc = (acc_weight * cor).sum()# rmse是所有预测月份的均方根误差rmse = torch.mean((y_pred - y_true)**2, dim=0).sqrt().sum()return 2/3. * acc - rmse\n\n\nsst损失函数\n\n在经纬度上计算均方根误差，再在样本维度上求均值，再返回所有月份的和\n# (5400+5010,26,1,24,48)rmse = torch.mean((y_pred - y_true)**2, dim=[2, 3])rmse = torch.sum(rmse.sqrt().mean(dim=0))return rmse\n\n\nnino损失函数\n\n# (5400+5010,24)with torch.no_grad():    rmse = torch.sqrt(torch.mean((y_pred - y_true)**2, dim=0)) * self.weightreturn rmse.sum()\n\n\n训练单步\n\n需要三个输入：input_sst, sst_true, nino_true, ssr_ratio，将input_sst和sst_true作为source和target送入STTransformer进行处理，输出为sst_pred, nino_pred。\n\n注：该模型虽然提供了两个Loss函数，但是只根据sst损失函数来更新梯度\n\n在计算得到梯度之后，更新参数之前，代码使用了梯度裁剪的方法来防止梯度爆炸\n\n注：梯度裁剪：如果梯度变得非常大，那么我们就调节它使其保持较小的状态\n\n\n训练单步的返回为sst损失, nino损失和nino_pred\n\n测试\n\n测试函数将测试数据数据送入网络得到了sst_pred, nino_pred，将他们存入了列表中，之后在样本维度将他们连接起来，这样的好处是损失计算是针对整个测试数据集的。\n\n推理\n\n在推理函数中使用了上面的test函数，可以直接计算损失：\nnino_true = torch.from_numpy(dataset.target_nino).float().to(self.device)sst_true = torch.from_numpy(dataset.target_sst).float().to(self.device)sc = self.score(nino_pred, nino_true)loss_sst = self.loss_sst(sst_pred, sst_true).item()loss_nino = self.loss_nino(nino_pred, nino_true).item()\n\n推理函数的返回值即为loss_sst,loss_nino,sc\n\n训练\n\n训练时首先将准备好的训练集和验证集用dataloader封装一下我们的cmip_dataset，并设定其为随机采样。将最好的score设定为负的无穷大浮点数。在每一个epoch里，更新ssr比率，调用train_once得到我们的损失和nino预测。根据nino预测和真实值我们可以得到score，它不只是在每个epoch结束后进行evaluate而是每300个batch评估一次，以免最优点被错过，因为该模型的训练时间较短。训练还设计了patience机制，若多个epoch之后score未变好就直接结束训练。\n\n保存config\n\n保存模型ConvTTLSTM\n\n训练入口main函数：\n\n\nmain做的都大同小异，首先读入数据，并划分为训练，验证和测试集，之后使用cmipdataset对训练集和测试集进行wrap，初始化训练器进行训练即可：\ntrainer = Trainer(configs)trainer.save_configs('config_train.pkl')trainer.train(dataset_train, dataset_eval, 'checkpoint.chk')\n\n模型模型结构论文设计的自注意力模块（Space-Time Attention）如下图所示，\n\n\n首先我们要定义一个SpaceTimeTransformer类，在其初始化函数中，首先保存其设置，设备，输入维度\n线性嵌入\n首先论文将clip分解为patches，用x来表示每一个patch，公式1进行了线性嵌入得到嵌入向量z，其中E和e都是可以学习的参数，e代表对每个patch的时空位置进行编码的位置嵌入向量。\n\n\n查询键值计算\n模型包含了L个编码块，在每个块中，为每一个patch的表示（由上一个块编码得到）中计算查询/键/值向量。其中LN（）代表LayerNorm；a = 1,…,A，其中A为多头注意力的数量，其中每个注意力头的隐维度数量为Dh = D/A\n\n\n自注意力计算\n自注意力权重可以按照如下的公式进行计算：\n\n\nSM（）代表softmax激活函数，自注意力仅在p(空间维度)或t(时间维度)上进行计算所以计算量被显著地降低了。\n编码过程\n第l个块的patch编码z可以通过:\n\n先计算值向量的加权和，公式如下：\n\n\n\n\n将这些向量沿HEAD维度进行连接，再传入多层感知机即可得到最终编码向量（注，在每一个操作中还使用了残差连接）：\n\n\n\n模型实现上边主要从理论方面解释了如何计算attention权重，下面从代码的角度分析如何去实现模型：\n我将encoding和decoding所做的处理进行了分析，如下图所示：\n\n\n首先代码定义了SpaceTimeTransformer类，在该类中定义了如下变量：\n\nsrc_emb\n该变量是input_embedding类的实例，用于对输入进行嵌入，所作的简而言之就是进行一个线性变换，加上位置编码和时间编码：\nassert len(x.size()) == 4 embedded_space = self.emb_space(self.spatial_pos)  # (1, S, 1, D)x = self.linear(x) + self.pe_time[:, :, :x.size(2)] + embedded_space  # (N, S, T, D)return self.norm(x)\ntgt_emb\n该变量是input_embedding类的实例，用于对输出进行嵌入。\n\nencoder\n\ndecoder\n\nlinear_output\n\n\n由 定义的变量可以看出，该模型采样了encoder-decoder框架，src即输入序列期待通过该框架生成目标序列tgt，encoder将输入句子通过非线性变换转化为中间表示，decoder根据中间表示和历史信息yi-1生成yi。\n该类的方法为前馈操作，编码方法，解码方法，生成掩膜：\n\nforward\n在forward方法中首先调用了encode方法将src和src_mask作为参数进行编码，如果处在训练过程中：为target生成mask，并将必要参数传入解码器进行解码得到了sst_pred。如果ssr_ratio&gt;1e-6，那么使用Teacher forcing生成一个teacher_forcing_mask，否则该mask为0，Teacher forcing就是直接使用实际标签作为下一个时间步的输入，由老师（ground truth）带领着防止模型越走越偏。但是老师不能总是手把手领着学生走，要逐渐放手让学生自主学习，于是我们使用Scheduled Sampling rate来控制使用实际标签的概率。在训练初期，ratio=1，模型完全由老师带领着，随着训练轮数的增加，ratio以一定的方式衰减（该方案中使用线性衰减，ratio每次减小一个衰减率decay_rate），每个时间步以ratio的概率从伯努利分布中提取二进制随机数0或1，为1时输入就是实际标签，否则输入为。再将新的tgt送入decoder进行预测得到了sst_pred。\n如果处于验证阶段，每次预测一次sst_pred并加入，之后计算nino_pred并返回。\n\nencode\n在encode方法中，使用了unfold_StackOverChannel方法将原图像分解为patches\ndef unfold_StackOverChannel(img, kernel_size):    \"\"\"    divide the original image to patches, then stack the grids in each patch along the channels    Args:        img (N, *, C, H, W): the last two dimensions must be the spatial dimension        kernel_size: tuple of length 2    Returns:        output (N, *, C*H_k*N_k, H_output, W_output)    \"\"\"    n_dim = len(img.size())    assert n_dim == 4 or n_dim == 5    pt = img.unfold(-2, size=kernel_size[0], step=kernel_size[0])    pt = pt.unfold(-2, size=kernel_size[1], step=kernel_size[1]).flatten(-2)  # (N, *, C, n0, n1, k0*k1)    if n_dim == 4:  # (N, C, H, W)        pt = pt.permute(0, 1, 4, 2, 3).flatten(1, 2)    elif n_dim == 5:  # (N, T, C, H, W)        pt = pt.permute(0, 1, 2, 5, 3, 4).flatten(2, 3)    assert pt.size(-3) == img.size(-3) * kernel_size[0] * kernel_size[1]    return pt\n\n分解为patches后，将其reshape并做一个embeding，再将编码张量送入encoder中进行处理并返回（memory）\n\ndecode\n与encode的过程类似，也需将tgt分解为patches并将其嵌入传给decoder进行解码（还有memory,mask等参数）并返回\n\ngenerate_square_subsequent_mask\n该方法为生成掩膜的方法\n\n\n实验数据处理读入数据\n\n首先使用xarray库读入数据集\n\n\n\n\n查看cmip数据集的sst变量的shape\n\n\n\n数据扁平化\n\n使用sel方法选择纬度在一定范围内的数据：\n\n\n\n这一步的主要作用在于降低空间分辨率，从而减少计算量\n\n\n分解为cmip6和cmip5并对每一个数据集进行数据变换，以cmip6为例，他只使用sst特征，一共有15个模式，每个模式151年，并将同种模式下的数据拼接起来，之后采用滑窗构造数据集（每3年采样一次，去重）：\n\n\n\n构造CMIP数据集\n\n12+26 = 38\n\n下面是我手动分析如何构造cmipdataset的过程，简要概括一下就是，cmipdataset将cmip5、cmip6连接在了一起，对于cmip5的操作，对于cmip6是同理的。下面的红色的shape主要是针对cmip6的，概括一下数据集构建的过程：\n\n将序列数据集模拟为视频数据集，设定输入帧时间间隔，输入帧长度，预测偏移和要预测的未来帧长度，具体如下图所示；\n以gap=5为采样间隔提取clips，将clips分为input_sst(长度为12)和target_sst(长度为26)，每两个输入clip之间有7个月是重复的，输出clip之间有21个帧是重复的；\n维度转换在每一步中已清晰列出，注意，为了模拟视频数据集，代码手动添加了channel维度；\n\n\n\n\n\n下图是数据集的生成结果，可以看出sst_input，sst_target，nino target均与手动推导的shape是一致的：\n\n\n\n验证集的处理类似，这里不再赘述：\n\n\n模型训练导入训练以及模型配置：\n\n单卡gpu\nbatch-size=8\nepochs=100\ngradient_clipping = False\nweight_decay=0\nd_model=256\npatience = 3\npatch_size=(2,3)\nemb_spatial_size = 12*16\nnumber of heads = 4\nnum of encoding layers = 3\nnum of decoding layers = 3\n\n\n\n\n\n模型验证将训练好的模型进行验证，先将模型的weight进行读取，将得到的模型在测试集上进行推理，最终的score分数约为33，如下图所示：\n\n\n\n\n精度优化自注意力权重修改\n计算注意力权重时，将顺序计算改为对空间和时间同时进行计算\n\n\n并将合并式注意力替代分离式注意力重新进行训练，发现效果没有提升\n结论实验证明，将时间序列数据集当作视频使用transformer进行训练是可行的，最终的score可以达到32。相较于CNN，transformer的结构更加复杂，而且自注意力的设计对于网络的性能影响很大，稍微修改一点，网络就有可能无法收敛。实验证明使用transformer去捕获长范围的时间依赖是十分有效的。\n","categories":["nlp项目"],"tags":["nlp","time-transformer","AI-EARTH"]},{"title":"跨域问题解决","url":"/2023/08/05/projects/nlp%20project/%E8%B7%A8%E5%9F%9F/","content":"跨域问题\n为什么会出现跨域\n\n同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互：即两个页面具有相同的协议（protocol），主机（host）和端口号（port）\n\n跨域案例当一个请求url的协议、域名、端口三者之间任意一个与当前页面url不同即为跨域\n\n\n\n\n当前页面url\n被请求页面url\n是否跨域\n原因\n\n\n\nhttp://www.lluozh.com/\nhttp://www.lluozh.com/index.html\n否\n同源(协议、域名、端口号相同)\n\n\n\n客户端发起的这个OPTIONS可以说是一个\"预请求\"，用于探测后续真正需要发起的跨域POST请求对于服务器来说是否是安全可接受的，因为跨域提交数据对于服务器来说可能存在很大的安全问题\n请求头Access-Control-Request-Method用于提醒服务器在接下来的请求中将会使用什么样的方法来发起请求\nAccess-Control-Allow-Method和Access-Control-Allow-Origin分别告知客户端，服务器允许客户端用于跨域的方法和域名\n\n解决\n下载flask-cors包\n\n","categories":["nlp项目"],"tags":["跨域","flask"]},{"title":"基于知识图谱的开放域问答系统","url":"/2023/08/05/projects/nlp%20project/%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%A7%88/","content":"基于知识图谱的开放域问答系统一. 项目总体介绍1. 任务目标开放域问答系统：\n使用大量不同主题的文档来回答问题，是自然语言处理（NLP）、信息检索（IR）和相关领域长期研究的主题。\n\n\n知识图谱：\n知识图谱（Knowledge Graph），是结构化的语义知识库，用于以符号形式描述物理世界中的概念及其相互关系。其基本组成单位是“实体-关系-实体”三元组，以及实体及其相关属性-值对，实体间通过关系相互联结，构成网状的知识结构。\n\n\n2. 模型整体设计及流程\n\n具体流程如下：\n\n使用NER模型从问题中抽取实体并将其送入知识库进行匹配，找出所有可能的候选关系。\n使用相似度模型计算所有候选关系与问题实体的相似度，找到可能性最大的候选关系。\n使用该候选关系在知识图谱中查找，找到最终答案。\n\n二. 模型介绍1. 命名实体识别（NER）命名实体识别( NER )是信息提取、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工具，旨在将非结构化文本中提到的命名实体定位并分类为预定义的类别，例如人姓名、组织、地点、医疗代码、时间表达、数量、货币价值、百分比等。\nBIO标注法\n将每个元素标注为“B-X”、“I-X”或者“O”。其中，“B-X”表示此元素所在的片段属于X类型并且此元素在此片段的开头，“I-X”表示此元素所在的片段属于X类型并且此元素在此片段的中间位置，“O”表示不属于任何类型，如下图所示：\n\n\nNER模型结构\n\n\n上图展示的NER模型使用Bert+BiLSTM+CRF的结构，首先使用Bert对输入的句子进行embedding,然后将这些向量输入BILSTM提取句子信息，最后输入CRF测算不同标注序列的概率，最后选取概率最大的序列作为最终结果。具体流程如下图所示。\n\n\n2. 相似度计算（SIM）模型设计\n\nKGQA子任务(关系识别)\n确定哪个关系必须被逻辑形式的特定部分使用是一项关键任务。类似于实体链接，我们需要学习映射自然语言表达到知识图谱，在该任务中是针对关系映射。\n\n阶段目标\n获得问题与知识三元组&lt;头实体，关系，尾实体&gt; 中相对应的关系。\n\n上游任务\n获得通过NER阶段识别到的头实体。\n\n下游任务\n通过头实体与SIM计算得到的关系检索尾实体（答案）。\n\n\n\n\n\n\n流程实现\n\n根据识别到的实体，通过es接口找到可能的候选关系的列表\n\n训练相似度模型进行关系预测：输入为问句和候选关系的拼接，输出为两者相似度\n\n获得问句和候选关系的相似度，以最高相似度的关系作为结果用于下游任务\n\n\n三. 数据集介绍知识库\n知识库来源于百科类数据，由百科类搜索页面的事实性三元组构成。格式为&lt;头实体，关系，尾实体&gt;\n\n\n\n\n\n实体数量\n关系数量\n高频关系(&gt;100)\n三元组数量\n\n\n\n3121457\n245838\n3833\n20559652\n\n\n问答数据集\n问答数据集为json格式，每行为一条问答对。问题是one-hop问题，即答案为知识库中的一条三元组。数据格式如下，其中id为问答对索引，quetion为问题，answer为答案，来自知识库，以’ ||| ‘分割。\n\n\n\n\nCorpus\nTrain\nDev\nTest Public\nTest Private\n\n\n\nNum Samples\n18k\n2k\n2k\n3k\n\n\nNum Relations\n2164\n1258\n1260\n423\n\n\n四. 项目设计与体验优化1. 项目设计前端项目采用前端采用uni-app框架，开发者编写一套代码，可发布到iOS、Android、Web（响应式）、以及各种小程序、快应用等多个平台。\n\n\n2. 项目设计后端项目后端采用flask框架，搭建简便快速，较其他同类型框架更为灵活、轻便、安全且容易上手；flask社区活跃，基于flask的应用插件及其丰富，足够满足后端需求，同时它也具有很好的扩展性。\n\n\n3. 体验优化意图识别\n普通的问答系统难以满足日益增长的用户需求，如果是知识库中不存在的问题或是用户的意图不够明确的话，问答系统都难以给出我们期望的回复，因此实现一个可以能够理解我们在问什么的，并能根据我们的询问以不同的方式来回复的聊天机器人是很必要的。目前的话，该项目采用的svm分类器，对预先可能的结果进行分类。作为训练数据目前主要有三类，如打招呼，百科信息询问，普通聊天。若分类为信息询问，则接入我们的问答接口，如果是普通聊天，则接入我们的聊天机器人接口。因为是手动构想用户可能的输入作为训练数据，所有难免效果不好，未来我们打算采用RASA这一更加强大的框架作为我们的意图分类器。\n聊天室\n设计聊天室的功能，是有多方面因素推动的，而非冗余的扩展。\n\n首先的目的是分不同的群组，每个群组有特定支持的机器人，即该机器人是用该领域的语料训练的，并且表现较好。\n\n二是收集特定领域的语料数据，有利于机器人把握句子的语义，持续有新的训练数据补充来对模型进行更新，有利于模型的迭代优化。\n\n\n\n\n五. 个人工作总结\n后端模型代码基于该仓库进行修改\n\n\nNER和SIM模型解耦（提取出推理部分，去掉了冗余wrapper）\n\nFlask服务器搭建及与前端交互的代码（socketio）编写加调试\n\n前端Uniapp聊天室编写及与后端交互的代码编写加调试\n\n将该项目开源到gitee仓库并进行维护\n\n\n","categories":["nlp项目"],"tags":["知识图谱","问答系统"]},{"title":"Pytorch Ligntning 轻量级框架浅析","url":"/2023/08/05/projects/kinetics%20project/Lightning/","content":"Pytorch Ligntning 轻量级框架浅析\n该文章为基于官方文档的学习总结\n\n使用该框架的优点（why not using it?）\n保持了全部的灵活性\n更可读，将工程代码和研究代码解耦\n更容易重现（reproduce）\n更易扩展，且不需要改变模型\n\n使用流程定义 LightningModuleSYSTEM VS MODEL\n\n一个lightning 模块不仅仅只是model，更是一个系统\n\n\n\n实际上lightning模块仅仅是一个torch.nn.Module模块，该模块将所有的研究代码集中到了一个文件当中，使它包含了：\n\nThe Train loop\nThe Validation loop\nThe Test loop\nThe Prediction loop\nThe Model or system of Models\nThe Optimizers and LR Schedulers\n\n通过Hooks特性，我们自定义训练的任何细节，详见：Hooks\nFORWARD vs TRAINING_STEP\nlighting推荐将训练和推理相分离\n\n使用forward进行推理或预测\n使用training_step进行训练\n\n使用Lightning Trainer来拟合数据\n首先需要定义数据集：\ndata_module = UCF101DataLoader()\n初始化lightning模块和trainer，之后调用fit进行训练：\nclassification_module = VideoClassificationLightningModule()trainer = pytorch_lightning.Trainer(gpus=[0, 1], strategy=\"ddp\", max_epochs=30,default_root_dir=\"logs_ucf101\", precision=16)trainer.fit(classification_module, data_module)\ntrainer支持多种训练功能的自动化\n\nEpoch and batch iteration\noptimizer.step(), loss.backward(), optimizer.zero_grad() calls\nCalling of model.eval(), enabling/disabling grads during evaluation\nCheckpoint Saving and Loading\nTensorboard (see loggers options)\nMulti-GPU support\nTPU\n16-bit precision AMP support\n\n\n\n基本特色自动化优化只要在train_step（）返回loss损失，lighting就会自动地帮我们反向传播，更新优化器等；对于GAN，强化学习这类涉及多个优化器的模型，我们也可以关闭自动优化自己控制：\ndef __init__(self):    self.automatic_optimization = Falsedef training_step(self, batch, batch_idx):    # access your optimizers with use_pl_optimizer=False. Default is True,    # setting use_pl_optimizer=True will maintain plugin/precision support    opt_a, opt_b = self.optimizers(use_pl_optimizer=True)    loss_a = self.generator(batch)    opt_a.zero_grad()    # use `manual_backward()` instead of `loss.backward` to automate half precision, etc...    self.manual_backward(loss_a)    opt_a.step()    loss_b = self.discriminator(batch)    opt_b.zero_grad()    self.manual_backward(loss_b)    opt_b.step()\n\n预测和部署进行预测的三种方式\n\n提取子模型：\n# ----------------------------------# to use as embedding extractor# ----------------------------------autoencoder = LitAutoEncoder.load_from_checkpoint(\"path/to/checkpoint_file.ckpt\")encoder_model = autoencoder.encoderencoder_model.eval()# ----------------------------------# to use as image generator# ----------------------------------decoder_model = autoencoder.decoderdecoder_model.eval()\n使用forward函数：\n# ----------------------------------# using the AE to extract embeddings# ----------------------------------class LitAutoEncoder(LightningModule):    def __init__(self):        super().__init__()        self.encoder = nn.Sequential(nn.Linear(28 * 28, 64))    def forward(self, x):        embedding = self.encoder(x)        return embeddingautoencoder = LitAutoEncoder()embedding = autoencoder(torch.rand(1, 28 * 28))\n生产（production）:\n\nOnnx using to_onnx() method\n\nautoencoder = LitAutoEncoder()input_sample = torch.randn((1, 28 * 28))autoencoder.to_onnx(file_path=\"model.onnx\", input_sample=input_sample, export_params=True)\n\n\nTorchScript using to_torchscript() method.\n\nautoencoder = LitAutoEncoder()autoencoder.to_torchscript(file_path=\"model.pt\")\n\n多种加速方式（accelerators）\nCPU\n# train on CPU / 什么都不设置，默认在cpu上trainer = Trainer()# train on 8 CPUstrainer = Trainer(accelerator=\"cpu\", devices=8)# train on 128 machines，8 devices per machinetrainer = pl.Trainer(accelerator=\"cpu\", devices=8, num_nodes=128)\nGPU\n# train on 1 GPUtrainer = pl.Trainer(accelerator=\"gpu\", devices=1)# train on multiple GPUs across nodes (32 GPUs here)trainer = pl.Trainer(accelerator=\"gpu\", devices=4, num_nodes=8)# train on gpu 1, 3, 5 (3 GPUs total)trainer = pl.Trainer(accelerator=\"gpu\", devices=[1, 3, 5])# Multi GPU with mixed precisiontrainer = pl.Trainer(accelerator=\"gpu\", devices=2, precision=16)\nTPU\n\nIPU\n\n\n模型checkpoint保存训练超参\nclass MyLightningModule(LightningModule):    def __init__(self, learning_rate, *args, **kwargs):        super().__init__()        self.save_hyperparameters()# all init args were saved to the checkpointcheckpoint = torch.load(CKPT_PATH)print(checkpoint[\"hyper_parameters\"])# {\"learning_rate\": the_value}\n\n使用self.save_hyperparameters()会自动保存传入init的超参数到checkpoint，可以从字典里的”hyper_parameters”键中找到超参\n恢复训练状态\nmodel = LitModel()trainer = Trainer()# automatically restores model, epoch, step, LR schedulers, apex, etc...trainer.fit(model, ckpt_path=\"some/path/to/my_checkpoint.ckpt\")\n\n恢复模型权重\nLightning 会在每个epoch结束时自动保存模型，一旦训练完成就可以按照下面的方法加载checkpoint：\nmodel = LitModel.load_from_checkpoint(path_to_saved_checkpoint)\n\n下面的是手动加载的方式，与上面的方式等价：\n# load the ckptckpt = torch.load(\"path/to/checkpoint.ckpt\")# equivalent to the abovemodel = LitModel()model.load_state_dict(ckpt[\"state_dict\"])\n\n数据流对于每一个loop（training，validation，test，predict）我们都可以实现3个hooks来自定义数据流向：\n\nx_step\nx_step_end(optional)\nx_epoch_end(optional)\n\nouts = []for batch in data:    out = training_step(batch)    out = training_step_end(out)    outs.append(out)training_epoch_end(outs)\n\n在Lightning中与之等价的方式为：\ndef training_step(self, batch, batch_idx):    prediction = ...    return predictiondef training_epoch_end(self, outs):    for out in outs:        ...\n\n如果使用dp/dpp2分布式模式，意味着每个batch的数据分散到了多个GPU中，有时我们可能需要将其集合起来进行处理，在这种情况下，可以实现training_step_end()方法来将所有devices的output进行处理来得到结果：\ndef training_step(self, batch, batch_idx):    x, y = batch    y_hat = self.model(x)    loss = F.cross_entropy(y_hat, y)    pred = ...    return {\"loss\": loss, \"pred\": pred}def training_step_end(self, batch_parts):    # predictions from each GPU    predictions = batch_parts[\"pred\"]    # losses from each GPU    losses = batch_parts[\"loss\"]    gpu_0_prediction = predictions[0]    gpu_1_prediction = predictions[1]    # do something with both outputs(average maybe)    return (losses[0] + losses[1]) / 2def training_epoch_end(self, training_step_outputs):    for out in training_step_outputs:        ...\n\n整个过程的流程（伪代码）如下，lightning将如下的细节为我们隐藏：\nouts = []for batch_idx, train_batch in enumerate(train_dataloader):    batches = split_batch(train_batch)    dp_outs = []    for sub_batch in batches:        # 1        dp_out = training_step(sub_batch, batch_idx)        dp_outs.append(dp_out)    # 2    out = training_step_end(dp_outs)    outs.append(out)# do something with the outputs for all batches# 3training_epoch_end(outs)\n\n额外扩展\nLightningDataModule\nCallbacks\nLogging\nAccelerators\nPlugins\nLoops\n\n调试\nlightning提供很多可以用来调试的工具\n\n\n限制batches数量\n# use only 10 train batches and three val batches per epochtrainer = Trainer(limit_train_batches=10, limit_val_batches=3)# use 20% of total train batches and 10% of total val batches per epochtrainer = Trainer(limit_train_batches=0.2, limit_val_batches=0.1)\n\n每个epoch随机选择较少数量的的batch来进行训练\n\n过拟合batches\n# Automatically overfit the same batches to your model for a sanity test# use only 10 train batchestrainer = Trainer(overfit_batches=10)# use only 20% of total train batchestrainer = Trainer(overfit_batches=0.2)\n\n每个epoch固定选择较少数量的的batch来进行训练\n\n快速开发运行\n# unit test all the code - hits every line of your code once to see if you have bugs,# instead of waiting hours to crash somewheretrainer = Trainer(fast_dev_run=True)# unit test all the code - hits every line of your code with four batchestrainer = Trainer(fast_dev_run=4)\n\n对所有代码进行单元测试，看是否存在bug\n\n验证检查间隔\n# run validation every 25% of a training epochtrainer = Trainer(val_check_interval=0.25)\n\n每1/4个epoch进行一次validation\n\n性能测试\n# Profile your code to find speed/memory bottlenecksTrainer(profiler=\"simple\")\n\n其他有用的特性\nAutomatic early stopping\nAutomatic truncated-back-propagation-through-time\nAutomatically scale your batch size\nAutomatically find learning rate\nLoad checkpoints directly from S3\nScale to massive compute clusters\nUse multiple dataloaders per train/val/test/predict loop\nUse multiple optimizers to do reinforcement learning or even GANs\n\n","categories":["kinetics项目"],"tags":["轻量级框架","lightning"]},{"url":"/2023/08/05/projects/kinetics%20project/code_learning/","content":""},{"title":"使用docker配置深度学习环境","url":"/2023/08/05/projects/kinetics%20project/docker%20for%20pytrorch/","content":"docker使用基础\n参考教程：\nhttps://www.runoob.com/docker/docker-container-usage.html\nhttps://blog.csdn.net/dreamhome_s/article/details/106049253\n这里默认docker已安装好\n\n1. dockers运行命令docker run --gpus all -itd --name torchtest -v $PWD -w /tmp/workplace -p 10035:22 -p 8889:8888 pytorch/pytorch:latest bash\n\nnotes:\n\n10035映射到容器的22号端口：用于SSH远程连接服务器\n\n8889映射到8888端口：用于远程访问服务器的jupyter notebook\n\n若端口号被占用，换一个未被占用的即可\n\n-v -w：将当前目录挂载到容器的workplace目录下\n\n-i: 交互式操作。\n\n-t: 终端。\n\n-d: 在后台执行\n\n\n可以将该命令写入脚本里方便持续执行，如图：\n\n\n2. docker进入命令\ndocker exec：推荐大家使用 docker exec 命令，因为此命令会退出容器终端，但不会导致容器的停止。\n\ndocker exec -it torchtest /bin/bash\n\n使用该命令可以进入终端，退出root也不会导致容器停止。\n3. 开启SSH服务\n安装SSH服务：\n\napt updateapt install openssh-serverservice ssh start\n\n\n设置容器密码：\n\n输入passwd设置密码\n\n\n修改容器配置：\n\napt install vimvim /etc/ssh/sshd_config# 在 sshd_config 文件里PermitRootLogin prohibit-password # 注释掉PermitRootLogin yes # 添加该行\n\n\n重新激活SSH服务：\n\nservice ssh restart\n\n\n在本机测试是否可以连接成功：\n\n\n\n4. docker 保存镜像\n当对环境做出了修改时，安装新的包等，我们需要对当前比较稳定的环境做一个备份。方便错误恢复或是迁移到其他机器。\n\n\n有这个需求的原因是需要在宿主机和docker容器加一个端口映射，但是我不想丢失之前对容器所做的任何变动，才有了这一步骤\n\n基础版-基于备份导出容器\nsudo docker export 1e560fca3906 &gt; ubuntu.tar\n\n导入容器\ncat docker/ubuntu.tar | sudo docker import - test/ubuntu:v1\n\n进阶版-基于版本控制更新镜像\ndocker commit -m=\"has update\" -a=\"runoob\" e218edb10161 runoob/ubuntu:v2\n\n各个参数说明：\n\n-m: 提交的描述信息\n-a: 指定镜像作者\ne218edb10161：容器 ID\nrunoob/ubuntu:v2: 指定要创建的目标镜像名\n\n可以使用 docker images 命令来查看我们的新镜像 runoob/ubuntu:v2：\n","categories":["kinetics项目"],"tags":["环境配置","docker"]},{"title":"Composer代码问题记录","url":"/2023/03/02/projects/kinetics%20project/composer/","content":"问题记录代码实现有误\ntnt_four_scales_with_ball\nleft_group_people_repre = person_feats_thisbatch_proj.flatten(0,1)[left_group_people_idx.flatten(0,1)].view(B, self.num_person_per_group, -1)  # (B, N/2, d)\n\n\n\n原代码中的方法不能正确提取数据。\n正解如下图所示：\n","categories":["群体行为识别","问题记录"],"tags":["composer","问题记录"]},{"title":"docker内配置facebook pyslowfast环境","url":"/2023/08/05/projects/kinetics%20project/installation%20of%20slowfast/","content":"facebook PySlowFast 安装环境配置并处理依赖\ndocker环境配置方法参考docker for pytorch.md\n下面是项目安装所需要的依赖，详见该仓库\n\nfvcore轻量级的核心库，提供视觉框架开发最通用和基础的功能\nFeatures:\nBesides some basic utilities, fvcore includes the following features:\n\nCommon pytorch layers, functions and losses in fvcore.nn.\nA hierarchical per-operator flop counting tool: see this note for details.\nRecursive parameter counting: see API doc.\nRecompute BatchNorm population statistics: see its API doc.\nA stateless, scale-invariant hyperparameter scheduler: see its API doc.\n\nFFmpeg用来处理多媒体内容（音频，视频，字幕）的工具库集合。 官方网站：website\n\nsth interesting: Using Git to develop FFmpeg\n\nTools\n\nffmpeg is a command line toolbox to manipulate, convert and stream multimedia content.\nffplay is a minimalistic multimedia player.\nffprobe is a simple analysis tool to inspect multimedia content.\nAdditional small tools such as aviocat, ismindex and qt-faststart.\n\nPyAV是对FFmpeg python 风格的binding，提供对下层的库提供强大的控制。PyAV 用于通过容器、流、数据包、编解码器和帧直接和精确地访问媒体。文档链接\npsutil获取运行进程和系统利用率信息的库（CPU, memory, disks, network, sensors）。文档链接\ntensorboardpytorch教程\n更详细的\nPytorch下的tensorboard可视化\nPytorch使用tensorboardX可视化\nPyTorchVideoPyTorchVideo is a deeplearning library with a focus on video understanding work. PytorchVideo provides reusable, modular and efficient components needed to accelerate the video understanding research. PyTorchVideo is developed using PyTorch and supports different deeplearning video components like video models, video datasets, and video-specific transforms.\ngetting started\nquick start\nUsing PyTorchVideo model zoo\nDetectron2https://github.com/facebookresearch/detectron2\npytorchinstall from binaries\nPyTorch is supported on Linux distributions that use glibc &gt;= v2.17\nUbuntu, minimum version 13.04\nPython 3.7 or greater\n\nbuilding from source\n install bleeding edge PyTorch code\n\npre-knowledge\nGPU 计算能力表：https://developer.nvidia.com/cuda-gpus\n\n\nCUDA是一个工具包，是NVIDIA推出的用于自家GPU上的并行计算框架。For convenience, the NVIDIA driver is installed as part of the CUDA Toolkit installation\ncuDNN是一个SDK，是一个专门用于神经网络的加速包，注意，它跟我们的CUDA没有一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般有一个最新版本的cuDNN版本与CUDA对应更好，链接地址\n\n\n\n\n\n\n数据下载与处理\nkinetics数据集下载 github:https://github.com/cvdfoundation/kinetics-dataset\n\n\n我下载的数据集为kinetics-700-2020，可参考：https://github.com/cvdfoundation/kinetics-dataset#kinetics-700-2020\n\n\n数据集下载：bash ./k700_2020_downloader.sh\n确定下载目录和数据集目录\n将训练，验证，测试数据集，标注下载到对应目录\n使用命令：wget -P 下载到指定目录 -c 断点续传 -i 下载多个文件\n\n\n数据集处理：bash ./k700_2020_extractor.sh\n分别解压训练，验证，测试数据集和标注\n使用命令 tar zxf 来解压 -C 解压到的目录\n\n\n\n\n下载数据集也可参考https://github.com/activitynet/ActivityNet/tree/master/Crawler/Kinetics，但只有k600之前的\n\n可参考该仓库进行数据集准备：https://github.com/facebookresearch/video-nonlocal-net/blob/main/DATASET.md\n\n获得类别标签映射，因为原仓库是针对k400的，所以我重新生成了映射\n\n详见data_process文件夹下的preprocess.py的generatejsonmap函数\n\n\n 使用gen_py_list.py改变文件夹名称，并对训练集和验证集生成txt列表.\n\n\n\n若gen_py_list.py中途报错，则生成的txt列表会不全，这里写了个简单的函数来进行重新生成（preprocess.py下的generatetxtlist()）。若输出与实际数据集视频数相等，则生成正确（ 即和“ls -lR /tmp/data/train | grep “^-“ | wc -l ”的结果进行比较）\n\n\n使用downscale_video_joblib.py把视频的高度缩小为256 pixels\n\n检查文件数是否匹配即可\n\n\n\n\n调整视频大小到256, 准备训练集，验证集，测试集的csv文件如 train.csv, val.csv, test.csv. 格式如下:\npath_to_video_1 label_1path_to_video_2 label_2path_to_video_3 label_3...path_to_video_N label_N\n依据txt列表生成CSV文件：\n\n\n# data_process/preprocess.py# generate_csv_file() functionwith open(\"data process/trainlist.txt\",\"r\") as file:     print(\"f\")     lines = file.readlines()     print(\"d\")     list_paths = []     list_labels = []     for line in lines:         elems = line.strip().split()         list_labels.append(int(elems[1]))         list_paths.append(videodir+elems[0])     series_paths = pd.Series(np.array(list_paths))     series_labels = pd.Series(np.array(list_labels))     d = {         \"video_path\":series_paths,         \"label\":series_labels     }     print(d)     df = pd.DataFrame(d)     df.to_csv(\"data process/train.csv\")\n\n","categories":["kinetics项目","环境安装"],"tags":["环境配置","docker","pySlowFast"]},{"title":"setuptools入门","url":"/2023/08/05/projects/kinetics%20project/setuptools/","content":"setuptools Quickstartbasics\n声明使用setuptools 来打包项目\n\n# pyproject.toml[build-system]requires = [\"setuptools\"]build-backend = \"setuptools.build_meta\"\n\n\n通过配置文件setup.py来 specify 包信息\n\nfrom setuptools import setupsetup(    name='mypackage',    version='0.0.1',    packages=['mypackage'],    install_requires=[        'requests',        'importlib-metadata; python_version == \"3.8\"',    ],)\n\n\n需要一个构建器builder\n\n# pip install buildpython -m build\n\nextensions\n自动包发现\n\nfrom setuptools import find_packages  # or find_namespace_packagessetup(    # ...    packages=find_packages(        where='.',        include=['mypackage*'],  # [\"*\"] by default        exclude=['mypackage.tests'],  # empty by default    ),    # ...)\n\n\n依赖管理\n\nsetup(    # ...    install_requires=[\"docutils\", \"requests &lt;= 0.4\"],    # ...)\n\n\n开发者模式\n\npip install --editable .\n\nexperiments\n遵循教程，实验打包流程：https://packaging.python.org/en/latest/tutorials/packaging-projects/\n\n\n","categories":["kinetics项目"],"tags":["环境配置","setuptools"]},{"title":"混合精度训练初探","url":"/2023/08/05/projects/huawei%20project/apex/","content":"自动半精度（混合精度）训练一. apex 与 ampapex是英伟达构建的一个pytorch扩展，amp为其中提供混合精度的库\n二. fp16的问题2.1 数据溢出（下溢）\n\n2.2 舍入误差\n\n三. 解决方法3.1 FP32权重备份\n\n只有更新的时候采用F32\n3.2 loss scale损失放大根据链式法则，可以通过放大loss从而放大梯度来解决舍入误差\n3.3 提高算数精度利用fp16进行乘法和存储，利用fp32来进行加法计算，来减少加法过程中的舍入误差，保证精度不损失\n四. 快速使用from apex import ampmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",loss_scale=128.0) # 这里是“欧一”，不是“零一”# loss.backward() becomes:with amp.scale_loss(loss, optimizer) as scaled_loss:    scaled_loss.backward()\n\nopt_level 优先使用O2，若无法收敛则使用O1\n如下是两个pytorch原生支持的apex混合精度和nvidia apex的loss scaler的具体实现：\nimport torchtry:    from apex import amp    has_apex = True    print(\"successfully import amp\")except ImportError:    amp = None    has_apex = False    print(\"can not import amp from apex\")class ApexScaler:    state_dict_key = \"amp\"    def __call__(self, loss, optimizer, clip_grad=None, parameters=None, create_graph=False):        with amp.scale_loss(loss, optimizer) as scaled_loss:            scaled_loss.backward(create_graph=create_graph)        if clip_grad is not None:            torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), clip_grad)        optimizer.step()    def state_dict(self):        if 'state_dict' in amp.__dict__:            return amp.state_dict()    def load_state_dict(self, state_dict):        if 'load_state_dict' in amp.__dict__:            amp.load_state_dict(state_dict)class NativeScaler:    state_dict_key = \"amp_scaler\"    def __init__(self):        # GradScaler对象用来自动做梯度缩放        self._scaler = torch.cuda.amp.GradScaler()    def __call__(self, loss, optimizer, clip_grad=None, parameters=None, create_graph=False):        self._scaler.scale(loss).backward(create_graph=create_graph)        if clip_grad is not None:            assert parameters is not None            self._scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place            torch.nn.utils.clip_grad_norm_(parameters, clip_grad)        self._scaler.step(optimizer)        self._scaler.update()    def state_dict(self):        return self._scaler.state_dict()    def load_state_dict(self, state_dict):        self._scaler.load_state_dict(state_dict)\n\napex + 分布式：\napex ddp默认使用当前设备，torch ddp需要手动指定运行的设备，用法和torch类似，\n但需注意\nmodel, optimizer = amp.initialize(model, optimizer, flags...)\n\n应在\nmodel = apex.parallel.DistributedDataParallel(model)\n\n之前\n","categories":["华为项目"],"tags":["混合精度","amp"]},{"url":"/2023/08/05/projects/huawei%20project/%E4%BA%92%E8%81%94%E7%BD%91+%E4%BA%A7%E4%B8%9A%E8%B5%9B%E9%81%93%E5%8D%8E%E4%B8%BA%E5%91%BD%E9%A2%98%E5%88%86%E5%B7%A5/","content":"互联网＋项目项目内容介绍—我们要做的是什么\n应通俗易懂，避免大量专业术语的使用\n\n包括：背景，行业诉求，项目方案，技术创新及突破点，与行业竞品的对比的差异点与技术壁垒，落地效果+落地场景，取得的成果(有数据支撑)\n命题解读我们的命题是”基于昇腾算力及CANN的创新媒体处理应用“。其中媒体指的是交通场景下的道路视频，通过对交通视频进行处理，我们可以将其应用于自动驾驶仿真系统。\n\n\n背景\n自动驾驶汽车目前存在很多事故，影响严重\n究其原因是技术存在壁垒，难以突破\n我们的研究可以用于自动驾驶离线测试或者高级辅助驾驶系统：我们基于市面上常见的仿真系统，将源码进行修改，并将我们的核心算法嵌入其中\n\n行业诉求\n我们通过行业调研得知\n\n安全性：感知前方车辆的制动行为和换道行为对于预测潜在的危险事件具有重要意义。\n而我们研究的车辆行为识别和车辆轨迹预测可以辅助路径规划和运动决策，可以有效确保自动驾驶的安全性。\n车辆行为识别在构建安全可靠的自动驾驶系统和高级辅助驾驶系统时，为了分析交通场景的动态演变并做出合理的决策，需要自动感知车辆周围其他车辆的驾驶行为。而预测驾驶行为这一点目前依然是相当有挑战性的，若能提出一个高效的算法，提高预测精度，对于自动驾驶系统的稳定性和安全性都有较大提升。例如，感知前方车辆的制动行为和换道行为对于预测潜在的危险事件具有重要意义。\n车辆轨迹预测为了确保安全，仅仅关注感知、规划和控制是不够的。高速、准确的轨迹预测对于后续的控制决策和确保自动驾驶的安全性非常重要。车辆的轨迹预测功能根据过去行驶的轨迹和周边环境如：静态交通设施和动态行驶的车辆、行走的行人等信息，预测视频中车辆未来的轨迹。这有助于构建范围更大、更为全面的智能交通系统。\n目前该领域存在的问题\n这两大部分论文里都有，可以参考\n\n车辆行为识别\n\n车辆轨迹预测\n\n项目方案\n高级辅助驾驶系统\n\n\n项目调研：简述调研流程\n项目计划：开发高级辅助驾驶系统的项目计划\n项目实施：简要介绍我们的算法如何嵌入辅助驾驶系统\n项目落地：期待的落地效果+落地场景\n\n技术创新及突破点针对上述调研的存在的问题，我们提出了对应的改进\n\n复杂场景下车辆与行人轨迹预测：改进社会池化模块\n复杂场景下车辆与行人轨迹预测：对行人朝向的方位角进行建模\n基于3DCNN的车辆行为识别：使用多流输入，并在网络中进行深度融合\n基于3DCNN的车辆行为识别：提出三维感受野增强模块\n基于3DCNN的车辆行为识别：提出通道注意力特征融合模块\n\n行业竞品的对比用于汽车工业商业目的的模拟软件\n用于车辆动力学的 CarSim、用于复杂车辆模型和交通场景的 PanoSim、用于高级驾驶辅助系统（ADAS）的 PreScan。\n如何制作PPT我的想法\n我们PPT第一遍做最好不要套模板，定下主色调之后，我们PPT的主要内容是图片和文字，我们先把这个做好。\nPPT制作要点\n\n材料准备：精炼，优势点，突破点突出，要把更多的时间投入加分项的介绍\n\n评分规则：突出长处，弱化短处，但不要有缺失：商业分析，教育维度\n\n更多思考：技术，行业，商业，社会\n\n\n任务分工每个人的任务都分成两部分：包括文档撰写＋PPT制作。下面以任务点的形式领取任务：    \n阶段性：\n\n初版日期：7/19~7/22\n\n分工：\n\n团队维度【张】\n\n命题解读【田】链接\n\n背景及意义：政策，自动驾驶，事故【张】\n\n行业诉求【田】调研，安全性和实时性\n\n目前该领域存在的问题：论文中已有【崔】\n\n项目方案\n\n调研：调研自动驾驶离线测试或者高级辅助驾驶系统【贺】\n目前提到的这些模拟软件在github上是否开源，或者有没有做类似东西的\n…\n\n\n计划【】\n实施【】【】论文实验，融合：用了哪些框架（项目整体架构：前后端分离）\n落地【崔】落地效果+落地场景（简单设想）\n\n\n技术创新及突破点【贺】\n\n商业分析：我们的软件/系统怎么可以赚钱【许】【吴】【余】（具体这块儿我不太懂，可以参考b站往年互联网+比赛视频，链接）\n\n行业竞品的对比\n优势分析\n风险分析\n市场营销\n\n\n教育维度【崔】\n\n项目符合将专业知识与产业实际问题有效结合，并转化为商业价值或社会价值\n充分体现团队解决复杂问题的综合能力和高级思维，体现项目成长对团队成员创新创业精神\n…\n\n\n\n"},{"url":"/2023/08/05/projects/huawei%20project/%E5%8D%8E%E4%B8%BA%E9%A1%B9%E7%9B%AE%EF%BC%9A%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95%E5%8F%8A%E5%A4%8D%E7%9B%98/","content":"pytorch 模型迁移复盘1遇到的问题VPN连接\n目前，该问题已解决\n\n连接华为提供的服务器需要vpn，在连vpn时遇到了一些问题：\n\nIP访问地址未设置正确\n\n\n\n需启用隧道验证功能和IPSEC安全协议，通过预设身份验证字来连接\n\n\n数据集大小\n目前，该问题已解决\n\n因为数据集较大，imagenet有近140G，直接下载会较慢，通过OBS链接进行下载会快很多。下载后对数据集解压会出现硬盘存储空间不足的问题：\n\n\n解决方法：\n直接从gpu环境上scp一份解压好的上去\nscp -r imagenet root@192.168.88.155:/opt/npu\n\nLinux scp命令用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器，而且scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。\n\n\n从本地服务器传到另一台服务器的docker容器而无需密码\nnohup scp -i /home/lyc/.ssh/id_rsa -P 10035 -r ImageNet2012/train/ root@202.117.21.93:/home/workspace/dataset/imagenet &gt; transfer_imagenet_to docker 2&gt;&amp;1 &amp;\n\n代码版本不匹配\n目前该问题已解决\n\n因为我用的代码是pytorch1.7, 其中有一些新的接口1.5不支持，因此在NPU的torch1.5环境上需要修改API使之能跑通。主要修改点是torch.cuda.amp.autocast这个接口，将torch原生的amp接口改成apex的amp接口。\nNPU环境不太好改\n目前环境未出现问题\n\n需要直接在裸机上跑，不能使用conda，因此想改变环境不太容易，目前的环境启动方法为：’’source /home/gp/test_op/setenv.sh’’。该文件的主要内容是设置一些NPU相关的环境变量。\nGPU训练僵化\n目前，该问题未解决\n\n因为是多进程训练，当只有主进程输出的时候若其他进程意外退出，会导致整个程序僵死，而且其他进程出现了什么问题难以获知。因此可以将设置改为所有卡都进行输出，这样哪个卡报错从日志就可以获知。\n如下是发现的问题：\n\n\n从日志可以发现损失变成了nan导致训练直接结束\n\n一开始以为是Loss scale过大导致loss为nan，实则发现，loss scale是在获得损失值并判断它是否为nan之后，也就是模型采用的loss函数导致了其为nan,和混合精度没有关系，目前还在想办法解决这个问题\n\n\n循环依赖\n目前，该问题已解决\n\n首先，因为想迁移到NPU的同时兼容GPU，所有在获得参数后将其保存在了主程序的函数（useNpu）中，并在之后用到cuda的地方进行判断，看从main.py中引入的useNpu是否为True，如果为真就使用适配NPU的API，否则不变。但是这样改了之后出现了循环依赖:\n\n\n原因是main中引用了datasets中的build_dataset函数，通过层层import，最终又引用回了main文件，所以又需要再次引用datasets中的build_dataset函数，因此导致了循环依赖。\n\n目前的修改方法主要有两种，将usenpu作为参数传给对应方法的默认参数，从而取代原先的import\n去掉兼容GPU的功能，这样改兼容性差，不是很合理\n\n采用第一种方法可以完美解决问题\nunicode编码错误\n目前，该问题已解决\n\n当把循环依赖改好了后，出现了UnicodeDecodeError，我怀疑是我在注释里用了中文所以导致出现了问题，但是utf-8是支持中文的而且gpu跑就没有这个问题，所以有点困惑。因为之前是在服务器上改的，没有语法错误提示，我拉到本地IDE中同步一下看看代码有没有问题。\n\n\n"},{"url":"/2023/08/05/projects/huawei%20project/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BB%BF%E7%9C%9F%E6%B5%8B%E8%AF%95%E8%B0%83%E7%A0%94/","content":"自动驾驶仿真测试系统调研调研方法我们采取了阅读自动驾驶相关论文、github开源项目搜索、官网搜索等方式，对目前市面上用于研究或商业目的的自动驾驶仿真系统进行了调研。以下是我们的调研结果：\n自动驾驶主要结构我们首先调研了自动驾驶仿真工具的整体功能模块结构，如下图所示：\n\n\n如图，自动驾驶仿真系统的主要结构包括：GUI主控，感知，决策和控制四个部分。GUI主控是展示自动驾驶算法的用户界面和仿真场景，在上面我们可以直观地检验我们所设计的算法的效果。感知是视觉算法的主阵地，通过车道线检测、标识牌检测、障碍物检测、车辆目标检测算法，我们可以估计目标与自动驾驶车辆的距离并进行决策。雷达和GPS也是进行决策的辅助信息。在决策模块，我们将通过感知得到的相关距离等数据进行利用以对未来的路径规划进行决策。控制模块根据得到的决策对车辆进行控制，以改变车辆行为。\n目前市面上用于工程商业目的的自动驾驶仿真系统包括：用于车辆动力学的 CarSim、用于复杂车辆模型和交通场景的 PanoSim、用于高级驾驶辅助系统（ADAS）的 PreScan。例如PanoSim支持自动驾驶感知/决策/规划/控制算法开发。它构建的交通场景具有一定的真实性与复杂性，适合我们在之上进行算法的开发。\n我们对项目从两个角度进行了调研：github上的开源代码和仿真平台商业软件\ngithub开源代码\nunity\n\n效果未知，因为星数极少\n\n\n自动驾驶场景的Unity仿真：链接\nAutoDriveSimulator：链接\n\n\nc++\n\n效果未知，因为星数极少\n\n\n自动驾驶模拟仿真实现：链接，程序主要模块如上图所示\n\n\npython\n\n项目可以正常演示，较合适，但需要申请仿真服务器API接口的使用权限，下面有介绍\n\n\n将算法与仿真平台相结合的开源项目：链接，运行示意图如下：\n\n\n\n\n仿真平台（不开源，需要申请使用）\nAD Chauffeur：官网\n申请得到用户名和密码：\n\n\n\n\n\n\npanosim：官网\n\n调研结果推荐使用第三种方案，即python + 仿真平台API\n"},{"title":"pytorch多进程训练","url":"/2023/08/05/projects/huawei%20project/distributed/","content":"pytorch多进程训练一. 基础知识\ngroup：进程组，默认情况下只有一个组，多进程中一个group有多个world\nworld：全局进程个数\nrank：表示进程号，用于进程间通信（值越低，优先级越高）\nlocal-rank：进程内GPU编号\n\n二. 开启分布式模式def init_distributed_mode(args):    # 函数里的每一行代码都会在每个进程上单独执行    log = [] # 记录环境信息    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:        args.rank = int(os.environ[\"RANK\"])        args.world_size = int(os.environ['WORLD_SIZE'])        args.gpu = int(os.environ['LOCAL_RANK'])        log.extend([args.rank,args.world_size,args.gpu])    elif 'SLURM_PROCID' in os.environ:        args.rank = int(os.environ['SLURM_PROCID'])        args.gpu = args.rank % torch.cuda.device_count()        log.extend([args.rank,args.gpu])    else:        print('Not using distributed mode')        args.distributed = False        return    print(f\"args.gpu:{args.gpu}\")    args.distributed = True    # 打印环境信息    print(f\"environment info: {log}\")    torch.cuda.set_device(args.gpu)    args.dist_backend = 'nccl'    print('| distributed init (rank {}): {}'.format(        args.rank, args.dist_url), flush=True)    # 分布式初始化    torch.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,                                         world_size=args.world_size, rank=args.rank)    # 同步所有进程    torch.distributed.barrier()    setup_for_distributed(args.rank == 0)\n\n","categories":["华为项目"],"tags":["分布式训练","distributed"]}]